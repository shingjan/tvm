Get devices for measurement successfully!
https://storage.cloud.google.com/octoml-aquarium-models/onnx_model_zoo/vision_classification_inception-v2.onnx
file existed. Skipping downloading.
/home/ubuntu/cache-workloads/inception-v2.onnx
Workload: inception-v2
  input_name: data_0
  input_shape: [1, 3, 224, 224]
  input_dtype: float32
==== Task 0: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_24 (weight 2 key: ["9db1fd34470fc877a2c0431d681f01a4", [1, 64, 7, 7, 16], [22, 64, 1, 1, 16, 16], [1, 22, 1, 1, 16], [1, 22, 1, 1, 16], [1, 22, 1, 1, 16], [1, 22, 7, 7, 16]]) =====
placeholder = PLACEHOLDER [1, 64, 7, 7, 16]
placeholder = PLACEHOLDER [22, 64, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 22, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 22, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 22, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 1: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_14 (weight 1 key: ["9db1fd34470fc877a2c0431d681f01a4", [1, 36, 14, 14, 16], [12, 36, 1, 1, 16, 16], [1, 12, 1, 1, 16], [1, 12, 1, 1, 16], [1, 12, 1, 1, 16], [1, 12, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 36, 14, 14, 16]
placeholder = PLACEHOLDER [12, 36, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 2: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_8 (weight 1 key: ["d85f86643f68d4261269b8274457244f", [1, 8, 28, 28, 16], [10, 8, 3, 3, 16, 16], [1, 10, 1, 1, 16], [1, 10, 1, 1, 16], [1, 10, 1, 1, 16], [1, 10, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 8, 28, 28, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 29)) && (i3 >= 1)) && (i3 < 29)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [10, 8, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), ((oh*2) + kh), ((ow*2) + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 3: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_11 (weight 1 key: ["6b0d226afab7de584e086dc68f47c79a", [1, 4, 14, 14, 16], [6, 4, 3, 3, 16, 16], [1, 6, 1, 1, 16], [1, 6, 1, 1, 16], [1, 6, 1, 1, 16], [1, 6, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 4, 14, 14, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 15)) && (i3 >= 1)) && (i3 < 15)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [6, 4, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 4: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_13 (weight 1 key: ["f6615ae9259e3b2add2908c0cd980cb6", [1, 36, 14, 14, 16], [12, 36, 1, 1, 16, 16], [1, 12, 1, 1, 16], [1, 12, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 36, 14, 14, 16]
placeholder = PLACEHOLDER [12, 36, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 5: vm_mod_fused_nn_max_pool2d (weight 1 key: ["840abcf4051ab92cd9ec49f77358d7e7", [1, 2, 112, 112, 32], [1, 2, 56, 56, 32]]) =====
placeholder = PLACEHOLDER [1, 2, 112, 112, 32]
pad_temp(ax0, ax1, ax2, ax3, ax4) = tir.if_then_else(((ax2 < 112) && (ax3 < 112)), placeholder[ax0, ax1, ax2, ax3, ax4], -3.40282e+38f)
tensor(ax0, ax1, ax2, ax3, ax4) max= pad_temp[ax0, ax1, ((ax2*2) + rv0), ((ax3*2) + rv1), ax4]

==== Task 6: vm_mod_fused_nn_max_pool2d_4 (weight 1 key: ["4c30bb331afe286230790b9cd09fe258", [1, 64, 7, 7, 16], [1, 64, 7, 7, 16]]) =====
placeholder = PLACEHOLDER [1, 64, 7, 7, 16]
pad_temp(ax0, ax1, ax2, ax3, ax4) = tir.if_then_else(((((ax2 >= 1) && (ax2 < 8)) && (ax3 >= 1)) && (ax3 < 8)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], -3.40282e+38f)
tensor(ax0, ax1, ax2, ax3, ax4) max= pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]

==== Task 7: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_14 (weight 1 key: ["ce1b4a245fb9b3a0526fcd7e77d29d3f", [1, 12, 14, 14, 16], [16, 12, 3, 3, 16, 16], [1, 16, 1, 1, 16], [1, 16, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 12, 14, 14, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 15)) && (i3 >= 1)) && (i3 < 15)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [16, 12, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 16, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 8: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 (weight 1 key: ["f6615ae9259e3b2add2908c0cd980cb6", [1, 20, 28, 28, 16], [8, 20, 1, 1, 16, 16], [1, 8, 1, 1, 16], [1, 8, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 20, 28, 28, 16]
placeholder = PLACEHOLDER [8, 20, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 9: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu (weight 1 key: ["f6615ae9259e3b2add2908c0cd980cb6", [1, 4, 56, 56, 16], [4, 4, 1, 1, 16, 16], [1, 4, 1, 1, 16], [1, 4, 56, 56, 16]]) =====
placeholder = PLACEHOLDER [1, 4, 56, 56, 16]
placeholder = PLACEHOLDER [4, 4, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 10: vm_mod_fused_nn_avg_pool2d_1 (weight 1 key: ["afaae8b373f21045eb860b447beb9f7a", [1, 16, 28, 28, 16], [1, 16, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 16, 28, 28, 16]
pad_temp(ax0, ax1, ax2, ax3, ax4) = tir.if_then_else(((((ax2 >= 1) && (ax2 < 29)) && (ax3 >= 1)) && (ax3 < 29)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)
tensor(ax0, ax1, ax2, ax3, ax4) += pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]
tensor(ax0, ax1, ax2, ax3, ax4) = (tensor[ax0, ax1, ax2, ax3, ax4]/float32(max((((min(((ax2 - 1) + 2), 27) - ((ax2 - 1) + max((0 - (ax2 - 1)), 0))) + 1)*((min(((ax3 - 1) + 2), 27) - ((ax3 - 1) + max((0 - (ax3 - 1)), 0))) + 1)), 1)))

==== Task 11: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_17 (weight 1 key: ["6b0d226afab7de584e086dc68f47c79a", [1, 8, 14, 14, 16], [10, 8, 3, 3, 16, 16], [1, 10, 1, 1, 16], [1, 10, 1, 1, 16], [1, 10, 1, 1, 16], [1, 10, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 8, 14, 14, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 15)) && (i3 >= 1)) && (i3 < 15)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [10, 8, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 12: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_16 (weight 1 key: ["f6615ae9259e3b2add2908c0cd980cb6", [1, 64, 7, 7, 16], [10, 64, 1, 1, 16, 16], [1, 10, 1, 1, 16], [1, 10, 7, 7, 16]]) =====
placeholder = PLACEHOLDER [1, 64, 7, 7, 16]
placeholder = PLACEHOLDER [10, 64, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 13: vm_mod_fused_nn_max_pool2d_1 (weight 1 key: ["840abcf4051ab92cd9ec49f77358d7e7", [1, 12, 56, 56, 16], [1, 12, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 12, 56, 56, 16]
pad_temp(ax0, ax1, ax2, ax3, ax4) = tir.if_then_else(((ax2 < 56) && (ax3 < 56)), placeholder[ax0, ax1, ax2, ax3, ax4], -3.40282e+38f)
tensor(ax0, ax1, ax2, ax3, ax4) max= pad_temp[ax0, ax1, ((ax2*2) + rv0), ((ax3*2) + rv1), ax4]

==== Task 14: vm_mod_fused_nn_avg_pool2d_2 (weight 4 key: ["50e10b057da3b7c5b1a3d4b1e0473794", [1, 36, 14, 14, 16], [1, 36, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 36, 14, 14, 16]
pad_temp(ax0, ax1, ax2, ax3, ax4) = tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)
tensor(ax0, ax1, ax2, ax3, ax4) += pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]
tensor(ax0, ax1, ax2, ax3, ax4) = (tensor[ax0, ax1, ax2, ax3, ax4]/float32(max((((min(((ax2 - 1) + 2), 13) - ((ax2 - 1) + max((0 - (ax2 - 1)), 0))) + 1)*((min(((ax3 - 1) + 2), 13) - ((ax3 - 1) + max((0 - (ax3 - 1)), 0))) + 1)), 1)))

==== Task 15: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_17 (weight 1 key: ["ce1b4a245fb9b3a0526fcd7e77d29d3f", [1, 10, 7, 7, 16], [14, 10, 3, 3, 16, 16], [1, 14, 1, 1, 16], [1, 14, 7, 7, 16]]) =====
placeholder = PLACEHOLDER [1, 10, 7, 7, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 8)) && (i3 >= 1)) && (i3 < 8)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [14, 10, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 14, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 16: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 (weight 2 key: ["ce1b4a245fb9b3a0526fcd7e77d29d3f", [1, 6, 14, 14, 16], [8, 6, 3, 3, 16, 16], [1, 8, 1, 1, 16], [1, 8, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 6, 14, 14, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 15)) && (i3 >= 1)) && (i3 < 15)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [8, 6, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 17: vm_mod_fused_nn_max_pool2d_3 (weight 1 key: ["840abcf4051ab92cd9ec49f77358d7e7", [1, 36, 14, 14, 16], [1, 36, 7, 7, 16]]) =====
placeholder = PLACEHOLDER [1, 36, 14, 14, 16]
pad_temp(ax0, ax1, ax2, ax3, ax4) = tir.if_then_else(((ax2 < 14) && (ax3 < 14)), placeholder[ax0, ax1, ax2, ax3, ax4], -3.40282e+38f)
tensor(ax0, ax1, ax2, ax3, ax4) max= pad_temp[ax0, ax1, ((ax2*2) + rv0), ((ax3*2) + rv1), ax4]

==== Task 18: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu (weight 1 key: ["5ed464b35716e41a42d30187d80b5975", [1, 1, 224, 224, 3], [2, 1, 7, 7, 3, 32], [1, 2, 1, 1, 32], [1, 2, 1, 1, 32], [1, 2, 1, 1, 32], [1, 2, 112, 112, 32]]) =====
placeholder = PLACEHOLDER [1, 1, 224, 224, 3]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 3) && (i2 < 227)) && (i3 >= 3)) && (i3 < 227)), placeholder[i0, i1, (i2 - 3), (i3 - 3), i4], 0f)
placeholder = PLACEHOLDER [2, 1, 7, 7, 3, 32]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 3), ((oh*2) + kh), ((ow*2) + kw), floormod(ic, 3)]*placeholder[oc_chunk, floordiv(ic, 3), kh, kw, floormod(ic, 3), oc_block])
placeholder = PLACEHOLDER [1, 2, 1, 1, 32]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 2, 1, 1, 32]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 2, 1, 1, 32]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 19: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_19 (weight 3 key: ["9db1fd34470fc877a2c0431d681f01a4", [1, 36, 14, 14, 16], [6, 36, 1, 1, 16, 16], [1, 6, 1, 1, 16], [1, 6, 1, 1, 16], [1, 6, 1, 1, 16], [1, 6, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 36, 14, 14, 16]
placeholder = PLACEHOLDER [6, 36, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 20: vm_mod_fused_nn_softmax (weight 1 key: ["d7b65649a4dd54becea0a52aabbc5af5", [1, 1000], [1, 1000]]) =====
placeholder = PLACEHOLDER [1, 1000]
T_softmax_maxelem(i0) max= placeholder[i0, k]
T_softmax_exp(i0, i1) = tir.exp((placeholder[i0, i1] - T_softmax_maxelem[i0]))
T_softmax_expsum(i0) += T_softmax_exp[i0, k]
T_softmax_norm(i0, i1) = (T_softmax_exp[i0, i1]/T_softmax_expsum[i0])

==== Task 21: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_25 (weight 2 key: ["6b0d226afab7de584e086dc68f47c79a", [1, 12, 7, 7, 16], [20, 12, 3, 3, 16, 16], [1, 20, 1, 1, 16], [1, 20, 1, 1, 16], [1, 20, 1, 1, 16], [1, 20, 7, 7, 16]]) =====
placeholder = PLACEHOLDER [1, 12, 7, 7, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 8)) && (i3 >= 1)) && (i3 < 8)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [20, 12, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 20, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 20, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 20, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 22: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_16 (weight 1 key: ["9db1fd34470fc877a2c0431d681f01a4", [1, 36, 14, 14, 16], [10, 36, 1, 1, 16, 16], [1, 10, 1, 1, 16], [1, 10, 1, 1, 16], [1, 10, 1, 1, 16], [1, 10, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 36, 14, 14, 16]
placeholder = PLACEHOLDER [10, 36, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 23: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 (weight 2 key: ["f6615ae9259e3b2add2908c0cd980cb6", [1, 12, 28, 28, 16], [4, 12, 1, 1, 16, 16], [1, 4, 1, 1, 16], [1, 4, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 12, 28, 28, 16]
placeholder = PLACEHOLDER [4, 12, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 24: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11 (weight 1 key: ["f6615ae9259e3b2add2908c0cd980cb6", [1, 36, 14, 14, 16], [10, 36, 1, 1, 16, 16], [1, 10, 1, 1, 16], [1, 10, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 36, 14, 14, 16]
placeholder = PLACEHOLDER [10, 36, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 25: vm_mod_fused_nn_max_pool2d_2 (weight 1 key: ["840abcf4051ab92cd9ec49f77358d7e7", [1, 20, 28, 28, 16], [1, 20, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 20, 28, 28, 16]
pad_temp(ax0, ax1, ax2, ax3, ax4) = tir.if_then_else(((ax2 < 28) && (ax3 < 28)), placeholder[ax0, ax1, ax2, ax3, ax4], -3.40282e+38f)
tensor(ax0, ax1, ax2, ax3, ax4) max= pad_temp[ax0, ax1, ((ax2*2) + rv0), ((ax3*2) + rv1), ax4]

==== Task 26: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18 (weight 1 key: ["ce1b4a245fb9b3a0526fcd7e77d29d3f", [1, 12, 7, 7, 16], [14, 12, 3, 3, 16, 16], [1, 14, 1, 1, 16], [1, 14, 7, 7, 16]]) =====
placeholder = PLACEHOLDER [1, 12, 7, 7, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 8)) && (i3 >= 1)) && (i3 < 8)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [14, 12, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 14, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 27: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_4 (weight 2 key: ["6b0d226afab7de584e086dc68f47c79a", [1, 6, 28, 28, 16], [6, 6, 3, 3, 16, 16], [1, 6, 1, 1, 16], [1, 6, 1, 1, 16], [1, 6, 1, 1, 16], [1, 6, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 6, 28, 28, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 29)) && (i3 >= 1)) && (i3 < 29)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [6, 6, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 28: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_2 (weight 1 key: ["9db1fd34470fc877a2c0431d681f01a4", [1, 12, 28, 28, 16], [4, 12, 1, 1, 16, 16], [1, 4, 1, 1, 16], [1, 4, 1, 1, 16], [1, 4, 1, 1, 16], [1, 4, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 12, 28, 28, 16]
placeholder = PLACEHOLDER [4, 12, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 29: vm_mod_fused_nn_avg_pool2d_3 (weight 1 key: ["720f4ce2919e6f5776d2f884eaae37a7", [1, 64, 7, 7, 16], [1, 64, 7, 7, 16]]) =====
placeholder = PLACEHOLDER [1, 64, 7, 7, 16]
pad_temp(ax0, ax1, ax2, ax3, ax4) = tir.if_then_else(((((ax2 >= 1) && (ax2 < 8)) && (ax3 >= 1)) && (ax3 < 8)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)
tensor(ax0, ax1, ax2, ax3, ax4) += pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]
tensor(ax0, ax1, ax2, ax3, ax4) = (tensor[ax0, ax1, ax2, ax3, ax4]/float32(max((((min(((ax2 - 1) + 2), 6) - ((ax2 - 1) + max((0 - (ax2 - 1)), 0))) + 1)*((min(((ax3 - 1) + 2), 6) - ((ax3 - 1) + max((0 - (ax3 - 1)), 0))) + 1)), 1)))

==== Task 30: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_9 (weight 4 key: ["f6615ae9259e3b2add2908c0cd980cb6", [1, 36, 14, 14, 16], [8, 36, 1, 1, 16, 16], [1, 8, 1, 1, 16], [1, 8, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 36, 14, 14, 16]
placeholder = PLACEHOLDER [8, 36, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 31: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_12 (weight 1 key: ["ce1b4a245fb9b3a0526fcd7e77d29d3f", [1, 10, 14, 14, 16], [12, 10, 3, 3, 16, 16], [1, 12, 1, 1, 16], [1, 12, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 10, 14, 14, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 15)) && (i3 >= 1)) && (i3 < 15)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [12, 10, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 32: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_21 (weight 1 key: ["6b0d226afab7de584e086dc68f47c79a", [1, 12, 14, 14, 16], [12, 12, 3, 3, 16, 16], [1, 12, 1, 1, 16], [1, 12, 1, 1, 16], [1, 12, 1, 1, 16], [1, 12, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 12, 14, 14, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 15)) && (i3 >= 1)) && (i3 < 15)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [12, 12, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 33: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_15 (weight 1 key: ["6b0d226afab7de584e086dc68f47c79a", [1, 6, 14, 14, 16], [8, 6, 3, 3, 16, 16], [1, 8, 1, 1, 16], [1, 8, 1, 1, 16], [1, 8, 1, 1, 16], [1, 8, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 6, 14, 14, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 15)) && (i3 >= 1)) && (i3 < 15)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [8, 6, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 34: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_5 (weight 1 key: ["9db1fd34470fc877a2c0431d681f01a4", [1, 12, 28, 28, 16], [2, 12, 1, 1, 16, 16], [1, 2, 1, 1, 16], [1, 2, 1, 1, 16], [1, 2, 1, 1, 16], [1, 2, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 12, 28, 28, 16]
placeholder = PLACEHOLDER [2, 12, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 2, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 2, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 2, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 35: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 (weight 3 key: ["f6615ae9259e3b2add2908c0cd980cb6", [1, 36, 14, 14, 16], [6, 36, 1, 1, 16, 16], [1, 6, 1, 1, 16], [1, 6, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 36, 14, 14, 16]
placeholder = PLACEHOLDER [6, 36, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 36: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_7 (weight 1 key: ["6b0d226afab7de584e086dc68f47c79a", [1, 4, 28, 28, 16], [6, 4, 3, 3, 16, 16], [1, 6, 1, 1, 16], [1, 6, 1, 1, 16], [1, 6, 1, 1, 16], [1, 6, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 4, 28, 28, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 29)) && (i3 >= 1)) && (i3 < 29)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [6, 4, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 37: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_1 (weight 1 key: ["6b0d226afab7de584e086dc68f47c79a", [1, 4, 56, 56, 16], [12, 4, 3, 3, 16, 16], [1, 12, 1, 1, 16], [1, 12, 1, 1, 16], [1, 12, 1, 1, 16], [1, 12, 56, 56, 16]]) =====
placeholder = PLACEHOLDER [1, 4, 56, 56, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 57)) && (i3 >= 1)) && (i3 < 57)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [12, 4, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 38: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_10 (weight 1 key: ["9db1fd34470fc877a2c0431d681f01a4", [1, 36, 14, 14, 16], [14, 36, 1, 1, 16, 16], [1, 14, 1, 1, 16], [1, 14, 1, 1, 16], [1, 14, 1, 1, 16], [1, 14, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 36, 14, 14, 16]
placeholder = PLACEHOLDER [14, 36, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 14, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 14, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 14, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 39: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 (weight 1 key: ["f6615ae9259e3b2add2908c0cd980cb6", [1, 36, 14, 14, 16], [4, 36, 1, 1, 16, 16], [1, 4, 1, 1, 16], [1, 4, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 36, 14, 14, 16]
placeholder = PLACEHOLDER [4, 36, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 40: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 (weight 3 key: ["ce1b4a245fb9b3a0526fcd7e77d29d3f", [1, 4, 28, 28, 16], [6, 4, 3, 3, 16, 16], [1, 6, 1, 1, 16], [1, 6, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 4, 28, 28, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 29)) && (i3 >= 1)) && (i3 < 29)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [6, 4, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 41: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_12 (weight 2 key: ["6b0d226afab7de584e086dc68f47c79a", [1, 8, 14, 14, 16], [8, 8, 3, 3, 16, 16], [1, 8, 1, 1, 16], [1, 8, 1, 1, 16], [1, 8, 1, 1, 16], [1, 8, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 8, 14, 14, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 15)) && (i3 >= 1)) && (i3 < 15)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [8, 8, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 42: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_23 (weight 1 key: ["d85f86643f68d4261269b8274457244f", [1, 16, 14, 14, 16], [16, 16, 3, 3, 16, 16], [1, 16, 1, 1, 16], [1, 16, 1, 1, 16], [1, 16, 1, 1, 16], [1, 16, 7, 7, 16]]) =====
placeholder = PLACEHOLDER [1, 16, 14, 14, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 15)) && (i3 >= 1)) && (i3 < 15)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [16, 16, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), ((oh*2) + kh), ((ow*2) + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 16, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 16, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 16, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 43: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_27 (weight 2 key: ["9db1fd34470fc877a2c0431d681f01a4", [1, 64, 7, 7, 16], [8, 64, 1, 1, 16, 16], [1, 8, 1, 1, 16], [1, 8, 1, 1, 16], [1, 8, 1, 1, 16], [1, 8, 7, 7, 16]]) =====
placeholder = PLACEHOLDER [1, 64, 7, 7, 16]
placeholder = PLACEHOLDER [8, 64, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 44: vm_mod_fused_nn_avg_pool2d_4 (weight 1 key: ["712badddce997fd3a780b8d35d27ba51", [1, 64, 7, 7, 16], [1, 64, 1, 1, 16]]) =====
placeholder = PLACEHOLDER [1, 64, 7, 7, 16]
tensor(ax0, ax1, ax2, ax3, ax4) += placeholder[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]
tensor(ax0, ax1, ax2, ax3, ax4) = (tensor[ax0, ax1, ax2, ax3, ax4]/float32(max((((min((ax2 + 6), 6) - (ax2 + max((0 - ax2), 0))) + 1)*((min((ax3 + 6), 6) - (ax3 + max((0 - ax3), 0))) + 1)), 1)))

==== Task 45: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15 (weight 3 key: ["f6615ae9259e3b2add2908c0cd980cb6", [1, 64, 7, 7, 16], [12, 64, 1, 1, 16, 16], [1, 12, 1, 1, 16], [1, 12, 7, 7, 16]]) =====
placeholder = PLACEHOLDER [1, 64, 7, 7, 16]
placeholder = PLACEHOLDER [12, 64, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 46: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_20 (weight 1 key: ["6b0d226afab7de584e086dc68f47c79a", [1, 8, 14, 14, 16], [12, 8, 3, 3, 16, 16], [1, 12, 1, 1, 16], [1, 12, 1, 1, 16], [1, 12, 1, 1, 16], [1, 12, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 8, 14, 14, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 15)) && (i3 >= 1)) && (i3 < 15)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [12, 8, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 47: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_13 (weight 2 key: ["9db1fd34470fc877a2c0431d681f01a4", [1, 36, 14, 14, 16], [8, 36, 1, 1, 16, 16], [1, 8, 1, 1, 16], [1, 8, 1, 1, 16], [1, 8, 1, 1, 16], [1, 8, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 36, 14, 14, 16]
placeholder = PLACEHOLDER [8, 36, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 48: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_3 (weight 1 key: ["6b0d226afab7de584e086dc68f47c79a", [1, 4, 28, 28, 16], [4, 4, 3, 3, 16, 16], [1, 4, 1, 1, 16], [1, 4, 1, 1, 16], [1, 4, 1, 1, 16], [1, 4, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 4, 28, 28, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 29)) && (i3 >= 1)) && (i3 < 29)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [4, 4, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 49: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_26 (weight 2 key: ["6b0d226afab7de584e086dc68f47c79a", [1, 14, 7, 7, 16], [14, 14, 3, 3, 16, 16], [1, 14, 1, 1, 16], [1, 14, 1, 1, 16], [1, 14, 1, 1, 16], [1, 14, 7, 7, 16]]) =====
placeholder = PLACEHOLDER [1, 14, 7, 7, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 8)) && (i3 >= 1)) && (i3 < 8)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [14, 14, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 14, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 14, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 14, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 50: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_22 (weight 1 key: ["d85f86643f68d4261269b8274457244f", [1, 8, 14, 14, 16], [12, 8, 3, 3, 16, 16], [1, 12, 1, 1, 16], [1, 12, 1, 1, 16], [1, 12, 1, 1, 16], [1, 12, 7, 7, 16]]) =====
placeholder = PLACEHOLDER [1, 8, 14, 14, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 15)) && (i3 >= 1)) && (i3 < 15)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [12, 8, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), ((oh*2) + kh), ((ow*2) + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
==== Task 51: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_18 (weight 1 key: ["6b0d226afab7de584e086dc68f47c79a", [1, 10, 14, 14, 16], [10, 10, 3, 3, 16, 16], [1, 10, 1, 1, 16], [1, 10, 1, 1, 16], [1, 10, 1, 1, 16], [1, 10, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 10, 14, 14, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 15)) && (i3 >= 1)) && (i3 < 15)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [10, 10, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 52: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 (weight 1 key: ["f6615ae9259e3b2add2908c0cd980cb6", [1, 20, 28, 28, 16], [4, 20, 1, 1, 16, 16], [1, 4, 1, 1, 16], [1, 4, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 20, 28, 28, 16]
placeholder = PLACEHOLDER [4, 20, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 53: vm_mod_fused_nn_dense_add (weight 1 key: ["7d44c6e3c81cd80f61ff2265b2bae89a", [1, 1024], [1000, 1024], [1, 1000], [1, 1000]]) =====
placeholder = PLACEHOLDER [1, 1024]
placeholder = PLACEHOLDER [1000, 1024]
T_matmul_NT(i, j) += (placeholder[i, k]*placeholder[j, k])
placeholder = PLACEHOLDER [1, 1000]
T_add(ax0, ax1) = (T_matmul_NT[ax0, ax1] + placeholder[ax0, ax1])

==== Task 54: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10 (weight 1 key: ["ce1b4a245fb9b3a0526fcd7e77d29d3f", [1, 8, 14, 14, 16], [10, 8, 3, 3, 16, 16], [1, 10, 1, 1, 16], [1, 10, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 8, 14, 14, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 15)) && (i3 >= 1)) && (i3 < 15)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [10, 8, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 55: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 (weight 2 key: ["f6615ae9259e3b2add2908c0cd980cb6", [1, 16, 28, 28, 16], [4, 16, 1, 1, 16, 16], [1, 4, 1, 1, 16], [1, 4, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 16, 28, 28, 16]
placeholder = PLACEHOLDER [4, 16, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 56: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_6 (weight 2 key: ["9db1fd34470fc877a2c0431d681f01a4", [1, 16, 28, 28, 16], [4, 16, 1, 1, 16, 16], [1, 4, 1, 1, 16], [1, 4, 1, 1, 16], [1, 4, 1, 1, 16], [1, 4, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 16, 28, 28, 16]
placeholder = PLACEHOLDER [4, 16, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 57: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_9 (weight 1 key: ["d85f86643f68d4261269b8274457244f", [1, 6, 28, 28, 16], [6, 6, 3, 3, 16, 16], [1, 6, 1, 1, 16], [1, 6, 1, 1, 16], [1, 6, 1, 1, 16], [1, 6, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 6, 28, 28, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 29)) && (i3 >= 1)) && (i3 < 29)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [6, 6, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), ((oh*2) + kh), ((ow*2) + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 58: vm_mod_fused_nn_avg_pool2d (weight 1 key: ["afaae8b373f21045eb860b447beb9f7a", [1, 12, 28, 28, 16], [1, 12, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 12, 28, 28, 16]
pad_temp(ax0, ax1, ax2, ax3, ax4) = tir.if_then_else(((((ax2 >= 1) && (ax2 < 29)) && (ax3 >= 1)) && (ax3 < 29)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)
tensor(ax0, ax1, ax2, ax3, ax4) += pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]
tensor(ax0, ax1, ax2, ax3, ax4) = (tensor[ax0, ax1, ax2, ax3, ax4]/float32(max((((min(((ax2 - 1) + 2), 27) - ((ax2 - 1) + max((0 - (ax2 - 1)), 0))) + 1)*((min(((ax3 - 1) + 2), 27) - ((ax3 - 1) + max((0 - (ax3 - 1)), 0))) + 1)), 1)))

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |            - |              - |      0 |
|    1 |            - |              - |      0 |
|    2 |            - |              - |      0 |
|    3 |            - |              - |      0 |
|    4 |            - |              - |      0 |
|    5 |            - |              - |      0 |
|    6 |            - |              - |      0 |
|    7 |            - |              - |      0 |
|    8 |            - |              - |      0 |
|    9 |            - |              - |      0 |
|   10 |            - |              - |      0 |
|   11 |            - |              - |      0 |
|   12 |            - |              - |      0 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1935	fail_ct: 19	Time elapsed: 1.26
GA Iter: 0	Max score: 0.9997	Min score: 0.9289	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9997	Min score: 0.9870	#Pop: 128	#M+: 1383	#M-: 78
EvolutionarySearch		#s: 128	Time elapsed: 3.07
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.92 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
/home/ubuntu/anaconda3/lib/python3.9/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html
  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)
Time elapsed for training: 4.15 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 2003	fail_ct: 0	Time elapsed: 1.35
GA Iter: 0	Max score: 0.9995	Min score: 0.9261	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9878	#Pop: 128	#M+: 1379	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 4.97
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.24 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 5.63 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 0	Used time : 1 s	Next ID: 0	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |            - |              - |      0 |
|    2 |            - |              - |      0 |
|    3 |            - |              - |      0 |
|    4 |            - |              - |      0 |
|    5 |            - |              - |      0 |
|    6 |            - |              - |      0 |
|    7 |            - |              - |      0 |
|    8 |            - |              - |      0 |
|    9 |            - |              - |      0 |
|   10 |            - |              - |      0 |
|   11 |            - |              - |      0 |
|   12 |            - |              - |      0 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 64	Used time : 22 s	Next ID: 1	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |            - |              - |      0 |
|    3 |            - |              - |      0 |
|    4 |            - |              - |      0 |
|    5 |            - |              - |      0 |
|    6 |            - |              - |      0 |
|    7 |            - |              - |      0 |
|    8 |            - |              - |      0 |
|    9 |            - |              - |      0 |
|   10 |            - |              - |      0 |
|   11 |            - |              - |      0 |
|   12 |            - |              - |      0 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1754	fail_ct: 0	Time elapsed: 1.03
GA Iter: 0	Max score: 0.9990	Min score: 0.9199	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9868	#Pop: 128	#M+: 1393	#M-: 29
EvolutionarySearch		#s: 128	Time elapsed: 6.14
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................Estimated total latency: - ms	Trials: 128	Used time : 46 s	Next ID: 2	
.T***************************************************************Time elapsed for measurement: 24.77 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.79 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1715	fail_ct: 0	Time elapsed: 1.92
GA Iter: 0	Max score: 1.0000	Min score: 0.9293	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9881	#Pop: 128	#M+: 1383	#M-: 33
EvolutionarySearch		#s: 128	Time elapsed: 7.22
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 20.79 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 13.14 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 2003	fail_ct: 0	Time elapsed: 0.70
GA Iter: 0	Max score: 0.9993	Min score: 0.9272	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9998	Min score: 0.9850	#Pop: 128	#M+: 1382	#M-: 78
EvolutionarySearch		#s: 128	Time elapsed: 3.17
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 21.43 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 7.43 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |            - |              - |      0 |
|    4 |            - |              - |      0 |
|    5 |            - |              - |      0 |
|    6 |            - |              - |      0 |
|    7 |            - |              - |      0 |
|    8 |            - |              - |      0 |
|    9 |            - |              - |      0 |
|   10 |            - |              - |      0 |
|   11 |            - |              - |      0 |
|   12 |            - |              - |      0 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 192	Used time : 81 s	Next ID: 3	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |            - |              - |      0 |
|    5 |            - |              - |      0 |
|    6 |            - |              - |      0 |
|    7 |            - |              - |      0 |
|    8 |            - |              - |      0 |
|    9 |            - |              - |      0 |
|   10 |            - |              - |      0 |
|   11 |            - |              - |      0 |
|   12 |            - |              - |      0 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 256	Used time : 125 s	Next ID: 4	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |            - |              - |      0 |
|    6 |            - |              - |      0 |
|    7 |            - |              - |      0 |
|    8 |            - |              - |      0 |
|    9 |            - |              - |      0 |
|   10 |            - |              - |      0 |
|   11 |            - |              - |      0 |
|   12 |            - |              - |      0 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Iter: 5	#Pop: 32	#Target: 50	fail_ct: 9468	Time elapsed: 2.41
#Target has been reduced to 25 due to too many failures or duplications
Sample Initial Population	#s: 32	fail_ct: 11378	Time elapsed: 2.94
GA Iter: 0	Max score: 0.9738	Min score: 0.0086	#Pop: 32	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9972	Min score: 0.0206	#Pop: 128	#M+: 363	#M-: 6790
EvolutionarySearch		#s: 128	Time elapsed: 2.48
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 17.97 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 5.11 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Iter: 5	#Pop: 32	#Target: 50	fail_ct: 9508	Time elapsed: 2.51
#Target has been reduced to 25 due to too many failures or duplications
Sample Initial Population	#s: 32	fail_ct: 11405	Time elapsed: 3.06
GA Iter: 0	Max score: 0.9915	Min score: 0.0248	#Pop: 32	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9915	Min score: 0.0048	#Pop: 111	#M+: 357	#M-: 6883
EvolutionarySearch		#s: 111	Time elapsed: 2.19
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.18 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 7.72 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1639	fail_ct: 125	Time elapsed: 0.89
GA Iter: 0	Max score: 0.9988	Min score: 0.9245	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9997	Min score: 0.9866	#Pop: 128	#M+: 1375	#M-: 28
EvolutionarySearch		#s: 128	Time elapsed: 5.08
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 22.34 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 9.69 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 320	Used time : 157 s	Next ID: 5	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |            - |              - |      0 |
|    7 |            - |              - |      0 |
|    8 |            - |              - |      0 |
|    9 |            - |              - |      0 |
|   10 |            - |              - |      0 |
|   11 |            - |              - |      0 |
|   12 |            - |              - |      0 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 384	Used time : 186 s	Next ID: 6	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |            - |              - |      0 |
|    8 |            - |              - |      0 |
|    9 |            - |              - |      0 |
|   10 |            - |              - |      0 |
|   11 |            - |              - |      0 |
|   12 |            - |              - |      0 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 448	Used time : 214 s	Next ID: 7	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 2015	fail_ct: 0	Time elapsed: 0.79
GA Iter: 0	Max score: 0.9999	Min score: 0.9304	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9845	#Pop: 128	#M+: 1380	#M-: 78
EvolutionarySearch		#s: 128	Time elapsed: 3.78
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 18.72 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 10.05 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 2022	fail_ct: 0	Time elapsed: 1.44
GA Iter: 0	Max score: 0.9997	Min score: 0.9276	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9862	#Pop: 128	#M+: 1380	#M-: 78
EvolutionarySearch		#s: 128	Time elapsed: 3.89
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................|    7 |        0.157 |        1108.53 |     64 |
|    8 |            - |              - |      0 |
|    9 |            - |              - |      0 |
|   10 |            - |              - |      0 |
|   11 |            - |              - |      0 |
|   12 |            - |              - |      0 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 512	Used time : 252 s	Next ID: 8	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |            - |              - |      0 |
|   10 |            - |              - |      0 |
|   11 |            - |              - |      0 |
|   12 |            - |              - |      0 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 576	Used time : 286 s	Next ID: 9	
.T***************************************************************Time elapsed for measurement: 25.91 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.72 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 153	fail_ct: 1621	Time elapsed: 1.01
GA Iter: 0	Max score: 0.9988	Min score: 0.1960	#Pop: 128	#M+: 0	#M-: 0
[14:53:55] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
for ax1 (0,16)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,28)
    for ax3 (0,28)
      for ax0 (None)
        for ax1 (None)
          for ax2 (None)
            for ax3 (None)
              vectorize ax4 (None)
                pad_temp = ...
      for ax4 (0,16)
        tensor = ...

with: [14:53:55] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 29)) && (ax3 >= 1)) && (ax3 < 29)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=16)), iter_var(ax2, range(min=0, ext=30)), iter_var(ax3, range(min=0, ext=30)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=16)), iter_var(ax2, range(min=0, ext=28)), iter_var(ax3, range(min=0, ext=28)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.9993	Min score: 0.9517	#Pop: 128	#M+: 423	#M-: 6502
EvolutionarySearch		#s: 128	Time elapsed: 4.05
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.69 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 14.37 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1739	fail_ct: 0	Time elapsed: 0.96
GA Iter: 0	Max score: 0.9995	Min score: 0.9272	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9998	Min score: 0.9874	#Pop: 128	#M+: 1382	#M-: 36
EvolutionarySearch		#s: 128	Time elapsed: 5.37
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 19.43 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 12.68 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |            - |              - |      0 |
|   11 |            - |              - |      0 |
|   12 |            - |              - |      0 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 640	Used time : 321 s	Next ID: 10	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |            - |              - |      0 |
|   12 |            - |              - |      0 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 704	Used time : 353 s	Next ID: 11	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |            - |              - |      0 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1946	fail_ct: 13	Time elapsed: 0.99
GA Iter: 0	Max score: 0.9999	Min score: 0.9387	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9858	#Pop: 128	#M+: 1370	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 4.21
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.97 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 6.05 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Iter: 5	#Pop: 32	#Target: 50	fail_ct: 9481	Time elapsed: 2.10
#Target has been reduced to 25 due to too many failures or duplications
Sample Initial Population	#s: 32	fail_ct: 11380	Time elapsed: 2.55
GA Iter: 0	Max score: 0.9750	Min score: 0.0233	#Pop: 32	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9924	Min score: 0.0014	#Pop: 119	#M+: 378	#M-: 6823
EvolutionarySearch		#s: 119	Time elapsed: 2.00
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 10.41 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.19 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 155	fail_ct: 1640	Time elapsed: 1.02
GA Iter: 0	Max score: 0.9956	Min score: 0.2262	#Pop: 128	#M+: 0	#M-: 0
[14:55:49] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ (None)
  for ax1 (None)
    for ax2 (None)
      tensor auto_unroll: 512
      for ax0 (None)
        for ax1 (None)
          for ax2 (None)
            for ax3 (None)
              for ax4 (None)
                for rv0 (None)
                  for rv1 (None)
                    tensor = ...
      for ax3 (None)
        for ax0 (None)
          for ax1 (None)
            for ax2 (None)
              for ax3 (None)
                vectorize ax4 (None)
                  pad_temp = ...
        for ax4 (None)
          tensor = ...

with: [14:55:49] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[14:55:51] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
for ax1 (0,36)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax3 (0,14)
      for ax0 (None)
        for ax1 (None)
          for ax2 (None)
            for ax3 (None)
              vectorize ax4 (None)
                pad_temp = ...
      for ax4 (0,16)
        tensor = ...

with: [14:55:51] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.9999	Min score: 0.9495	#Pop: 128	#M+: 411	#M-: 6584
EvolutionarySearch		#s: 128	Time elapsed: 2.55
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 11.77 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 9.16 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 768	Used time : 392 s	Next ID: 12	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 832	Used time : 417 s	Next ID: 13	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 896	Used time : 436 s	Next ID: 14	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1493	fail_ct: 140	Time elapsed: 1.25
GA Iter: 0	Max score: 0.9995	Min score: 0.9117	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9864	#Pop: 128	#M+: 1390	#M-: 33
EvolutionarySearch		#s: 128	Time elapsed: 6.68
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.52 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.20 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1603	fail_ct: 144	Time elapsed: 1.09
GA Iter: 0	Max score: 0.9995	Min score: 0.9230	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9877	#Pop: 128	#M+: 1397	#M-: 30
EvolutionarySearch		#s: 128	Time elapsed: 4.64
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 24.68 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 12.32 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 960	Used time : 461 s	Next ID: 15	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1024	Used time : 487 s	Next ID: 16	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Iter: 5	#Pop: 32	#Target: 50	fail_ct: 9482	Time elapsed: 1.83
#Target has been reduced to 25 due to too many failures or duplications
Sample Initial Population	#s: 32	fail_ct: 11400	Time elapsed: 2.20
GA Iter: 0	Max score: 0.9918	Min score: 0.0037	#Pop: 32	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9956	Min score: 0.0037	#Pop: 121	#M+: 347	#M-: 6867
EvolutionarySearch		#s: 121	Time elapsed: 1.46
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 9.32 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 20.63 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1767	fail_ct: 0	Time elapsed: 1.38
GA Iter: 0	Max score: 0.9996	Min score: 0.9280	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9882	#Pop: 128	#M+: 1373	#M-: 33
EvolutionarySearch		#s: 128	Time elapsed: 6.72
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1088	Used time : 530 s	Next ID: 17	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1152	Used time : 563 s	Next ID: 18	
.T***************************************************************Time elapsed for measurement: 21.49 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 6.41 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1992	fail_ct: 2	Time elapsed: 1.12
GA Iter: 0	Max score: 0.9999	Min score: 0.9380	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9878	#Pop: 128	#M+: 1385	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 5.42
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 17.72 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 19.63 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 9
Sample Initial Population	#s: 1165	fail_ct: 111	Time elapsed: 0.41
GA Iter: 0	Max score: 0.9998	Min score: 0.8820	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9856	#Pop: 128	#M+: 1372	#M-: 113
EvolutionarySearch		#s: 128	Time elapsed: 2.72
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.51 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 13.95 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1216	Used time : 599 s	Next ID: 19	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1280	Used time : 643 s	Next ID: 20	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1545	fail_ct: 129	Time elapsed: 0.94
GA Iter: 0	Max score: 0.9992	Min score: 0.9016	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9858	#Pop: 128	#M+: 1389	#M-: 31
EvolutionarySearch		#s: 128	Time elapsed: 4.97
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 17.82 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 10.22 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1980	fail_ct: 0	Time elapsed: 0.94
GA Iter: 0	Max score: 0.9992	Min score: 0.9258	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9866	#Pop: 128	#M+: 1389	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 5.05
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 23.23 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 15.94 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 2001	fail_ct: 0	Time elapsed: 1.04
GA Iter: 0	Max score: 0.9997	Min score: 0.9331	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9998	Min score: 0.9866	#Pop: 128	#M+: 1384	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 3.42
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.52 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 11.76 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1344	Used time : 673 s	Next ID: 21	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1408	Used time : 707 s	Next ID: 22	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1472	Used time : 753 s	Next ID: 23	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1991	fail_ct: 0	Time elapsed: 0.75
GA Iter: 0	Max score: 0.9993	Min score: 0.9437	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9883	#Pop: 128	#M+: 1367	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 4.25
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.45 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 22.07 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Iter: 5	#Pop: 32	#Target: 50	fail_ct: 9486	Time elapsed: 3.30
#Target has been reduced to 25 due to too many failures or duplications
Sample Initial Population	#s: 32	fail_ct: 11391	Time elapsed: 3.94
GA Iter: 0	Max score: 0.9571	Min score: 0.0355	#Pop: 32	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9894	Min score: 0.0297	#Pop: 114	#M+: 362	#M-: 6861
EvolutionarySearch		#s: 114	Time elapsed: 2.20
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.66 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 11.35 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1536	Used time : 782 s	Next ID: 24	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1600	Used time : 823 s	Next ID: 25	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1506	fail_ct: 138	Time elapsed: 1.23
GA Iter: 0	Max score: 0.9991	Min score: 0.9141	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9994	Min score: 0.9858	#Pop: 128	#M+: 1389	#M-: 36
EvolutionarySearch		#s: 128	Time elapsed: 4.33
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.89 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.57 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1634	fail_ct: 145	Time elapsed: 1.43
GA Iter: 0	Max score: 1.0000	Min score: 0.9246	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9869	#Pop: 128	#M+: 1379	#M-: 31
EvolutionarySearch		#s: 128	Time elapsed: 7.65
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1664	Used time : 855 s	Next ID: 26	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1728	Used time : 881 s	Next ID: 27	
.T***************************************************************Time elapsed for measurement: 28.49 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 8.33 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 2009	fail_ct: 1	Time elapsed: 0.98
GA Iter: 0	Max score: 0.9999	Min score: 0.9394	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9880	#Pop: 128	#M+: 1389	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 6.58
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
..............................................................
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1792	Used time : 927 s	Next ID: 28	
.T.T**************************************************************Time elapsed for measurement: 26.79 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 10.59 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 158	fail_ct: 1639	Time elapsed: 1.29
GA Iter: 0	Max score: 0.9996	Min score: 0.2742	#Pop: 128	#M+: 0	#M-: 0
[15:04:48] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
for ax1 (0,64)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,7)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,7)
      vectorize ax4 (0,16)
        tensor = ...

with: [15:04:48] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 8)) && (ax3 >= 1)) && (ax3 < 8)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=64)), iter_var(ax2, range(min=0, ext=9)), iter_var(ax3, range(min=0, ext=9)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=64)), iter_var(ax2, range(min=0, ext=7)), iter_var(ax3, range(min=0, ext=7)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.9996	Min score: 0.9534	#Pop: 128	#M+: 410	#M-: 6587
EvolutionarySearch		#s: 128	Time elapsed: 6.14
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.76 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 19.94 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1998	fail_ct: 1	Time elapsed: 1.55
GA Iter: 0	Max score: 0.9996	Min score: 0.9367	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9996	Min score: 0.9868	#Pop: 128	#M+: 1372	#M-: 80
EvolutionarySearch		#s: 128	Time elapsed: 6.14
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1856	Used time : 972 s	Next ID: 29	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1920	Used time : 1016 s	Next ID: 30	
.T***************************************************************Time elapsed for measurement: 24.80 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 9.81 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1620	fail_ct: 159	Time elapsed: 1.31
GA Iter: 0	Max score: 0.9982	Min score: 0.9275	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9872	#Pop: 128	#M+: 1393	#M-: 37
EvolutionarySearch		#s: 128	Time elapsed: 10.36
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1984	Used time : 1059 s	Next ID: 31	
.T***************************************************************Time elapsed for measurement: 25.80 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 14.50 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1625	fail_ct: 137	Time elapsed: 2.43
GA Iter: 0	Max score: 0.9993	Min score: 0.9134	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9869	#Pop: 128	#M+: 1383	#M-: 36
EvolutionarySearch		#s: 128	Time elapsed: 8.02
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
..............................................................
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2048	Used time : 1111 s	Next ID: 32	
.T.T**************************************************************Time elapsed for measurement: 27.33 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 14.55 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1599	fail_ct: 147	Time elapsed: 2.45
GA Iter: 0	Max score: 0.9998	Min score: 0.9311	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9878	#Pop: 128	#M+: 1380	#M-: 31
EvolutionarySearch		#s: 128	Time elapsed: 7.86
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 18.08 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 14.32 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 2001	fail_ct: 1	Time elapsed: 1.48
GA Iter: 0	Max score: 0.9998	Min score: 0.9386	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9866	#Pop: 128	#M+: 1382	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 7.96
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 20.52 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 12.72 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2112	Used time : 1164 s	Next ID: 33	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2176	Used time : 1207 s	Next ID: 34	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1996	fail_ct: 0	Time elapsed: 0.77
GA Iter: 0	Max score: 0.9999	Min score: 0.9400	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9880	#Pop: 128	#M+: 1384	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 3.98
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................|   34 |        0.014 |         708.74 |     64 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2240	Used time : 1250 s	Next ID: 35	
.T***************************************************************Time elapsed for measurement: 24.75 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 10.98 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1750	fail_ct: 0	Time elapsed: 3.18
GA Iter: 0	Max score: 0.9994	Min score: 0.9391	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9869	#Pop: 128	#M+: 1377	#M-: 34
EvolutionarySearch		#s: 128	Time elapsed: 7.66
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2304	Used time : 1291 s	Next ID: 36	
.T***************************************************************Time elapsed for measurement: 30.33 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 21.05 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1817	fail_ct: 0	Time elapsed: 1.26
GA Iter: 0	Max score: 0.9998	Min score: 0.9249	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9876	#Pop: 128	#M+: 1390	#M-: 34
EvolutionarySearch		#s: 128	Time elapsed: 6.57
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
..............................................................
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2368	Used time : 1353 s	Next ID: 37	
.T.T**************************************************************Time elapsed for measurement: 30.68 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 19.73 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1990	fail_ct: 0	Time elapsed: 1.06
GA Iter: 0	Max score: 0.9986	Min score: 0.9325	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9875	#Pop: 128	#M+: 1381	#M-: 68
EvolutionarySearch		#s: 128	Time elapsed: 6.21
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 27.84 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 20.49 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 2001	fail_ct: 1	Time elapsed: 1.86
GA Iter: 0	Max score: 1.0000	Min score: 0.9258	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9871	#Pop: 128	#M+: 1378	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 6.32
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 22.05 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 11.83 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.628 |        1108.87 |     64 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2432	Used time : 1412 s	Next ID: 38	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.628 |        1108.87 |     64 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2496	Used time : 1467 s	Next ID: 39	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1737	fail_ct: 0	Time elapsed: 1.86
GA Iter: 0	Max score: 1.0000	Min score: 0.9298	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9862	#Pop: 128	#M+: 1390	#M-: 35
EvolutionarySearch		#s: 128	Time elapsed: 9.21
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.628 |        1108.87 |     64 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2560	Used time : 1510 s	Next ID: 40	
.T***************************************************************Time elapsed for measurement: 27.36 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 20.49 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1722	fail_ct: 0	Time elapsed: 1.09
GA Iter: 0	Max score: 0.9998	Min score: 0.9160	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9878	#Pop: 128	#M+: 1387	#M-: 36
EvolutionarySearch		#s: 128	Time elapsed: 5.78
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 22.28 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 11.89 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1727	fail_ct: 0	Time elapsed: 1.42
GA Iter: 0	Max score: 0.9964	Min score: 0.9308	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9996	Min score: 0.9872	#Pop: 128	#M+: 1381	#M-: 36
EvolutionarySearch		#s: 128	Time elapsed: 7.04
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 22.80 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 20.18 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.628 |        1108.87 |     64 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.063 |        1383.36 |     64 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2624	Used time : 1569 s	Next ID: 41	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.628 |        1108.87 |     64 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.063 |        1383.36 |     64 |
|   41 |        0.099 |         587.15 |     64 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2688	Used time : 1610 s	Next ID: 42	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1940	fail_ct: 18	Time elapsed: 1.22
GA Iter: 0	Max score: 0.9999	Min score: 0.9340	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9868	#Pop: 128	#M+: 1381	#M-: 82
EvolutionarySearch		#s: 128	Time elapsed: 5.83
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.628 |        1108.87 |     64 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.063 |        1383.36 |     64 |
|   41 |        0.099 |         587.15 |     64 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2752	Used time : 1662 s	Next ID: 43	
.T***************************************************************Time elapsed for measurement: 23.86 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 10.92 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 746	fail_ct: 1087	Time elapsed: 0.87
GA Iter: 0	Max score: 0.9992	Min score: 0.8324	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9873	#Pop: 128	#M+: 1390	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 4.11
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.94 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 14.21 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1946	fail_ct: 12	Time elapsed: 1.32
GA Iter: 0	Max score: 0.9999	Min score: 0.9385	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9868	#Pop: 128	#M+: 1374	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 6.44
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 26.46 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 19.19 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.628 |        1108.87 |     64 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.063 |        1383.36 |     64 |
|   41 |        0.099 |         587.15 |     64 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2816	Used time : 1704 s	Next ID: 44	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.628 |        1108.87 |     64 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.063 |        1383.36 |     64 |
|   41 |        0.099 |         587.15 |     64 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |            - |              - |      0 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2880	Used time : 1738 s	Next ID: 45	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1803	fail_ct: 0	Time elapsed: 1.35
GA Iter: 0	Max score: 0.9995	Min score: 0.9275	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9877	#Pop: 128	#M+: 1380	#M-: 35
EvolutionarySearch		#s: 128	Time elapsed: 10.27
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
.............................................................|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.628 |        1108.87 |     64 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.063 |        1383.36 |     64 |
|   41 |        0.099 |         587.15 |     64 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |            - |              - |      0 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2944	Used time : 1792 s	Next ID: 46	
.T.T.T*************************************************************Time elapsed for measurement: 24.23 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 15.23 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1994	fail_ct: 1	Time elapsed: 1.63
GA Iter: 0	Max score: 0.9981	Min score: 0.9406	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9886	#Pop: 128	#M+: 1375	#M-: 64
EvolutionarySearch		#s: 128	Time elapsed: 6.30
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
.............................................................
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.628 |        1108.87 |     64 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.063 |        1383.36 |     64 |
|   41 |        0.099 |         587.15 |     64 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.126 |         689.37 |     64 |
|   47 |            - |              - |      0 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 3008	Used time : 1844 s	Next ID: 47	
.T..T**************************************************************Time elapsed for measurement: 24.30 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 25.93 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1767	fail_ct: 0	Time elapsed: 1.96
GA Iter: 0	Max score: 0.9998	Min score: 0.9288	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9998	Min score: 0.9873	#Pop: 128	#M+: 1395	#M-: 28
EvolutionarySearch		#s: 128	Time elapsed: 9.63
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 22.59 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 21.08 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1509	fail_ct: 143	Time elapsed: 1.53
GA Iter: 0	Max score: 0.9989	Min score: 0.9062	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9997	Min score: 0.9855	#Pop: 128	#M+: 1368	#M-: 33
EvolutionarySearch		#s: 128	Time elapsed: 7.80
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.628 |        1108.87 |     64 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.063 |        1383.36 |     64 |
|   41 |        0.099 |         587.15 |     64 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.126 |         689.37 |     64 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |            - |              - |      0 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 3072	Used time : 1902 s	Next ID: 48	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.628 |        1108.87 |     64 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.063 |        1383.36 |     64 |
|   41 |        0.099 |         587.15 |     64 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.126 |         689.37 |     64 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |            - |              - |      0 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 3136	Used time : 1958 s	Next ID: 49	
.T***************************************************************Time elapsed for measurement: 25.55 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 27.15 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1676	fail_ct: 0	Time elapsed: 2.49
GA Iter: 0	Max score: 0.9995	Min score: 0.9195	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9858	#Pop: 128	#M+: 1382	#M-: 34
EvolutionarySearch		#s: 128	Time elapsed: 8.78
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 22.39 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 7.49 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1612	fail_ct: 133	Time elapsed: 1.37
GA Iter: 0	Max score: 0.9988	Min score: 0.9193	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9994	Min score: 0.9857	#Pop: 128	#M+: 1399	#M-: 30
EvolutionarySearch		#s: 128	Time elapsed: 11.94
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 25.66 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 16.35 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.628 |        1108.87 |     64 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.063 |        1383.36 |     64 |
|   41 |        0.099 |         587.15 |     64 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.126 |         689.37 |     64 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.097 |         457.79 |     64 |
|   50 |            - |              - |      0 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 3200	Used time : 2020 s	Next ID: 50	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.628 |        1108.87 |     64 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.063 |        1383.36 |     64 |
|   41 |        0.099 |         587.15 |     64 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.126 |         689.37 |     64 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.097 |         457.79 |     64 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |            - |              - |      0 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 3264	Used time : 2061 s	Next ID: 51	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 2013	fail_ct: 0	Time elapsed: 1.17
GA Iter: 0	Max score: 0.9983	Min score: 0.9410	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9998	Min score: 0.9878	#Pop: 128	#M+: 1376	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 7.78
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
..............................................................|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.628 |        1108.87 |     64 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.063 |        1383.36 |     64 |
|   41 |        0.099 |         587.15 |     64 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.126 |         689.37 |     64 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.097 |         457.79 |     64 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.146 |         621.07 |     64 |
|   52 |            - |              - |      0 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 3328	Used time : 2117 s	Next ID: 52	
.T.T**************************************************************Time elapsed for measurement: 24.77 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 27.62 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1610	fail_ct: 271	Time elapsed: 0.90
GA Iter: 0	Max score: 0.9997	Min score: 0.9283	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9998	Min score: 0.9889	#Pop: 128	#M+: 1389	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 4.63
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 17.12 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 14.59 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1703	fail_ct: 0	Time elapsed: 1.13
GA Iter: 0	Max score: 1.0000	Min score: 0.9293	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9888	#Pop: 128	#M+: 1385	#M-: 35
EvolutionarySearch		#s: 128	Time elapsed: 6.00
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.628 |        1108.87 |     64 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.063 |        1383.36 |     64 |
|   41 |        0.099 |         587.15 |     64 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.126 |         689.37 |     64 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.097 |         457.79 |     64 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.146 |         621.07 |     64 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |            - |              - |      0 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 3392	Used time : 2179 s	Next ID: 53	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.628 |        1108.87 |     64 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.063 |        1383.36 |     64 |
|   41 |        0.099 |         587.15 |     64 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.126 |         689.37 |     64 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.097 |         457.79 |     64 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.146 |         621.07 |     64 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |            - |              - |      0 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 3456	Used time : 2216 s	Next ID: 54	
.T***************************************************************Time elapsed for measurement: 26.04 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 30.57 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 2013	fail_ct: 0	Time elapsed: 1.62
GA Iter: 0	Max score: 0.9991	Min score: 0.9380	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9887	#Pop: 128	#M+: 1377	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 7.25
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
..............................................................
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.628 |        1108.87 |     64 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.063 |        1383.36 |     64 |
|   41 |        0.099 |         587.15 |     64 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.126 |         689.37 |     64 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.097 |         457.79 |     64 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.146 |         621.07 |     64 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |            - |              - |      0 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 3520	Used time : 2280 s	Next ID: 55	
.T.T**************************************************************Time elapsed for measurement: 22.12 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 24.53 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 2003	fail_ct: 3	Time elapsed: 2.41
GA Iter: 0	Max score: 0.9997	Min score: 0.9441	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9853	#Pop: 128	#M+: 1374	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 6.36
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.628 |        1108.87 |     64 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.063 |        1383.36 |     64 |
|   41 |        0.099 |         587.15 |     64 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.126 |         689.37 |     64 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.097 |         457.79 |     64 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.146 |         621.07 |     64 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |            - |              - |      0 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 3584	Used time : 2336 s	Next ID: 56	
.T***************************************************************Time elapsed for measurement: 30.48 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 25.17 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1585	fail_ct: 133	Time elapsed: 2.61
GA Iter: 0	Max score: 0.9999	Min score: 0.9289	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9873	#Pop: 128	#M+: 1397	#M-: 29
EvolutionarySearch		#s: 128	Time elapsed: 10.27
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.628 |        1108.87 |     64 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.063 |        1383.36 |     64 |
|   41 |        0.099 |         587.15 |     64 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.126 |         689.37 |     64 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.097 |         457.79 |     64 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.146 |         621.07 |     64 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |            - |              - |      0 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 3648	Used time : 2401 s	Next ID: 57	
.T***************************************************************Time elapsed for measurement: 23.75 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 10.02 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 156	fail_ct: 1654	Time elapsed: 1.35
GA Iter: 0	Max score: 0.9996	Min score: 0.1695	#Pop: 128	#M+: 0	#M-: 0
[15:29:24] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
for ax1 (0,12)
  for ax2 (0,28)
    tensor auto_unroll: 512
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            for ax4 (None)
              for rv0 (None)
                for rv1 (None)
                  tensor = ...
    for ax3 (0,28)
      for ax0 (None)
        for ax1 (None)
          for ax2 (None)
            for ax3 (None)
              vectorize ax4 (None)
                pad_temp = ...
      for ax4 (0,16)
        tensor = ...

with: [15:29:24] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 29)) && (ax3 >= 1)) && (ax3 < 29)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=12)), iter_var(ax2, range(min=0, ext=30)), iter_var(ax3, range(min=0, ext=30)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=12)), iter_var(ax2, range(min=0, ext=28)), iter_var(ax3, range(min=0, ext=28)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:29:25] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
for ax1 (0,12)
  for ax2 (0,28)
    tensor auto_unroll: 512
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            for ax4 (None)
              for rv0 (None)
                for rv1 (None)
                  tensor = ...
    for ax3 (0,28)
      for ax0 (None)
        for ax1 (None)
          for ax2 (None)
            for ax3 (None)
              vectorize ax4 (None)
                pad_temp = ...
      for ax4 (0,16)
        tensor = ...

with: [15:29:25] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 29)) && (ax3 >= 1)) && (ax3 < 29)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=12)), iter_var(ax2, range(min=0, ext=30)), iter_var(ax3, range(min=0, ext=30)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=12)), iter_var(ax2, range(min=0, ext=28)), iter_var(ax3, range(min=0, ext=28)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 1.0000	Min score: 0.9561	#Pop: 128	#M+: 418	#M-: 6562
EvolutionarySearch		#s: 128	Time elapsed: 5.82
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 18.82 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 27.61 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1820	fail_ct: 0	Time elapsed: 1.84
GA Iter: 0	Max score: 1.0000	Min score: 0.9385	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9875	#Pop: 128	#M+: 1388	#M-: 34
EvolutionarySearch		#s: 128	Time elapsed: 8.33
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
........................................................
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.628 |        1108.87 |     64 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.063 |        1383.36 |     64 |
|   41 |        0.099 |         587.15 |     64 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.126 |         689.37 |     64 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.097 |         457.79 |     64 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.146 |         621.07 |     64 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 3712	Used time : 2448 s	Next ID: 58	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.628 |        1108.87 |     64 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.063 |        1383.36 |     64 |
|   41 |        0.099 |         587.15 |     64 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.126 |         689.37 |     64 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.097 |         457.79 |     64 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.146 |         621.07 |     64 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 4.603 ms	Trials: 3776	Used time : 2502 s	Next ID: 37	
.T..T.T.T.T.T.T*********************************************************Time elapsed for measurement: 25.13 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 13.13 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1622	fail_ct: 141	Time elapsed: 2.03
GA Iter: 0	Max score: 0.9457	Min score: 0.4800	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.1423	Min score: 0.9388	#Pop: 128	#M+: 1380	#M-: 36
EvolutionarySearch		#s: 128	Time elapsed: 13.68
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 29.19 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 25.19 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1818	fail_ct: 0	Time elapsed: 2.32
GA Iter: 0	Max score: 0.7343	Min score: 0.3031	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9876	Min score: 0.6932	#Pop: 128	#M+: 1395	#M-: 39
EvolutionarySearch		#s: 128	Time elapsed: 9.84
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
.........................................................
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.186 |         702.48 |     64 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.406 |        1716.12 |    128 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.063 |        1383.36 |     64 |
|   41 |        0.099 |         587.15 |     64 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.126 |         689.37 |     64 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.097 |         457.79 |     64 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.146 |         621.07 |     64 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 4.380 ms	Trials: 3840	Used time : 2550 s	Next ID: 27	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.406 |        1716.12 |    128 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.063 |        1383.36 |     64 |
|   41 |        0.099 |         587.15 |     64 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.126 |         689.37 |     64 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.097 |         457.79 |     64 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.146 |         621.07 |     64 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 4.124 ms	Trials: 3904	Used time : 2621 s	Next ID: 37	
.T..T..T..*************************************************************Time elapsed for measurement: 29.77 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 12.77 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1735	fail_ct: 0	Time elapsed: 2.21
GA Iter: 0	Max score: 0.9575	Min score: 0.5097	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9782	Min score: 0.8017	#Pop: 128	#M+: 1386	#M-: 29
EvolutionarySearch		#s: 128	Time elapsed: 14.30
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 25.57 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 28.66 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1740	fail_ct: 0	Time elapsed: 3.20
GA Iter: 0	Max score: 1.1305	Min score: 0.4734	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.1558	Min score: 0.9536	#Pop: 128	#M+: 1389	#M-: 37
EvolutionarySearch		#s: 128	Time elapsed: 14.75
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 22.47 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 26.75 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.199 |        1204.51 |     64 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.341 |        2043.60 |    192 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.063 |        1383.36 |     64 |
|   41 |        0.099 |         587.15 |     64 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.126 |         689.37 |     64 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.097 |         457.79 |     64 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.146 |         621.07 |     64 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 4.059 ms	Trials: 3968	Used time : 2676 s	Next ID: 18	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.128 |        1862.31 |    128 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.341 |        2043.60 |    192 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.063 |        1383.36 |     64 |
|   41 |        0.099 |         587.15 |     64 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.126 |         689.37 |     64 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.097 |         457.79 |     64 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.146 |         621.07 |     64 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 3.989 ms	Trials: 4032	Used time : 2747 s	Next ID: 41	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.128 |        1862.31 |    128 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1499	fail_ct: 143	Time elapsed: 1.79
GA Iter: 0	Max score: 1.0675	Min score: 0.4634	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.1648	Min score: 0.9335	#Pop: 128	#M+: 1400	#M-: 30
EvolutionarySearch		#s: 128	Time elapsed: 11.61
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
............................................................|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.341 |        2043.60 |    192 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.063 |        1383.36 |     64 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.126 |         689.37 |     64 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.097 |         457.79 |     64 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.146 |         621.07 |     64 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 3.844 ms	Trials: 4096	Used time : 2815 s	Next ID: 49	
.T.T.T.T************************************************************Time elapsed for measurement: 26.87 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 25.14 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1730	fail_ct: 0	Time elapsed: 2.41
GA Iter: 0	Max score: 0.8510	Min score: 0.4294	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9796	Min score: 0.8170	#Pop: 128	#M+: 1391	#M-: 35
EvolutionarySearch		#s: 128	Time elapsed: 14.86
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.99 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 13.42 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1595	fail_ct: 102	Time elapsed: 1.32
GA Iter: 0	Max score: 0.9821	Min score: 0.3834	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0356	Min score: 0.7812	#Pop: 128	#M+: 1383	#M-: 38
EvolutionarySearch		#s: 128	Time elapsed: 9.50
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 25.40 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 35.46 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.128 |        1862.31 |    128 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.341 |        2043.60 |    192 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.063 |        1383.36 |     64 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.126 |         689.37 |     64 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.146 |         621.07 |     64 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 3.703 ms	Trials: 4160	Used time : 2881 s	Next ID: 40	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.128 |        1862.31 |    128 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.086 |         627.49 |     64 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.341 |        2043.60 |    192 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.038 |        2265.71 |    128 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.126 |         689.37 |     64 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.146 |         621.07 |     64 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 3.629 ms	Trials: 4224	Used time : 2929 s	Next ID: 21	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.157 |        1108.53 |     64 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.128 |        1862.31 |    128 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1609	fail_ct: 143	Time elapsed: 1.98
GA Iter: 0	Max score: 0.9335	Min score: 0.3915	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0181	Min score: 0.8319	#Pop: 128	#M+: 1384	#M-: 37
EvolutionarySearch		#s: 128	Time elapsed: 9.90
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.65 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 34.64 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1578	fail_ct: 154	Time elapsed: 1.03
GA Iter: 0	Max score: 0.8202	Min score: 0.3810	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0074	Min score: 0.7386	#Pop: 128	#M+: 1397	#M-: 32
EvolutionarySearch		#s: 128	Time elapsed: 9.81
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 29.57 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 28.29 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1666	fail_ct: 130	Time elapsed: 3.12
GA Iter: 0	Max score: 0.9548	Min score: 0.3471	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0315	Min score: 0.9059	#Pop: 128	#M+: 1385	#M-: 34
EvolutionarySearch		#s: 128	Time elapsed: 12.40
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.16 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 35.64 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.341 |        2043.60 |    192 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.038 |        2265.71 |    128 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.126 |         689.37 |     64 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.146 |         621.07 |     64 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 3.507 ms	Trials: 4288	Used time : 3001 s	Next ID: 7	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.123 |        1415.28 |    128 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.128 |        1862.31 |    128 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.341 |        2043.60 |    192 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.038 |        2265.71 |    128 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.126 |         689.37 |     64 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.146 |         621.07 |     64 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 3.473 ms	Trials: 4352	Used time : 3062 s	Next ID: 51	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.123 |        1415.28 |    128 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.128 |        1862.31 |    128 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.137 |         949.98 |     64 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.341 |        2043.60 |    192 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.038 |        2265.71 |    128 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.126 |         689.37 |     64 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 3.362 ms	Trials: 4416	Used time : 3132 s	Next ID: 32	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1990	fail_ct: 1	Time elapsed: 1.52
GA Iter: 0	Max score: 0.8665	Min score: 0.4469	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9491	Min score: 0.8379	#Pop: 128	#M+: 1390	#M-: 67
EvolutionarySearch		#s: 128	Time elapsed: 5.96
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.85 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 20.07 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1711	fail_ct: 0	Time elapsed: 3.16
GA Iter: 0	Max score: 0.8514	Min score: 0.4723	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9676	Min score: 0.8101	#Pop: 128	#M+: 1389	#M-: 35
EvolutionarySearch		#s: 128	Time elapsed: 14.04
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
..............................................................|    7 |        0.123 |        1415.28 |    128 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.128 |        1862.31 |    128 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.032 |         894.31 |     64 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.341 |        2043.60 |    192 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.038 |        2265.71 |    128 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.126 |         689.37 |     64 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 3.278 ms	Trials: 4480	Used time : 3199 s	Next ID: 30	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.128 |         565.54 |     64 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.123 |        1415.28 |    128 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.128 |        1862.31 |    128 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.341 |        2043.60 |    192 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.038 |        2265.71 |    128 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.126 |         689.37 |     64 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 3.211 ms	Trials: 4544	Used time : 3243 s	Next ID: 2	
.T.T**************************************************************Time elapsed for measurement: 27.06 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 37.57 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1760	fail_ct: 0	Time elapsed: 2.45
GA Iter: 0	Max score: 0.8211	Min score: 0.3768	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9938	Min score: 0.6896	#Pop: 128	#M+: 1378	#M-: 35
EvolutionarySearch		#s: 128	Time elapsed: 10.77
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.58 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 31.39 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1600	fail_ct: 154	Time elapsed: 1.77
GA Iter: 0	Max score: 0.7399	Min score: 0.3170	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9981	Min score: 0.7498	#Pop: 128	#M+: 1385	#M-: 27
EvolutionarySearch		#s: 128	Time elapsed: 7.22
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 18.41 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 27.03 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.123 |        1415.28 |    128 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.128 |        1862.31 |    128 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.341 |        2043.60 |    192 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.038 |        2265.71 |    128 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.126 |         689.37 |     64 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 3.115 ms	Trials: 4608	Used time : 3325 s	Next ID: 46	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.123 |        1415.28 |    128 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.128 |        1862.31 |    128 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.121 |         898.21 |     64 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.341 |        2043.60 |    192 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.038 |        2265.71 |    128 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 3.031 ms	Trials: 4672	Used time : 3386 s	Next ID: 31	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.123 |        1415.28 |    128 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.128 |        1862.31 |    128 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.058 |         750.16 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1802	fail_ct: 0	Time elapsed: 2.71
GA Iter: 0	Max score: 0.5642	Min score: 0.2894	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9341	Min score: 0.6297	#Pop: 128	#M+: 1376	#M-: 43
EvolutionarySearch		#s: 128	Time elapsed: 10.86
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...........................................................|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.341 |        2043.60 |    192 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.038 |        2265.71 |    128 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.954 ms	Trials: 4736	Used time : 3441 s	Next ID: 37	
.T....T**************************************************************Time elapsed for measurement: 29.05 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 35.71 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1810	fail_ct: 0	Time elapsed: 1.70
GA Iter: 0	Max score: 0.5713	Min score: 0.2711	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9722	Min score: 0.7504	#Pop: 128	#M+: 1389	#M-: 26
EvolutionarySearch		#s: 128	Time elapsed: 13.77
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 27.15 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 36.52 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1791	fail_ct: 0	Time elapsed: 3.22
GA Iter: 0	Max score: 0.8227	Min score: 0.3634	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9083	Min score: 0.7098	#Pop: 128	#M+: 1389	#M-: 40
EvolutionarySearch		#s: 128	Time elapsed: 11.25
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 17.67 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 45.82 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.123 |        1415.28 |    128 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.128 |        1862.31 |    128 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.308 |        2258.30 |    256 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.038 |        2265.71 |    128 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.922 ms	Trials: 4800	Used time : 3519 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.123 |        1415.28 |    128 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.128 |        1862.31 |    128 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.094 |         926.99 |     64 |
|   37 |        0.263 |        2643.75 |    320 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.038 |        2265.71 |    128 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.877 ms	Trials: 4864	Used time : 3599 s	Next ID: 36	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.123 |        1415.28 |    128 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.046 |         940.26 |     64 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.128 |        1862.31 |    128 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.058 |         750.16 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1616	fail_ct: 142	Time elapsed: 1.07
GA Iter: 0	Max score: 0.8891	Min score: 0.3905	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9897	Min score: 0.8047	#Pop: 128	#M+: 1394	#M-: 34
EvolutionarySearch		#s: 128	Time elapsed: 7.83
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.263 |        2643.75 |    320 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.038 |        2265.71 |    128 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.821 ms	Trials: 4928	Used time : 3677 s	Next ID: 16	
.T***************************************************************Time elapsed for measurement: 30.66 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 20.79 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1932	fail_ct: 18	Time elapsed: 1.82
GA Iter: 0	Max score: 0.8695	Min score: 0.4837	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9665	Min score: 0.7462	#Pop: 128	#M+: 1379	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 5.61
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 11.39 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 38.91 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2000	fail_ct: 1	Time elapsed: 0.99
GA Iter: 0	Max score: 0.9366	Min score: 0.4489	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0241	Min score: 0.8514	#Pop: 128	#M+: 1389	#M-: 82
EvolutionarySearch		#s: 128	Time elapsed: 7.25
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 11.77 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 36.18 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.046 |         774.73 |     64 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.123 |        1415.28 |    128 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.128 |        1862.31 |    128 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.263 |        2643.75 |    320 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.038 |        2265.71 |    128 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.769 ms	Trials: 4992	Used time : 3738 s	Next ID: 0	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.123 |        1415.28 |    128 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.128 |        1862.31 |    128 |
|   19 |        0.028 |         765.67 |     64 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.263 |        2643.75 |    320 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.038 |        2265.71 |    128 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.714 ms	Trials: 5056	Used time : 3796 s	Next ID: 19	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.123 |        1415.28 |    128 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.128 |        1862.31 |    128 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.058 |         750.16 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2016	fail_ct: 1	Time elapsed: 1.13
GA Iter: 0	Max score: 0.7844	Min score: 0.4483	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9210	Min score: 0.7011	#Pop: 128	#M+: 1386	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 6.39
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 18.07 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 34.07 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1750	fail_ct: 0	Time elapsed: 3.28
GA Iter: 0	Max score: 0.8051	Min score: 0.3984	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0633	Min score: 0.8512	#Pop: 128	#M+: 1382	#M-: 37
EvolutionarySearch		#s: 128	Time elapsed: 11.03
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 24.46 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 48.17 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1962	fail_ct: 10	Time elapsed: 1.39
GA Iter: 0	Max score: 0.8916	Min score: 0.4825	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9616	Min score: 0.7241	#Pop: 128	#M+: 1381	#M-: 81
EvolutionarySearch		#s: 128	Time elapsed: 5.72
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.91 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 18.02 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.026 |         843.26 |     64 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.263 |        2643.75 |    320 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.038 |        2265.71 |    128 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.667 ms	Trials: 5120	Used time : 3852 s	Next ID: 35	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.123 |        1415.28 |    128 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.128 |        1862.31 |    128 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.263 |        2643.75 |    320 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.038 |        2265.71 |    128 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.077 |         753.79 |     64 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.623 ms	Trials: 5184	Used time : 3912 s	Next ID: 48	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.123 |        1415.28 |    128 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.128 |        1862.31 |    128 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.263 |        2643.75 |    320 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.038 |        2265.71 |    128 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.026 |         752.60 |     64 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.573 ms	Trials: 5248	Used time : 4000 s	Next ID: 45	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2011	fail_ct: 1	Time elapsed: 1.86
GA Iter: 0	Max score: 0.6810	Min score: 0.3937	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9089	Min score: 0.6803	#Pop: 128	#M+: 1385	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 6.23
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.74 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 53.41 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1991	fail_ct: 3	Time elapsed: 2.26
GA Iter: 0	Max score: 0.8046	Min score: 0.4635	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9102	Min score: 0.7386	#Pop: 128	#M+: 1380	#M-: 67
EvolutionarySearch		#s: 128	Time elapsed: 7.61
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 19.73 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 42.20 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    7 |        0.123 |        1415.28 |    128 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.128 |        1862.31 |    128 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.263 |        2643.75 |    320 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.038 |        2265.71 |    128 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.035 |         822.07 |     64 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.533 ms	Trials: 5312	Used time : 4040 s	Next ID: 47	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.123 |        1415.28 |    128 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.128 |        1862.31 |    128 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.263 |        2643.75 |    320 |
|   38 |        0.069 |         733.25 |     64 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.038 |        2265.71 |    128 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.493 ms	Trials: 5376	Used time : 4117 s	Next ID: 38	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.123 |        1415.28 |    128 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.128 |        1862.31 |    128 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.263 |        2643.75 |    320 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.038 |        2265.71 |    128 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1748	fail_ct: 0	Time elapsed: 2.19
GA Iter: 0	Max score: 0.8013	Min score: 0.3060	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0374	Min score: 0.7740	#Pop: 128	#M+: 1374	#M-: 26
EvolutionarySearch		#s: 128	Time elapsed: 11.16
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 19.38 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 24.02 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1810	fail_ct: 0	Time elapsed: 2.94
GA Iter: 0	Max score: 0.8226	Min score: 0.2446	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9947	Min score: 0.7978	#Pop: 128	#M+: 1387	#M-: 17
EvolutionarySearch		#s: 128	Time elapsed: 16.37
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 26.90 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 39.52 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1741	fail_ct: 0	Time elapsed: 1.43
GA Iter: 0	Max score: 0.8400	Min score: 0.4034	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0114	Min score: 0.7891	#Pop: 128	#M+: 1382	#M-: 38
EvolutionarySearch		#s: 128	Time elapsed: 7.69
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.79 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.97 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.069 |        1055.33 |     64 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.455 ms	Trials: 5440	Used time : 4189 s	Next ID: 54	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.123 |        1415.28 |    128 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.128 |        1862.31 |    128 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.263 |        2643.75 |    320 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.038 |        2265.71 |    128 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.414 ms	Trials: 5504	Used time : 4246 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.123 |        1415.28 |    128 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.128 |        1862.31 |    128 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.242 |        2881.17 |    384 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.038 |        2265.71 |    128 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.393 ms	Trials: 5568	Used time : 4333 s	Next ID: 18	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.123 |        1415.28 |    128 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1646	fail_ct: 137	Time elapsed: 0.83
GA Iter: 0	Max score: 0.8278	Min score: 0.3158	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0411	Min score: 0.8453	#Pop: 128	#M+: 1381	#M-: 54
EvolutionarySearch		#s: 128	Time elapsed: 5.05
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 10.80 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 45.28 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1621	fail_ct: 127	Time elapsed: 2.34
GA Iter: 0	Max score: 0.8079	Min score: 0.3628	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9642	Min score: 0.7189	#Pop: 128	#M+: 1394	#M-: 33
EvolutionarySearch		#s: 128	Time elapsed: 10.93
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.01 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 23.18 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.117 |        2046.45 |    192 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.242 |        2881.17 |    384 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.038 |        2265.71 |    128 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.381 ms	Trials: 5632	Used time : 4361 s	Next ID: 7	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.117 |        2046.45 |    192 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.058 |         750.16 |     64 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.242 |        2881.17 |    384 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.038 |        2265.71 |    128 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.351 ms	Trials: 5696	Used time : 4423 s	Next ID: 33	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.117 |        2046.45 |    192 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.058 |        2263.89 |    128 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.242 |        2881.17 |    384 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.038 |        2265.71 |    128 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1625	fail_ct: 140	Time elapsed: 2.14
GA Iter: 0	Max score: 0.8121	Min score: 0.2359	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0298	Min score: 0.8713	#Pop: 128	#M+: 1384	#M-: 34
EvolutionarySearch		#s: 128	Time elapsed: 8.75
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 11.86 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 35.87 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1767	fail_ct: 0	Time elapsed: 2.01
GA Iter: 0	Max score: 0.7192	Min score: 0.2548	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9664	Min score: 0.7840	#Pop: 128	#M+: 1386	#M-: 25
EvolutionarySearch		#s: 128	Time elapsed: 8.80
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 30.34 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 54.29 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1512	fail_ct: 116	Time elapsed: 1.09
GA Iter: 0	Max score: 0.8494	Min score: 0.3183	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0369	Min score: 0.8142	#Pop: 128	#M+: 1396	#M-: 23
EvolutionarySearch		#s: 128	Time elapsed: 5.48
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 18.95 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 24.69 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.316 ms	Trials: 5760	Used time : 4474 s	Next ID: 27	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.117 |        2046.45 |    192 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.048 |        2719.31 |    192 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.242 |        2881.17 |    384 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.038 |        2265.71 |    128 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.297 ms	Trials: 5824	Used time : 4533 s	Next ID: 40	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.117 |        2046.45 |    192 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.056 |         676.08 |     64 |
|   27 |        0.048 |        2719.31 |    192 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.242 |        2881.17 |    384 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.035 |        2460.89 |    192 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.288 ms	Trials: 5888	Used time : 4629 s	Next ID: 26	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.052 |        1381.02 |     64 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.117 |        2046.45 |    192 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1751	fail_ct: 0	Time elapsed: 1.90
GA Iter: 0	Max score: 0.6925	Min score: 0.2670	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0085	Min score: 0.6901	#Pop: 128	#M+: 1392	#M-: 29
EvolutionarySearch		#s: 128	Time elapsed: 7.85
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 26.65 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 38.94 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2015	fail_ct: 0	Time elapsed: 1.78
GA Iter: 0	Max score: 0.8504	Min score: 0.3606	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9450	Min score: 0.7624	#Pop: 128	#M+: 1375	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 9.20
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.23 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 29.17 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2020	fail_ct: 0	Time elapsed: 1.59
GA Iter: 0	Max score: 0.7043	Min score: 0.3690	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9274	Min score: 0.6444	#Pop: 128	#M+: 1382	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 9.31
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 22.91 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 22.98 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2719.31 |    192 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.242 |        2881.17 |    384 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.035 |        2460.89 |    192 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.250 ms	Trials: 5952	Used time : 4680 s	Next ID: 11	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.051 |        1262.13 |     64 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.117 |        2046.45 |    192 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2719.31 |    192 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.242 |        2881.17 |    384 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.035 |        2460.89 |    192 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.226 ms	Trials: 6016	Used time : 4755 s	Next ID: 8	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.049 |         890.97 |     64 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.117 |        2046.45 |    192 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2719.31 |    192 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.242 |        2881.17 |    384 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.035 |        2460.89 |    192 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.209 ms	Trials: 6080	Used time : 4812 s	Next ID: 4	

----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1812	fail_ct: 0	Time elapsed: 1.60
GA Iter: 0	Max score: 0.4355	Min score: 0.2255	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0876	Min score: 0.8456	#Pop: 128	#M+: 1390	#M-: 13
EvolutionarySearch		#s: 128	Time elapsed: 13.52
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 22.48 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 21.67 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1683	fail_ct: 0	Time elapsed: 1.35
GA Iter: 0	Max score: 0.6049	Min score: 0.2398	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0051	Min score: 0.6380	#Pop: 128	#M+: 1387	#M-: 27
EvolutionarySearch		#s: 128	Time elapsed: 5.81
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 23.43 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 40.69 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.117 |        2046.45 |    192 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2719.31 |    192 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.242 |        2881.17 |    384 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.035 |        2460.89 |    192 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.182 ms	Trials: 6144	Used time : 4869 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.117 |        2046.45 |    192 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2719.31 |    192 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2987.90 |    448 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.035 |        2460.89 |    192 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.047 |        1221.63 |     64 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.173 ms	Trials: 6208	Used time : 4929 s	Next ID: 42	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.117 |        2046.45 |    192 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2719.31 |    192 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2011	fail_ct: 1	Time elapsed: 1.37
GA Iter: 0	Max score: 0.8912	Min score: 0.3942	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9517	Min score: 0.8119	#Pop: 128	#M+: 1378	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 9.63
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.32 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 47.89 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1949	fail_ct: 18	Time elapsed: 1.28
GA Iter: 0	Max score: 1.0230	Min score: 0.4788	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0253	Min score: 0.8759	#Pop: 128	#M+: 1382	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 6.77
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 21.01 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 46.93 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1806	fail_ct: 0	Time elapsed: 2.50
GA Iter: 0	Max score: 0.7456	Min score: 0.2552	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9954	Min score: 0.8805	#Pop: 128	#M+: 1395	#M-: 10
EvolutionarySearch		#s: 128	Time elapsed: 14.47
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 20.03 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 29.02 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2987.90 |    448 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.035 |        2460.89 |    192 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.022 |        1160.07 |     64 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.156 ms	Trials: 6272	Used time : 5001 s	Next ID: 56	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.117 |        2046.45 |    192 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2719.31 |    192 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2987.90 |    448 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.035 |        2460.89 |    192 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.020 |         643.02 |     64 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.139 ms	Trials: 6336	Used time : 5075 s	Next ID: 43	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.117 |        2046.45 |    192 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2719.31 |    192 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2987.90 |    448 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.035 |        2460.89 |    192 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.116 ms	Trials: 6400	Used time : 5151 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1770	fail_ct: 0	Time elapsed: 2.37
GA Iter: 0	Max score: 0.7563	Min score: 0.3701	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9722	Min score: 0.8639	#Pop: 128	#M+: 1389	#M-: 51
EvolutionarySearch		#s: 128	Time elapsed: 12.15
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 18.34 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 57.31 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2013	fail_ct: 1	Time elapsed: 1.24
GA Iter: 0	Max score: 0.8431	Min score: 0.3840	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9594	Min score: 0.7514	#Pop: 128	#M+: 1381	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 7.47
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.89 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 53.53 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.117 |        2046.45 |    192 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2719.31 |    192 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2987.90 |    512 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.035 |        2460.89 |    192 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.116 ms	Trials: 6464	Used time : 5218 s	Next ID: 18	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2089.94 |    256 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2719.31 |    192 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2987.90 |    512 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.035 |        2460.89 |    192 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.019 |        1369.77 |     64 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.113 ms	Trials: 6528	Used time : 5308 s	Next ID: 55	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2089.94 |    256 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2719.31 |    192 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2987.90 |    512 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.035 |        2460.89 |    192 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.031 |        1885.63 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2014	fail_ct: 0	Time elapsed: 1.55
GA Iter: 0	Max score: 0.8898	Min score: 0.4014	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9589	Min score: 0.7541	#Pop: 128	#M+: 1380	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 8.43
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 22.93 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 53.23 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1995	fail_ct: 0	Time elapsed: 1.43
GA Iter: 0	Max score: 0.8306	Min score: 0.3360	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9057	Min score: 0.6469	#Pop: 128	#M+: 1393	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 7.59
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 18.31 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 24.17 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1600	fail_ct: 133	Time elapsed: 1.88
GA Iter: 0	Max score: 0.8754	Min score: 0.3712	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.2265	Min score: 0.8574	#Pop: 128	#M+: 1376	#M-: 20
EvolutionarySearch		#s: 128	Time elapsed: 7.74
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
..............................................................|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.037 |         859.87 |     64 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.100 ms	Trials: 6592	Used time : 5385 s	Next ID: 52	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2089.94 |    256 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.037 |         974.15 |     64 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2719.31 |    192 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2987.90 |    512 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.035 |        2460.89 |    192 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.077 ms	Trials: 6656	Used time : 5471 s	Next ID: 22	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2089.94 |    256 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2719.31 |    192 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2987.90 |    512 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.035 |        2460.89 |    192 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.037 |         884.21 |     64 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.056 ms	Trials: 6720	Used time : 5523 s	Next ID: 57	
.T.T**************************************************************Time elapsed for measurement: 28.56 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 34.84 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2016	fail_ct: 0	Time elapsed: 1.14
GA Iter: 0	Max score: 0.9239	Min score: 0.4155	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9710	Min score: 0.8398	#Pop: 128	#M+: 1383	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 8.99
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 27.29 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 40.00 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1770	fail_ct: 0	Time elapsed: 2.33
GA Iter: 0	Max score: 0.7483	Min score: 0.3759	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9652	Min score: 0.8682	#Pop: 128	#M+: 1391	#M-: 55
EvolutionarySearch		#s: 128	Time elapsed: 10.87
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 19.03 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 60.34 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2089.94 |    256 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.018 |        1065.88 |     64 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2719.31 |    192 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2987.90 |    512 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.035 |        2460.89 |    192 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.035 ms	Trials: 6784	Used time : 5597 s	Next ID: 23	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2089.94 |    256 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2719.31 |    192 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2987.90 |    512 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.035 |        2460.89 |    192 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.020 ms	Trials: 6848	Used time : 5675 s	Next ID: 18	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2089.94 |    320 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2719.31 |    192 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1764	fail_ct: 0	Time elapsed: 2.28
GA Iter: 0	Max score: 0.8465	Min score: 0.2603	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0238	Min score: 0.8974	#Pop: 128	#M+: 1392	#M-: 15
EvolutionarySearch		#s: 128	Time elapsed: 10.81
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.22 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 45.06 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1713	fail_ct: 0	Time elapsed: 2.00
GA Iter: 0	Max score: 0.8966	Min score: 0.3593	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0800	Min score: 0.7632	#Pop: 128	#M+: 1401	#M-: 26
EvolutionarySearch		#s: 128	Time elapsed: 9.00
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 24.99 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 36.37 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1761	fail_ct: 0	Time elapsed: 2.57
GA Iter: 0	Max score: 0.7328	Min score: 0.2485	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9625	Min score: 0.8584	#Pop: 128	#M+: 1389	#M-: 15
EvolutionarySearch		#s: 128	Time elapsed: 14.17
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.39 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 25.87 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2987.90 |    512 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.035 |        2460.89 |    192 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.020 ms	Trials: 6912	Used time : 5768 s	Next ID: 40	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.034 |         643.26 |     64 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2089.94 |    320 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2719.31 |    192 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2987.90 |    512 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    256 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 2.012 ms	Trials: 6976	Used time : 5841 s	Next ID: 3	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2089.94 |    320 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2719.31 |    192 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2987.90 |    512 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    256 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.989 ms	Trials: 7040	Used time : 5914 s	Next ID: 40	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1610	fail_ct: 147	Time elapsed: 2.25
GA Iter: 0	Max score: 0.7345	Min score: 0.2195	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0211	Min score: 0.8406	#Pop: 128	#M+: 1397	#M-: 13
EvolutionarySearch		#s: 128	Time elapsed: 6.48
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.74 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 51.94 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1609	fail_ct: 146	Time elapsed: 2.47
GA Iter: 0	Max score: 0.7445	Min score: 0.2298	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0231	Min score: 0.8769	#Pop: 128	#M+: 1391	#M-: 11
EvolutionarySearch		#s: 128	Time elapsed: 13.85
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 19.69 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 41.04 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2089.94 |    320 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2719.31 |    192 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2987.90 |    512 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    320 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.989 ms	Trials: 7104	Used time : 5974 s	Next ID: 27	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2089.94 |    320 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2721.88 |    256 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2987.90 |    512 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    320 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.989 ms	Trials: 7168	Used time : 6049 s	Next ID: 27	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.032 |        1370.59 |     64 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2089.94 |    320 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    320 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2987.90 |    512 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    320 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.031 |        1885.63 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2005	fail_ct: 0	Time elapsed: 1.72
GA Iter: 0	Max score: 0.7416	Min score: 0.2938	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9114	Min score: 0.6886	#Pop: 128	#M+: 1377	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 7.05
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.43 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 34.71 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1815	fail_ct: 0	Time elapsed: 2.40
GA Iter: 0	Max score: 0.7449	Min score: 0.2432	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9961	Min score: 0.9177	#Pop: 128	#M+: 1393	#M-: 11
EvolutionarySearch		#s: 128	Time elapsed: 12.18
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 22.52 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 38.25 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1480	fail_ct: 140	Time elapsed: 1.60
GA Iter: 0	Max score: 0.8915	Min score: 0.3448	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9989	Min score: 0.8527	#Pop: 128	#M+: 1384	#M-: 24
EvolutionarySearch		#s: 128	Time elapsed: 7.22
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.71 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 47.25 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.988 ms	Trials: 7232	Used time : 6127 s	Next ID: 1	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2089.94 |    320 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    320 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2987.90 |    512 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    320 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.977 ms	Trials: 7296	Used time : 6187 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.031 |        1007.35 |     64 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2089.94 |    320 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    320 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2990.17 |    576 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    320 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.977 ms	Trials: 7360	Used time : 6263 s	Next ID: 15	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.018 |        1775.17 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1708	fail_ct: 0	Time elapsed: 3.02
GA Iter: 0	Max score: 0.7760	Min score: 0.3730	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9884	Min score: 0.8057	#Pop: 128	#M+: 1396	#M-: 27
EvolutionarySearch		#s: 128	Time elapsed: 12.94
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 22.67 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 47.01 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1658	fail_ct: 110	Time elapsed: 3.00
GA Iter: 0	Max score: 0.7677	Min score: 0.2952	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9786	Min score: 0.7889	#Pop: 128	#M+: 1382	#M-: 54
EvolutionarySearch		#s: 128	Time elapsed: 8.21
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 17.56 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 73.20 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2089.94 |    320 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    320 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2990.17 |    576 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    320 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.031 |         700.72 |     64 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.963 ms	Trials: 7424	Used time : 6332 s	Next ID: 50	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.093 |        1871.13 |    192 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2089.94 |    320 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    320 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2990.17 |    576 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    320 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.946 ms	Trials: 7488	Used time : 6418 s	Next ID: 7	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.074 |        2359.28 |    256 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2089.94 |    320 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    320 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.015 |        1878.63 |    128 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2990.17 |    576 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    320 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2000	fail_ct: 0	Time elapsed: 1.70
GA Iter: 0	Max score: 0.7201	Min score: 0.2797	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9858	Min score: 0.7802	#Pop: 128	#M+: 1389	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 6.64
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.13 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 36.70 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2037	fail_ct: 1	Time elapsed: 1.40
GA Iter: 0	Max score: 0.7673	Min score: 0.4803	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8728	Min score: 0.7011	#Pop: 128	#M+: 1382	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 9.56
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
..............................................................|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.927 ms	Trials: 7552	Used time : 6520 s	Next ID: 30	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.074 |        2359.28 |    256 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.027 |         969.84 |     64 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2089.94 |    320 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    320 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    192 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2990.17 |    576 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    320 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.922 ms	Trials: 7616	Used time : 6581 s	Next ID: 9	
.T.T**************************************************************Time elapsed for measurement: 28.07 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 80.57 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1829	fail_ct: 0	Time elapsed: 1.71
GA Iter: 0	Max score: 0.6316	Min score: 0.2260	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9854	Min score: 0.9155	#Pop: 128	#M+: 1381	#M-: 7
EvolutionarySearch		#s: 128	Time elapsed: 8.76
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 35.46 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 63.33 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1645	fail_ct: 122	Time elapsed: 1.47
GA Iter: 0	Max score: 0.6870	Min score: 0.2253	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0164	Min score: 0.9038	#Pop: 128	#M+: 1393	#M-: 24
EvolutionarySearch		#s: 128	Time elapsed: 6.90
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.53 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 57.90 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.074 |        2359.28 |    256 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2089.94 |    320 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    320 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    192 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2990.17 |    576 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    320 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.907 ms	Trials: 7680	Used time : 6701 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.074 |        2359.28 |    256 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2089.94 |    320 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    320 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    192 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.053 |        2454.43 |    128 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2990.17 |    640 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    320 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.907 ms	Trials: 7744	Used time : 6811 s	Next ID: 32	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.074 |        2359.28 |    256 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2089.94 |    320 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    320 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    192 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1472	fail_ct: 139	Time elapsed: 2.60
GA Iter: 0	Max score: 0.6401	Min score: 0.1736	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0124	Min score: 0.8577	#Pop: 128	#M+: 1386	#M-: 18
EvolutionarySearch		#s: 128	Time elapsed: 11.35
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 18.12 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 44.56 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1996	fail_ct: 0	Time elapsed: 2.45
GA Iter: 0	Max score: 0.6792	Min score: 0.3068	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0058	Min score: 0.6625	#Pop: 128	#M+: 1374	#M-: 78
EvolutionarySearch		#s: 128	Time elapsed: 6.60
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.48 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 48.70 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1736	fail_ct: 0	Time elapsed: 2.87
GA Iter: 0	Max score: 0.6621	Min score: 0.2204	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9875	Min score: 0.8498	#Pop: 128	#M+: 1383	#M-: 24
EvolutionarySearch		#s: 128	Time elapsed: 13.60
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 25.56 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 55.02 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2990.17 |    640 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    320 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.026 |        1690.81 |    128 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.905 ms	Trials: 7808	Used time : 6892 s	Next ID: 49	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.074 |        2359.28 |    256 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2089.94 |    320 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.026 |        1391.56 |     64 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    320 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    192 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2990.17 |    640 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    320 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.891 ms	Trials: 7872	Used time : 6968 s	Next ID: 24	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.074 |        2359.28 |    256 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2089.94 |    320 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    320 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    192 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2990.17 |    640 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    320 |
|   41 |        0.026 |        2240.87 |    128 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.882 ms	Trials: 7936	Used time : 7041 s	Next ID: 41	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1654	fail_ct: 114	Time elapsed: 1.39
GA Iter: 0	Max score: 0.6095	Min score: 0.2420	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9029	Min score: 0.7328	#Pop: 128	#M+: 1379	#M-: 56
EvolutionarySearch		#s: 128	Time elapsed: 9.89
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 23.42 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 23.89 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1574	fail_ct: 117	Time elapsed: 1.54
GA Iter: 0	Max score: 0.7672	Min score: 0.2107	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0684	Min score: 0.8265	#Pop: 128	#M+: 1383	#M-: 50
EvolutionarySearch		#s: 128	Time elapsed: 8.07
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 25.07 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 27.83 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    7 |        0.074 |        2359.28 |    256 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2089.94 |    320 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    320 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    192 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2990.17 |    640 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    320 |
|   41 |        0.026 |        2267.27 |    192 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.881 ms	Trials: 8000	Used time : 7139 s	Next ID: 7	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.074 |        2359.28 |    320 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2089.94 |    320 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.025 |        2149.30 |    128 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    320 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    192 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2990.17 |    640 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    320 |
|   41 |        0.026 |        2267.27 |    192 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.881 ms	Trials: 8064	Used time : 7198 s	Next ID: 21	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.074 |        2359.28 |    320 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2089.94 |    320 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    320 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    192 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2990.17 |    640 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    320 |
|   41 |        0.026 |        2267.27 |    192 |
|   42 |        0.031 |        1885.63 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1744	fail_ct: 0	Time elapsed: 3.27
GA Iter: 0	Max score: 0.6797	Min score: 0.3290	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9748	Min score: 0.8830	#Pop: 128	#M+: 1372	#M-: 57
EvolutionarySearch		#s: 128	Time elapsed: 12.20
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 17.69 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 50.39 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1808	fail_ct: 0	Time elapsed: 3.26
GA Iter: 0	Max score: 0.7760	Min score: 0.2523	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0087	Min score: 0.9292	#Pop: 128	#M+: 1390	#M-: 6
EvolutionarySearch		#s: 128	Time elapsed: 12.10
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.45 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 50.69 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1622	fail_ct: 151	Time elapsed: 1.78
GA Iter: 0	Max score: 0.6552	Min score: 0.2331	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0007	Min score: 0.8728	#Pop: 128	#M+: 1393	#M-: 17
EvolutionarySearch		#s: 128	Time elapsed: 8.81
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 26.74 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 21.10 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.872 ms	Trials: 8128	Used time : 7261 s	Next ID: 18	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.074 |        2359.28 |    320 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2100.02 |    384 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    320 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    192 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.233 |        2990.17 |    640 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    320 |
|   41 |        0.026 |        2267.27 |    192 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.871 ms	Trials: 8192	Used time : 7344 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.074 |        2359.28 |    320 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2100.02 |    384 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    320 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    192 |
|   31 |        0.044 |        2466.62 |    128 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.230 |        3025.90 |    704 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    320 |
|   41 |        0.026 |        2267.27 |    192 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.868 ms	Trials: 8256	Used time : 7427 s	Next ID: 31	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.074 |        2359.28 |    320 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.018 |        1775.17 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2011	fail_ct: 2	Time elapsed: 1.86
GA Iter: 0	Max score: 0.7269	Min score: 0.3327	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9421	Min score: 0.7517	#Pop: 128	#M+: 1379	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 12.72
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 24.85 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 76.03 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1819	fail_ct: 0	Time elapsed: 1.40
GA Iter: 0	Max score: 0.6433	Min score: 0.2644	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9830	Min score: 0.9202	#Pop: 128	#M+: 1408	#M-: 8
EvolutionarySearch		#s: 128	Time elapsed: 10.85
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 28.75 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 41.50 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2100.02 |    384 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    320 |
|   28 |        0.021 |         909.53 |     64 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    192 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.230 |        3025.90 |    704 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    320 |
|   41 |        0.026 |        2267.27 |    192 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.867 ms	Trials: 8320	Used time : 7486 s	Next ID: 28	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.074 |        2359.28 |    320 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2100.02 |    384 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    320 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    192 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.230 |        3025.90 |    704 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    320 |
|   41 |        0.026 |        2267.27 |    192 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.857 ms	Trials: 8384	Used time : 7602 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.074 |        2359.28 |    320 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2100.02 |    384 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    320 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    192 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.230 |        3025.90 |    768 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    320 |
|   41 |        0.026 |        2267.27 |    192 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.042 |        2061.11 |    128 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1767	fail_ct: 0	Time elapsed: 3.23
GA Iter: 0	Max score: 0.8255	Min score: 0.2174	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9623	Min score: 0.7840	#Pop: 128	#M+: 1374	#M-: 41
EvolutionarySearch		#s: 128	Time elapsed: 11.02
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 28.26 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 76.62 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1770	fail_ct: 0	Time elapsed: 2.20
GA Iter: 0	Max score: 0.8086	Min score: 0.2280	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9714	Min score: 0.8864	#Pop: 128	#M+: 1376	#M-: 14
EvolutionarySearch		#s: 128	Time elapsed: 16.78
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 22.06 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 65.02 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 155	fail_ct: 1632	Time elapsed: 0.75
GA Iter: 0	Max score: 0.9676	Min score: 0.0687	#Pop: 116	#M+: 0	#M-: 0
[17:00:25] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (None)
  for ax2 (None)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            for ax4 (None)
              for rv0 (None)
                for rv1 (None)
                  tensor = ...
    for ax3 (None)
      for ax0 (None)
        for ax1 (None)
          for ax2 (None)
            for ax3 (None)
              vectorize ax4 (None)
                pad_temp = ...
      for ax4 (None)
        tensor = ...

with: [17:00:25] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[17:00:27] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      vectorize ax4 (0,16)
        tensor = ...

with: [17:00:27] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[17:00:27] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
for ax1 (0,36)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [17:00:27] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.9676	Min score: 0.4511	#Pop: 128	#M+: 424	#M-: 6296
EvolutionarySearch		#s: 128	Time elapsed: 5.46
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.44 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 6.55 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.857 ms	Trials: 8448	Used time : 7685 s	Next ID: 46	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.074 |        2359.28 |    320 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2100.02 |    384 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    320 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    192 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.230 |        3025.90 |    768 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    320 |
|   41 |        0.026 |        2267.27 |    192 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.853 ms	Trials: 8512	Used time : 7805 s	Next ID: 40	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.074 |        2359.28 |    320 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |     64 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2100.02 |    384 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    320 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    192 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.230 |        3025.90 |    768 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    384 |
|   41 |        0.026 |        2267.27 |    192 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.853 ms	Trials: 8576	Used time : 7911 s	Next ID: 14	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.074 |        2359.28 |    320 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2100.02 |    384 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1625	fail_ct: 125	Time elapsed: 0.90
GA Iter: 0	Max score: 0.7622	Min score: 0.2144	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0168	Min score: 0.8860	#Pop: 128	#M+: 1391	#M-: 8
EvolutionarySearch		#s: 128	Time elapsed: 5.32
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 22.85 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 48.04 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1578	fail_ct: 153	Time elapsed: 0.79
GA Iter: 0	Max score: 0.7924	Min score: 0.2340	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0852	Min score: 0.9195	#Pop: 128	#M+: 1391	#M-: 16
EvolutionarySearch		#s: 128	Time elapsed: 6.15
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 20.79 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 41.95 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1797	fail_ct: 0	Time elapsed: 2.82
GA Iter: 0	Max score: 0.7296	Min score: 0.2726	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9884	Min score: 0.9189	#Pop: 128	#M+: 1401	#M-: 7
EvolutionarySearch		#s: 128	Time elapsed: 16.56
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    320 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    192 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.230 |        3025.90 |    768 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    384 |
|   41 |        0.026 |        2267.27 |    192 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.853 ms	Trials: 8640	Used time : 7937 s	Next ID: 27	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.074 |        2359.28 |    320 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.020 |        2147.88 |    128 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2100.02 |    384 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    384 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    192 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.230 |        3025.90 |    768 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    384 |
|   41 |        0.026 |        2267.27 |    192 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.853 ms	Trials: 8704	Used time : 8014 s	Next ID: 16	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.074 |        2359.28 |    320 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2100.02 |    384 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    384 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    192 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.230 |        3025.90 |    768 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    384 |
|   41 |        0.026 |        2267.27 |    192 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.851 ms	Trials: 8768	Used time : 8084 s	Next ID: 37	
.T***************************************************************Time elapsed for measurement: 27.40 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 41.82 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1759	fail_ct: 0	Time elapsed: 2.21
GA Iter: 0	Max score: 0.7358	Min score: 0.3714	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9608	Min score: 0.8641	#Pop: 128	#M+: 1393	#M-: 65
EvolutionarySearch		#s: 128	Time elapsed: 12.52
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.85 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 33.39 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2005	fail_ct: 0	Time elapsed: 1.88
GA Iter: 0	Max score: 0.7121	Min score: 0.2527	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9890	Min score: 0.8336	#Pop: 128	#M+: 1388	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 9.33
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 23.84 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 41.03 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.074 |        2359.28 |    320 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.114 |        2100.02 |    384 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    384 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    192 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.230 |        3025.90 |    832 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    384 |
|   41 |        0.026 |        2267.27 |    192 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.851 ms	Trials: 8832	Used time : 8173 s	Next ID: 18	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.074 |        2359.28 |    320 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.112 |        2140.39 |    448 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    384 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    192 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.230 |        3025.90 |    832 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    384 |
|   41 |        0.026 |        2267.27 |    192 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.849 ms	Trials: 8896	Used time : 8237 s	Next ID: 30	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.074 |        2359.28 |    320 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.112 |        2140.39 |    448 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    384 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    256 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2006	fail_ct: 1	Time elapsed: 1.66
GA Iter: 0	Max score: 0.8200	Min score: 0.2667	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9450	Min score: 0.8553	#Pop: 128	#M+: 1389	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 9.59
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 23.12 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 48.70 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1745	fail_ct: 0	Time elapsed: 3.22
GA Iter: 0	Max score: 0.5922	Min score: 0.2411	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9656	Min score: 0.8312	#Pop: 128	#M+: 1387	#M-: 32
EvolutionarySearch		#s: 128	Time elapsed: 15.34
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 20.55 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 35.50 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1637	fail_ct: 129	Time elapsed: 2.36
GA Iter: 0	Max score: 0.7480	Min score: 0.2478	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9585	Min score: 0.7736	#Pop: 128	#M+: 1380	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 11.54
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.230 |        3025.90 |    832 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    384 |
|   41 |        0.026 |        2267.27 |    192 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.849 ms	Trials: 8960	Used time : 8313 s	Next ID: 30	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.074 |        2359.28 |    320 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.112 |        2140.39 |    448 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    384 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.038 |        2295.79 |    128 |
|   37 |        0.230 |        3025.90 |    832 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    384 |
|   41 |        0.026 |        2267.27 |    192 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.849 ms	Trials: 9024	Used time : 8396 s	Next ID: 36	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.074 |        2359.28 |    320 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.112 |        2140.39 |    448 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    384 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |    832 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    384 |
|   41 |        0.026 |        2267.27 |    192 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.846 ms	Trials: 9088	Used time : 8471 s	Next ID: 7	
.T***************************************************************Time elapsed for measurement: 27.49 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 48.59 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1975	fail_ct: 1	Time elapsed: 1.51
GA Iter: 0	Max score: 0.6647	Min score: 0.2387	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0003	Min score: 0.7523	#Pop: 128	#M+: 1387	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 8.69
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 24.11 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 46.19 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1956	fail_ct: 9	Time elapsed: 1.76
GA Iter: 0	Max score: 0.8912	Min score: 0.2849	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9705	Min score: 0.7342	#Pop: 128	#M+: 1372	#M-: 69
EvolutionarySearch		#s: 128	Time elapsed: 10.65
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 29.30 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 47.49 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.112 |        2140.39 |    448 |
|   19 |        0.013 |        1738.50 |    128 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    384 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |    832 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    384 |
|   41 |        0.026 |        2267.27 |    192 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.846 ms	Trials: 9152	Used time : 8562 s	Next ID: 19	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.112 |        2140.39 |    448 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    384 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |    832 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    384 |
|   41 |        0.026 |        2267.27 |    192 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.012 |        1555.25 |    128 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.841 ms	Trials: 9216	Used time : 8643 s	Next ID: 45	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.018 |        1944.45 |    128 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.112 |        2140.39 |    448 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    384 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1930	fail_ct: 11	Time elapsed: 0.89
GA Iter: 0	Max score: 0.7249	Min score: 0.2459	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9907	Min score: 0.6137	#Pop: 128	#M+: 1384	#M-: 69
EvolutionarySearch		#s: 128	Time elapsed: 4.35
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.38 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 54.17 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1818	fail_ct: 0	Time elapsed: 1.78
GA Iter: 0	Max score: 0.7431	Min score: 0.2294	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9883	Min score: 0.9239	#Pop: 128	#M+: 1394	#M-: 9
EvolutionarySearch		#s: 128	Time elapsed: 12.89
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.38 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 54.25 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1542	fail_ct: 166	Time elapsed: 2.99
GA Iter: 0	Max score: 0.6572	Min score: 0.1935	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0653	Min score: 0.8496	#Pop: 128	#M+: 1389	#M-: 26
EvolutionarySearch		#s: 128	Time elapsed: 10.53
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 20.63 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 57.51 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |    832 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    384 |
|   41 |        0.026 |        2267.27 |    192 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.837 ms	Trials: 9280	Used time : 8732 s	Next ID: 0	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.112 |        2140.39 |    448 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    384 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |    832 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    384 |
|   41 |        0.026 |        2267.27 |    192 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.835 ms	Trials: 9344	Used time : 8805 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.112 |        2140.39 |    448 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    384 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |    896 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    384 |
|   41 |        0.026 |        2267.27 |    192 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.035 |        2571.07 |    128 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.835 ms	Trials: 9408	Used time : 8891 s	Next ID: 51	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2011	fail_ct: 0	Time elapsed: 1.09
GA Iter: 0	Max score: 0.7231	Min score: 0.2956	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9848	Min score: 0.7641	#Pop: 128	#M+: 1376	#M-: 78
EvolutionarySearch		#s: 128	Time elapsed: 7.19
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.68 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 48.40 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1748	fail_ct: 1	Time elapsed: 1.46
GA Iter: 0	Max score: 0.6455	Min score: 0.2477	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0271	Min score: 0.9002	#Pop: 128	#M+: 1396	#M-: 13
EvolutionarySearch		#s: 128	Time elapsed: 9.59
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.24 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 43.84 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.034 |        1885.49 |    128 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.112 |        2140.39 |    448 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    384 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |    896 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    384 |
|   41 |        0.026 |        2267.27 |    192 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.833 ms	Trials: 9472	Used time : 8983 s	Next ID: 8	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.112 |        2140.39 |    448 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    384 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |    896 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    384 |
|   41 |        0.026 |        2267.27 |    192 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.829 ms	Trials: 9536	Used time : 9054 s	Next ID: 41	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.112 |        2140.39 |    448 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    384 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |    896 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    384 |
|   41 |        0.024 |        2461.41 |    256 |
|   42 |        0.031 |        1885.63 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1772	fail_ct: 0	Time elapsed: 3.17
GA Iter: 0	Max score: 0.7885	Min score: 0.2279	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9477	Min score: 0.8887	#Pop: 128	#M+: 1393	#M-: 12
EvolutionarySearch		#s: 128	Time elapsed: 18.57
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.825 ms	Trials: 9600	Used time : 9123 s	Next ID: 41	
.T***************************************************************Time elapsed for measurement: 29.51 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 60.24 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1746	fail_ct: 0	Time elapsed: 2.24
GA Iter: 0	Max score: 0.6095	Min score: 0.2257	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9101	#Pop: 128	#M+: 1389	#M-: 10
EvolutionarySearch		#s: 128	Time elapsed: 11.17
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.18 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 59.28 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1641	fail_ct: 139	Time elapsed: 1.11
GA Iter: 0	Max score: 0.6273	Min score: 0.2378	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9783	Min score: 0.8778	#Pop: 128	#M+: 1384	#M-: 12
EvolutionarySearch		#s: 128	Time elapsed: 12.04
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 23.27 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 57.77 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.112 |        2140.39 |    448 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    384 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |    896 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.033 |        2658.53 |    384 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.825 ms	Trials: 9664	Used time : 9235 s	Next ID: 40	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.112 |        2140.39 |    448 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    384 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.051 |        2576.56 |    192 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |    896 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2759.50 |    448 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.822 ms	Trials: 9728	Used time : 9322 s	Next ID: 32	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.112 |        2140.39 |    448 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    384 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.050 |        2581.56 |    256 |
|   33 |        0.023 |        1903.01 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1654	fail_ct: 129	Time elapsed: 1.35
GA Iter: 0	Max score: 0.8119	Min score: 0.2410	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0165	Min score: 0.8790	#Pop: 128	#M+: 1398	#M-: 10
EvolutionarySearch		#s: 128	Time elapsed: 11.30
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 24.85 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 37.86 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1999	fail_ct: 1	Time elapsed: 1.10
GA Iter: 0	Max score: 0.7862	Min score: 0.2890	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9731	Min score: 0.7958	#Pop: 128	#M+: 1385	#M-: 78
EvolutionarySearch		#s: 128	Time elapsed: 5.23
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.66 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 37.28 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1791	fail_ct: 0	Time elapsed: 2.32
GA Iter: 0	Max score: 0.7079	Min score: 0.2484	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9813	Min score: 0.9252	#Pop: 128	#M+: 1387	#M-: 10
EvolutionarySearch		#s: 128	Time elapsed: 7.88
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.27 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 49.35 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |    896 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2759.50 |    448 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.822 ms	Trials: 9792	Used time : 9417 s	Next ID: 32	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.112 |        2140.39 |    448 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    384 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        1947.19 |    128 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |    896 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2759.50 |    448 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.821 ms	Trials: 9856	Used time : 9493 s	Next ID: 35	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.112 |        2140.39 |    448 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    384 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |    896 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2759.50 |    448 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.820 ms	Trials: 9920	Used time : 9552 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.032 |        2230.34 |    128 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1722	fail_ct: 0	Time elapsed: 1.54
GA Iter: 0	Max score: 0.8364	Min score: 0.2861	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0051	Min score: 0.8640	#Pop: 128	#M+: 1387	#M-: 21
EvolutionarySearch		#s: 128	Time elapsed: 12.45
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.112 |        2140.39 |    448 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    384 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |    960 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2759.50 |    448 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.820 ms	Trials: 9984	Used time : 9626 s	Next ID: 2	
.T***************************************************************Time elapsed for measurement: 26.09 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 49.25 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1723	fail_ct: 0	Time elapsed: 1.86
GA Iter: 0	Max score: 0.6363	Min score: 0.3464	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9507	Min score: 0.8624	#Pop: 128	#M+: 1393	#M-: 64
EvolutionarySearch		#s: 128	Time elapsed: 6.24
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 11.89 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 16.58 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1949	fail_ct: 13	Time elapsed: 1.01
GA Iter: 0	Max score: 0.9245	Min score: 0.3893	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9782	Min score: 0.6892	#Pop: 128	#M+: 1368	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 6.52
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 19.66 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 37.37 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.112 |        2140.39 |    448 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    384 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |    960 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2759.50 |    448 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.816 ms	Trials: 10048	Used time : 9716 s	Next ID: 18	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.016 |         998.36 |     64 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    512 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    384 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |    960 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2759.50 |    448 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.815 ms	Trials: 10112	Used time : 9752 s	Next ID: 12	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    512 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    384 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1638	fail_ct: 141	Time elapsed: 1.21
GA Iter: 0	Max score: 0.7575	Min score: 0.2514	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9859	Min score: 0.8959	#Pop: 128	#M+: 1396	#M-: 10
EvolutionarySearch		#s: 128	Time elapsed: 7.80
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.34 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 30.73 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1992	fail_ct: 1	Time elapsed: 1.78
GA Iter: 0	Max score: 0.7497	Min score: 0.2764	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9492	Min score: 0.6743	#Pop: 128	#M+: 1384	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 6.94
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.93 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 46.25 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1746	fail_ct: 0	Time elapsed: 2.11
GA Iter: 0	Max score: 0.7280	Min score: 0.2282	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9566	Min score: 0.7966	#Pop: 128	#M+: 1386	#M-: 22
EvolutionarySearch		#s: 128	Time elapsed: 6.65
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 10.84 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 5.21 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |    960 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2759.50 |    448 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.807 ms	Trials: 10176	Used time : 9817 s	Next ID: 27	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    512 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    448 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |    960 |
|   38 |        0.032 |        1608.42 |    128 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2759.50 |    448 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.807 ms	Trials: 10240	Used time : 9870 s	Next ID: 38	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    512 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    448 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |    960 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2759.50 |    448 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.031 |        1885.63 |    128 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.799 ms	Trials: 10304	Used time : 9943 s	Next ID: 42	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1799	fail_ct: 0	Time elapsed: 1.02
GA Iter: 0	Max score: 0.6970	Min score: 0.2755	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9879	Min score: 0.9293	#Pop: 128	#M+: 1389	#M-: 9
EvolutionarySearch		#s: 128	Time elapsed: 5.18
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.27 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 46.62 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2006	fail_ct: 2	Time elapsed: 0.93
GA Iter: 0	Max score: 0.6989	Min score: 0.2776	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9508	Min score: 0.7575	#Pop: 128	#M+: 1390	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 5.57
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.68 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 48.07 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    512 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    448 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |    960 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2759.50 |    448 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.797 ms	Trials: 10368	Used time : 9968 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    512 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    448 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1024 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2759.50 |    448 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.015 |        1917.99 |    128 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.797 ms	Trials: 10432	Used time : 10036 s	Next ID: 47	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    512 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    448 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1024 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2759.50 |    448 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1823	fail_ct: 0	Time elapsed: 2.84
GA Iter: 0	Max score: 0.6550	Min score: 0.2818	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9904	Min score: 0.9302	#Pop: 128	#M+: 1383	#M-: 13
EvolutionarySearch		#s: 128	Time elapsed: 13.71
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.796 ms	Trials: 10496	Used time : 10103 s	Next ID: 37	
.T***************************************************************Time elapsed for measurement: 28.34 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 46.20 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1741	fail_ct: 0	Time elapsed: 1.86
GA Iter: 0	Max score: 0.5491	Min score: 0.2015	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0022	Min score: 0.7769	#Pop: 128	#M+: 1377	#M-: 20
EvolutionarySearch		#s: 128	Time elapsed: 9.86
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 21.45 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 56.01 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1622	fail_ct: 160	Time elapsed: 1.44
GA Iter: 0	Max score: 0.7109	Min score: 0.2362	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9868	Min score: 0.9263	#Pop: 128	#M+: 1397	#M-: 19
EvolutionarySearch		#s: 128	Time elapsed: 6.02
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.27 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 50.46 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.029 |        2520.50 |    128 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    512 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    448 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1088 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2759.50 |    448 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.796 ms	Trials: 10560	Used time : 10195 s	Next ID: 11	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    512 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    448 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.043 |        2517.96 |    192 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1088 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2759.50 |    448 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.795 ms	Trials: 10624	Used time : 10285 s	Next ID: 31	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    512 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    448 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.041 |        2647.32 |    256 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1607	fail_ct: 159	Time elapsed: 1.53
GA Iter: 0	Max score: 0.5896	Min score: 0.2229	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9831	Min score: 0.9125	#Pop: 128	#M+: 1390	#M-: 21
EvolutionarySearch		#s: 128	Time elapsed: 7.33
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.81 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 51.28 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1752	fail_ct: 0	Time elapsed: 1.63
GA Iter: 0	Max score: 0.6786	Min score: 0.3384	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9523	Min score: 0.8425	#Pop: 128	#M+: 1374	#M-: 65
EvolutionarySearch		#s: 128	Time elapsed: 10.11
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.62 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 45.60 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1764	fail_ct: 0	Time elapsed: 1.50
GA Iter: 0	Max score: 0.7401	Min score: 0.2352	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0452	Min score: 0.8723	#Pop: 128	#M+: 1388	#M-: 10
EvolutionarySearch		#s: 128	Time elapsed: 7.39
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 11.87 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 38.25 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1088 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2759.50 |    448 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.792 ms	Trials: 10688	Used time : 10359 s	Next ID: 31	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    512 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    448 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1088 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2759.50 |    448 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.792 ms	Trials: 10752	Used time : 10432 s	Next ID: 18	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    576 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    448 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1088 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2759.50 |    448 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.028 |        2597.09 |    128 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.792 ms	Trials: 10816	Used time : 10507 s	Next ID: 54	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1682	fail_ct: 123	Time elapsed: 0.98
GA Iter: 0	Max score: 0.6352	Min score: 0.2511	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9798	Min score: 0.7867	#Pop: 128	#M+: 1378	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 4.91
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 9.60 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 26.39 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1763	fail_ct: 0	Time elapsed: 2.09
GA Iter: 0	Max score: 0.6889	Min score: 0.2182	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9649	Min score: 0.8853	#Pop: 128	#M+: 1384	#M-: 9
EvolutionarySearch		#s: 128	Time elapsed: 10.12
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.80 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 57.70 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    384 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    576 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    448 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1088 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2759.50 |    448 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.792 ms	Trials: 10880	Used time : 10566 s	Next ID: 7	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    576 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    448 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1088 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2759.50 |    448 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.792 ms	Trials: 10944	Used time : 10608 s	Next ID: 40	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    576 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    448 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.014 |         708.74 |     64 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1088 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    512 |
|   41 |        0.024 |        2461.41 |    320 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2006	fail_ct: 0	Time elapsed: 1.92
GA Iter: 0	Max score: 0.9171	Min score: 0.3940	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9643	Min score: 0.6851	#Pop: 128	#M+: 1371	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 6.71
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 24.83 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 36.55 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1638	fail_ct: 145	Time elapsed: 2.16
GA Iter: 0	Max score: 0.8685	Min score: 0.2336	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0083	Min score: 0.9057	#Pop: 128	#M+: 1394	#M-: 10
EvolutionarySearch		#s: 128	Time elapsed: 10.48
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.54 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 43.12 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1560	fail_ct: 124	Time elapsed: 1.26
GA Iter: 0	Max score: 0.6239	Min score: 0.1920	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0019	Min score: 0.7626	#Pop: 128	#M+: 1384	#M-: 31
EvolutionarySearch		#s: 128	Time elapsed: 6.92
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.51 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 42.38 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.791 ms	Trials: 11008	Used time : 10692 s	Next ID: 34	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    576 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.048 |        2734.48 |    448 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1088 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    512 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.784 ms	Trials: 11072	Used time : 10763 s	Next ID: 27	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    576 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    192 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    512 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1088 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    512 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.784 ms	Trials: 11136	Used time : 10834 s	Next ID: 21	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1574	fail_ct: 137	Time elapsed: 1.67
GA Iter: 0	Max score: 0.5773	Min score: 0.1897	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9575	Min score: 0.7983	#Pop: 128	#M+: 1389	#M-: 25
EvolutionarySearch		#s: 128	Time elapsed: 7.50
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    576 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    256 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    512 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1088 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    512 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.784 ms	Trials: 11200	Used time : 10902 s	Next ID: 21	
.T***************************************************************Time elapsed for measurement: 24.58 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 38.68 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1801	fail_ct: 0	Time elapsed: 2.49
GA Iter: 0	Max score: 0.6784	Min score: 0.2778	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9873	Min score: 0.9307	#Pop: 128	#M+: 1394	#M-: 10
EvolutionarySearch		#s: 128	Time elapsed: 11.14
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 20.37 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 56.45 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2013	fail_ct: 0	Time elapsed: 1.06
GA Iter: 0	Max score: 0.6995	Min score: 0.2514	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9800	Min score: 0.8247	#Pop: 128	#M+: 1377	#M-: 66
EvolutionarySearch		#s: 128	Time elapsed: 5.06
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.55 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 45.89 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    576 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    512 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1088 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    512 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.784 ms	Trials: 11264	Used time : 10974 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    576 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    512 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1152 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    512 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.014 |        1913.79 |    128 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.784 ms	Trials: 11328	Used time : 11065 s	Next ID: 56	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    576 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    512 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1737	fail_ct: 0	Time elapsed: 1.62
GA Iter: 0	Max score: 0.8479	Min score: 0.2660	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0449	Min score: 0.8751	#Pop: 128	#M+: 1400	#M-: 21
EvolutionarySearch		#s: 128	Time elapsed: 8.44
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.31 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 50.60 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1537	fail_ct: 134	Time elapsed: 1.31
GA Iter: 0	Max score: 0.5106	Min score: 0.1606	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9732	Min score: 0.7943	#Pop: 128	#M+: 1372	#M-: 18
EvolutionarySearch		#s: 128	Time elapsed: 6.44
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.04 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 44.63 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1488	fail_ct: 145	Time elapsed: 1.37
GA Iter: 0	Max score: 0.7263	Min score: 0.1706	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9774	Min score: 0.8524	#Pop: 128	#M+: 1399	#M-: 19
EvolutionarySearch		#s: 128	Time elapsed: 8.32
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.43 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 41.48 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1152 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    512 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.027 |        2147.61 |    128 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.783 ms	Trials: 11392	Used time : 11130 s	Next ID: 48	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    576 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    512 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1152 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    512 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2272.68 |    192 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.779 ms	Trials: 11456	Used time : 11206 s	Next ID: 49	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    576 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    512 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1152 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    512 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2279.92 |    256 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.778 ms	Trials: 11520	Used time : 11273 s	Next ID: 49	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1811	fail_ct: 0	Time elapsed: 2.30
GA Iter: 0	Max score: 0.7532	Min score: 0.2509	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0001	Min score: 0.9326	#Pop: 128	#M+: 1394	#M-: 15
EvolutionarySearch		#s: 128	Time elapsed: 9.75
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.49 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 54.56 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1616	fail_ct: 143	Time elapsed: 1.52
GA Iter: 0	Max score: 0.8700	Min score: 0.2320	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0264	Min score: 0.9158	#Pop: 128	#M+: 1384	#M-: 9
EvolutionarySearch		#s: 128	Time elapsed: 6.97
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 11.31 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 61.37 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    576 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    512 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1152 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    512 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.778 ms	Trials: 11584	Used time : 11337 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.019 |        2278.59 |    192 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    576 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    512 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1216 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    512 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.778 ms	Trials: 11648	Used time : 11417 s	Next ID: 16	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    256 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    576 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    512 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1216 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    512 |
|   41 |        0.024 |        2461.41 |    320 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1600	fail_ct: 145	Time elapsed: 0.84
GA Iter: 0	Max score: 0.8368	Min score: 0.2606	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9880	Min score: 0.8932	#Pop: 128	#M+: 1391	#M-: 10
EvolutionarySearch		#s: 128	Time elapsed: 5.10
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 11.05 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 22.88 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1730	fail_ct: 0	Time elapsed: 1.47
GA Iter: 0	Max score: 0.6744	Min score: 0.2283	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0577	Min score: 0.8801	#Pop: 128	#M+: 1382	#M-: 52
EvolutionarySearch		#s: 128	Time elapsed: 6.78
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 19.79 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 53.56 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1790	fail_ct: 0	Time elapsed: 1.01
GA Iter: 0	Max score: 0.7867	Min score: 0.2127	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0204	Min score: 0.8530	#Pop: 128	#M+: 1391	#M-: 36
EvolutionarySearch		#s: 128	Time elapsed: 7.87
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.96 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 44.76 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.776 ms	Trials: 11712	Used time : 11498 s	Next ID: 16	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    576 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    512 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1216 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    512 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.038 |        2281.64 |    192 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.776 ms	Trials: 11776	Used time : 11539 s	Next ID: 46	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    576 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    512 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1216 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    512 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.033 |        2605.77 |    256 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.772 ms	Trials: 11840	Used time : 11620 s	Next ID: 46	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1739	fail_ct: 0	Time elapsed: 2.58
GA Iter: 0	Max score: 0.6466	Min score: 0.3245	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9665	Min score: 0.8563	#Pop: 128	#M+: 1397	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 12.44
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.65 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 37.09 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2007	fail_ct: 3	Time elapsed: 0.86
GA Iter: 0	Max score: 0.7474	Min score: 0.2760	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9451	Min score: 0.8280	#Pop: 128	#M+: 1377	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 5.94
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 11.00 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 44.15 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    576 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    512 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1216 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    512 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.772 ms	Trials: 11904	Used time : 11691 s	Next ID: 18	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    640 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    512 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1216 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    512 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    128 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.772 ms	Trials: 11968	Used time : 11757 s	Next ID: 55	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    640 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    512 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1216 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    512 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1802	fail_ct: 0	Time elapsed: 2.05
GA Iter: 0	Max score: 0.8003	Min score: 0.2702	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9896	Min score: 0.9320	#Pop: 128	#M+: 1393	#M-: 16
EvolutionarySearch		#s: 128	Time elapsed: 9.63
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 19.72 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 59.47 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1763	fail_ct: 0	Time elapsed: 1.38
GA Iter: 0	Max score: 0.6885	Min score: 0.2272	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9707	Min score: 0.8879	#Pop: 128	#M+: 1388	#M-: 7
EvolutionarySearch		#s: 128	Time elapsed: 9.93
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.61 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 34.73 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1635	fail_ct: 154	Time elapsed: 0.89
GA Iter: 0	Max score: 0.6242	Min score: 0.2306	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9872	Min score: 0.9009	#Pop: 128	#M+: 1396	#M-: 10
EvolutionarySearch		#s: 128	Time elapsed: 6.69
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 11.36 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 35.39 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.772 ms	Trials: 12032	Used time : 11820 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    640 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    512 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1280 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    512 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.772 ms	Trials: 12096	Used time : 11911 s	Next ID: 40	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    640 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    512 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1280 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    576 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.772 ms	Trials: 12160	Used time : 11970 s	Next ID: 27	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    640 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1983	fail_ct: 0	Time elapsed: 1.56
GA Iter: 0	Max score: 0.8082	Min score: 0.2730	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9474	Min score: 0.8428	#Pop: 128	#M+: 1376	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 7.93
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.34 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 54.60 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1745	fail_ct: 0	Time elapsed: 2.29
GA Iter: 0	Max score: 0.8252	Min score: 0.2201	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9933	Min score: 0.8692	#Pop: 128	#M+: 1394	#M-: 33
EvolutionarySearch		#s: 128	Time elapsed: 10.96
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.46 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 43.10 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    576 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    320 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1280 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    576 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.772 ms	Trials: 12224	Used time : 12025 s	Next ID: 30	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    640 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    576 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.035 |        2469.57 |    192 |
|   37 |        0.230 |        3025.90 |   1280 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    576 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.772 ms	Trials: 12288	Used time : 12104 s	Next ID: 36	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    640 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    576 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.033 |        2624.85 |    256 |
|   37 |        0.230 |        3025.90 |   1280 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    576 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1766	fail_ct: 0	Time elapsed: 1.56
GA Iter: 0	Max score: 0.6509	Min score: 0.2344	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9522	Min score: 0.8926	#Pop: 128	#M+: 1381	#M-: 35
EvolutionarySearch		#s: 128	Time elapsed: 7.49
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 18.21 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 67.47 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1837	fail_ct: 0	Time elapsed: 2.19
GA Iter: 0	Max score: 0.7142	Min score: 0.2768	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9779	Min score: 0.9310	#Pop: 128	#M+: 1396	#M-: 12
EvolutionarySearch		#s: 128	Time elapsed: 8.91
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 18.32 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 40.62 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1604	fail_ct: 151	Time elapsed: 1.46
GA Iter: 0	Max score: 0.6955	Min score: 0.2465	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9844	Min score: 0.8642	#Pop: 128	#M+: 1390	#M-: 21
EvolutionarySearch		#s: 128	Time elapsed: 9.95
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.769 ms	Trials: 12352	Used time : 12175 s	Next ID: 36	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    640 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    576 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1280 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    576 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.769 ms	Trials: 12416	Used time : 12270 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    640 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    576 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.023 |        1903.01 |    128 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1344 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    576 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.769 ms	Trials: 12480	Used time : 12340 s	Next ID: 33	
.T***************************************************************Time elapsed for measurement: 26.48 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 40.71 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1922	fail_ct: 19	Time elapsed: 0.79
GA Iter: 0	Max score: 0.7741	Min score: 0.2467	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9768	Min score: 0.7647	#Pop: 128	#M+: 1394	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 3.64
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.52 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 48.89 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1943	fail_ct: 11	Time elapsed: 1.38
GA Iter: 0	Max score: 0.7257	Min score: 0.2533	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9496	Min score: 0.7801	#Pop: 128	#M+: 1377	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 6.60
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.84 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 51.27 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2070.88 |    192 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    640 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    576 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1344 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    576 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.766 ms	Trials: 12544	Used time : 12419 s	Next ID: 0	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2095.24 |    256 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    640 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    576 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1344 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    576 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.765 ms	Trials: 12608	Used time : 12488 s	Next ID: 0	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    640 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    576 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.019 |        2259.43 |    192 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1751	fail_ct: 0	Time elapsed: 1.72
GA Iter: 0	Max score: 0.5990	Min score: 0.3076	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9649	Min score: 0.8723	#Pop: 128	#M+: 1385	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 8.89
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 25.29 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 58.01 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1968	fail_ct: 10	Time elapsed: 1.12
GA Iter: 0	Max score: 0.6686	Min score: 0.2352	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9449	Min score: 0.7187	#Pop: 128	#M+: 1370	#M-: 68
EvolutionarySearch		#s: 128	Time elapsed: 5.01
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.46 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 54.46 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1959	fail_ct: 11	Time elapsed: 1.17
GA Iter: 0	Max score: 0.5719	Min score: 0.2607	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9840	Min score: 0.7211	#Pop: 128	#M+: 1387	#M-: 80
EvolutionarySearch		#s: 128	Time elapsed: 4.85
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 20.21 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 59.13 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1344 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    576 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.765 ms	Trials: 12672	Used time : 12565 s	Next ID: 18	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    704 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    576 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1344 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    576 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1732.81 |    192 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.765 ms	Trials: 12736	Used time : 12659 s	Next ID: 45	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    704 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    576 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1344 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    576 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1735.40 |    256 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.765 ms	Trials: 12800	Used time : 12736 s	Next ID: 45	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1988	fail_ct: 1	Time elapsed: 1.87
GA Iter: 0	Max score: 0.6596	Min score: 0.2220	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9550	Min score: 0.7965	#Pop: 128	#M+: 1377	#M-: 85
EvolutionarySearch		#s: 128	Time elapsed: 8.36
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 21.14 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 34.96 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2001	fail_ct: 0	Time elapsed: 1.06
GA Iter: 0	Max score: 0.6362	Min score: 0.2422	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9644	Min score: 0.8337	#Pop: 128	#M+: 1377	#M-: 83
EvolutionarySearch		#s: 128	Time elapsed: 5.56
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.66 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 51.07 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    704 |
|   19 |        0.011 |        1979.61 |    192 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    576 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1344 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    576 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.765 ms	Trials: 12864	Used time : 12822 s	Next ID: 19	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    704 |
|   19 |        0.011 |        1979.61 |    256 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    576 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1344 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    576 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.765 ms	Trials: 12928	Used time : 12889 s	Next ID: 19	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    704 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    576 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1344 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    576 |
|   41 |        0.024 |        2461.41 |    320 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1807	fail_ct: 0	Time elapsed: 2.04
GA Iter: 0	Max score: 0.6504	Min score: 0.2617	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9883	Min score: 0.9290	#Pop: 128	#M+: 1397	#M-: 15
EvolutionarySearch		#s: 128	Time elapsed: 10.81
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.92 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 49.46 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1597	fail_ct: 147	Time elapsed: 2.23
GA Iter: 0	Max score: 0.5894	Min score: 0.1892	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0091	Min score: 0.8853	#Pop: 128	#M+: 1385	#M-: 17
EvolutionarySearch		#s: 128	Time elapsed: 8.99
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 18.62 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 39.73 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1560	fail_ct: 156	Time elapsed: 2.06
GA Iter: 0	Max score: 0.6533	Min score: 0.1913	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9969	Min score: 0.8949	#Pop: 128	#M+: 1390	#M-: 12
EvolutionarySearch		#s: 128	Time elapsed: 8.93
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.17 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 60.69 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.765 ms	Trials: 12992	Used time : 12959 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    704 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    576 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1408 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    576 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2758.76 |    192 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.765 ms	Trials: 13056	Used time : 13036 s	Next ID: 51	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    704 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    576 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1408 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    576 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    256 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.765 ms	Trials: 13120	Used time : 13106 s	Next ID: 51	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1990	fail_ct: 0	Time elapsed: 1.11
GA Iter: 0	Max score: 0.8754	Min score: 0.2572	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9752	Min score: 0.8278	#Pop: 128	#M+: 1379	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 6.02
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 23.29 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 46.28 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1995	fail_ct: 0	Time elapsed: 1.72
GA Iter: 0	Max score: 0.7389	Min score: 0.2649	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9753	Min score: 0.8433	#Pop: 128	#M+: 1382	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 7.17
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 9.96 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 18.57 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    704 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    576 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    192 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1408 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    576 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.765 ms	Trials: 13184	Used time : 13191 s	Next ID: 35	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    704 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    576 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    256 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1408 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    576 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.765 ms	Trials: 13248	Used time : 13268 s	Next ID: 35	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    704 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    576 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1408 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    576 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1779	fail_ct: 0	Time elapsed: 0.90
GA Iter: 0	Max score: 0.7171	Min score: 0.2516	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9740	Min score: 0.8912	#Pop: 128	#M+: 1394	#M-: 8
EvolutionarySearch		#s: 128	Time elapsed: 5.40
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 8.79 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 42.64 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1627	fail_ct: 144	Time elapsed: 1.45
GA Iter: 0	Max score: 0.7719	Min score: 0.2387	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9856	Min score: 0.9092	#Pop: 128	#M+: 1406	#M-: 13
EvolutionarySearch		#s: 128	Time elapsed: 8.37
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.27 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 75.84 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1670	fail_ct: 116	Time elapsed: 1.41
GA Iter: 0	Max score: 0.7741	Min score: 0.2405	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9589	Min score: 0.8154	#Pop: 128	#M+: 1378	#M-: 66
EvolutionarySearch		#s: 128	Time elapsed: 6.29
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 20.39 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 46.60 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.765 ms	Trials: 13312	Used time : 13306 s	Next ID: 40	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    704 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    576 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1408 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    640 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.765 ms	Trials: 13376	Used time : 13364 s	Next ID: 27	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    448 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    704 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    640 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1408 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    640 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.765 ms	Trials: 13440	Used time : 13463 s	Next ID: 7	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.021 |        2074.48 |    128 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    512 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    704 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2004	fail_ct: 0	Time elapsed: 1.26
GA Iter: 0	Max score: 0.7810	Min score: 0.2968	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9849	Min score: 0.7664	#Pop: 128	#M+: 1395	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 6.60
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.82 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 47.27 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1781	fail_ct: 0	Time elapsed: 2.40
GA Iter: 0	Max score: 0.7589	Min score: 0.2422	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9838	Min score: 0.9306	#Pop: 128	#M+: 1392	#M-: 17
EvolutionarySearch		#s: 128	Time elapsed: 8.67
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.40 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 38.86 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    640 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1408 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    640 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.765 ms	Trials: 13504	Used time : 13538 s	Next ID: 4	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    512 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    704 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    640 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1408 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    640 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.764 ms	Trials: 13568	Used time : 13608 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    512 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    704 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    640 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1472 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.010 |        1389.59 |     64 |
|   40 |        0.031 |        2768.99 |    640 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1973	fail_ct: 2	Time elapsed: 1.31
GA Iter: 0	Max score: 0.8689	Min score: 0.2715	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8884	Min score: 0.6320	#Pop: 128	#M+: 1383	#M-: 68
EvolutionarySearch		#s: 128	Time elapsed: 6.92
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 21.68 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 61.92 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 154	fail_ct: 1655	Time elapsed: 1.22
GA Iter: 0	Max score: 0.7088	Min score: 0.0649	#Pop: 80	#M+: 0	#M-: 0
[18:37:58] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [18:37:58] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[18:37:58] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [18:37:58] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[18:37:59] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [18:37:59] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[18:37:59] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [18:37:59] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[18:38:00] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [18:38:00] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[18:38:01] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [18:38:01] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[18:38:01] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [18:38:01] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[18:38:01] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [18:38:01] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[18:38:01] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [18:38:01] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[18:38:01] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [18:38:01] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[18:38:01] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [18:38:01] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[18:38:01] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [18:38:01] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[18:38:01] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [18:38:01] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[18:38:01] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [18:38:01] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[18:38:02] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (None)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (None)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (None)
      for ax4 (None)
        tensor = ...

with: [18:38:02] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[18:38:02] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [18:38:02] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[18:38:02] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [18:38:02] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[18:38:02] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [18:38:02] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[18:38:02] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [18:38:02] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[18:38:02] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [18:38:02] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[18:38:02] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [18:38:02] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.7732	Min score: 0.4060	#Pop: 128	#M+: 436	#M-: 6319
EvolutionarySearch		#s: 128	Time elapsed: 5.73
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.27 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 45.82 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2025	fail_ct: 0	Time elapsed: 1.17
GA Iter: 0	Max score: 0.7622	Min score: 0.3296	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0310	Min score: 0.8266	#Pop: 128	#M+: 1385	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 4.98
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.59 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 50.71 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.764 ms	Trials: 13632	Used time : 13673 s	Next ID: 39	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    512 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    128 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    704 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    640 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1472 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    640 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.762 ms	Trials: 13696	Used time : 13765 s	Next ID: 14	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    512 |
|    8 |        0.031 |        2071.72 |    192 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    704 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    640 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1472 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    640 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.762 ms	Trials: 13760	Used time : 13831 s	Next ID: 8	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    512 |
|    8 |        0.031 |        2111.34 |    256 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    704 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    128 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    640 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2015	fail_ct: 0	Time elapsed: 1.77
GA Iter: 0	Max score: 0.7625	Min score: 0.2771	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9535	Min score: 0.8543	#Pop: 128	#M+: 1373	#M-: 69
EvolutionarySearch		#s: 128	Time elapsed: 6.89
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 11.94 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 62.77 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1990	fail_ct: 0	Time elapsed: 1.36
GA Iter: 0	Max score: 0.7489	Min score: 0.2323	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9551	Min score: 0.7698	#Pop: 128	#M+: 1372	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 7.61
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 17.21 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 47.17 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1652	fail_ct: 140	Time elapsed: 1.70
GA Iter: 0	Max score: 0.8061	Min score: 0.2481	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9813	Min score: 0.8642	#Pop: 128	#M+: 1390	#M-: 11
EvolutionarySearch		#s: 128	Time elapsed: 8.70
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 17.44 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 43.00 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1472 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    640 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.762 ms	Trials: 13824	Used time : 13902 s	Next ID: 23	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.021 |        2116.21 |    128 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    512 |
|    8 |        0.031 |        2111.34 |    256 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    704 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    640 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1472 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    640 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.762 ms	Trials: 13888	Used time : 13986 s	Next ID: 1	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    512 |
|    8 |        0.031 |        2111.34 |    256 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    704 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    640 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    320 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1472 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    640 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.761 ms	Trials: 13952	Used time : 14060 s	Next ID: 32	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1751	fail_ct: 0	Time elapsed: 1.76
GA Iter: 0	Max score: 0.6284	Min score: 0.3619	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9686	Min score: 0.8769	#Pop: 128	#M+: 1383	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 9.77
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.29 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 27.33 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1810	fail_ct: 0	Time elapsed: 1.57
GA Iter: 0	Max score: 0.7352	Min score: 0.2456	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9690	Min score: 0.9296	#Pop: 128	#M+: 1384	#M-: 14
EvolutionarySearch		#s: 128	Time elapsed: 7.61
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.95 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 53.86 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    512 |
|    8 |        0.031 |        2111.34 |    256 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2162.08 |    704 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    640 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1472 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    640 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.761 ms	Trials: 14016	Used time : 14131 s	Next ID: 18	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    512 |
|    8 |        0.031 |        2111.34 |    256 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2163.28 |    768 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    640 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1472 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    640 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.761 ms	Trials: 14080	Used time : 14183 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    512 |
|    8 |        0.031 |        2111.34 |    256 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2163.28 |    768 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    640 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1536 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1780	fail_ct: 0	Time elapsed: 1.36
GA Iter: 0	Max score: 0.7327	Min score: 0.2192	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0001	Min score: 0.8947	#Pop: 128	#M+: 1388	#M-: 14
EvolutionarySearch		#s: 128	Time elapsed: 9.50
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.63 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 57.68 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1706	fail_ct: 0	Time elapsed: 2.28
GA Iter: 0	Max score: 0.7431	Min score: 0.1959	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0162	Min score: 0.7763	#Pop: 128	#M+: 1393	#M-: 19
EvolutionarySearch		#s: 128	Time elapsed: 11.30
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 20.69 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 54.80 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1991	fail_ct: 0	Time elapsed: 0.94
GA Iter: 0	Max score: 0.7607	Min score: 0.2490	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9406	Min score: 0.7892	#Pop: 128	#M+: 1383	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 4.22
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.53 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 50.20 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    640 |
|   41 |        0.024 |        2461.41 |    320 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.761 ms	Trials: 14144	Used time : 14263 s	Next ID: 41	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    512 |
|    8 |        0.031 |        2111.34 |    256 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2163.28 |    768 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    640 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1536 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    640 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.029 |        2003.69 |    192 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.761 ms	Trials: 14208	Used time : 14345 s	Next ID: 42	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    512 |
|    8 |        0.031 |        2111.34 |    256 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2163.28 |    768 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    640 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1536 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    640 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    256 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    192 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.760 ms	Trials: 14272	Used time : 14435 s	Next ID: 47	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    512 |
|    8 |        0.031 |        2111.34 |    256 |
|    9 |        0.012 |        2193.95 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2009	fail_ct: 1	Time elapsed: 1.63
GA Iter: 0	Max score: 0.7146	Min score: 0.2491	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9492	Min score: 0.8429	#Pop: 128	#M+: 1369	#M-: 63
EvolutionarySearch		#s: 128	Time elapsed: 7.33
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.45 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 38.78 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1827	fail_ct: 0	Time elapsed: 2.22
GA Iter: 0	Max score: 0.7141	Min score: 0.2485	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9817	Min score: 0.9304	#Pop: 128	#M+: 1397	#M-: 16
EvolutionarySearch		#s: 128	Time elapsed: 10.57
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.55 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 47.12 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2163.28 |    768 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    640 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1536 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    640 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    256 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    256 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.760 ms	Trials: 14336	Used time : 14505 s	Next ID: 47	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    512 |
|    8 |        0.031 |        2111.34 |    256 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2163.28 |    768 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    640 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1536 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    640 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    256 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.760 ms	Trials: 14400	Used time : 14567 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    512 |
|    8 |        0.031 |        2111.34 |    256 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2163.28 |    768 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    640 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1600 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    640 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    256 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1618	fail_ct: 150	Time elapsed: 2.18
GA Iter: 0	Max score: 0.6266	Min score: 0.2131	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9860	Min score: 0.9095	#Pop: 128	#M+: 1389	#M-: 11
EvolutionarySearch		#s: 128	Time elapsed: 10.45
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.72 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 43.60 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2011	fail_ct: 1	Time elapsed: 1.27
GA Iter: 0	Max score: 0.6635	Min score: 0.2466	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9464	Min score: 0.8470	#Pop: 128	#M+: 1397	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 6.16
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.22 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 66.26 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1785	fail_ct: 0	Time elapsed: 2.40
GA Iter: 0	Max score: 0.8030	Min score: 0.2130	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9741	Min score: 0.8978	#Pop: 128	#M+: 1389	#M-: 8
EvolutionarySearch		#s: 128	Time elapsed: 10.72
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 17.04 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 49.20 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.760 ms	Trials: 14464	Used time : 14639 s	Next ID: 27	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    512 |
|    8 |        0.031 |        2111.34 |    256 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2163.28 |    768 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    704 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    384 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1600 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    640 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    256 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.760 ms	Trials: 14528	Used time : 14710 s	Next ID: 30	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    512 |
|    8 |        0.031 |        2111.34 |    256 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2163.28 |    768 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    704 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1600 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    640 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    256 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.760 ms	Trials: 14592	Used time : 14798 s	Next ID: 40	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    192 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    512 |
|    8 |        0.031 |        2111.34 |    256 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1731	fail_ct: 0	Time elapsed: 1.69
GA Iter: 0	Max score: 0.6974	Min score: 0.2301	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9799	Min score: 0.8648	#Pop: 128	#M+: 1388	#M-: 12
EvolutionarySearch		#s: 128	Time elapsed: 10.20
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.38 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 64.08 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1714	fail_ct: 0	Time elapsed: 2.08
GA Iter: 0	Max score: 0.6412	Min score: 0.2284	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9758	Min score: 0.8632	#Pop: 128	#M+: 1376	#M-: 16
EvolutionarySearch		#s: 128	Time elapsed: 9.54
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.11 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 52.23 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   18 |        0.111 |        2163.28 |    768 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    704 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1600 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    704 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    256 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.760 ms	Trials: 14656	Used time : 14878 s	Next ID: 2	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    256 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    512 |
|    8 |        0.031 |        2111.34 |    256 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2163.28 |    768 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    704 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1600 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    704 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    256 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.760 ms	Trials: 14720	Used time : 14969 s	Next ID: 2	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    512 |
|    8 |        0.031 |        2111.34 |    256 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2163.28 |    768 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    704 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1600 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    704 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    256 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2010	fail_ct: 1	Time elapsed: 0.71
GA Iter: 0	Max score: 0.8464	Min score: 0.3000	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9760	Min score: 0.8453	#Pop: 128	#M+: 1376	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 7.65
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.93 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 68.34 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1737	fail_ct: 0	Time elapsed: 2.26
GA Iter: 0	Max score: 0.7308	Min score: 0.3527	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9581	Min score: 0.8931	#Pop: 128	#M+: 1388	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 7.61
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 10.70 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 37.45 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1818	fail_ct: 0	Time elapsed: 2.43
GA Iter: 0	Max score: 0.7308	Min score: 0.2359	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9840	Min score: 0.9297	#Pop: 128	#M+: 1391	#M-: 20
EvolutionarySearch		#s: 128	Time elapsed: 11.22
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 23.05 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 76.88 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.760 ms	Trials: 14784	Used time : 15049 s	Next ID: 8	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    512 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.111 |        2163.28 |    768 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    704 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1600 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    704 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    256 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.760 ms	Trials: 14848	Used time : 15141 s	Next ID: 18	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    512 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.106 |        2258.61 |    832 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    704 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1600 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    704 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    256 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.756 ms	Trials: 14912	Used time : 15199 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2368.94 |    512 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.106 |        2258.61 |    832 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1630	fail_ct: 122	Time elapsed: 1.96
GA Iter: 0	Max score: 0.5826	Min score: 0.2584	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9782	Min score: 0.8200	#Pop: 128	#M+: 1381	#M-: 68
EvolutionarySearch		#s: 128	Time elapsed: 7.74
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 17.88 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 55.94 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1734	fail_ct: 0	Time elapsed: 2.27
GA Iter: 0	Max score: 0.5924	Min score: 0.2017	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0109	Min score: 0.8841	#Pop: 128	#M+: 1397	#M-: 11
EvolutionarySearch		#s: 128	Time elapsed: 12.35
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 19.37 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 40.75 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1497	fail_ct: 138	Time elapsed: 0.68
GA Iter: 0	Max score: 0.6538	Min score: 0.2140	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9547	Min score: 0.8532	#Pop: 128	#M+: 1397	#M-: 14
EvolutionarySearch		#s: 128	Time elapsed: 3.88
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 11.17 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 37.89 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    704 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1664 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    704 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    256 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.756 ms	Trials: 14976	Used time : 15313 s	Next ID: 7	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2374.74 |    576 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2642.87 |    192 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.106 |        2258.61 |    832 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    704 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1664 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    704 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    256 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.756 ms	Trials: 15040	Used time : 15397 s	Next ID: 11	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2374.74 |    576 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2704.17 |    256 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.106 |        2258.61 |    832 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.018 |        2081.82 |    128 |
|   27 |        0.047 |        2748.98 |    704 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1664 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    704 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    256 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.755 ms	Trials: 15104	Used time : 15472 s	Next ID: 26	

----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1739	fail_ct: 0	Time elapsed: 2.39
GA Iter: 0	Max score: 0.7365	Min score: 0.2412	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0057	Min score: 0.9224	#Pop: 128	#M+: 1386	#M-: 12
EvolutionarySearch		#s: 128	Time elapsed: 10.82
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 11.75 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 71.57 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1739	fail_ct: 0	Time elapsed: 2.34
GA Iter: 0	Max score: 0.7263	Min score: 0.2347	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0227	Min score: 0.9471	#Pop: 128	#M+: 1378	#M-: 11
EvolutionarySearch		#s: 128	Time elapsed: 11.78
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 24.34 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 68.28 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2374.74 |    576 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2704.17 |    256 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.106 |        2258.61 |    832 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    704 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1664 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    704 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    256 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2656.58 |    192 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.754 ms	Trials: 15168	Used time : 15526 s	Next ID: 54	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2374.74 |    576 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2704.17 |    256 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.106 |        2258.61 |    832 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    704 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1664 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    704 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    256 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2679.05 |    256 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.754 ms	Trials: 15232	Used time : 15623 s	Next ID: 54	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2374.74 |    576 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2704.17 |    256 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.106 |        2258.61 |    832 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    704 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1617	fail_ct: 257	Time elapsed: 0.57
GA Iter: 0	Max score: 0.9739	Min score: 0.7682	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9832	Min score: 0.8763	#Pop: 128	#M+: 1387	#M-: 78
EvolutionarySearch		#s: 128	Time elapsed: 2.60
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 11.43 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 54.71 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1615	fail_ct: 125	Time elapsed: 1.75
GA Iter: 0	Max score: 0.5932	Min score: 0.1919	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9803	Min score: 0.8159	#Pop: 128	#M+: 1391	#M-: 19
EvolutionarySearch		#s: 128	Time elapsed: 8.83
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.75 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 65.38 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1459	fail_ct: 161	Time elapsed: 1.68
GA Iter: 0	Max score: 0.8737	Min score: 0.2323	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0183	Min score: 0.8472	#Pop: 128	#M+: 1394	#M-: 24
EvolutionarySearch		#s: 128	Time elapsed: 7.82
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 23.72 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 44.84 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1664 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    704 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    256 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.009 |         228.03 |     64 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.753 ms	Trials: 15296	Used time : 15730 s	Next ID: 53	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2374.74 |    576 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2704.17 |    256 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.106 |        2258.61 |    832 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    320 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    704 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1664 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    704 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    256 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.752 ms	Trials: 15360	Used time : 15799 s	Next ID: 21	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2374.74 |    576 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2704.17 |    256 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.018 |        1775.17 |    128 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.106 |        2258.61 |    832 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    704 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1664 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    704 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    256 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.752 ms	Trials: 15424	Used time : 15892 s	Next ID: 15	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1811	fail_ct: 0	Time elapsed: 1.10
GA Iter: 0	Max score: 0.7989	Min score: 0.2533	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9854	Min score: 0.9291	#Pop: 128	#M+: 1394	#M-: 17
EvolutionarySearch		#s: 128	Time elapsed: 8.38
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.30 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 51.66 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1721	fail_ct: 0	Time elapsed: 2.33
GA Iter: 0	Max score: 0.6687	Min score: 0.2005	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9868	Min score: 0.9163	#Pop: 128	#M+: 1399	#M-: 13
EvolutionarySearch		#s: 128	Time elapsed: 10.91
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.21 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 63.53 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2374.74 |    576 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2704.17 |    256 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.106 |        2258.61 |    832 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    704 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1664 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    704 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    256 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.748 ms	Trials: 15488	Used time : 15971 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2374.74 |    576 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2704.17 |    256 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.106 |        2258.61 |    832 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    704 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1728 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    704 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    256 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.748 ms	Trials: 15552	Used time : 16048 s	Next ID: 11	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2374.74 |    576 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.106 |        2258.61 |    832 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    704 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1728 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    704 |
|   41 |        0.024 |        2461.41 |    384 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1521	fail_ct: 140	Time elapsed: 1.98
GA Iter: 0	Max score: 0.7466	Min score: 0.1865	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9641	Min score: 0.8409	#Pop: 128	#M+: 1383	#M-: 15
EvolutionarySearch		#s: 128	Time elapsed: 9.97
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.99 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 51.78 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2002	fail_ct: 0	Time elapsed: 1.13
GA Iter: 0	Max score: 0.7105	Min score: 0.2503	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9911	Min score: 0.8390	#Pop: 128	#M+: 1378	#M-: 68
EvolutionarySearch		#s: 128	Time elapsed: 5.77
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 23.67 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 52.87 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1612	fail_ct: 143	Time elapsed: 0.99
GA Iter: 0	Max score: 0.8277	Min score: 0.2213	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9910	Min score: 0.9349	#Pop: 128	#M+: 1384	#M-: 10
EvolutionarySearch		#s: 128	Time elapsed: 6.09
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.92 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 74.19 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   42 |        0.028 |        2074.72 |    256 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    320 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.748 ms	Trials: 15616	Used time : 16141 s	Next ID: 49	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2374.74 |    576 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.106 |        2258.61 |    832 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    704 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1728 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    704 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    256 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        1978.26 |    192 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.748 ms	Trials: 15680	Used time : 16222 s	Next ID: 56	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2374.74 |    576 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.106 |        2258.61 |    832 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    704 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1728 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    704 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    256 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        2029.29 |    256 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.748 ms	Trials: 15744	Used time : 16306 s	Next ID: 27	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2374.74 |    576 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1679	fail_ct: 0	Time elapsed: 1.78
GA Iter: 0	Max score: 0.7020	Min score: 0.1873	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9619	Min score: 0.7743	#Pop: 128	#M+: 1391	#M-: 17
EvolutionarySearch		#s: 128	Time elapsed: 8.24
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.86 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 68.32 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1763	fail_ct: 0	Time elapsed: 1.59
GA Iter: 0	Max score: 0.6376	Min score: 0.2285	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9693	Min score: 0.9082	#Pop: 128	#M+: 1399	#M-: 9
EvolutionarySearch		#s: 128	Time elapsed: 8.49
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 17.91 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 56.95 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.106 |        2258.61 |    832 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    768 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1728 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    704 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    256 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        2029.29 |    256 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.748 ms	Trials: 15808	Used time : 16403 s	Next ID: 42	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2374.74 |    576 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.106 |        2258.61 |    832 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    768 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1728 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    704 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        2029.29 |    256 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.748 ms	Trials: 15872	Used time : 16499 s	Next ID: 40	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2374.74 |    576 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.106 |        2258.61 |    832 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    768 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1728 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    768 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1731	fail_ct: 0	Time elapsed: 0.93
GA Iter: 0	Max score: 0.6517	Min score: 0.3124	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9308	Min score: 0.8641	#Pop: 128	#M+: 1379	#M-: 69
EvolutionarySearch		#s: 128	Time elapsed: 5.33
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 11.16 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 59.58 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1799	fail_ct: 0	Time elapsed: 2.51
GA Iter: 0	Max score: 0.7543	Min score: 0.2557	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9892	Min score: 0.9290	#Pop: 128	#M+: 1389	#M-: 17
EvolutionarySearch		#s: 128	Time elapsed: 10.52
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.90 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 81.56 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1935	fail_ct: 19	Time elapsed: 1.12
GA Iter: 0	Max score: 0.8947	Min score: 0.2775	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9764	Min score: 0.7830	#Pop: 128	#M+: 1385	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 6.46
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 19.65 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 62.23 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        2029.29 |    256 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.748 ms	Trials: 15936	Used time : 16584 s	Next ID: 18	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2374.74 |    576 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |    896 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    768 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1728 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    768 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        2029.29 |    256 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.742 ms	Trials: 16000	Used time : 16661 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2374.74 |    576 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |    896 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    768 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1792 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    768 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1518.57 |    128 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        2029.29 |    256 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.742 ms	Trials: 16064	Used time : 16771 s	Next ID: 43	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2374.74 |    576 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |    896 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1601	fail_ct: 151	Time elapsed: 2.01
GA Iter: 0	Max score: 0.5659	Min score: 0.2028	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9885	Min score: 0.9211	#Pop: 128	#M+: 1377	#M-: 17
EvolutionarySearch		#s: 128	Time elapsed: 9.63
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.42 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 41.09 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1646	fail_ct: 111	Time elapsed: 1.36
GA Iter: 0	Max score: 0.7136	Min score: 0.2751	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0051	Min score: 0.8911	#Pop: 128	#M+: 1384	#M-: 8
EvolutionarySearch		#s: 128	Time elapsed: 7.42
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.18 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 88.50 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    768 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.041 |        2660.61 |    320 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1792 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    768 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        2029.29 |    256 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.742 ms	Trials: 16128	Used time : 16861 s	Next ID: 31	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2374.74 |    576 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |    896 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    768 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.050 |        2607.25 |    384 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1792 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    768 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        2029.29 |    256 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.741 ms	Trials: 16192	Used time : 16930 s	Next ID: 32	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2374.74 |    576 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |    896 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.017 |        2170.93 |    128 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    768 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1792 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    768 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        2029.29 |    256 |
|   57 |        0.016 |        2047.68 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1988	fail_ct: 1	Time elapsed: 1.12
GA Iter: 0	Max score: 0.7604	Min score: 0.2818	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9827	Min score: 0.8118	#Pop: 128	#M+: 1386	#M-: 79
EvolutionarySearch		#s: 128	Time elapsed: 6.21
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.72 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 55.52 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1796	fail_ct: 0	Time elapsed: 2.49
GA Iter: 0	Max score: 0.8290	Min score: 0.2567	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9756	Min score: 0.9304	#Pop: 128	#M+: 1390	#M-: 17
EvolutionarySearch		#s: 128	Time elapsed: 12.01
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 22.88 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 59.94 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2007	fail_ct: 1	Time elapsed: 0.90
GA Iter: 0	Max score: 0.7359	Min score: 0.2821	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9611	Min score: 0.8408	#Pop: 128	#M+: 1405	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 4.62
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.55 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 78.87 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.740 ms	Trials: 16256	Used time : 17042 s	Next ID: 24	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2374.74 |    576 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |    896 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    768 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1792 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    768 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        2029.29 |    256 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.740 ms	Trials: 16320	Used time : 17122 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2374.74 |    576 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |    896 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    768 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1856 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    768 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    192 |
|   56 |        0.013 |        2029.29 |    256 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.740 ms	Trials: 16384	Used time : 17220 s	Next ID: 55	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2374.74 |    576 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |    896 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2214.70 |    128 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    768 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1984	fail_ct: 0	Time elapsed: 1.20
GA Iter: 0	Max score: 0.6899	Min score: 0.2219	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0080	Min score: 0.7981	#Pop: 128	#M+: 1377	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 7.36
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 11.72 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 68.30 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1768	fail_ct: 0	Time elapsed: 1.75
GA Iter: 0	Max score: 0.6955	Min score: 0.2247	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9928	Min score: 0.9058	#Pop: 128	#M+: 1379	#M-: 14
EvolutionarySearch		#s: 128	Time elapsed: 10.21
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.57 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 65.86 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2010	fail_ct: 0	Time elapsed: 1.61
GA Iter: 0	Max score: 0.8612	Min score: 0.2504	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9648	Min score: 0.8415	#Pop: 128	#M+: 1394	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 8.46
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.68 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 44.22 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1856 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    768 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    256 |
|   56 |        0.013 |        2029.29 |    256 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.740 ms	Trials: 16448	Used time : 17318 s	Next ID: 22	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2374.74 |    576 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |    896 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    768 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1856 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    768 |
|   41 |        0.024 |        2461.41 |    384 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    256 |
|   56 |        0.013 |        2029.29 |    256 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.739 ms	Trials: 16512	Used time : 17407 s	Next ID: 41	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2374.74 |    576 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |    896 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    768 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    448 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1856 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    768 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    256 |
|   56 |        0.013 |        2029.29 |    256 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.739 ms	Trials: 16576	Used time : 17500 s	Next ID: 30	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1616	fail_ct: 143	Time elapsed: 0.80
GA Iter: 0	Max score: 0.7435	Min score: 0.2420	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9610	Min score: 0.8331	#Pop: 128	#M+: 1390	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 3.94
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 9.55 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 51.24 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1752	fail_ct: 0	Time elapsed: 1.87
GA Iter: 0	Max score: 0.6844	Min score: 0.2889	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9704	Min score: 0.8311	#Pop: 128	#M+: 1379	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 10.77
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.70 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 30.34 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.073 |        2374.74 |    576 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |    896 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    768 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    512 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1856 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    768 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    256 |
|   56 |        0.013 |        2029.29 |    256 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.739 ms	Trials: 16640	Used time : 17569 s	Next ID: 7	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2445.66 |    640 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |    896 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    768 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    512 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1856 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    768 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    256 |
|   56 |        0.013 |        2029.29 |    256 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.737 ms	Trials: 16704	Used time : 17634 s	Next ID: 18	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2445.66 |    640 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |     64 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |    960 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    768 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    512 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1856 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 155	fail_ct: 1633	Time elapsed: 1.59
GA Iter: 0	Max score: 0.9879	Min score: 0.0612	#Pop: 104	#M+: 0	#M-: 0
[19:43:26] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,16)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,28)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,28)
      for ax4 (0,16)
        tensor = ...

with: [19:43:26] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 29)) && (ax3 >= 1)) && (ax3 < 29)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=16)), iter_var(ax2, range(min=0, ext=30)), iter_var(ax3, range(min=0, ext=30)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=16)), iter_var(ax2, range(min=0, ext=28)), iter_var(ax3, range(min=0, ext=28)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[19:43:26] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,16)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,28)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,28)
      for ax4 (0,16)
        tensor = ...

with: [19:43:26] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 29)) && (ax3 >= 1)) && (ax3 < 29)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=16)), iter_var(ax2, range(min=0, ext=30)), iter_var(ax3, range(min=0, ext=30)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=16)), iter_var(ax2, range(min=0, ext=28)), iter_var(ax3, range(min=0, ext=28)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[19:43:28] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (None)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (None)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (None)
      for ax4 (None)
        tensor = ...

with: [19:43:28] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 29)) && (ax3 >= 1)) && (ax3 < 29)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=16)), iter_var(ax2, range(min=0, ext=30)), iter_var(ax3, range(min=0, ext=30)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=16)), iter_var(ax2, range(min=0, ext=28)), iter_var(ax3, range(min=0, ext=28)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.9879	Min score: 0.3393	#Pop: 128	#M+: 403	#M-: 6510
EvolutionarySearch		#s: 128	Time elapsed: 5.76
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 11.69 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 62.54 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2014	fail_ct: 2	Time elapsed: 1.25
GA Iter: 0	Max score: 0.8858	Min score: 0.2634	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9607	Min score: 0.8441	#Pop: 128	#M+: 1375	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 7.55
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 18.66 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 50.05 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1603	fail_ct: 138	Time elapsed: 0.83
GA Iter: 0	Max score: 0.9115	Min score: 0.2173	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9844	Min score: 0.8818	#Pop: 128	#M+: 1404	#M-: 12
EvolutionarySearch		#s: 128	Time elapsed: 4.58
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.05 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 54.92 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    768 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    256 |
|   56 |        0.013 |        2029.29 |    256 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.737 ms	Trials: 16768	Used time : 17691 s	Next ID: 10	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2445.66 |    640 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |    960 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    768 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    512 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1856 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    768 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    256 |
|   56 |        0.013 |        2029.29 |    256 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.737 ms	Trials: 16832	Used time : 17772 s	Next ID: 56	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2445.66 |    640 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |    960 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    768 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    512 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1856 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    768 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    256 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.016 |        2047.68 |    128 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.736 ms	Trials: 16896	Used time : 17850 s	Next ID: 57	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2445.66 |    640 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1800	fail_ct: 0	Time elapsed: 2.29
GA Iter: 0	Max score: 0.6895	Min score: 0.2514	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9782	Min score: 0.9291	#Pop: 128	#M+: 1379	#M-: 18
EvolutionarySearch		#s: 128	Time elapsed: 10.09
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 19.84 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 61.37 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1630	fail_ct: 137	Time elapsed: 1.47
GA Iter: 0	Max score: 0.5618	Min score: 0.2060	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9912	Min score: 0.9262	#Pop: 128	#M+: 1388	#M-: 16
EvolutionarySearch		#s: 128	Time elapsed: 9.74
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 17.27 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 49.02 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |    960 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    768 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    512 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1856 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    768 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    256 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.734 ms	Trials: 16960	Used time : 17923 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2445.66 |    640 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |    960 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    768 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    512 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1920 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    768 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    256 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.734 ms	Trials: 17024	Used time : 18017 s	Next ID: 27	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2445.66 |    640 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |    960 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    832 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    512 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1920 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    768 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1751	fail_ct: 0	Time elapsed: 1.64
GA Iter: 0	Max score: 0.5916	Min score: 0.2110	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9669	Min score: 0.9151	#Pop: 128	#M+: 1390	#M-: 9
EvolutionarySearch		#s: 128	Time elapsed: 10.21
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.67 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 58.39 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1996	fail_ct: 0	Time elapsed: 1.21
GA Iter: 0	Max score: 0.6928	Min score: 0.2592	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9684	Min score: 0.7004	#Pop: 128	#M+: 1373	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 7.10
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    256 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.734 ms	Trials: 17088	Used time : 18095 s	Next ID: 40	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2445.66 |    640 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |    960 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    832 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    512 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1920 |
|   38 |        0.024 |        2158.05 |    192 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    832 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    256 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.734 ms	Trials: 17152	Used time : 18180 s	Next ID: 38	
.T***************************************************************Time elapsed for measurement: 27.81 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 62.80 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1987	fail_ct: 0	Time elapsed: 1.12
GA Iter: 0	Max score: 0.8523	Min score: 0.2487	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9390	Min score: 0.7612	#Pop: 128	#M+: 1378	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 6.50
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.42 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 60.25 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1828	fail_ct: 0	Time elapsed: 1.76
GA Iter: 0	Max score: 0.6324	Min score: 0.2239	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9875	Min score: 0.9310	#Pop: 128	#M+: 1388	#M-: 14
EvolutionarySearch		#s: 128	Time elapsed: 9.30
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2445.66 |    640 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |    960 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    832 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    512 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1920 |
|   38 |        0.021 |        2407.18 |    256 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    832 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    256 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.731 ms	Trials: 17216	Used time : 18280 s	Next ID: 38	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2445.66 |    640 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |    960 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    832 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    512 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1920 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    832 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    256 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.731 ms	Trials: 17280	Used time : 18362 s	Next ID: 37	
.T***************************************************************Time elapsed for measurement: 24.78 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 61.50 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1609	fail_ct: 126	Time elapsed: 2.06
GA Iter: 0	Max score: 0.6434	Min score: 0.2299	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0017	Min score: 0.9050	#Pop: 128	#M+: 1384	#M-: 8
EvolutionarySearch		#s: 128	Time elapsed: 9.75
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.99 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 64.71 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1749	fail_ct: 0	Time elapsed: 1.47
GA Iter: 0	Max score: 0.7549	Min score: 0.2579	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0008	Min score: 0.8902	#Pop: 128	#M+: 1389	#M-: 13
EvolutionarySearch		#s: 128	Time elapsed: 9.09
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 21.34 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 56.95 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2445.66 |    640 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2358.33 |    320 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |    960 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    832 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    512 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1984 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    832 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    256 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.731 ms	Trials: 17344	Used time : 18460 s	Next ID: 16	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2445.66 |    640 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |    960 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    832 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    512 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1984 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    832 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.023 |        2536.86 |    192 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    256 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.731 ms	Trials: 17408	Used time : 18551 s	Next ID: 48	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2445.66 |    640 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |    960 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    832 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    512 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1757	fail_ct: 0	Time elapsed: 1.40
GA Iter: 0	Max score: 0.6619	Min score: 0.2623	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9934	Min score: 0.8988	#Pop: 128	#M+: 1387	#M-: 14
EvolutionarySearch		#s: 128	Time elapsed: 9.27
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.13 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 68.16 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 156	fail_ct: 1641	Time elapsed: 1.70
GA Iter: 0	Max score: 1.0011	Min score: 0.0899	#Pop: 109	#M+: 0	#M-: 0
[20:00:52] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ (None)
  for ax1 (None)
    tensor auto_unroll: 16
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            for ax4 (None)
              for rv0 (None)
                for rv1 (None)
                  tensor = ...
    for ax2 (None)
      for ax0 (None)
        for ax1 (None)
          for ax2 (None)
            for ax3 (None)
              vectorize ax4 (None)
                pad_temp = ...
      for ax3 (None)
        for ax4 (None)
          tensor = ...

with: [20:00:52] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 29)) && (ax3 >= 1)) && (ax3 < 29)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=12)), iter_var(ax2, range(min=0, ext=30)), iter_var(ax3, range(min=0, ext=30)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=12)), iter_var(ax2, range(min=0, ext=28)), iter_var(ax3, range(min=0, ext=28)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[20:00:52] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,12)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,28)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,28)
      for ax4 (0,16)
        tensor = ...

with: [20:00:52] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 29)) && (ax3 >= 1)) && (ax3 < 29)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=12)), iter_var(ax2, range(min=0, ext=30)), iter_var(ax3, range(min=0, ext=30)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=12)), iter_var(ax2, range(min=0, ext=28)), iter_var(ax3, range(min=0, ext=28)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[20:00:52] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,12)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,28)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,28)
      for ax4 (0,16)
        tensor = ...

with: [20:00:52] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 29)) && (ax3 >= 1)) && (ax3 < 29)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=12)), iter_var(ax2, range(min=0, ext=30)), iter_var(ax3, range(min=0, ext=30)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=12)), iter_var(ax2, range(min=0, ext=28)), iter_var(ax3, range(min=0, ext=28)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 1.0011	Min score: 0.3453	#Pop: 128	#M+: 422	#M-: 6593
EvolutionarySearch		#s: 128	Time elapsed: 5.87
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.24 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 58.47 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1743	fail_ct: 0	Time elapsed: 1.94
GA Iter: 0	Max score: 0.5987	Min score: 0.2981	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9303	Min score: 0.8299	#Pop: 128	#M+: 1362	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 10.25
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.41 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 57.17 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1984 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    832 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    256 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    256 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.730 ms	Trials: 17472	Used time : 18640 s	Next ID: 48	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2445.66 |    640 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |    960 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    832 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    512 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1984 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    832 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    256 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         198.26 |     64 |
-------------------------------------------------
Estimated total latency: 1.730 ms	Trials: 17536	Used time : 18734 s	Next ID: 58	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2445.66 |    640 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |    960 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    832 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    512 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1984 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    832 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    256 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.730 ms	Trials: 17600	Used time : 18812 s	Next ID: 18	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1804	fail_ct: 0	Time elapsed: 1.53
GA Iter: 0	Max score: 0.7161	Min score: 0.2416	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9881	Min score: 0.9323	#Pop: 128	#M+: 1390	#M-: 14
EvolutionarySearch		#s: 128	Time elapsed: 8.46
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 18.04 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 64.26 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1775	fail_ct: 0	Time elapsed: 1.34
GA Iter: 0	Max score: 0.7911	Min score: 0.2108	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0037	Min score: 0.9181	#Pop: 128	#M+: 1384	#M-: 29
EvolutionarySearch		#s: 128	Time elapsed: 6.83
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.00 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 76.71 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2445.66 |    640 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1024 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    832 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    512 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   1984 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    832 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    256 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.730 ms	Trials: 17664	Used time : 18896 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2445.66 |    640 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1024 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    832 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    512 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   2048 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    832 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.033 |        2609.21 |    320 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    256 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.730 ms	Trials: 17728	Used time : 18988 s	Next ID: 46	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2445.66 |    640 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1024 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    832 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    512 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   2048 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    832 |
|   41 |        0.024 |        2461.41 |    448 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1597	fail_ct: 165	Time elapsed: 2.13
GA Iter: 0	Max score: 0.7375	Min score: 0.2044	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9890	Min score: 0.9362	#Pop: 128	#M+: 1393	#M-: 14
EvolutionarySearch		#s: 128	Time elapsed: 10.75
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 11.91 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 67.96 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1618	fail_ct: 148	Time elapsed: 1.21
GA Iter: 0	Max score: 0.8139	Min score: 0.2303	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9742	Min score: 0.8249	#Pop: 128	#M+: 1384	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 4.91
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.89 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 38.29 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2009	fail_ct: 1	Time elapsed: 1.68
GA Iter: 0	Max score: 0.7179	Min score: 0.2634	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9410	Min score: 0.7645	#Pop: 128	#M+: 1384	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 8.09
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.99 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 63.71 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    256 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.729 ms	Trials: 17792	Used time : 19085 s	Next ID: 27	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2445.66 |    640 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1024 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    896 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    512 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   2048 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    832 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    256 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.729 ms	Trials: 17856	Used time : 19178 s	Next ID: 7	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    704 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1024 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    896 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    512 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   2048 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    832 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    128 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    256 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.729 ms	Trials: 17920	Used time : 19236 s	Next ID: 52	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         249.04 |     64 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    704 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 32	fail_ct: 1879	Time elapsed: 0.70
GA Iter: 0	Max score: 0.9908	Min score: -0.0070	#Pop: 13	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0400	Min score: -0.0177	#Pop: 72	#M+: 355	#M-: 6988
EvolutionarySearch		#s: 72	Time elapsed: 2.68
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 10.72 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 8.58 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1756	fail_ct: 0	Time elapsed: 0.88
GA Iter: 0	Max score: 0.6660	Min score: 0.2291	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9662	Min score: 0.9083	#Pop: 128	#M+: 1384	#M-: 12
EvolutionarySearch		#s: 128	Time elapsed: 6.75
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.27 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 58.03 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1024 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    896 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    512 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   2048 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    832 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    256 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.729 ms	Trials: 17984	Used time : 19324 s	Next ID: 5	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    704 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1024 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    896 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    512 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   2048 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2768.99 |    832 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    256 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.729 ms	Trials: 18048	Used time : 19347 s	Next ID: 40	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    704 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1024 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    896 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    512 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   2048 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    896 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2011	fail_ct: 1	Time elapsed: 1.58
GA Iter: 0	Max score: 0.6459	Min score: 0.2701	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9530	Min score: 0.8543	#Pop: 128	#M+: 1382	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 6.99
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 18.83 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 57.95 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1843	fail_ct: 0	Time elapsed: 2.45
GA Iter: 0	Max score: 0.7877	Min score: 0.2359	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9850	Min score: 0.9270	#Pop: 128	#M+: 1388	#M-: 18
EvolutionarySearch		#s: 128	Time elapsed: 13.45
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.85 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 51.67 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2000	fail_ct: 0	Time elapsed: 1.56
GA Iter: 0	Max score: 0.7137	Min score: 0.2496	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9549	Min score: 0.8485	#Pop: 128	#M+: 1364	#M-: 66
EvolutionarySearch		#s: 128	Time elapsed: 6.96
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.29 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 51.05 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2098.80 |    256 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.729 ms	Trials: 18112	Used time : 19425 s	Next ID: 55	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    704 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1024 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    896 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    512 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   2048 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    896 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.729 ms	Trials: 18176	Used time : 19511 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    704 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1024 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    896 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    512 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   2112 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    896 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.729 ms	Trials: 18240	Used time : 19593 s	Next ID: 30	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    704 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1024 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1631	fail_ct: 135	Time elapsed: 2.09
GA Iter: 0	Max score: 0.5318	Min score: 0.2332	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0076	Min score: 0.8853	#Pop: 128	#M+: 1389	#M-: 6
EvolutionarySearch		#s: 128	Time elapsed: 9.20
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.09 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 100.54 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1773	fail_ct: 0	Time elapsed: 1.79
GA Iter: 0	Max score: 0.6644	Min score: 0.2061	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0013	Min score: 0.9116	#Pop: 128	#M+: 1389	#M-: 31
EvolutionarySearch		#s: 128	Time elapsed: 9.25
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 19.04 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 47.45 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    896 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    576 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2637.19 |    448 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   2112 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    896 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.729 ms	Trials: 18304	Used time : 19670 s	Next ID: 32	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    704 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1024 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    896 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    576 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2663.52 |    512 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.033 |        2624.85 |    320 |
|   37 |        0.230 |        3025.90 |   2112 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    896 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.728 ms	Trials: 18368	Used time : 19796 s	Next ID: 36	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    704 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1024 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    896 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    576 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2663.52 |    512 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.031 |        2802.80 |    384 |
|   37 |        0.230 |        3025.90 |   2112 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    896 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    320 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1970	fail_ct: 9	Time elapsed: 1.50
GA Iter: 0	Max score: 0.7285	Min score: 0.2570	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9341	Min score: 0.7285	#Pop: 128	#M+: 1384	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 7.94
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 21.01 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 79.10 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1810	fail_ct: 0	Time elapsed: 1.80
GA Iter: 0	Max score: 0.7685	Min score: 0.2527	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0169	Min score: 0.9324	#Pop: 128	#M+: 1376	#M-: 20
EvolutionarySearch		#s: 128	Time elapsed: 12.03
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 20.24 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 73.14 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1990	fail_ct: 4	Time elapsed: 1.54
GA Iter: 0	Max score: 0.6169	Min score: 0.2229	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9705	Min score: 0.8601	#Pop: 128	#M+: 1363	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 6.51
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.44 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 59.95 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.726 ms	Trials: 18432	Used time : 19874 s	Next ID: 45	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    704 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1024 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    896 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    576 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2663.52 |    512 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.031 |        2802.80 |    384 |
|   37 |        0.230 |        3025.90 |   2112 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    896 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    384 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.726 ms	Trials: 18496	Used time : 19984 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    704 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1024 |
|   19 |        0.011 |        1983.38 |    320 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    896 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    576 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2663.52 |    512 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.031 |        2802.80 |    384 |
|   37 |        0.230 |        3025.90 |   2176 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    896 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    384 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.726 ms	Trials: 18560	Used time : 20092 s	Next ID: 19	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    320 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    704 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1024 |
|   19 |        0.011 |        1995.03 |    384 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    896 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1938	fail_ct: 13	Time elapsed: 0.78
GA Iter: 0	Max score: 0.5995	Min score: 0.2596	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9528	Min score: 0.7976	#Pop: 128	#M+: 1385	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 6.38
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 23.98 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 81.49 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 156	fail_ct: 1630	Time elapsed: 1.24
GA Iter: 0	Max score: 0.5470	Min score: 0.1240	#Pop: 58	#M+: 0	#M-: 0
[20:26:42] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (None)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (None)
    for ax3 (None)
      for ax0 (None)
        for ax1 (None)
          for ax2 (None)
            for ax3 (None)
              vectorize ax4 (None)
                pad_temp = ...
      for ax4 (None)
        tensor = ...

with: [20:26:42] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[20:26:42] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [20:26:42] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[20:26:43] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [20:26:43] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[20:26:43] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [20:26:43] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[20:26:43] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [20:26:43] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[20:26:44] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [20:26:44] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[20:26:44] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [20:26:44] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[20:26:44] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [20:26:44] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[20:26:45] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [20:26:45] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[20:26:45] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,36)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for ax4 (None)
            for rv0 (None)
              for rv1 (None)
                tensor = ...
  for ax2 (0,14)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            vectorize ax4 (None)
              pad_temp = ...
    for ax3 (0,14)
      for ax4 (0,16)
        tensor = ...

with: [20:26:45] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_temp, body=[tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=16)), iter_var(ax3, range(min=0, ext=16)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]], init=[], axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=36)), iter_var(ax2, range(min=0, ext=14)), iter_var(ax3, range(min=0, ext=14)), iter_var(ax4, range(min=0, ext=16))], reduce_axis=[iter_var(rv0, range(min=0, ext=3)), iter_var(rv1, range(min=0, ext=3))], tag=pool_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fe23ff926b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.7190	Min score: 0.2909	#Pop: 128	#M+: 429	#M-: 6408
EvolutionarySearch		#s: 128	Time elapsed: 4.61
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 11.88 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 76.88 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1608	fail_ct: 150	Time elapsed: 1.25
GA Iter: 0	Max score: 0.8690	Min score: 0.2073	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9745	Min score: 0.9151	#Pop: 128	#M+: 1390	#M-: 22
EvolutionarySearch		#s: 128	Time elapsed: 6.22
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 10.64 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 22.93 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   30 |        0.014 |        2026.79 |    576 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2663.52 |    512 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.031 |        2802.80 |    384 |
|   37 |        0.230 |        3025.90 |   2176 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    896 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    384 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.726 ms	Trials: 18624	Used time : 20176 s	Next ID: 0	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    384 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    704 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    192 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1024 |
|   19 |        0.011 |        1995.03 |    384 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    896 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    576 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2663.52 |    512 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.031 |        2802.80 |    384 |
|   37 |        0.230 |        3025.90 |   2176 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    896 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    384 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.726 ms	Trials: 18688	Used time : 20289 s	Next ID: 14	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    384 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    704 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    256 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1024 |
|   19 |        0.011 |        1995.03 |    384 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    896 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    576 |
|   31 |        0.040 |        2721.05 |    384 |
|   32 |        0.049 |        2663.52 |    512 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.031 |        2802.80 |    384 |
|   37 |        0.230 |        3025.90 |   2176 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    896 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    384 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.726 ms	Trials: 18752	Used time : 20383 s	Next ID: 31	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    384 |
|    1 |        0.020 |        2128.29 |    192 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2023	fail_ct: 0	Time elapsed: 1.09
GA Iter: 0	Max score: 0.9103	Min score: 0.2974	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9699	Min score: 0.8815	#Pop: 128	#M+: 1377	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 5.20
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    704 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    256 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1024 |
|   19 |        0.011 |        1995.03 |    384 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.010 |        1874.03 |    192 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    896 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    576 |
|   31 |        0.040 |        2721.05 |    448 |
|   32 |        0.049 |        2663.52 |    512 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.031 |        2802.80 |    384 |
|   37 |        0.230 |        3025.90 |   2176 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    896 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    384 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.726 ms	Trials: 18816	Used time : 20425 s	Next ID: 23	
.T***************************************************************Time elapsed for measurement: 26.66 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 79.74 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2015	fail_ct: 0	Time elapsed: 1.42
GA Iter: 0	Max score: 0.7529	Min score: 0.2316	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9862	Min score: 0.8579	#Pop: 128	#M+: 1384	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 6.22
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 11.46 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 79.35 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1624	fail_ct: 143	Time elapsed: 2.18
GA Iter: 0	Max score: 0.6782	Min score: 0.2195	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9914	Min score: 0.9351	#Pop: 128	#M+: 1390	#M-: 23
EvolutionarySearch		#s: 128	Time elapsed: 10.20
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 10.60 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 55.07 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    384 |
|    1 |        0.020 |        2128.29 |    192 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    704 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    256 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1024 |
|   19 |        0.011 |        1995.03 |    384 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.009 |        2042.36 |    256 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    896 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    576 |
|   31 |        0.040 |        2721.05 |    448 |
|   32 |        0.049 |        2663.52 |    512 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.031 |        2802.80 |    384 |
|   37 |        0.230 |        3025.90 |   2176 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    896 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    384 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.724 ms	Trials: 18880	Used time : 20538 s	Next ID: 1	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    384 |
|    1 |        0.020 |        2128.29 |    256 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    704 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    256 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1024 |
|   19 |        0.011 |        1995.03 |    384 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.009 |        2042.36 |    256 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    896 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    576 |
|   31 |        0.040 |        2721.05 |    448 |
|   32 |        0.049 |        2663.52 |    512 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.031 |        2802.80 |    384 |
|   37 |        0.230 |        3025.90 |   2176 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    896 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    384 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.724 ms	Trials: 18944	Used time : 20636 s	Next ID: 27	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    384 |
|    1 |        0.020 |        2128.29 |    256 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    704 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    256 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1024 |
|   19 |        0.011 |        1995.03 |    384 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    384 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.009 |        2042.36 |    256 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    960 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    576 |
|   31 |        0.040 |        2721.05 |    448 |
|   32 |        0.049 |        2663.52 |    512 |
|   33 |        0.019 |        2259.43 |    192 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1566	fail_ct: 123	Time elapsed: 2.06
GA Iter: 0	Max score: 0.6513	Min score: 0.1923	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0082	Min score: 0.8364	#Pop: 128	#M+: 1384	#M-: 14
EvolutionarySearch		#s: 128	Time elapsed: 10.44
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.37 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 83.06 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1829	fail_ct: 0	Time elapsed: 1.47
GA Iter: 0	Max score: 0.6982	Min score: 0.2292	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9940	Min score: 0.9331	#Pop: 128	#M+: 1388	#M-: 19
EvolutionarySearch		#s: 128	Time elapsed: 6.03
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.48 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 64.43 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1548	fail_ct: 166	Time elapsed: 2.03
GA Iter: 0	Max score: 0.6751	Min score: 0.1794	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9862	Min score: 0.8965	#Pop: 128	#M+: 1388	#M-: 13
EvolutionarySearch		#s: 128	Time elapsed: 11.44
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 23.69 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 43.30 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.031 |        2802.80 |    384 |
|   37 |        0.230 |        3025.90 |   2176 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    896 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    384 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.724 ms	Trials: 19008	Used time : 20715 s	Next ID: 21	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    384 |
|    1 |        0.020 |        2128.29 |    256 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    704 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    256 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1024 |
|   19 |        0.011 |        1995.03 |    384 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    448 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.009 |        2042.36 |    256 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    960 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    576 |
|   31 |        0.040 |        2721.05 |    448 |
|   32 |        0.049 |        2663.52 |    512 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.031 |        2802.80 |    384 |
|   37 |        0.230 |        3025.90 |   2176 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    896 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    384 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.724 ms	Trials: 19072	Used time : 20825 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    384 |
|    1 |        0.020 |        2128.29 |    256 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    704 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    256 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1024 |
|   19 |        0.011 |        1995.03 |    384 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    448 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.009 |        2042.36 |    256 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    960 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    576 |
|   31 |        0.040 |        2721.05 |    448 |
|   32 |        0.049 |        2663.52 |    512 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.031 |        2802.80 |    384 |
|   37 |        0.230 |        3025.90 |   2240 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    896 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    384 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    320 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.724 ms	Trials: 19136	Used time : 20910 s	Next ID: 51	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    384 |
|    1 |        0.020 |        2128.29 |    256 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         252.39 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1665	fail_ct: 0	Time elapsed: 0.83
GA Iter: 0	Max score: 0.7015	Min score: 0.2731	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0252	Min score: 0.8223	#Pop: 128	#M+: 1387	#M-: 20
EvolutionarySearch		#s: 128	Time elapsed: 6.65
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 24.50 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 92.77 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1745	fail_ct: 0	Time elapsed: 1.47
GA Iter: 0	Max score: 0.5490	Min score: 0.2927	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9786	Min score: 0.8368	#Pop: 128	#M+: 1386	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 5.68
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.27 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 76.62 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    704 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    256 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1024 |
|   19 |        0.011 |        1995.03 |    384 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    448 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.009 |        2042.36 |    256 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    960 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    576 |
|   31 |        0.040 |        2721.05 |    448 |
|   32 |        0.049 |        2663.52 |    512 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.031 |        2802.80 |    384 |
|   37 |        0.230 |        3025.90 |   2240 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    896 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    384 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.013 |        1608.47 |    128 |
|   51 |        0.033 |        2762.05 |    384 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.724 ms	Trials: 19200	Used time : 20991 s	Next ID: 50	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    384 |
|    1 |        0.020 |        2128.29 |    256 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    704 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    256 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1024 |
|   19 |        0.011 |        1995.03 |    384 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    448 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.009 |        2042.36 |    256 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    960 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    576 |
|   31 |        0.040 |        2721.05 |    448 |
|   32 |        0.049 |        2663.52 |    512 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.031 |        2802.80 |    384 |
|   37 |        0.230 |        3025.90 |   2240 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    896 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    384 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.012 |        1775.63 |    192 |
|   51 |        0.033 |        2762.05 |    384 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.723 ms	Trials: 19264	Used time : 21116 s	Next ID: 18	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    384 |
|    1 |        0.020 |        2128.29 |    256 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    704 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    256 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1088 |
|   19 |        0.011 |        1995.03 |    384 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    448 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.009 |        2042.36 |    256 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    960 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    576 |
|   31 |        0.040 |        2721.05 |    448 |
|   32 |        0.049 |        2663.52 |    512 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.031 |        2802.80 |    384 |
|   37 |        0.230 |        3025.90 |   2240 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    896 |
|   41 |        0.024 |        2461.41 |    448 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1768	fail_ct: 0	Time elapsed: 1.93
GA Iter: 0	Max score: 0.7794	Min score: 0.2376	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9635	Min score: 0.9006	#Pop: 128	#M+: 1395	#M-: 9
EvolutionarySearch		#s: 128	Time elapsed: 7.84
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 10.41 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 71.09 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1768	fail_ct: 0	Time elapsed: 2.59
GA Iter: 0	Max score: 0.5878	Min score: 0.2150	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9792	Min score: 0.9041	#Pop: 128	#M+: 1398	#M-: 17
EvolutionarySearch		#s: 128	Time elapsed: 10.16
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 10.99 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 69.46 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1633	fail_ct: 135	Time elapsed: 1.83
GA Iter: 0	Max score: 0.6414	Min score: 0.2633	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9595	Min score: 0.8311	#Pop: 128	#M+: 1384	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 9.15
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 17.17 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 83.96 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    384 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.012 |        1775.63 |    192 |
|   51 |        0.033 |        2762.05 |    384 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.723 ms	Trials: 19328	Used time : 21216 s	Next ID: 40	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    384 |
|    1 |        0.020 |        2128.29 |    256 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    704 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    256 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1088 |
|   19 |        0.011 |        1995.03 |    384 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    448 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.009 |        2042.36 |    256 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    960 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    576 |
|   31 |        0.040 |        2721.05 |    448 |
|   32 |        0.049 |        2663.52 |    512 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.031 |        2802.80 |    384 |
|   37 |        0.230 |        3025.90 |   2240 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    960 |
|   41 |        0.024 |        2461.41 |    448 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    384 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.012 |        1775.63 |    192 |
|   51 |        0.033 |        2762.05 |    384 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.723 ms	Trials: 19392	Used time : 21308 s	Next ID: 41	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    384 |
|    1 |        0.020 |        2128.29 |    256 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    704 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    256 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1088 |
|   19 |        0.011 |        1995.03 |    384 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    448 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.009 |        2042.36 |    256 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    960 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    576 |
|   31 |        0.040 |        2721.05 |    448 |
|   32 |        0.049 |        2663.52 |    512 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.031 |        2802.80 |    384 |
|   37 |        0.230 |        3025.90 |   2240 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    960 |
|   41 |        0.024 |        2461.41 |    512 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    384 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.012 |        1775.63 |    192 |
|   51 |        0.033 |        2762.05 |    384 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.723 ms	Trials: 19456	Used time : 21402 s	Next ID: 7	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    384 |
|    1 |        0.020 |        2128.29 |    256 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    768 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1981	fail_ct: 1	Time elapsed: 1.17
GA Iter: 0	Max score: 0.7852	Min score: 0.2501	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9670	Min score: 0.8420	#Pop: 128	#M+: 1379	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 5.77
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................|   14 |        0.005 |         217.03 |    256 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1088 |
|   19 |        0.011 |        1995.03 |    384 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    448 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.009 |        2042.36 |    256 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    960 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    576 |
|   31 |        0.040 |        2721.05 |    448 |
|   32 |        0.049 |        2663.52 |    512 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    320 |
|   36 |        0.031 |        2802.80 |    384 |
|   37 |        0.230 |        3025.90 |   2240 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    960 |
|   41 |        0.024 |        2461.41 |    512 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    384 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.012 |        1775.63 |    192 |
|   51 |        0.033 |        2762.05 |    384 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.723 ms	Trials: 19520	Used time : 21514 s	Next ID: 35	
.T***************************************************************Time elapsed for measurement: 25.85 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 64.94 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1792	fail_ct: 0	Time elapsed: 2.66
GA Iter: 0	Max score: 0.7579	Min score: 0.2414	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9803	Min score: 0.9303	#Pop: 128	#M+: 1385	#M-: 17
EvolutionarySearch		#s: 128	Time elapsed: 13.49
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 20.26 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 74.33 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2013	fail_ct: 0	Time elapsed: 0.96
GA Iter: 0	Max score: 0.8394	Min score: 0.2529	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9533	Min score: 0.8174	#Pop: 128	#M+: 1381	#M-: 78
EvolutionarySearch		#s: 128	Time elapsed: 4.71
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 8.86 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 82.23 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    384 |
|    1 |        0.020 |        2128.29 |    256 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    768 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    256 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1088 |
|   19 |        0.011 |        1995.03 |    384 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    448 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.009 |        2042.36 |    256 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    960 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    576 |
|   31 |        0.040 |        2721.05 |    448 |
|   32 |        0.049 |        2663.52 |    512 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    384 |
|   36 |        0.031 |        2802.80 |    384 |
|   37 |        0.230 |        3025.90 |   2240 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    960 |
|   41 |        0.024 |        2461.41 |    512 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    384 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.012 |        1775.63 |    192 |
|   51 |        0.033 |        2762.05 |    384 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.723 ms	Trials: 19584	Used time : 21612 s	Next ID: 37	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    384 |
|    1 |        0.020 |        2128.29 |    256 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2230.73 |    192 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    768 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    256 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1088 |
|   19 |        0.011 |        1995.03 |    384 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    448 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.009 |        2042.36 |    256 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    960 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    576 |
|   31 |        0.040 |        2721.05 |    448 |
|   32 |        0.049 |        2663.52 |    512 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    384 |
|   36 |        0.031 |        2802.80 |    384 |
|   37 |        0.230 |        3032.53 |   2304 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    960 |
|   41 |        0.024 |        2461.41 |    512 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    384 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.012 |        1775.63 |    192 |
|   51 |        0.033 |        2762.05 |    384 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.722 ms	Trials: 19648	Used time : 21723 s	Next ID: 4	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    384 |
|    1 |        0.020 |        2128.29 |    256 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2237.45 |    256 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    768 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    256 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1088 |
|   19 |        0.011 |        1995.03 |    384 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    448 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.009 |        2042.36 |    256 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    960 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    576 |
|   31 |        0.040 |        2721.05 |    448 |
|   32 |        0.049 |        2663.52 |    512 |
|   33 |        0.019 |        2259.43 |    192 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1992	fail_ct: 0	Time elapsed: 1.76
GA Iter: 0	Max score: 0.7000	Min score: 0.2402	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9724	Min score: 0.8440	#Pop: 128	#M+: 1369	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 7.15
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.69 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 74.19 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1482	fail_ct: 153	Time elapsed: 1.28
GA Iter: 0	Max score: 0.6713	Min score: 0.1634	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9881	Min score: 0.8603	#Pop: 128	#M+: 1402	#M-: 19
EvolutionarySearch		#s: 128	Time elapsed: 8.64
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 21.59 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 86.25 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1833	fail_ct: 0	Time elapsed: 2.39
GA Iter: 0	Max score: 0.6953	Min score: 0.2495	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9718	Min score: 0.9272	#Pop: 128	#M+: 1390	#M-: 15
EvolutionarySearch		#s: 128	Time elapsed: 13.18
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    384 |
|   36 |        0.031 |        2802.80 |    384 |
|   37 |        0.230 |        3032.53 |   2304 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    960 |
|   41 |        0.024 |        2461.41 |    512 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    384 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.012 |        1775.63 |    192 |
|   51 |        0.033 |        2762.05 |    384 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.722 ms	Trials: 19712	Used time : 21820 s	Next ID: 4	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    384 |
|    1 |        0.020 |        2128.29 |    256 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2250.77 |    320 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    768 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    256 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1088 |
|   19 |        0.011 |        1995.03 |    384 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    448 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.009 |        2042.36 |    256 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    960 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    576 |
|   31 |        0.040 |        2721.05 |    448 |
|   32 |        0.049 |        2663.52 |    512 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    384 |
|   36 |        0.031 |        2802.80 |    384 |
|   37 |        0.230 |        3032.53 |   2304 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    960 |
|   41 |        0.024 |        2461.41 |    512 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    384 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    384 |
|   50 |        0.012 |        1775.63 |    192 |
|   51 |        0.033 |        2762.05 |    384 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.722 ms	Trials: 19776	Used time : 21916 s	Next ID: 49	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    384 |
|    1 |        0.020 |        2128.29 |    256 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2250.77 |    320 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    768 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    256 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1088 |
|   19 |        0.011 |        1995.03 |    384 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    448 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.009 |        2042.36 |    256 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    960 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    576 |
|   31 |        0.040 |        2721.05 |    448 |
|   32 |        0.049 |        2663.52 |    512 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    384 |
|   36 |        0.031 |        2802.80 |    384 |
|   37 |        0.230 |        3032.53 |   2304 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    960 |
|   41 |        0.024 |        2461.41 |    512 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    384 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    448 |
|   50 |        0.012 |        1775.63 |    192 |
|   51 |        0.033 |        2762.05 |    384 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.722 ms	Trials: 19840	Used time : 22035 s	Next ID: 37	
.T***************************************************************Time elapsed for measurement: 26.57 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 69.29 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1612	fail_ct: 143	Time elapsed: 1.06
GA Iter: 0	Max score: 0.7173	Min score: 0.2163	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9942	Min score: 0.8770	#Pop: 128	#M+: 1390	#M-: 17
EvolutionarySearch		#s: 128	Time elapsed: 5.94
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 21.00 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 70.96 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1622	fail_ct: 145	Time elapsed: 1.51
GA Iter: 0	Max score: 0.6025	Min score: 0.2235	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0282	Min score: 0.9105	#Pop: 128	#M+: 1386	#M-: 11
EvolutionarySearch		#s: 128	Time elapsed: 9.32
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.28 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 59.54 s

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    384 |
|    1 |        0.020 |        2128.29 |    256 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2250.77 |    320 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    768 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    256 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1088 |
|   19 |        0.011 |        1995.03 |    384 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    448 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.009 |        2042.36 |    256 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    960 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    576 |
|   31 |        0.040 |        2721.05 |    448 |
|   32 |        0.049 |        2663.52 |    512 |
|   33 |        0.019 |        2259.43 |    192 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    384 |
|   36 |        0.031 |        2802.80 |    384 |
|   37 |        0.230 |        3032.53 |   2368 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    960 |
|   41 |        0.024 |        2461.41 |    512 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    384 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    448 |
|   50 |        0.012 |        1775.63 |    192 |
|   51 |        0.033 |        2762.05 |    384 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.722 ms	Trials: 19904	Used time : 22147 s	Next ID: 33	

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |        2100.61 |    384 |
|    1 |        0.020 |        2128.29 |    256 |
|    2 |        0.028 |        2582.27 |    320 |
|    3 |        0.011 |        1995.76 |    128 |
|    4 |        0.019 |        2250.77 |    320 |
|    5 |        0.007 |         252.39 |    128 |
|    6 |        0.004 |         128.62 |     64 |
|    7 |        0.071 |        2446.65 |    768 |
|    8 |        0.031 |        2111.34 |    320 |
|    9 |        0.012 |        2193.95 |    128 |
|   10 |        0.008 |         251.32 |    128 |
|   11 |        0.027 |        2704.17 |    320 |
|   12 |        0.008 |        1904.70 |    128 |
|   13 |        0.006 |         226.66 |     64 |
|   14 |        0.005 |         217.03 |    256 |
|   15 |        0.014 |        2244.10 |    192 |
|   16 |        0.018 |        2415.50 |    384 |
|   17 |        0.003 |          87.87 |     64 |
|   18 |        0.101 |        2374.55 |   1088 |
|   19 |        0.011 |        1995.03 |    384 |
|   20 |        0.006 |           0.70 |     64 |
|   21 |        0.020 |        2669.76 |    448 |
|   22 |        0.016 |        2336.31 |    192 |
|   23 |        0.009 |        2042.36 |    256 |
|   24 |        0.016 |        2276.42 |    192 |
|   25 |        0.004 |         152.64 |     64 |
|   26 |        0.017 |        2199.26 |    192 |
|   27 |        0.047 |        2748.98 |    960 |
|   28 |        0.011 |        1752.27 |    128 |
|   29 |        0.004 |         130.95 |     64 |
|   30 |        0.014 |        2026.79 |    576 |
|   31 |        0.040 |        2721.05 |    448 |
|   32 |        0.049 |        2663.52 |    512 |
|   33 |        0.019 |        2347.11 |    256 |
|   34 |        0.007 |        1486.51 |    128 |
|   35 |        0.011 |        2003.20 |    384 |
|   36 |        0.031 |        2802.80 |    384 |
|   37 |        0.230 |        3032.53 |   2368 |
|   38 |        0.021 |        2407.18 |    320 |
|   39 |        0.009 |        1638.82 |    128 |
|   40 |        0.031 |        2771.07 |    960 |
|   41 |        0.024 |        2461.41 |    512 |
|   42 |        0.028 |        2074.72 |    320 |
|   43 |        0.008 |        1571.01 |    192 |
|   44 |        0.003 |          18.01 |     64 |
|   45 |        0.011 |        1738.74 |    384 |
|   46 |        0.032 |        2672.68 |    384 |
|   47 |        0.014 |        2013.54 |    320 |
|   48 |        0.022 |        2642.17 |    320 |
|   49 |        0.019 |        2329.34 |    448 |
|   50 |        0.012 |        1775.63 |    192 |
|   51 |        0.033 |        2762.05 |    384 |
|   52 |        0.015 |        2216.20 |    192 |
|   53 |        0.007 |         274.40 |    128 |
|   54 |        0.027 |        2700.15 |    320 |
|   55 |        0.012 |        2099.07 |    320 |
|   56 |        0.012 |        2111.98 |    320 |
|   57 |        0.014 |        2293.07 |    192 |
|   58 |        0.008 |         200.25 |    128 |
-------------------------------------------------
Estimated total latency: 1.721 ms	Trials: 19968	Used time : 22246 s	Next ID: 33	

==== Task 0: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_24 (weight 2 key: ["9db1fd34470fc877a2c0431d681f01a4", [1, 64, 7, 7, 16], [22, 64, 1, 1, 16, 16], [1, 22, 1, 1, 16], [1, 22, 1, 1, 16], [1, 22, 1, 1, 16], [1, 22, 7, 7, 16]]) =====
placeholder = PLACEHOLDER [1, 64, 7, 7, 16]
placeholder = PLACEHOLDER [22, 64, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 22, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 22, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 22, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=11)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=7)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=1)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=11)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=7)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=1)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 512)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [50176], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [360448], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [352], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [352], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [352], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [17248], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_8: placeholder_15: Buffer(placeholder_13, float32, [1, 22, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 22, 7, 7, 16], []), placeholder_6: placeholder_16: Buffer(placeholder_11, float32, [22, 64, 1, 1, 16, 16], []), placeholder_7: placeholder_17: Buffer(placeholder_12, float32, [1, 22, 1, 1, 16], []), placeholder_9: placeholder_18: Buffer(placeholder_14, float32, [1, 22, 1, 1, 16], []), placeholder_5: placeholder_19: Buffer(placeholder_10, float32, [1, 64, 7, 7, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused: int32, 0, 77) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 64) {
        let cse_var_144: int32 = ((ic.outer*784) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 7)*112))
        let cse_var_143: int32 = ((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 7)*32768) + (ic.outer*256))
        let cse_var_142: int32 = (cse_var_144 + 19)
        let cse_var_141: int32 = (cse_var_144 + 17)
        let cse_var_140: int32 = (cse_var_144 + 16)
        let cse_var_139: int32 = (cse_var_144 + 15)
        let cse_var_138: int32 = (cse_var_144 + 14)
        let cse_var_137: int32 = (cse_var_144 + 13)
        let cse_var_136: int32 = (cse_var_144 + 12)
        let cse_var_135: int32 = (cse_var_144 + 111)
        let cse_var_134: int32 = (cse_var_144 + 110)
        let cse_var_133: int32 = (cse_var_144 + 11)
        let cse_var_132: int32 = (cse_var_144 + 109)
        let cse_var_131: int32 = (cse_var_144 + 108)
        let cse_var_130: int32 = (cse_var_144 + 107)
        let cse_var_129: int32 = (cse_var_144 + 106)
        let cse_var_128: int32 = (cse_var_144 + 105)
        let cse_var_127: int32 = (cse_var_144 + 103)
        let cse_var_126: int32 = (cse_var_144 + 18)
        let cse_var_125: int32 = (cse_var_144 + 35)
        let cse_var_124: int32 = (cse_var_144 + 33)
        let cse_var_123: int32 = (cse_var_144 + 32)
        let cse_var_122: int32 = (cse_var_144 + 31)
        let cse_var_121: int32 = (cse_var_144 + 30)
        let cse_var_120: int32 = (cse_var_144 + 3)
        let cse_var_119: int32 = (cse_var_144 + 29)
        let cse_var_118: int32 = (cse_var_144 + 28)
        let cse_var_117: int32 = (cse_var_144 + 104)
        let cse_var_116: int32 = (cse_var_144 + 26)
        let cse_var_115: int32 = (cse_var_144 + 25)
        let cse_var_114: int32 = (cse_var_144 + 24)
        let cse_var_113: int32 = (cse_var_144 + 23)
        let cse_var_112: int32 = (cse_var_144 + 22)
        let cse_var_111: int32 = (cse_var_144 + 21)
        let cse_var_110: int32 = (cse_var_144 + 20)
        let cse_var_109: int32 = (cse_var_144 + 2)
        let cse_var_108: int32 = (cse_var_144 + 27)
        let cse_var_107: int32 = (cse_var_143 + 16576)
        let cse_var_106: int32 = (cse_var_143 + 16560)
        let cse_var_105: int32 = (cse_var_143 + 16544)
        let cse_var_104: int32 = (cse_var_143 + 16528)
        let cse_var_103: int32 = (cse_var_143 + 16512)
        let cse_var_102: int32 = (cse_var_143 + 16496)
        let cse_var_101: int32 = (cse_var_143 + 16480)
        let cse_var_100: int32 = (cse_var_143 + 16464)
        let cse_var_99: int32 = (cse_var_144 + 34)
        let cse_var_98: int32 = (cse_var_143 + 16432)
        let cse_var_97: int32 = (cse_var_143 + 16416)
        let cse_var_96: int32 = (cse_var_143 + 16400)
        let cse_var_95: int32 = (cse_var_143 + 16384)
        let cse_var_94: int32 = (cse_var_143 + 160)
        let cse_var_93: int32 = (cse_var_143 + 16)
        let cse_var_92: int32 = (cse_var_143 + 144)
        let cse_var_91: int32 = (cse_var_143 + 112)
        let cse_var_90: int32 = (cse_var_143 + 16448)
        let cse_var_89: int32 = (cse_var_144 + 102)
        let cse_var_88: int32 = (cse_var_144 + 101)
        let cse_var_87: int32 = (cse_var_144 + 100)
        let cse_var_86: int32 = (cse_var_144 + 10)
        let cse_var_85: int32 = (cse_var_144 + 1)
        let cse_var_84: int32 = (cse_var_143 + 96)
        let cse_var_83: int32 = (cse_var_143 + 80)
        let cse_var_82: int32 = (cse_var_143 + 64)
        let cse_var_81: int32 = (cse_var_143 + 16592)
        let cse_var_80: int32 = (cse_var_143 + 32)
        let cse_var_79: int32 = (cse_var_143 + 240)
        let cse_var_78: int32 = (cse_var_143 + 224)
        let cse_var_77: int32 = (cse_var_143 + 208)
        let cse_var_76: int32 = (cse_var_143 + 192)
        let cse_var_75: int32 = (cse_var_143 + 176)
        let cse_var_74: int32 = (cse_var_143 + 16624)
        let cse_var_73: int32 = (cse_var_143 + 16608)
        let cse_var_72: int32 = (cse_var_143 + 48)
        let cse_var_71: int32 = (cse_var_144 + 82)
        let cse_var_70: int32 = (cse_var_144 + 81)
        let cse_var_69: int32 = (cse_var_144 + 80)
        let cse_var_68: int32 = (cse_var_144 + 8)
        let cse_var_67: int32 = (cse_var_144 + 79)
        let cse_var_66: int32 = (cse_var_144 + 78)
        let cse_var_65: int32 = (cse_var_144 + 77)
        let cse_var_64: int32 = (cse_var_143 + 128)
        let cse_var_63: int32 = (cse_var_144 + 75)
        let cse_var_62: int32 = (cse_var_144 + 74)
        let cse_var_61: int32 = (cse_var_144 + 73)
        let cse_var_60: int32 = (cse_var_144 + 72)
        let cse_var_59: int32 = (cse_var_144 + 71)
        let cse_var_58: int32 = (cse_var_144 + 70)
        let cse_var_57: int32 = (cse_var_144 + 7)
        let cse_var_56: int32 = (cse_var_144 + 69)
        let cse_var_55: int32 = (cse_var_144 + 76)
        let cse_var_54: int32 = (cse_var_144 + 99)
        let cse_var_53: int32 = (cse_var_144 + 98)
        let cse_var_52: int32 = (cse_var_144 + 97)
        let cse_var_51: int32 = (cse_var_144 + 96)
        let cse_var_50: int32 = (cse_var_144 + 95)
        let cse_var_49: int32 = (cse_var_144 + 94)
        let cse_var_48: int32 = (cse_var_144 + 93)
        let cse_var_47: int32 = (cse_var_144 + 92)
        let cse_var_46: int32 = (cse_var_144 + 83)
        let cse_var_45: int32 = (cse_var_144 + 90)
        let cse_var_44: int32 = (cse_var_144 + 9)
        let cse_var_43: int32 = (cse_var_144 + 89)
        let cse_var_42: int32 = (cse_var_144 + 88)
        let cse_var_41: int32 = (cse_var_144 + 87)
        let cse_var_40: int32 = (cse_var_144 + 86)
        let cse_var_39: int32 = (cse_var_144 + 85)
        let cse_var_38: int32 = (cse_var_144 + 84)
        let cse_var_37: int32 = (cse_var_144 + 91)
        let cse_var_36: int32 = (cse_var_144 + 50)
        let cse_var_35: int32 = (cse_var_144 + 5)
        let cse_var_34: int32 = (cse_var_144 + 49)
        let cse_var_33: int32 = (cse_var_144 + 48)
        let cse_var_32: int32 = (cse_var_144 + 47)
        let cse_var_31: int32 = (cse_var_144 + 46)
        let cse_var_30: int32 = (cse_var_144 + 45)
        let cse_var_29: int32 = (cse_var_144 + 44)
        let cse_var_28: int32 = (cse_var_144 + 68)
        let cse_var_27: int32 = (cse_var_144 + 42)
        let cse_var_26: int32 = (cse_var_144 + 41)
        let cse_var_25: int32 = (cse_var_144 + 40)
        let cse_var_24: int32 = (cse_var_144 + 4)
        let cse_var_23: int32 = (cse_var_144 + 39)
        let cse_var_22: int32 = (cse_var_144 + 38)
        let cse_var_21: int32 = (cse_var_144 + 37)
        let cse_var_20: int32 = (cse_var_144 + 36)
        let cse_var_19: int32 = (cse_var_144 + 43)
        let cse_var_18: int32 = (cse_var_144 + 67)
        let cse_var_17: int32 = (cse_var_144 + 66)
        let cse_var_16: int32 = (cse_var_144 + 65)
        let cse_var_15: int32 = (cse_var_144 + 64)
        let cse_var_14: int32 = (cse_var_144 + 63)
        let cse_var_13: int32 = (cse_var_144 + 62)
        let cse_var_12: int32 = (cse_var_144 + 61)
        let cse_var_11: int32 = (cse_var_144 + 60)
        let cse_var_10: int32 = (cse_var_144 + 51)
        let cse_var_9: int32 = (cse_var_144 + 59)
        let cse_var_8: int32 = (cse_var_144 + 58)
        let cse_var_7: int32 = (cse_var_144 + 57)
        let cse_var_6: int32 = (cse_var_144 + 56)
        let cse_var_5: int32 = (cse_var_144 + 55)
        let cse_var_4: int32 = (cse_var_144 + 54)
        let cse_var_3: int32 = (cse_var_144 + 53)
        let cse_var_2: int32 = (cse_var_144 + 52)
        let cse_var_1: int32 = (cse_var_144 + 6)
         {
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_144], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_140], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_123], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_33], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_15], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_69], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_51], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_144], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_140], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_123], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_33], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_15], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_69], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_51], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_85], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_141], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_124], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_34], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_16], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_70], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_52], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_85], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_141], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_124], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_34], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_16], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_70], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_52], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_109], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_126], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_99], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_36], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_17], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_71], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_53], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_109], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_126], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_99], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_36], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_17], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_71], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_53], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_120], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_142], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_125], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_10], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_18], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_46], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_54], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_120], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_142], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_125], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_10], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_18], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_46], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_54], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_24], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_110], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_20], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_28], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_38], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_87], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_24], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_110], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_20], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_28], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_38], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_87], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_35], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_111], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_21], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_56], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_39], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_88], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_35], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_111], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_21], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_56], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_39], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_88], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_112], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_22], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_58], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_40], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_89], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_112], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_22], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_58], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_40], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_89], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_57], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_113], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_23], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_59], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_41], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_127], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_57], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_113], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_23], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_59], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_41], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_127], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_68], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_114], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_25], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_60], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_42], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_117], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_68], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_114], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_25], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_60], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_42], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_117], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_44], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_115], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_26], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_61], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_43], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_128], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_44], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_115], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_26], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_61], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_43], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_128], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_86], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_116], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_27], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_62], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_45], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_129], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_86], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_116], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_27], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_62], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_45], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_129], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_133], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_108], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_19], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_9], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_63], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_37], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_130], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_133], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_108], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_19], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_9], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_63], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_37], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_130], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_136], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_118], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_29], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_11], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_55], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_47], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_131], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_136], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_118], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_29], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_11], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_55], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_47], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_131], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_137], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_119], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_30], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_12], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_65], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_48], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_132], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_137], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_119], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_30], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_12], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_65], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_48], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_132], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_138], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_121], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_31], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_13], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_66], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_49], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_134], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_138], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_121], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_31], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_13], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_66], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_49], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_134], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_139], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_122], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_32], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_14], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_67], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_50], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_135], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_139], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_122], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_32], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_14], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_67], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_50], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_135], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_146: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 7)
          let cse_var_145: int32 = ((cse_var_146*32) + (ax1.inner*16))
          T_relu[ramp(((((cse_var_146*1568) + (ax1.inner*784)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 7)*112)) + (ax3.inner*16)), 1, 16)] = max((((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(cse_var_145, 1, 16)])*placeholder_3[ramp(cse_var_145, 1, 16)]) + placeholder_4[ramp(cse_var_145, 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 1: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_14 (weight 1 key: ["9db1fd34470fc877a2c0431d681f01a4", [1, 36, 14, 14, 16], [12, 36, 1, 1, 16, 16], [1, 12, 1, 1, 16], [1, 12, 1, 1, 16], [1, 12, 1, 1, 16], [1, 12, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 36, 14, 14, 16]
placeholder = PLACEHOLDER [12, 36, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=1)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=2)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=3)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=1)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=7)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=1)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=4)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=3)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=1)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=1)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 64)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [112896], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [110592], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [192], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [192], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [192], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [37632], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_5: placeholder_15: Buffer(placeholder_10, float32, [1, 36, 14, 14, 16], []), placeholder_7: placeholder_16: Buffer(placeholder_12, float32, [1, 12, 1, 1, 16], []), placeholder_9: placeholder_17: Buffer(placeholder_14, float32, [1, 12, 1, 1, 16], []), placeholder_6: placeholder_18: Buffer(placeholder_11, float32, [12, 36, 1, 1, 16, 16], []), placeholder_8: placeholder_19: Buffer(placeholder_13, float32, [1, 12, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 12, 14, 14, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 168) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 144) {
        let cse_var_36: int32 = (((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 84)*55296) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 3)*18432)) + (ic.outer*64))
        let cse_var_35: int32 = (cse_var_36 + 16)
        let cse_var_34: int32 = (cse_var_36 + 32)
        let cse_var_33: int32 = (cse_var_36 + 48)
        let cse_var_32: int32 = (cse_var_36 + 9216)
        let cse_var_31: int32 = (cse_var_36 + 9232)
        let cse_var_30: int32 = (cse_var_36 + 9248)
        let cse_var_29: int32 = (cse_var_36 + 9264)
        let cse_var_28: int32 = (((floordiv(ic.outer, 4)*3136) + (floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 84), 3)*112)) + (floormod(ic.outer, 4)*4))
        let cse_var_27: int32 = (cse_var_28 + 99)
        let cse_var_26: int32 = (cse_var_28 + 98)
        let cse_var_25: int32 = (cse_var_28 + 97)
        let cse_var_24: int32 = (cse_var_28 + 96)
        let cse_var_23: int32 = (cse_var_28 + 83)
        let cse_var_22: int32 = (cse_var_28 + 82)
        let cse_var_21: int32 = (cse_var_28 + 1)
        let cse_var_20: int32 = (cse_var_28 + 16)
        let cse_var_19: int32 = (cse_var_28 + 17)
        let cse_var_18: int32 = (cse_var_28 + 18)
        let cse_var_17: int32 = (cse_var_28 + 19)
        let cse_var_16: int32 = (cse_var_28 + 2)
        let cse_var_15: int32 = (cse_var_28 + 3)
        let cse_var_14: int32 = (cse_var_28 + 33)
        let cse_var_13: int32 = (cse_var_28 + 34)
        let cse_var_12: int32 = (cse_var_28 + 35)
        let cse_var_11: int32 = (cse_var_28 + 48)
        let cse_var_10: int32 = (cse_var_28 + 49)
        let cse_var_9: int32 = (cse_var_28 + 50)
        let cse_var_8: int32 = (cse_var_28 + 51)
        let cse_var_7: int32 = (cse_var_28 + 64)
        let cse_var_6: int32 = (cse_var_28 + 65)
        let cse_var_5: int32 = (cse_var_28 + 66)
        let cse_var_4: int32 = (cse_var_28 + 67)
        let cse_var_3: int32 = (cse_var_28 + 80)
        let cse_var_2: int32 = (cse_var_28 + 81)
        let cse_var_1: int32 = (cse_var_28 + 32)
         {
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_28], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_21], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_16], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_15], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_20], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_19], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_18], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_17], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_14], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_13], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_12], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_11], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_10], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_9], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_22], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_23], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_24], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_25], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_26], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_27], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_28], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_21], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_16], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_15], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_20], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_19], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_18], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_17], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_14], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_13], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_12], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_11], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_10], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_9], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_22], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_23], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_24], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_25], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_26], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_27], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_39: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 3)
          let cse_var_38: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 84)
          let cse_var_37: int32 = (((cse_var_38*96) + (cse_var_39*32)) + (ax1.inner*16))
          T_relu[ramp((((((cse_var_38*18816) + (cse_var_39*6272)) + (ax1.inner*3136)) + (floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 84), 3)*112)) + (ax3.inner*16)), 1, 16)] = max((((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(cse_var_37, 1, 16)])*placeholder_3[ramp(cse_var_37, 1, 16)]) + placeholder_4[ramp(cse_var_37, 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 2: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_8 (weight 1 key: ["d85f86643f68d4261269b8274457244f", [1, 8, 28, 28, 16], [10, 8, 3, 3, 16, 16], [1, 10, 1, 1, 16], [1, 10, 1, 1, 16], [1, 10, 1, 1, 16], [1, 10, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 8, 28, 28, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 29)) && (i3 >= 1)) && (i3 < 29)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [10, 8, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), ((oh*2) + kh), ((ow*2) + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3, data_pad_i4 = tuple(data_pad.op.axis) + tuple(data_pad.op.reduce_axis)
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=7)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=1)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=2)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=3)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=7)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=1)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=1)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=2)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
s[data_pad].compute_at(s[conv2d_NCHWc], conv2d_NCHWc_kh_o)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 512)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[data_pad].vectorize(data_pad_i4)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [100352], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [184320], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [160], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [160], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [160], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [31360], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_6: placeholder_15: Buffer(placeholder_11, float32, [10, 8, 3, 3, 16, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 10, 14, 14, 16], []), placeholder_7: placeholder_16: Buffer(placeholder_12, float32, [1, 10, 1, 1, 16], []), placeholder_8: placeholder_17: Buffer(placeholder_13, float32, [1, 10, 1, 1, 16], []), placeholder_5: placeholder_18: Buffer(placeholder_10, float32, [1, 8, 28, 28, 16], []), placeholder_9: placeholder_19: Buffer(placeholder_14, float32, [1, 10, 1, 1, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused: int32, 0, 70) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global;
    allocate(data_pad: Pointer(global float32), float32, [720]), storage_scope = global;
    for (ax3.outer.inner: int32, 0, 2) {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 8) {
        let cse_var_5: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 7)
        let cse_var_4: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 14)
        let cse_var_3: bool = (7 <= cse_var_4)
        let cse_var_2: bool = (1 <= ((cse_var_5*4) + (ax3.outer.inner*2)))
        let cse_var_1: int32 = ((((ic.outer*12544) + (floordiv(cse_var_4, 7)*6272)) + (cse_var_5*64)) + (ax3.outer.inner*32))
         {
          data_pad_1: Buffer(data_pad, float32, [720], [])[ramp(0, 1, 16)] = @tir.if_then_else((cse_var_3 && cse_var_2), placeholder[ramp((cse_var_1 - 464), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(16, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_1 - 448), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(32, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_1 - 432), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(48, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 16), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(64, 1, 16)] = placeholder[ramp(cse_var_1, 1, 16)]
          data_pad_1[ramp(80, 1, 16)] = placeholder[ramp((cse_var_1 + 16), 1, 16)]
          data_pad_1[ramp(96, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 432), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(112, 1, 16)] = placeholder[ramp((cse_var_1 + 448), 1, 16)]
          data_pad_1[ramp(128, 1, 16)] = placeholder[ramp((cse_var_1 + 464), 1, 16)]
          data_pad_1[ramp(144, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 880), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(160, 1, 16)] = placeholder[ramp((cse_var_1 + 896), 1, 16)]
          data_pad_1[ramp(176, 1, 16)] = placeholder[ramp((cse_var_1 + 912), 1, 16)]
          data_pad_1[ramp(192, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 1328), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(208, 1, 16)] = placeholder[ramp((cse_var_1 + 1344), 1, 16)]
          data_pad_1[ramp(224, 1, 16)] = placeholder[ramp((cse_var_1 + 1360), 1, 16)]
          data_pad_1[ramp(240, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 1776), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(256, 1, 16)] = placeholder[ramp((cse_var_1 + 1792), 1, 16)]
          data_pad_1[ramp(272, 1, 16)] = placeholder[ramp((cse_var_1 + 1808), 1, 16)]
          data_pad_1[ramp(288, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 2224), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(304, 1, 16)] = placeholder[ramp((cse_var_1 + 2240), 1, 16)]
          data_pad_1[ramp(320, 1, 16)] = placeholder[ramp((cse_var_1 + 2256), 1, 16)]
          data_pad_1[ramp(336, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 2672), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(352, 1, 16)] = placeholder[ramp((cse_var_1 + 2688), 1, 16)]
          data_pad_1[ramp(368, 1, 16)] = placeholder[ramp((cse_var_1 + 2704), 1, 16)]
          data_pad_1[ramp(384, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 3120), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(400, 1, 16)] = placeholder[ramp((cse_var_1 + 3136), 1, 16)]
          data_pad_1[ramp(416, 1, 16)] = placeholder[ramp((cse_var_1 + 3152), 1, 16)]
          data_pad_1[ramp(432, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 3568), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(448, 1, 16)] = placeholder[ramp((cse_var_1 + 3584), 1, 16)]
          data_pad_1[ramp(464, 1, 16)] = placeholder[ramp((cse_var_1 + 3600), 1, 16)]
          data_pad_1[ramp(480, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 4016), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(496, 1, 16)] = placeholder[ramp((cse_var_1 + 4032), 1, 16)]
          data_pad_1[ramp(512, 1, 16)] = placeholder[ramp((cse_var_1 + 4048), 1, 16)]
          data_pad_1[ramp(528, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 4464), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(544, 1, 16)] = placeholder[ramp((cse_var_1 + 4480), 1, 16)]
          data_pad_1[ramp(560, 1, 16)] = placeholder[ramp((cse_var_1 + 4496), 1, 16)]
          data_pad_1[ramp(576, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 4912), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(592, 1, 16)] = placeholder[ramp((cse_var_1 + 4928), 1, 16)]
          data_pad_1[ramp(608, 1, 16)] = placeholder[ramp((cse_var_1 + 4944), 1, 16)]
          data_pad_1[ramp(624, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 5360), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(640, 1, 16)] = placeholder[ramp((cse_var_1 + 5376), 1, 16)]
          data_pad_1[ramp(656, 1, 16)] = placeholder[ramp((cse_var_1 + 5392), 1, 16)]
          data_pad_1[ramp(672, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 5808), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(688, 1, 16)] = placeholder[ramp((cse_var_1 + 5824), 1, 16)]
          data_pad_1[ramp(704, 1, 16)] = placeholder[ramp((cse_var_1 + 5840), 1, 16)]
          for (kw.outer: int32, 0, 3) {
            for (ic.inner: int32, 0, 16) {
              let cse_var_26: int32 = ((kw.outer*16) + ic.inner)
              let cse_var_25: int32 = (cse_var_26 + 144)
              let cse_var_24: int32 = (cse_var_26 + 192)
              let cse_var_23: int32 = (cse_var_26 + 240)
              let cse_var_22: int32 = (cse_var_26 + 288)
              let cse_var_21: int32 = (cse_var_26 + 384)
              let cse_var_20: int32 = (cse_var_26 + 432)
              let cse_var_19: int32 = (cse_var_26 + 48)
              let cse_var_18: int32 = (cse_var_26 + 480)
              let cse_var_17: int32 = (cse_var_26 + 528)
              let cse_var_16: int32 = (cse_var_26 + 576)
              let cse_var_15: int32 = (cse_var_26 + 624)
              let cse_var_14: int32 = (cse_var_26 + 672)
              let cse_var_13: int32 = (cse_var_26 + 96)
              let cse_var_12: int32 = (cse_var_26 + 336)
              let cse_var_11: int32 = ((((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 14)*36864) + (ic.outer*2304)) + (kw.outer*256)) + (ic.inner*16))
              let cse_var_10: int32 = (cse_var_11 + 1536)
              let cse_var_9: int32 = (cse_var_11 + 768)
              let cse_var_8: int32 = (cse_var_11 + 19968)
              let cse_var_7: int32 = (cse_var_11 + 19200)
              let cse_var_6: int32 = (cse_var_11 + 18432)
               {
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_26], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_24], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_26], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_24], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_25], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_25], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_24], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_24], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
              }
            }
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax2.inner: int32, 0, 7) {
          let cse_var_28: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 14)
          let cse_var_27: int32 = ((cse_var_28*32) + (ax1.inner*16))
          T_relu[ramp(((((((cse_var_28*6272) + (ax1.inner*3136)) + (floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 14), 7)*1568)) + (ax2.inner*224)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 7)*32)) + (ax3.outer.inner*16)), 1, 16)] = max((((conv2d_NCHWc_1[((ax1.inner*7) + ax2.inner)] + placeholder_2[ramp(cse_var_27, 1, 16)])*placeholder_3[ramp(cse_var_27, 1, 16)]) + placeholder_4[ramp(cse_var_27, 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 3: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_11 (weight 1 key: ["6b0d226afab7de584e086dc68f47c79a", [1, 4, 14, 14, 16], [6, 4, 3, 3, 16, 16], [1, 6, 1, 1, 16], [1, 6, 1, 1, 16], [1, 6, 1, 1, 16], [1, 6, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 4, 14, 14, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 15)) && (i3 >= 1)) && (i3 < 15)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [6, 4, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3, data_pad_i4 = tuple(data_pad.op.axis) + tuple(data_pad.op.reduce_axis)
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=7)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=1)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=14)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=32)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=3)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=7)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=1)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=1)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=14)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
s[data_pad].compute_at(s[conv2d_NCHWc], conv2d_NCHWc_ic_o)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 512)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[data_pad].vectorize(data_pad_i4)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [12544], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [55296], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [96], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [96], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [96], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [18816], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_9: placeholder_15: Buffer(placeholder_14, float32, [1, 6, 1, 1, 16], []), placeholder_7: placeholder_16: Buffer(placeholder_12, float32, [1, 6, 1, 1, 16], []), placeholder_8: placeholder_17: Buffer(placeholder_13, float32, [1, 6, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 6, 14, 14, 16], []), placeholder_5: placeholder_18: Buffer(placeholder_10, float32, [1, 4, 14, 14, 16], []), placeholder_6: placeholder_19: Buffer(placeholder_11, float32, [6, 4, 3, 3, 16, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 84) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global;
    allocate(data_pad: Pointer(global float32), float32, [864]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 2) {
        let cse_var_11: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)
        let cse_var_10: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 14)
        let cse_var_9: bool = (cse_var_11 < 14)
        let cse_var_8: bool = (cse_var_10 < 13)
        let cse_var_7: bool = (14 <= cse_var_11)
        let cse_var_6: bool = (1 <= cse_var_10)
        let cse_var_5: bool = (cse_var_9 && cse_var_8)
        let cse_var_4: bool = (cse_var_9 && cse_var_6)
        let cse_var_3: bool = (cse_var_7 && cse_var_8)
        let cse_var_2: bool = (cse_var_7 && cse_var_6)
        let cse_var_1: int32 = (((ic.outer*6272) + (floordiv(cse_var_11, 14)*1568)) + (cse_var_10*16))
         {
          data_pad_1: Buffer(data_pad, float32, [864], [])[ramp(0, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 240), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(16, 1, 16)] = @tir.if_then_else(cse_var_7, placeholder[ramp((cse_var_1 - 224), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(32, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_1 - 208), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(48, 1, 16)] = @tir.if_then_else(cse_var_6, placeholder[ramp((cse_var_1 - 16), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(64, 1, 16)] = placeholder[ramp(cse_var_1, 1, 16)]
          data_pad_1[ramp(80, 1, 16)] = @tir.if_then_else(cse_var_8, placeholder[ramp((cse_var_1 + 16), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(96, 1, 16)] = @tir.if_then_else(cse_var_6, placeholder[ramp((cse_var_1 + 208), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(112, 1, 16)] = placeholder[ramp((cse_var_1 + 224), 1, 16)]
          data_pad_1[ramp(128, 1, 16)] = @tir.if_then_else(cse_var_8, placeholder[ramp((cse_var_1 + 240), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(144, 1, 16)] = @tir.if_then_else(cse_var_6, placeholder[ramp((cse_var_1 + 432), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(160, 1, 16)] = placeholder[ramp((cse_var_1 + 448), 1, 16)]
          data_pad_1[ramp(176, 1, 16)] = @tir.if_then_else(cse_var_8, placeholder[ramp((cse_var_1 + 464), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(192, 1, 16)] = @tir.if_then_else(cse_var_6, placeholder[ramp((cse_var_1 + 656), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(208, 1, 16)] = placeholder[ramp((cse_var_1 + 672), 1, 16)]
          data_pad_1[ramp(224, 1, 16)] = @tir.if_then_else(cse_var_8, placeholder[ramp((cse_var_1 + 688), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(240, 1, 16)] = @tir.if_then_else(cse_var_6, placeholder[ramp((cse_var_1 + 880), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(256, 1, 16)] = placeholder[ramp((cse_var_1 + 896), 1, 16)]
          data_pad_1[ramp(272, 1, 16)] = @tir.if_then_else(cse_var_8, placeholder[ramp((cse_var_1 + 912), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(288, 1, 16)] = @tir.if_then_else(cse_var_6, placeholder[ramp((cse_var_1 + 1104), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(304, 1, 16)] = placeholder[ramp((cse_var_1 + 1120), 1, 16)]
          data_pad_1[ramp(320, 1, 16)] = @tir.if_then_else(cse_var_8, placeholder[ramp((cse_var_1 + 1136), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(336, 1, 16)] = @tir.if_then_else(cse_var_6, placeholder[ramp((cse_var_1 + 1328), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(352, 1, 16)] = placeholder[ramp((cse_var_1 + 1344), 1, 16)]
          data_pad_1[ramp(368, 1, 16)] = @tir.if_then_else(cse_var_8, placeholder[ramp((cse_var_1 + 1360), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(384, 1, 16)] = @tir.if_then_else(cse_var_4, placeholder[ramp((cse_var_1 + 1552), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(400, 1, 16)] = @tir.if_then_else(cse_var_9, placeholder[ramp((cse_var_1 + 1568), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(416, 1, 16)] = @tir.if_then_else(cse_var_5, placeholder[ramp((cse_var_1 + 1584), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(432, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 2896), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(448, 1, 16)] = @tir.if_then_else(cse_var_7, placeholder[ramp((cse_var_1 + 2912), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(464, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_1 + 2928), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(480, 1, 16)] = @tir.if_then_else(cse_var_6, placeholder[ramp((cse_var_1 + 3120), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(496, 1, 16)] = placeholder[ramp((cse_var_1 + 3136), 1, 16)]
          data_pad_1[ramp(512, 1, 16)] = @tir.if_then_else(cse_var_8, placeholder[ramp((cse_var_1 + 3152), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(528, 1, 16)] = @tir.if_then_else(cse_var_6, placeholder[ramp((cse_var_1 + 3344), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(544, 1, 16)] = placeholder[ramp((cse_var_1 + 3360), 1, 16)]
          data_pad_1[ramp(560, 1, 16)] = @tir.if_then_else(cse_var_8, placeholder[ramp((cse_var_1 + 3376), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(576, 1, 16)] = @tir.if_then_else(cse_var_6, placeholder[ramp((cse_var_1 + 3568), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(592, 1, 16)] = placeholder[ramp((cse_var_1 + 3584), 1, 16)]
          data_pad_1[ramp(608, 1, 16)] = @tir.if_then_else(cse_var_8, placeholder[ramp((cse_var_1 + 3600), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(624, 1, 16)] = @tir.if_then_else(cse_var_6, placeholder[ramp((cse_var_1 + 3792), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(640, 1, 16)] = placeholder[ramp((cse_var_1 + 3808), 1, 16)]
          data_pad_1[ramp(656, 1, 16)] = @tir.if_then_else(cse_var_8, placeholder[ramp((cse_var_1 + 3824), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(672, 1, 16)] = @tir.if_then_else(cse_var_6, placeholder[ramp((cse_var_1 + 4016), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(688, 1, 16)] = placeholder[ramp((cse_var_1 + 4032), 1, 16)]
          data_pad_1[ramp(704, 1, 16)] = @tir.if_then_else(cse_var_8, placeholder[ramp((cse_var_1 + 4048), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(720, 1, 16)] = @tir.if_then_else(cse_var_6, placeholder[ramp((cse_var_1 + 4240), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(736, 1, 16)] = placeholder[ramp((cse_var_1 + 4256), 1, 16)]
          data_pad_1[ramp(752, 1, 16)] = @tir.if_then_else(cse_var_8, placeholder[ramp((cse_var_1 + 4272), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(768, 1, 16)] = @tir.if_then_else(cse_var_6, placeholder[ramp((cse_var_1 + 4464), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(784, 1, 16)] = placeholder[ramp((cse_var_1 + 4480), 1, 16)]
          data_pad_1[ramp(800, 1, 16)] = @tir.if_then_else(cse_var_8, placeholder[ramp((cse_var_1 + 4496), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(816, 1, 16)] = @tir.if_then_else(cse_var_4, placeholder[ramp((cse_var_1 + 4688), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(832, 1, 16)] = @tir.if_then_else(cse_var_9, placeholder[ramp((cse_var_1 + 4704), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(848, 1, 16)] = @tir.if_then_else(cse_var_5, placeholder[ramp((cse_var_1 + 4720), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          for (kw.outer: int32, 0, 3) {
            for (ic.inner: int32, 0, 32) {
              let cse_var_28: int32 = floordiv(ic.inner, 16)
              let cse_var_27: int32 = floormod(ic.inner, 16)
              let cse_var_26: int32 = (((cse_var_28*432) + (kw.outer*16)) + cse_var_27)
              let cse_var_25: int32 = (cse_var_26 + 96)
              let cse_var_24: int32 = (cse_var_26 + 48)
              let cse_var_23: int32 = (cse_var_26 + 384)
              let cse_var_22: int32 = (cse_var_26 + 336)
              let cse_var_21: int32 = (cse_var_26 + 288)
              let cse_var_20: int32 = (cse_var_26 + 240)
              let cse_var_19: int32 = (cse_var_26 + 192)
              let cse_var_18: int32 = (cse_var_26 + 144)
              let cse_var_17: int32 = (((((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)*18432) + (ic.outer*4608)) + (cse_var_28*2304)) + (kw.outer*256)) + (cse_var_27*16))
              let cse_var_16: int32 = (cse_var_17 + 9984)
              let cse_var_15: int32 = (cse_var_17 + 9216)
              let cse_var_14: int32 = (cse_var_17 + 768)
              let cse_var_13: int32 = (cse_var_17 + 1536)
              let cse_var_12: int32 = (cse_var_17 + 10752)
               {
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_26], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_24], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_25], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_26], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_24], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_25], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_24], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_25], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_24], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_25], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_25], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_25], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
              }
            }
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax2.inner: int32, 0, 7) {
          let cse_var_30: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)
          let cse_var_29: int32 = ((cse_var_30*32) + (ax1.inner*16))
          T_relu[ramp((((((cse_var_30*6272) + (ax1.inner*3136)) + (floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28), 14)*1568)) + (ax2.inner*224)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 14)*16)), 1, 16)] = max((((conv2d_NCHWc_1[((ax1.inner*7) + ax2.inner)] + placeholder_2[ramp(cse_var_29, 1, 16)])*placeholder_3[ramp(cse_var_29, 1, 16)]) + placeholder_4[ramp(cse_var_29, 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 4: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_13 (weight 1 key: ["f6615ae9259e3b2add2908c0cd980cb6", [1, 36, 14, 14, 16], [12, 36, 1, 1, 16, 16], [1, 12, 1, 1, 16], [1, 12, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 36, 14, 14, 16]
placeholder = PLACEHOLDER [12, 36, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=1)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=4)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax1_o, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax2_o, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax3_o, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax4_o, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
s[T_relu].reorder(T_relu_ax0_o, T_relu_ax1_o, T_relu_ax2_o, T_relu_ax3_o, T_relu_ax4_o, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o)
T_relu_ax0_o_ax1_o_fused_ax2_o_fused_ax3_o_fused_ax4_o_fused = s[T_relu].fuse(T_relu_ax0_o, T_relu_ax1_o, T_relu_ax2_o, T_relu_ax3_o, T_relu_ax4_o)
s[T_relu].parallel(T_relu_ax0_o_ax1_o_fused_ax2_o_fused_ax3_o_fused_ax4_o_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 16)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_6: Pointer(float32), float32, [112896], []),
             placeholder_1: Buffer(placeholder_7: Pointer(float32), float32, [110592], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [192], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [37632], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_3: placeholder_9: Buffer(placeholder_6, float32, [1, 36, 14, 14, 16], []), placeholder_4: placeholder_10: Buffer(placeholder_7, float32, [12, 36, 1, 1, 16, 16], []), placeholder_5: placeholder_11: Buffer(placeholder_8, float32, [1, 12, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 12, 14, 14, 16], [])} {
  for (ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused.ax4.outer.fused: int32, 0, 168) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 144) {
        for (ic.inner: int32, 0, 4) {
          let cse_var_9: int32 = (((floordiv(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused.ax4.outer.fused, 28)*18432) + (ic.outer*64)) + (ic.inner*16))
          let cse_var_8: int32 = (cse_var_9 + 9216)
          let cse_var_7: int32 = ((((floordiv(ic.outer, 4)*3136) + (floormod(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused.ax4.outer.fused, 28)*112)) + (floormod(ic.outer, 4)*4)) + ic.inner)
          let cse_var_6: int32 = (cse_var_7 + 96)
          let cse_var_5: int32 = (cse_var_7 + 80)
          let cse_var_4: int32 = (cse_var_7 + 64)
          let cse_var_3: int32 = (cse_var_7 + 48)
          let cse_var_2: int32 = (cse_var_7 + 32)
          let cse_var_1: int32 = (cse_var_7 + 16)
           {
            conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_10: int32 = floordiv(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused.ax4.outer.fused, 28)
          T_relu[ramp(((((cse_var_10*6272) + (ax1.inner*3136)) + (floormod(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused.ax4.outer.fused, 28)*112)) + (ax3.inner*16)), 1, 16)] = max((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(((cse_var_10*32) + (ax1.inner*16)), 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 5: vm_mod_fused_nn_max_pool2d (weight 1 key: ["840abcf4051ab92cd9ec49f77358d7e7", [1, 2, 112, 112, 32], [1, 2, 56, 56, 32]]) =====
placeholder = PLACEHOLDER [1, 2, 112, 112, 32]
pad_temp(ax0, ax1, ax2, ax3, ax4) = tir.if_then_else(((ax2 < 112) && (ax3 < 112)), placeholder[ax0, ax1, ax2, ax3, ax4], -3.40282e+38f)
tensor(ax0, ax1, ax2, ax3, ax4) max= pad_temp[ax0, ax1, ((ax2*2) + rv0), ((ax3*2) + rv1), ax4]


Trace for this task is: 
pad_temp_ax0, pad_temp_ax1, pad_temp_ax2, pad_temp_ax3, pad_temp_ax4 = tuple(pad_temp.op.axis) + tuple(pad_temp.op.reduce_axis)
tensor_ax0, tensor_ax1, tensor_ax2, tensor_ax3, tensor_ax4, tensor_rv0, tensor_rv1 = tuple(tensor.op.axis) + tuple(tensor.op.reduce_axis)
s[tensor].compute_root()
s[pad_temp].compute_at(s[tensor], tensor_ax4)
tensor_ax0_ax1_fused_ax2_fused = s[tensor].fuse(tensor_ax0, tensor_ax1, tensor_ax2)
s[tensor].parallel(tensor_ax0_ax1_fused_ax2_fused)
s[tensor].pragma(tensor_ax0_ax1_fused_ax2_fused, "auto_unroll_max_step", 64)
s[tensor].pragma(tensor_ax0_ax1_fused_ax2_fused, "unroll_explicit", True)
pad_temp_ax3_ax4_fused = s[pad_temp].fuse(pad_temp_ax3, pad_temp_ax4)
s[pad_temp].vectorize(pad_temp_ax3_ax4_fused)


The best replacement found is:
@main = primfn(placeholder_1: handle, tensor_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_2: Pointer(float32), float32, [802816], []),
             tensor: Buffer(tensor_2: Pointer(float32), float32, [200704], [])}
  buffer_map = {placeholder_1: placeholder, tensor_1: tensor}
  preflattened_buffer_map = {placeholder_1: placeholder_3: Buffer(placeholder_2, float32, [1, 2, 112, 112, 32], []), tensor_1: tensor_3: Buffer(tensor_2, float32, [1, 2, 56, 56, 32], [])} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 112) "parallel" {
    allocate(pad_temp: Pointer(global float32), float32, [9]), storage_scope = global;
    for (ax3: int32, 0, 56) {
      for (ax4: int32, 0, 32) {
        let cse_var_4: bool = (ax3 < 55)
        let cse_var_3: bool = (floormod(ax0.ax1.fused.ax2.fused, 56) < 55)
        let cse_var_2: int32 = (((ax0.ax1.fused.ax2.fused*7168) + (ax3*64)) + ax4)
        let cse_var_1: int32 = (((ax0.ax1.fused.ax2.fused*1792) + (ax3*32)) + ax4)
         {
          pad_temp_1: Buffer(pad_temp, float32, [9], [], align=32)[0] = placeholder[cse_var_2]
          pad_temp_1[1] = placeholder[(cse_var_2 + 32)]
          pad_temp_1[2] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_2 + 64)], -3.40282e+38f32, dtype=float32)
          pad_temp_1[3] = placeholder[(cse_var_2 + 3584)]
          pad_temp_1[4] = placeholder[(cse_var_2 + 3616)]
          pad_temp_1[5] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_2 + 3648)], -3.40282e+38f32, dtype=float32)
          pad_temp_1[6] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_2 + 7168)], -3.40282e+38f32, dtype=float32)
          pad_temp_1[7] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_2 + 7200)], -3.40282e+38f32, dtype=float32)
          pad_temp_1[8] = @tir.if_then_else((cse_var_3 && cse_var_4), placeholder[(cse_var_2 + 7232)], -3.40282e+38f32, dtype=float32)
          tensor[cse_var_1] = -3.40282e+38f32
          tensor[cse_var_1] = max(tensor[cse_var_1], pad_temp_1[0])
          tensor[cse_var_1] = max(tensor[cse_var_1], pad_temp_1[1])
          tensor[cse_var_1] = max(tensor[cse_var_1], pad_temp_1[2])
          tensor[cse_var_1] = max(tensor[cse_var_1], pad_temp_1[3])
          tensor[cse_var_1] = max(tensor[cse_var_1], pad_temp_1[4])
          tensor[cse_var_1] = max(tensor[cse_var_1], pad_temp_1[5])
          tensor[cse_var_1] = max(tensor[cse_var_1], pad_temp_1[6])
          tensor[cse_var_1] = max(tensor[cse_var_1], pad_temp_1[7])
          tensor[cse_var_1] = max(tensor[cse_var_1], pad_temp_1[8])
        }
      }
    }
  }
}


==== Task 6: vm_mod_fused_nn_max_pool2d_4 (weight 1 key: ["4c30bb331afe286230790b9cd09fe258", [1, 64, 7, 7, 16], [1, 64, 7, 7, 16]]) =====
placeholder = PLACEHOLDER [1, 64, 7, 7, 16]
pad_temp(ax0, ax1, ax2, ax3, ax4) = tir.if_then_else(((((ax2 >= 1) && (ax2 < 8)) && (ax3 >= 1)) && (ax3 < 8)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], -3.40282e+38f)
tensor(ax0, ax1, ax2, ax3, ax4) max= pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]


Trace for this task is: 
pad_temp_ax0, pad_temp_ax1, pad_temp_ax2, pad_temp_ax3, pad_temp_ax4 = tuple(pad_temp.op.axis) + tuple(pad_temp.op.reduce_axis)
tensor_ax0, tensor_ax1, tensor_ax2, tensor_ax3, tensor_ax4, tensor_rv0, tensor_rv1 = tuple(tensor.op.axis) + tuple(tensor.op.reduce_axis)
s[tensor].compute_root()
s[pad_temp].compute_at(s[tensor], tensor_ax1)
tensor_ax0_ax1_fused = s[tensor].fuse(tensor_ax0, tensor_ax1)
s[tensor].parallel(tensor_ax0_ax1_fused)
s[tensor].pragma(tensor_ax0_ax1_fused, "auto_unroll_max_step", 16)
s[tensor].pragma(tensor_ax0_ax1_fused, "unroll_explicit", True)
s[pad_temp].vectorize(pad_temp_ax4)


The best replacement found is:
@main = primfn(placeholder_1: handle, tensor_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_2: Pointer(float32), float32, [50176], []),
             tensor: Buffer(tensor_2: Pointer(float32), float32, [50176], [])}
  buffer_map = {placeholder_1: placeholder, tensor_1: tensor}
  preflattened_buffer_map = {placeholder_1: placeholder_3: Buffer(placeholder_2, float32, [1, 64, 7, 7, 16], []), tensor_1: tensor_3: Buffer(tensor_2, float32, [1, 64, 7, 7, 16], [])} {
  for (ax0.ax1.fused: int32, 0, 64) "parallel" {
    allocate(pad_temp: Pointer(global float32), float32, [1296]), storage_scope = global {
      for (ax2: int32, 0, 9) {
        let cse_var_3: int32 = (ax2*144)
        let cse_var_2: int32 = ((ax0.ax1.fused*784) + (ax2*112))
        let cse_var_1: bool = ((1 <= ax2) && (ax2 < 8))
         {
          pad_temp_1: Buffer(pad_temp, float32, [1296], [])[ramp(cse_var_3, 1, 16)] = broadcast(-3.40282e+38f32, 16)
          pad_temp_1[ramp((cse_var_3 + 16), 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 112), 1, 16)], broadcast(-3.40282e+38f32, 16), dtype=float32x16)
          pad_temp_1[ramp((cse_var_3 + 32), 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 96), 1, 16)], broadcast(-3.40282e+38f32, 16), dtype=float32x16)
          pad_temp_1[ramp((cse_var_3 + 48), 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 80), 1, 16)], broadcast(-3.40282e+38f32, 16), dtype=float32x16)
          pad_temp_1[ramp((cse_var_3 + 64), 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 64), 1, 16)], broadcast(-3.40282e+38f32, 16), dtype=float32x16)
          pad_temp_1[ramp((cse_var_3 + 80), 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 48), 1, 16)], broadcast(-3.40282e+38f32, 16), dtype=float32x16)
          pad_temp_1[ramp((cse_var_3 + 96), 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 32), 1, 16)], broadcast(-3.40282e+38f32, 16), dtype=float32x16)
          pad_temp_1[ramp((cse_var_3 + 112), 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 16), 1, 16)], broadcast(-3.40282e+38f32, 16), dtype=float32x16)
          pad_temp_1[ramp((cse_var_3 + 128), 1, 16)] = broadcast(-3.40282e+38f32, 16)
        }
      }
      for (ax2_1: int32, 0, 7) {
        for (ax3: int32, 0, 7) {
          for (ax4: int32, 0, 16) {
            let cse_var_6: int32 = (ax3*16)
            let cse_var_5: int32 = (((ax2_1*144) + cse_var_6) + ax4)
            let cse_var_4: int32 = ((((ax0.ax1.fused*784) + (ax2_1*112)) + cse_var_6) + ax4)
             {
              tensor[cse_var_4] = -3.40282e+38f32
              tensor[cse_var_4] = max(tensor[cse_var_4], pad_temp_1[cse_var_5])
              tensor[cse_var_4] = max(tensor[cse_var_4], pad_temp_1[(cse_var_5 + 16)])
              tensor[cse_var_4] = max(tensor[cse_var_4], pad_temp_1[(cse_var_5 + 32)])
              tensor[cse_var_4] = max(tensor[cse_var_4], pad_temp_1[(cse_var_5 + 144)])
              tensor[cse_var_4] = max(tensor[cse_var_4], pad_temp_1[(cse_var_5 + 160)])
              tensor[cse_var_4] = max(tensor[cse_var_4], pad_temp_1[(cse_var_5 + 176)])
              tensor[cse_var_4] = max(tensor[cse_var_4], pad_temp_1[(cse_var_5 + 288)])
              tensor[cse_var_4] = max(tensor[cse_var_4], pad_temp_1[(cse_var_5 + 304)])
              tensor[cse_var_4] = max(tensor[cse_var_4], pad_temp_1[(cse_var_5 + 320)])
            }
          }
        }
      }
    }
  }
}


==== Task 7: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_14 (weight 1 key: ["ce1b4a245fb9b3a0526fcd7e77d29d3f", [1, 12, 14, 14, 16], [16, 12, 3, 3, 16, 16], [1, 16, 1, 1, 16], [1, 16, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 12, 14, 14, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 15)) && (i3 >= 1)) && (i3 < 15)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [16, 12, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 16, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3, data_pad_i4 = tuple(data_pad.op.axis) + tuple(data_pad.op.reduce_axis)
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=7)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=1)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=1)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=3)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax1_o, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax2_o, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=7)
T_relu_ax3_o, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=1)
T_relu_ax4_o, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
s[T_relu].reorder(T_relu_ax0_o, T_relu_ax1_o, T_relu_ax2_o, T_relu_ax3_o, T_relu_ax4_o, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o)
data_pad_i0_i1_fused_i2_fused_i3_fused = s[data_pad].fuse(data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3)
s[data_pad].parallel(data_pad_i0_i1_fused_i2_fused_i3_fused)
T_relu_ax0_o_ax1_o_fused_ax2_o_fused_ax3_o_fused_ax4_o_fused = s[T_relu].fuse(T_relu_ax0_o, T_relu_ax1_o, T_relu_ax2_o, T_relu_ax3_o, T_relu_ax4_o)
s[T_relu].parallel(T_relu_ax0_o_ax1_o_fused_ax2_o_fused_ax3_o_fused_ax4_o_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 512)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[data_pad].vectorize(data_pad_i4)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_6: Pointer(float32), float32, [37632], []),
             placeholder_1: Buffer(placeholder_7: Pointer(float32), float32, [442368], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [256], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [50176], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_3: placeholder_9: Buffer(placeholder_6, float32, [1, 12, 14, 14, 16], []), placeholder_4: placeholder_10: Buffer(placeholder_7, float32, [16, 12, 3, 3, 16, 16], []), placeholder_5: placeholder_11: Buffer(placeholder_8, float32, [1, 16, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 16, 14, 14, 16], [])} {
  allocate(data_pad: Pointer(global float32), float32, [49152]), storage_scope = global {
    for (i0.i1.fused.i2.fused.i3.fused: int32, 0, 3072) "parallel" {
      let cse_var_2: int32 = floormod(i0.i1.fused.i2.fused.i3.fused, 256)
      let cse_var_1: int32 = floormod(i0.i1.fused.i2.fused.i3.fused, 16)
      data_pad_1: Buffer(data_pad, float32, [49152], [])[ramp((i0.i1.fused.i2.fused.i3.fused*16), 1, 16)] = @tir.if_then_else(((((16 <= cse_var_2) && (cse_var_2 < 240)) && (1 <= cse_var_1)) && (cse_var_1 < 15)), placeholder[ramp(((((floordiv(i0.i1.fused.i2.fused.i3.fused, 256)*3136) + (floordiv(cse_var_2, 16)*224)) + (cse_var_1*16)) - 240), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
    }
    for (ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused.ax4.outer.fused: int32, 0, 224) "parallel" {
      allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global {
        conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
        conv2d_NCHWc_1[1] = broadcast(0f32, 16)
        conv2d_NCHWc_1[2] = broadcast(0f32, 16)
        conv2d_NCHWc_1[3] = broadcast(0f32, 16)
        conv2d_NCHWc_1[4] = broadcast(0f32, 16)
        conv2d_NCHWc_1[5] = broadcast(0f32, 16)
        conv2d_NCHWc_1[6] = broadcast(0f32, 16)
        conv2d_NCHWc_1[7] = broadcast(0f32, 16)
        conv2d_NCHWc_1[8] = broadcast(0f32, 16)
        conv2d_NCHWc_1[9] = broadcast(0f32, 16)
        conv2d_NCHWc_1[10] = broadcast(0f32, 16)
        conv2d_NCHWc_1[11] = broadcast(0f32, 16)
        conv2d_NCHWc_1[12] = broadcast(0f32, 16)
        conv2d_NCHWc_1[13] = broadcast(0f32, 16)
        for (ic.outer: int32, 0, 12) {
          for (kw.outer: int32, 0, 3) {
            for (ic.inner: int32, 0, 16) {
              let cse_var_17: int32 = ((((floordiv(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused.ax4.outer.fused, 28)*55296) + (ic.outer*2304)) + (kw.outer*256)) + (ic.inner*16))
              let cse_var_16: int32 = (cse_var_17 + 768)
              let cse_var_15: int32 = (cse_var_17 + 29184)
              let cse_var_14: int32 = (cse_var_17 + 28416)
              let cse_var_13: int32 = (cse_var_17 + 27648)
              let cse_var_12: int32 = (cse_var_17 + 1536)
              let cse_var_11: int32 = (((((ic.outer*4096) + (floordiv(floormod(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused.ax4.outer.fused, 28), 14)*1792)) + (kw.outer*16)) + (floormod(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused.ax4.outer.fused, 14)*16)) + ic.inner)
              let cse_var_10: int32 = (cse_var_11 + 768)
              let cse_var_9: int32 = (cse_var_11 + 512)
              let cse_var_8: int32 = (cse_var_11 + 256)
              let cse_var_7: int32 = (cse_var_11 + 2048)
              let cse_var_6: int32 = (cse_var_11 + 1792)
              let cse_var_5: int32 = (cse_var_11 + 1536)
              let cse_var_4: int32 = (cse_var_11 + 1280)
              let cse_var_3: int32 = (cse_var_11 + 1024)
               {
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_11], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_8], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_9], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_10], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_3], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_4], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_5], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_11], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_8], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_9], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_10], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_3], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_4], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_5], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_8], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_9], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_10], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_3], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_4], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_5], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_6], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_8], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_9], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_10], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_3], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_4], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_5], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_6], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_9], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_10], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_3], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_4], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_5], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_6], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_7], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_9], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_10], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_3], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_4], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_5], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_6], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_7], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
              }
            }
          }
        }
        for (ax1.inner: int32, 0, 2) {
          for (ax2.inner: int32, 0, 7) {
            let cse_var_18: int32 = floordiv(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused.ax4.outer.fused, 28)
            T_relu[ramp((((((cse_var_18*6272) + (ax1.inner*3136)) + (floordiv(floormod(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused.ax4.outer.fused, 28), 14)*1568)) + (ax2.inner*224)) + (floormod(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused.ax4.outer.fused, 14)*16)), 1, 16)] = max((conv2d_NCHWc_1[((ax1.inner*7) + ax2.inner)] + placeholder_2[ramp(((cse_var_18*32) + (ax1.inner*16)), 1, 16)]), broadcast(0f32, 16))
          }
        }
      }
    }
  }
}


==== Task 8: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 (weight 1 key: ["f6615ae9259e3b2add2908c0cd980cb6", [1, 20, 28, 28, 16], [8, 20, 1, 1, 16, 16], [1, 8, 1, 1, 16], [1, 8, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 20, 28, 28, 16]
placeholder = PLACEHOLDER [8, 20, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=1)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=2)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=4)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=4)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=7)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=1)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=28)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=8)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=4)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=4)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=7)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=1)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=28)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 512)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_6: Pointer(float32), float32, [250880], []),
             placeholder_1: Buffer(placeholder_7: Pointer(float32), float32, [40960], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [128], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [100352], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_3: placeholder_9: Buffer(placeholder_6, float32, [1, 20, 28, 28, 16], []), placeholder_4: placeholder_10: Buffer(placeholder_7, float32, [8, 20, 1, 1, 16, 16], []), placeholder_5: placeholder_11: Buffer(placeholder_8, float32, [1, 8, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 8, 28, 28, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused: int32, 0, 784) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [8]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [8], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 40) {
        let cse_var_48: int32 = ((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 196)*10240) + (ic.outer*128))
        let cse_var_47: int32 = (cse_var_48 + 16)
        let cse_var_46: int32 = (cse_var_48 + 32)
        let cse_var_45: int32 = (cse_var_48 + 48)
        let cse_var_44: int32 = (cse_var_48 + 5120)
        let cse_var_43: int32 = (cse_var_48 + 5136)
        let cse_var_42: int32 = (cse_var_48 + 5152)
        let cse_var_41: int32 = (cse_var_48 + 5168)
        let cse_var_40: int32 = (cse_var_48 + 5184)
        let cse_var_39: int32 = (cse_var_48 + 5200)
        let cse_var_38: int32 = (cse_var_48 + 5216)
        let cse_var_37: int32 = (cse_var_48 + 5232)
        let cse_var_36: int32 = (cse_var_48 + 64)
        let cse_var_35: int32 = (cse_var_48 + 80)
        let cse_var_34: int32 = (cse_var_48 + 96)
        let cse_var_33: int32 = (cse_var_48 + 112)
        let cse_var_32: int32 = ((((floordiv(ic.outer, 2)*12544) + (floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 196), 28)*1792)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 28)*16)) + (floormod(ic.outer, 2)*8))
        let cse_var_31: int32 = (cse_var_32 + 449)
        let cse_var_30: int32 = (cse_var_32 + 448)
        let cse_var_29: int32 = (cse_var_32 + 4)
        let cse_var_28: int32 = (cse_var_32 + 3)
        let cse_var_27: int32 = (cse_var_32 + 2)
        let cse_var_26: int32 = (cse_var_32 + 1351)
        let cse_var_25: int32 = (cse_var_32 + 1350)
        let cse_var_24: int32 = (cse_var_32 + 1349)
        let cse_var_23: int32 = (cse_var_32 + 1348)
        let cse_var_22: int32 = (cse_var_32 + 1347)
        let cse_var_21: int32 = (cse_var_32 + 1346)
        let cse_var_20: int32 = (cse_var_32 + 1345)
        let cse_var_19: int32 = (cse_var_32 + 1)
        let cse_var_18: int32 = (cse_var_32 + 451)
        let cse_var_17: int32 = (cse_var_32 + 450)
        let cse_var_16: int32 = (cse_var_32 + 452)
        let cse_var_15: int32 = (cse_var_32 + 453)
        let cse_var_14: int32 = (cse_var_32 + 454)
        let cse_var_13: int32 = (cse_var_32 + 455)
        let cse_var_12: int32 = (cse_var_32 + 5)
        let cse_var_11: int32 = (cse_var_32 + 6)
        let cse_var_10: int32 = (cse_var_32 + 7)
        let cse_var_9: int32 = (cse_var_32 + 896)
        let cse_var_8: int32 = (cse_var_32 + 897)
        let cse_var_7: int32 = (cse_var_32 + 898)
        let cse_var_6: int32 = (cse_var_32 + 899)
        let cse_var_5: int32 = (cse_var_32 + 900)
        let cse_var_4: int32 = (cse_var_32 + 901)
        let cse_var_3: int32 = (cse_var_32 + 902)
        let cse_var_2: int32 = (cse_var_32 + 903)
        let cse_var_1: int32 = (cse_var_32 + 1344)
         {
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_32], 16)*placeholder_1[ramp(cse_var_48, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_30], 16)*placeholder_1[ramp(cse_var_48, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_9], 16)*placeholder_1[ramp(cse_var_48, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_48, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_19], 16)*placeholder_1[ramp(cse_var_47, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_31], 16)*placeholder_1[ramp(cse_var_47, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_47, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_20], 16)*placeholder_1[ramp(cse_var_47, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_27], 16)*placeholder_1[ramp(cse_var_46, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_17], 16)*placeholder_1[ramp(cse_var_46, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_46, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_21], 16)*placeholder_1[ramp(cse_var_46, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_28], 16)*placeholder_1[ramp(cse_var_45, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_18], 16)*placeholder_1[ramp(cse_var_45, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_45, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_22], 16)*placeholder_1[ramp(cse_var_45, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_29], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_16], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_23], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_12], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_15], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_24], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_11], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_14], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_25], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_10], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_13], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_26], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_32], 16)*placeholder_1[ramp(cse_var_44, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_30], 16)*placeholder_1[ramp(cse_var_44, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_9], 16)*placeholder_1[ramp(cse_var_44, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_44, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_19], 16)*placeholder_1[ramp(cse_var_43, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_31], 16)*placeholder_1[ramp(cse_var_43, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_43, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_20], 16)*placeholder_1[ramp(cse_var_43, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_27], 16)*placeholder_1[ramp(cse_var_42, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_17], 16)*placeholder_1[ramp(cse_var_42, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_42, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_21], 16)*placeholder_1[ramp(cse_var_42, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_28], 16)*placeholder_1[ramp(cse_var_41, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_18], 16)*placeholder_1[ramp(cse_var_41, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_41, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_22], 16)*placeholder_1[ramp(cse_var_41, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_29], 16)*placeholder_1[ramp(cse_var_40, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_16], 16)*placeholder_1[ramp(cse_var_40, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_40, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_23], 16)*placeholder_1[ramp(cse_var_40, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_12], 16)*placeholder_1[ramp(cse_var_39, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_15], 16)*placeholder_1[ramp(cse_var_39, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_39, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_24], 16)*placeholder_1[ramp(cse_var_39, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_11], 16)*placeholder_1[ramp(cse_var_38, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_14], 16)*placeholder_1[ramp(cse_var_38, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_38, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_25], 16)*placeholder_1[ramp(cse_var_38, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_10], 16)*placeholder_1[ramp(cse_var_37, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_13], 16)*placeholder_1[ramp(cse_var_37, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_37, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_26], 16)*placeholder_1[ramp(cse_var_37, 1, 16)]))
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax2.inner: int32, 0, 4) {
          let cse_var_49: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 196)
          T_relu[ramp((((((cse_var_49*25088) + (ax1.inner*12544)) + (floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 196), 28)*1792)) + (ax2.inner*448)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 28)*16)), 1, 16)] = max((conv2d_NCHWc_1[((ax1.inner*4) + ax2.inner)] + placeholder_2[ramp(((cse_var_49*32) + (ax1.inner*16)), 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 9: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu (weight 1 key: ["f6615ae9259e3b2add2908c0cd980cb6", [1, 4, 56, 56, 16], [4, 4, 1, 1, 16, 16], [1, 4, 1, 1, 16], [1, 4, 56, 56, 16]]) =====
placeholder = PLACEHOLDER [1, 4, 56, 56, 16]
placeholder = PLACEHOLDER [4, 4, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=4)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=4)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=2)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=1)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=4)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=4)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=2)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=1)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 64)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_6: Pointer(float32), float32, [200704], []),
             placeholder_1: Buffer(placeholder_7: Pointer(float32), float32, [4096], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [64], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [200704], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_3: placeholder_9: Buffer(placeholder_6, float32, [1, 4, 56, 56, 16], []), placeholder_4: placeholder_10: Buffer(placeholder_7, float32, [4, 4, 1, 1, 16, 16], []), placeholder_5: placeholder_11: Buffer(placeholder_8, float32, [1, 4, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 4, 56, 56, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 1568) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [8]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [8], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 4) {
        for (ic.inner: int32, 0, 16) {
          let cse_var_6: int32 = ((ic.outer*256) + (ic.inner*16))
          let cse_var_5: int32 = (cse_var_6 + 3072)
          let cse_var_4: int32 = (cse_var_6 + 2048)
          let cse_var_3: int32 = (cse_var_6 + 1024)
          let cse_var_2: int32 = (((((ic.outer*50176) + (floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 112)*3584)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 4)*896)) + (floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 112), 4)*32)) + ic.inner)
          let cse_var_1: int32 = (cse_var_2 + 16)
           {
            conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
            conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
            conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_3, 1, 16)]))
            conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_3, 1, 16)]))
            conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_4, 1, 16)]))
            conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_4, 1, 16)]))
            conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
            conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
          }
        }
      }
      for (ax1.inner: int32, 0, 4) {
        for (ax3.inner: int32, 0, 2) {
          T_relu[ramp((((((ax1.inner*50176) + (floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 112)*3584)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 4)*896)) + (floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 112), 4)*32)) + (ax3.inner*16)), 1, 16)] = max((conv2d_NCHWc_1[((ax1.inner*2) + ax3.inner)] + placeholder_2[ramp((ax1.inner*16), 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 10: vm_mod_fused_nn_avg_pool2d_1 (weight 1 key: ["afaae8b373f21045eb860b447beb9f7a", [1, 16, 28, 28, 16], [1, 16, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 16, 28, 28, 16]
pad_temp(ax0, ax1, ax2, ax3, ax4) = tir.if_then_else(((((ax2 >= 1) && (ax2 < 29)) && (ax3 >= 1)) && (ax3 < 29)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)
tensor(ax0, ax1, ax2, ax3, ax4) += pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]
tensor(ax0, ax1, ax2, ax3, ax4) = (tensor[ax0, ax1, ax2, ax3, ax4]/float32(max((((min(((ax2 - 1) + 2), 27) - ((ax2 - 1) + max((0 - (ax2 - 1)), 0))) + 1)*((min(((ax3 - 1) + 2), 27) - ((ax3 - 1) + max((0 - (ax3 - 1)), 0))) + 1)), 1)))


Trace for this task is: 
pad_temp_ax0, pad_temp_ax1, pad_temp_ax2, pad_temp_ax3, pad_temp_ax4 = tuple(pad_temp.op.axis) + tuple(pad_temp.op.reduce_axis)
tensor_ax0, tensor_ax1, tensor_ax2, tensor_ax3, tensor_ax4, tensor_rv0, tensor_rv1 = tuple(tensor.op.axis) + tuple(tensor.op.reduce_axis)
tensor_ax0, tensor_ax1, tensor_ax2, tensor_ax3, tensor_ax4 = tuple(tensor.op.axis) + tuple(tensor.op.reduce_axis)
s[tensor].compute_at(s[tensor], tensor_ax4)
s[pad_temp].compute_at(s[tensor], tensor_ax1)
tensor_ax0_ax1_fused = s[tensor].fuse(tensor_ax0, tensor_ax1)
s[tensor].parallel(tensor_ax0_ax1_fused)
s[tensor].pragma(tensor_ax0, "auto_unroll_max_step", 16)
s[tensor].pragma(tensor_ax0, "unroll_explicit", True)
s[pad_temp].vectorize(pad_temp_ax4)


The best replacement found is:
@main = primfn(placeholder_1: handle, tensor_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_2: Pointer(float32), float32, [200704], []),
             tensor: Buffer(tensor_2: Pointer(float32), float32, [200704], [])}
  buffer_map = {placeholder_1: placeholder, tensor_1: tensor}
  preflattened_buffer_map = {placeholder_1: placeholder_3: Buffer(placeholder_2, float32, [1, 16, 28, 28, 16], []), tensor_1: tensor_3: Buffer(tensor_2, float32, [1, 16, 28, 28, 16], [])} {
  for (ax0.ax1.fused: int32, 0, 16) "parallel" {
    allocate(pad_temp: Pointer(global float32), float32, [14400]), storage_scope = global;
    allocate(tensor_4: Pointer(global float32), float32, [1]), storage_scope = global {
      for (ax2: int32, 0, 30) {
        for (ax3: int32, 0, 30) {
          let cse_var_1: int32 = (ax3*16)
          pad_temp_1: Buffer(pad_temp, float32, [14400], [])[ramp(((ax2*480) + cse_var_1), 1, 16)] = @tir.if_then_else(((((1 <= ax2) && (ax2 < 29)) && (1 <= ax3)) && (ax3 < 29)), placeholder[ramp(((((ax0.ax1.fused*12544) + (ax2*448)) + cse_var_1) - 464), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
        }
      }
      for (ax2_1: int32, 0, 28) {
        for (ax3_1: int32, 0, 28) {
          for (ax4: int32, 0, 16) {
            let cse_var_3: int32 = (ax3_1*16)
            let cse_var_2: int32 = (((ax2_1*480) + cse_var_3) + ax4)
             {
              tensor_5: Buffer(tensor_4, float32, [1], [], align=4)[0] = 0f32
              tensor_5[0] = (tensor_5[0] + pad_temp_1[cse_var_2])
              tensor_5[0] = (tensor_5[0] + pad_temp_1[(cse_var_2 + 16)])
              tensor_5[0] = (tensor_5[0] + pad_temp_1[(cse_var_2 + 32)])
              tensor_5[0] = (tensor_5[0] + pad_temp_1[(cse_var_2 + 480)])
              tensor_5[0] = (tensor_5[0] + pad_temp_1[(cse_var_2 + 496)])
              tensor_5[0] = (tensor_5[0] + pad_temp_1[(cse_var_2 + 512)])
              tensor_5[0] = (tensor_5[0] + pad_temp_1[(cse_var_2 + 960)])
              tensor_5[0] = (tensor_5[0] + pad_temp_1[(cse_var_2 + 976)])
              tensor_5[0] = (tensor_5[0] + pad_temp_1[(cse_var_2 + 992)])
              tensor[((((ax0.ax1.fused*12544) + (ax2_1*448)) + cse_var_3) + ax4)] = (tensor_5[0] / cast(float32, max(((((min((ax2_1 + 1), 27) + 2) - max((1 - ax2_1), 0)) - ax2_1)*(((min((ax3_1 + 1), 27) + 2) - max((1 - ax3_1), 0)) - ax3_1)), 1)))
            }
          }
        }
      }
    }
  }
}


==== Task 11: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_17 (weight 1 key: ["6b0d226afab7de584e086dc68f47c79a", [1, 8, 14, 14, 16], [10, 8, 3, 3, 16, 16], [1, 10, 1, 1, 16], [1, 10, 1, 1, 16], [1, 10, 1, 1, 16], [1, 10, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 8, 14, 14, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 15)) && (i3 >= 1)) && (i3 < 15)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [10, 8, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3, data_pad_i4 = tuple(data_pad.op.axis) + tuple(data_pad.op.reduce_axis)
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=2)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=2)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=3)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=3)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax1_o, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax2_o, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=2)
T_relu_ax3_o, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=14)
T_relu_ax4_o, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
s[T_relu].reorder(T_relu_ax0_o, T_relu_ax1_o, T_relu_ax2_o, T_relu_ax3_o, T_relu_ax4_o, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o)
s[data_pad].compute_at(s[conv2d_NCHWc], conv2d_NCHWc_ic_o)
T_relu_ax0_o_ax1_o_fused_ax2_o_fused_ax3_o_fused_ax4_o_fused = s[T_relu].fuse(T_relu_ax0_o, T_relu_ax1_o, T_relu_ax2_o, T_relu_ax3_o, T_relu_ax4_o)
s[T_relu].parallel(T_relu_ax0_o_ax1_o_fused_ax2_o_fused_ax3_o_fused_ax4_o_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 64)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[data_pad].vectorize(data_pad_i4)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [25088], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [184320], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [160], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [160], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [160], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [31360], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_7: placeholder_15: Buffer(placeholder_12, float32, [1, 10, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 10, 14, 14, 16], []), placeholder_8: placeholder_16: Buffer(placeholder_13, float32, [1, 10, 1, 1, 16], []), placeholder_9: placeholder_17: Buffer(placeholder_14, float32, [1, 10, 1, 1, 16], []), placeholder_5: placeholder_18: Buffer(placeholder_10, float32, [1, 8, 14, 14, 16], []), placeholder_6: placeholder_19: Buffer(placeholder_11, float32, [10, 8, 3, 3, 16, 16], [])} {
  for (ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused.ax4.outer.fused: int32, 0, 35) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [56]), storage_scope = global;
    allocate(data_pad: Pointer(global float32), float32, [576]), storage_scope = global {
      for (ow.outer.outer.inner: int32, 0, 2) {
        let cse_var_1: int32 = (ow.outer.outer.inner*7)
         {
          conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [56], [])[cse_var_1] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 1)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 2)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 3)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 4)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 5)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 6)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 28)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 29)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 30)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 31)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 32)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 33)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 34)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 14)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 15)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 16)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 17)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 18)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 19)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 20)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 42)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 43)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 44)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 45)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 46)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 47)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 48)] = broadcast(0f32, 16)
          for (ic.outer: int32, 0, 8) {
            let cse_var_7: int32 = floormod(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused.ax4.outer.fused, 7)
            let cse_var_6: bool = (ow.outer.outer.inner < 1)
            let cse_var_5: bool = (1 <= ow.outer.outer.inner)
            let cse_var_4: bool = (cse_var_7 < 6)
            let cse_var_3: bool = (1 <= cse_var_7)
            let cse_var_2: int32 = (((ic.outer*3136) + (cse_var_7*448)) + (ow.outer.outer.inner*112))
             {
              data_pad_1: Buffer(data_pad, float32, [576], [])[ramp(0, 1, 16)] = @tir.if_then_else((cse_var_3 && cse_var_5), placeholder[ramp((cse_var_2 - 240), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(16, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_2 - 224), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(32, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_2 - 208), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(48, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_2 - 192), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(64, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_2 - 176), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(80, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_2 - 160), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(96, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_2 - 144), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(112, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_2 - 128), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(128, 1, 16)] = @tir.if_then_else((cse_var_3 && cse_var_6), placeholder[ramp((cse_var_2 - 112), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(144, 1, 16)] = @tir.if_then_else(cse_var_5, placeholder[ramp((cse_var_2 - 16), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(160, 1, 16)] = placeholder[ramp(cse_var_2, 1, 16)]
              data_pad_1[ramp(176, 1, 16)] = placeholder[ramp((cse_var_2 + 16), 1, 16)]
              data_pad_1[ramp(192, 1, 16)] = placeholder[ramp((cse_var_2 + 32), 1, 16)]
              data_pad_1[ramp(208, 1, 16)] = placeholder[ramp((cse_var_2 + 48), 1, 16)]
              data_pad_1[ramp(224, 1, 16)] = placeholder[ramp((cse_var_2 + 64), 1, 16)]
              data_pad_1[ramp(240, 1, 16)] = placeholder[ramp((cse_var_2 + 80), 1, 16)]
              data_pad_1[ramp(256, 1, 16)] = placeholder[ramp((cse_var_2 + 96), 1, 16)]
              data_pad_1[ramp(272, 1, 16)] = @tir.if_then_else(cse_var_6, placeholder[ramp((cse_var_2 + 112), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(288, 1, 16)] = @tir.if_then_else(cse_var_5, placeholder[ramp((cse_var_2 + 208), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(304, 1, 16)] = placeholder[ramp((cse_var_2 + 224), 1, 16)]
              data_pad_1[ramp(320, 1, 16)] = placeholder[ramp((cse_var_2 + 240), 1, 16)]
              data_pad_1[ramp(336, 1, 16)] = placeholder[ramp((cse_var_2 + 256), 1, 16)]
              data_pad_1[ramp(352, 1, 16)] = placeholder[ramp((cse_var_2 + 272), 1, 16)]
              data_pad_1[ramp(368, 1, 16)] = placeholder[ramp((cse_var_2 + 288), 1, 16)]
              data_pad_1[ramp(384, 1, 16)] = placeholder[ramp((cse_var_2 + 304), 1, 16)]
              data_pad_1[ramp(400, 1, 16)] = placeholder[ramp((cse_var_2 + 320), 1, 16)]
              data_pad_1[ramp(416, 1, 16)] = @tir.if_then_else(cse_var_6, placeholder[ramp((cse_var_2 + 336), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(432, 1, 16)] = @tir.if_then_else((cse_var_4 && cse_var_5), placeholder[ramp((cse_var_2 + 432), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(448, 1, 16)] = @tir.if_then_else(cse_var_4, placeholder[ramp((cse_var_2 + 448), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(464, 1, 16)] = @tir.if_then_else(cse_var_4, placeholder[ramp((cse_var_2 + 464), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(480, 1, 16)] = @tir.if_then_else(cse_var_4, placeholder[ramp((cse_var_2 + 480), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(496, 1, 16)] = @tir.if_then_else(cse_var_4, placeholder[ramp((cse_var_2 + 496), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(512, 1, 16)] = @tir.if_then_else(cse_var_4, placeholder[ramp((cse_var_2 + 512), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(528, 1, 16)] = @tir.if_then_else(cse_var_4, placeholder[ramp((cse_var_2 + 528), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(544, 1, 16)] = @tir.if_then_else(cse_var_4, placeholder[ramp((cse_var_2 + 544), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(560, 1, 16)] = @tir.if_then_else((cse_var_4 && cse_var_6), placeholder[ramp((cse_var_2 + 560), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              for (oh.outer.inner: int32, 0, 2) {
                for (ic.inner: int32, 0, 16) {
                  for (kh.inner: int32, 0, 3) {
                    let cse_var_36: int32 = ((oh.outer.inner*14) + cse_var_1)
                    let cse_var_35: int32 = (cse_var_36 + 2)
                    let cse_var_34: int32 = (cse_var_36 + 28)
                    let cse_var_33: int32 = (cse_var_36 + 29)
                    let cse_var_32: int32 = (cse_var_36 + 3)
                    let cse_var_31: int32 = (cse_var_36 + 30)
                    let cse_var_30: int32 = (cse_var_36 + 31)
                    let cse_var_29: int32 = (cse_var_36 + 32)
                    let cse_var_28: int32 = (cse_var_36 + 33)
                    let cse_var_27: int32 = (cse_var_36 + 34)
                    let cse_var_26: int32 = (cse_var_36 + 4)
                    let cse_var_25: int32 = (cse_var_36 + 5)
                    let cse_var_24: int32 = (cse_var_36 + 6)
                    let cse_var_23: int32 = (cse_var_36 + 1)
                    let cse_var_22: int32 = (((oh.outer.inner*144) + (kh.inner*144)) + ic.inner)
                    let cse_var_21: int32 = (cse_var_22 + 112)
                    let cse_var_20: int32 = (cse_var_22 + 128)
                    let cse_var_19: int32 = (cse_var_22 + 16)
                    let cse_var_18: int32 = (cse_var_22 + 32)
                    let cse_var_17: int32 = (cse_var_22 + 64)
                    let cse_var_16: int32 = (cse_var_22 + 80)
                    let cse_var_15: int32 = (cse_var_22 + 96)
                    let cse_var_14: int32 = (cse_var_22 + 48)
                    let cse_var_13: int32 = ((((floordiv(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused.ax4.outer.fused, 7)*36864) + (ic.outer*2304)) + (kh.inner*768)) + (ic.inner*16))
                    let cse_var_12: int32 = (cse_var_13 + 18432)
                    let cse_var_11: int32 = (cse_var_13 + 512)
                    let cse_var_10: int32 = (cse_var_13 + 256)
                    let cse_var_9: int32 = (cse_var_13 + 18944)
                    let cse_var_8: int32 = (cse_var_13 + 18688)
                     {
                      conv2d_NCHWc_1[cse_var_36] = (conv2d_NCHWc_1[cse_var_36] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_23] = (conv2d_NCHWc_1[cse_var_23] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_35] = (conv2d_NCHWc_1[cse_var_35] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_32] = (conv2d_NCHWc_1[cse_var_32] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_26] = (conv2d_NCHWc_1[cse_var_26] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_25] = (conv2d_NCHWc_1[cse_var_25] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_24] = (conv2d_NCHWc_1[cse_var_24] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_34] = (conv2d_NCHWc_1[cse_var_34] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_33] = (conv2d_NCHWc_1[cse_var_33] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_31] = (conv2d_NCHWc_1[cse_var_31] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_30] = (conv2d_NCHWc_1[cse_var_30] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_29] = (conv2d_NCHWc_1[cse_var_29] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_28] = (conv2d_NCHWc_1[cse_var_28] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_27] = (conv2d_NCHWc_1[cse_var_27] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_36] = (conv2d_NCHWc_1[cse_var_36] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_23] = (conv2d_NCHWc_1[cse_var_23] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_35] = (conv2d_NCHWc_1[cse_var_35] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_32] = (conv2d_NCHWc_1[cse_var_32] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_26] = (conv2d_NCHWc_1[cse_var_26] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_25] = (conv2d_NCHWc_1[cse_var_25] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_24] = (conv2d_NCHWc_1[cse_var_24] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_34] = (conv2d_NCHWc_1[cse_var_34] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_33] = (conv2d_NCHWc_1[cse_var_33] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_31] = (conv2d_NCHWc_1[cse_var_31] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_30] = (conv2d_NCHWc_1[cse_var_30] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_29] = (conv2d_NCHWc_1[cse_var_29] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_28] = (conv2d_NCHWc_1[cse_var_28] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_27] = (conv2d_NCHWc_1[cse_var_27] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_36] = (conv2d_NCHWc_1[cse_var_36] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_23] = (conv2d_NCHWc_1[cse_var_23] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_35] = (conv2d_NCHWc_1[cse_var_35] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_32] = (conv2d_NCHWc_1[cse_var_32] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_26] = (conv2d_NCHWc_1[cse_var_26] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_25] = (conv2d_NCHWc_1[cse_var_25] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_24] = (conv2d_NCHWc_1[cse_var_24] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_34] = (conv2d_NCHWc_1[cse_var_34] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_33] = (conv2d_NCHWc_1[cse_var_33] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_31] = (conv2d_NCHWc_1[cse_var_31] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_30] = (conv2d_NCHWc_1[cse_var_30] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_29] = (conv2d_NCHWc_1[cse_var_29] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_28] = (conv2d_NCHWc_1[cse_var_28] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                      conv2d_NCHWc_1[cse_var_27] = (conv2d_NCHWc_1[cse_var_27] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                    }
                  }
                }
              }
            }
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax2.inner: int32, 0, 2) {
          for (ax3.inner: int32, 0, 14) {
            let cse_var_38: int32 = floordiv(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused.ax4.outer.fused, 7)
            let cse_var_37: int32 = ((cse_var_38*32) + (ax1.inner*16))
            T_relu[ramp((((((cse_var_38*6272) + (ax1.inner*3136)) + (floormod(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused.ax4.outer.fused, 7)*448)) + (ax2.inner*224)) + (ax3.inner*16)), 1, 16)] = max((((conv2d_NCHWc_1[(((ax1.inner*28) + (ax2.inner*14)) + ax3.inner)] + placeholder_2[ramp(cse_var_37, 1, 16)])*placeholder_3[ramp(cse_var_37, 1, 16)]) + placeholder_4[ramp(cse_var_37, 1, 16)]), broadcast(0f32, 16))
          }
        }
      }
    }
  }
}


==== Task 12: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_16 (weight 1 key: ["f6615ae9259e3b2add2908c0cd980cb6", [1, 64, 7, 7, 16], [10, 64, 1, 1, 16, 16], [1, 10, 1, 1, 16], [1, 10, 7, 7, 16]]) =====
placeholder = PLACEHOLDER [1, 64, 7, 7, 16]
placeholder = PLACEHOLDER [10, 64, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=1)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=8)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=1)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=1)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 64)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_6: Pointer(float32), float32, [50176], []),
             placeholder_1: Buffer(placeholder_7: Pointer(float32), float32, [163840], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [160], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [7840], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_3: placeholder_9: Buffer(placeholder_6, float32, [1, 64, 7, 7, 16], []), placeholder_4: placeholder_10: Buffer(placeholder_7, float32, [10, 64, 1, 1, 16, 16], []), placeholder_5: placeholder_11: Buffer(placeholder_8, float32, [1, 10, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 10, 7, 7, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 35) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 128) {
        for (ic.inner: int32, 0, 8) {
          let cse_var_9: int32 = (((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)*32768) + (ic.outer*128)) + (ic.inner*16))
          let cse_var_8: int32 = (cse_var_9 + 16384)
          let cse_var_7: int32 = ((((floordiv(ic.outer, 2)*784) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)*112)) + (floormod(ic.outer, 2)*8)) + ic.inner)
          let cse_var_6: int32 = (cse_var_7 + 96)
          let cse_var_5: int32 = (cse_var_7 + 80)
          let cse_var_4: int32 = (cse_var_7 + 64)
          let cse_var_3: int32 = (cse_var_7 + 48)
          let cse_var_2: int32 = (cse_var_7 + 32)
          let cse_var_1: int32 = (cse_var_7 + 16)
           {
            conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_10: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)
          T_relu[ramp(((((cse_var_10*1568) + (ax1.inner*784)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)*112)) + (ax3.inner*16)), 1, 16)] = max((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(((cse_var_10*32) + (ax1.inner*16)), 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 13: vm_mod_fused_nn_max_pool2d_1 (weight 1 key: ["840abcf4051ab92cd9ec49f77358d7e7", [1, 12, 56, 56, 16], [1, 12, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 12, 56, 56, 16]
pad_temp(ax0, ax1, ax2, ax3, ax4) = tir.if_then_else(((ax2 < 56) && (ax3 < 56)), placeholder[ax0, ax1, ax2, ax3, ax4], -3.40282e+38f)
tensor(ax0, ax1, ax2, ax3, ax4) max= pad_temp[ax0, ax1, ((ax2*2) + rv0), ((ax3*2) + rv1), ax4]


Trace for this task is: 
pad_temp_ax0, pad_temp_ax1, pad_temp_ax2, pad_temp_ax3, pad_temp_ax4 = tuple(pad_temp.op.axis) + tuple(pad_temp.op.reduce_axis)
tensor_ax0, tensor_ax1, tensor_ax2, tensor_ax3, tensor_ax4, tensor_rv0, tensor_rv1 = tuple(tensor.op.axis) + tuple(tensor.op.reduce_axis)
s[tensor].compute_root()
s[pad_temp].compute_at(s[tensor], tensor_ax4)
tensor_ax0_ax1_fused_ax2_fused = s[tensor].fuse(tensor_ax0, tensor_ax1, tensor_ax2)
s[tensor].parallel(tensor_ax0_ax1_fused_ax2_fused)
s[tensor].pragma(tensor_ax0_ax1_fused_ax2_fused, "auto_unroll_max_step", 64)
s[tensor].pragma(tensor_ax0_ax1_fused_ax2_fused, "unroll_explicit", True)
pad_temp_ax2_ax3_fused_ax4_fused = s[pad_temp].fuse(pad_temp_ax2, pad_temp_ax3, pad_temp_ax4)
s[pad_temp].vectorize(pad_temp_ax2_ax3_fused_ax4_fused)


The best replacement found is:
@main = primfn(placeholder_1: handle, tensor_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_2: Pointer(float32), float32, [602112], []),
             tensor: Buffer(tensor_2: Pointer(float32), float32, [150528], [])}
  buffer_map = {placeholder_1: placeholder, tensor_1: tensor}
  preflattened_buffer_map = {placeholder_1: placeholder_3: Buffer(placeholder_2, float32, [1, 12, 56, 56, 16], []), tensor_1: tensor_3: Buffer(tensor_2, float32, [1, 12, 28, 28, 16], [])} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 336) "parallel" {
    allocate(pad_temp: Pointer(global float32), float32, [9]), storage_scope = global;
    for (ax3: int32, 0, 28) {
      for (ax4: int32, 0, 16) {
        let cse_var_4: bool = (ax3 < 27)
        let cse_var_3: bool = (floormod(ax0.ax1.fused.ax2.fused, 28) < 27)
        let cse_var_2: int32 = (((ax0.ax1.fused.ax2.fused*448) + (ax3*16)) + ax4)
        let cse_var_1: int32 = (((ax0.ax1.fused.ax2.fused*1792) + (ax3*32)) + ax4)
         {
          pad_temp_1: Buffer(pad_temp, float32, [9], [], align=32)[0] = placeholder[cse_var_1]
          pad_temp_1[1] = placeholder[(cse_var_1 + 16)]
          pad_temp_1[2] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_1 + 32)], -3.40282e+38f32, dtype=float32)
          pad_temp_1[3] = placeholder[(cse_var_1 + 896)]
          pad_temp_1[4] = placeholder[(cse_var_1 + 912)]
          pad_temp_1[5] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_1 + 928)], -3.40282e+38f32, dtype=float32)
          pad_temp_1[6] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_1 + 1792)], -3.40282e+38f32, dtype=float32)
          pad_temp_1[7] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_1 + 1808)], -3.40282e+38f32, dtype=float32)
          pad_temp_1[8] = @tir.if_then_else((cse_var_3 && cse_var_4), placeholder[(cse_var_1 + 1824)], -3.40282e+38f32, dtype=float32)
          tensor[cse_var_2] = -3.40282e+38f32
          tensor[cse_var_2] = max(tensor[cse_var_2], pad_temp_1[0])
          tensor[cse_var_2] = max(tensor[cse_var_2], pad_temp_1[1])
          tensor[cse_var_2] = max(tensor[cse_var_2], pad_temp_1[2])
          tensor[cse_var_2] = max(tensor[cse_var_2], pad_temp_1[3])
          tensor[cse_var_2] = max(tensor[cse_var_2], pad_temp_1[4])
          tensor[cse_var_2] = max(tensor[cse_var_2], pad_temp_1[5])
          tensor[cse_var_2] = max(tensor[cse_var_2], pad_temp_1[6])
          tensor[cse_var_2] = max(tensor[cse_var_2], pad_temp_1[7])
          tensor[cse_var_2] = max(tensor[cse_var_2], pad_temp_1[8])
        }
      }
    }
  }
}


==== Task 14: vm_mod_fused_nn_avg_pool2d_2 (weight 4 key: ["50e10b057da3b7c5b1a3d4b1e0473794", [1, 36, 14, 14, 16], [1, 36, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 36, 14, 14, 16]
pad_temp(ax0, ax1, ax2, ax3, ax4) = tir.if_then_else(((((ax2 >= 1) && (ax2 < 15)) && (ax3 >= 1)) && (ax3 < 15)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)
tensor(ax0, ax1, ax2, ax3, ax4) += pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]
tensor(ax0, ax1, ax2, ax3, ax4) = (tensor[ax0, ax1, ax2, ax3, ax4]/float32(max((((min(((ax2 - 1) + 2), 13) - ((ax2 - 1) + max((0 - (ax2 - 1)), 0))) + 1)*((min(((ax3 - 1) + 2), 13) - ((ax3 - 1) + max((0 - (ax3 - 1)), 0))) + 1)), 1)))


Trace for this task is: 
pad_temp_ax0, pad_temp_ax1, pad_temp_ax2, pad_temp_ax3, pad_temp_ax4 = tuple(pad_temp.op.axis) + tuple(pad_temp.op.reduce_axis)
tensor_ax0, tensor_ax1, tensor_ax2, tensor_ax3, tensor_ax4, tensor_rv0, tensor_rv1 = tuple(tensor.op.axis) + tuple(tensor.op.reduce_axis)
tensor_ax0, tensor_ax1, tensor_ax2, tensor_ax3, tensor_ax4 = tuple(tensor.op.axis) + tuple(tensor.op.reduce_axis)
s[tensor].compute_root()
s[tensor].compute_at(s[tensor], tensor_ax4)
s[pad_temp].compute_at(s[tensor], tensor_ax1)
tensor_ax0_ax1_fused = s[tensor].fuse(tensor_ax0, tensor_ax1)
s[tensor].parallel(tensor_ax0_ax1_fused)
s[tensor].pragma(tensor_ax0, "auto_unroll_max_step", 512)
s[tensor].pragma(tensor_ax0, "unroll_explicit", True)
s[pad_temp].vectorize(pad_temp_ax4)


The best replacement found is:
@main = primfn(placeholder_1: handle, tensor_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_2: Pointer(float32), float32, [112896], []),
             tensor: Buffer(tensor_2: Pointer(float32), float32, [112896], [])}
  buffer_map = {placeholder_1: placeholder, tensor_1: tensor}
  preflattened_buffer_map = {placeholder_1: placeholder_3: Buffer(placeholder_2, float32, [1, 36, 14, 14, 16], []), tensor_1: tensor_3: Buffer(tensor_2, float32, [1, 36, 14, 14, 16], [])} {
  for (ax0.ax1.fused: int32, 0, 36) "parallel" {
    allocate(pad_temp: Pointer(global float32), float32, [4096]), storage_scope = global;
    allocate(tensor_4: Pointer(global float32), float32, [1]), storage_scope = global {
      for (ax2: int32, 0, 16) {
        for (ax3: int32, 0, 16) {
          let cse_var_1: int32 = (ax3*16)
          pad_temp_1: Buffer(pad_temp, float32, [4096], [])[ramp(((ax2*256) + cse_var_1), 1, 16)] = @tir.if_then_else(((((1 <= ax2) && (ax2 < 15)) && (1 <= ax3)) && (ax3 < 15)), placeholder[ramp(((((ax0.ax1.fused*3136) + (ax2*224)) + cse_var_1) - 240), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
        }
      }
      for (ax2_1: int32, 0, 14) {
        for (ax3_1: int32, 0, 14) {
          for (ax4: int32, 0, 16) {
            let cse_var_3: int32 = (ax3_1*16)
            let cse_var_2: int32 = (((ax2_1*256) + cse_var_3) + ax4)
             {
              tensor_5: Buffer(tensor_4, float32, [1], [], align=4)[0] = 0f32
              tensor_5[0] = (tensor_5[0] + pad_temp_1[cse_var_2])
              tensor_5[0] = (tensor_5[0] + pad_temp_1[(cse_var_2 + 16)])
              tensor_5[0] = (tensor_5[0] + pad_temp_1[(cse_var_2 + 32)])
              tensor_5[0] = (tensor_5[0] + pad_temp_1[(cse_var_2 + 256)])
              tensor_5[0] = (tensor_5[0] + pad_temp_1[(cse_var_2 + 272)])
              tensor_5[0] = (tensor_5[0] + pad_temp_1[(cse_var_2 + 288)])
              tensor_5[0] = (tensor_5[0] + pad_temp_1[(cse_var_2 + 512)])
              tensor_5[0] = (tensor_5[0] + pad_temp_1[(cse_var_2 + 528)])
              tensor_5[0] = (tensor_5[0] + pad_temp_1[(cse_var_2 + 544)])
              tensor[((((ax0.ax1.fused*3136) + (ax2_1*224)) + cse_var_3) + ax4)] = (tensor_5[0] / cast(float32, max(((((min((ax2_1 + 1), 13) + 2) - max((1 - ax2_1), 0)) - ax2_1)*(((min((ax3_1 + 1), 13) + 2) - max((1 - ax3_1), 0)) - ax3_1)), 1)))
            }
          }
        }
      }
    }
  }
}


==== Task 15: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_17 (weight 1 key: ["ce1b4a245fb9b3a0526fcd7e77d29d3f", [1, 10, 7, 7, 16], [14, 10, 3, 3, 16, 16], [1, 14, 1, 1, 16], [1, 14, 7, 7, 16]]) =====
placeholder = PLACEHOLDER [1, 10, 7, 7, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 8)) && (i3 >= 1)) && (i3 < 8)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [14, 10, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 14, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3, data_pad_i4 = tuple(data_pad.op.axis) + tuple(data_pad.op.reduce_axis)
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=7)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=1)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=1)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=3)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=7)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=1)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=1)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=1)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
s[data_pad].compute_at(s[conv2d_NCHWc], conv2d_NCHWc_kw_o)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 512)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[data_pad].vectorize(data_pad_i4)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_6: Pointer(float32), float32, [7840], []),
             placeholder_1: Buffer(placeholder_7: Pointer(float32), float32, [322560], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [224], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [10976], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_3: placeholder_9: Buffer(placeholder_6, float32, [1, 10, 7, 7, 16], []), placeholder_4: placeholder_10: Buffer(placeholder_7, float32, [14, 10, 3, 3, 16, 16], []), placeholder_5: placeholder_11: Buffer(placeholder_8, float32, [1, 14, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 14, 7, 7, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 49) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global;
    allocate(data_pad: Pointer(global float32), float32, [144]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 10) {
        for (kw.outer: int32, 0, 3) {
          let cse_var_4: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)
          let cse_var_3: int32 = (kw.outer + cse_var_4)
          let cse_var_2: int32 = (((ic.outer*784) + (kw.outer*16)) + (cse_var_4*16))
          let cse_var_1: bool = ((1 <= cse_var_3) && (cse_var_3 < 8))
           {
            data_pad_1: Buffer(data_pad, float32, [144], [])[ramp(0, 1, 16)] = broadcast(0f32, 16)
            data_pad_1[ramp(16, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 16), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(32, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 + 96), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(48, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 + 208), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(64, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 + 320), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(80, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 + 432), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(96, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 + 544), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(112, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 + 656), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(128, 1, 16)] = broadcast(0f32, 16)
            for (ic.inner: int32, 0, 16) {
              let cse_var_18: int32 = (ic.inner + 96)
              let cse_var_17: int32 = (ic.inner + 80)
              let cse_var_16: int32 = (ic.inner + 64)
              let cse_var_15: int32 = (ic.inner + 48)
              let cse_var_14: int32 = (ic.inner + 32)
              let cse_var_13: int32 = (ic.inner + 16)
              let cse_var_12: int32 = (ic.inner + 128)
              let cse_var_11: int32 = (ic.inner + 112)
              let cse_var_10: int32 = ((((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)*46080) + (ic.outer*2304)) + (kw.outer*256)) + (ic.inner*16))
              let cse_var_9: int32 = (cse_var_10 + 768)
              let cse_var_8: int32 = (cse_var_10 + 24576)
              let cse_var_7: int32 = (cse_var_10 + 23808)
              let cse_var_6: int32 = (cse_var_10 + 23040)
              let cse_var_5: int32 = (cse_var_10 + 1536)
               {
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_11], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_11], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_11], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_11], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
              }
            }
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax2.inner: int32, 0, 7) {
          let cse_var_19: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)
          T_relu[ramp(((((cse_var_19*1568) + (ax1.inner*784)) + (ax2.inner*112)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)*16)), 1, 16)] = max((conv2d_NCHWc_1[((ax1.inner*7) + ax2.inner)] + placeholder_2[ramp(((cse_var_19*32) + (ax1.inner*16)), 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 16: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 (weight 2 key: ["ce1b4a245fb9b3a0526fcd7e77d29d3f", [1, 6, 14, 14, 16], [8, 6, 3, 3, 16, 16], [1, 8, 1, 1, 16], [1, 8, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 6, 14, 14, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 15)) && (i3 >= 1)) && (i3 < 15)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [8, 6, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3, data_pad_i4 = tuple(data_pad.op.axis) + tuple(data_pad.op.reduce_axis)
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=4)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=14)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=2)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=3)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=4)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=14)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=2)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
s[data_pad].compute_at(s[conv2d_NCHWc], conv2d_NCHWc_kh_o)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 64)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[data_pad].vectorize(data_pad_i4)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_6: Pointer(float32), float32, [18816], []),
             placeholder_1: Buffer(placeholder_7: Pointer(float32), float32, [110592], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [128], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [25088], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_3: placeholder_9: Buffer(placeholder_6, float32, [1, 6, 14, 14, 16], []), placeholder_4: placeholder_10: Buffer(placeholder_7, float32, [8, 6, 3, 3, 16, 16], []), placeholder_5: placeholder_11: Buffer(placeholder_8, float32, [1, 8, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 8, 14, 14, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 112) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global;
    allocate(data_pad: Pointer(global float32), float32, [144]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 6) {
        for (kh.outer: int32, 0, 3) {
          let cse_var_5: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)
          let cse_var_4: int32 = (floordiv(cse_var_5, 2) + kh.outer)
          let cse_var_3: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 2)
          let cse_var_2: int32 = (((ic.outer*3136) + (kh.outer*224)) + (cse_var_5*112))
          let cse_var_1: bool = ((1 <= cse_var_4) && (cse_var_4 < 15))
           {
            data_pad_1: Buffer(data_pad, float32, [144], [])[ramp(0, 1, 16)] = @tir.if_then_else((cse_var_1 && (1 <= cse_var_3)), placeholder[ramp((cse_var_2 - 240), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(16, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 224), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(32, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 208), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(48, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 192), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(64, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 176), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(80, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 160), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(96, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 144), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(112, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 128), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(128, 1, 16)] = @tir.if_then_else((cse_var_1 && (cse_var_3 < 1)), placeholder[ramp((cse_var_2 - 112), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            for (ic.inner: int32, 0, 16) {
              let cse_var_19: int32 = (ic.inner + 96)
              let cse_var_18: int32 = (ic.inner + 80)
              let cse_var_17: int32 = (ic.inner + 64)
              let cse_var_16: int32 = (ic.inner + 48)
              let cse_var_15: int32 = (ic.inner + 32)
              let cse_var_14: int32 = (ic.inner + 16)
              let cse_var_13: int32 = (ic.inner + 128)
              let cse_var_12: int32 = (ic.inner + 112)
              let cse_var_11: int32 = ((((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)*27648) + (ic.outer*2304)) + (kh.outer*768)) + (ic.inner*16))
              let cse_var_10: int32 = (cse_var_11 + 512)
              let cse_var_9: int32 = (cse_var_11 + 256)
              let cse_var_8: int32 = (cse_var_11 + 14336)
              let cse_var_7: int32 = (cse_var_11 + 14080)
              let cse_var_6: int32 = (cse_var_11 + 13824)
               {
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
              }
            }
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_20: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)
          T_relu[ramp(((((cse_var_20*6272) + (ax1.inner*3136)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)*112)) + (ax3.inner*16)), 1, 16)] = max((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(((cse_var_20*32) + (ax1.inner*16)), 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 17: vm_mod_fused_nn_max_pool2d_3 (weight 1 key: ["840abcf4051ab92cd9ec49f77358d7e7", [1, 36, 14, 14, 16], [1, 36, 7, 7, 16]]) =====
placeholder = PLACEHOLDER [1, 36, 14, 14, 16]
pad_temp(ax0, ax1, ax2, ax3, ax4) = tir.if_then_else(((ax2 < 14) && (ax3 < 14)), placeholder[ax0, ax1, ax2, ax3, ax4], -3.40282e+38f)
tensor(ax0, ax1, ax2, ax3, ax4) max= pad_temp[ax0, ax1, ((ax2*2) + rv0), ((ax3*2) + rv1), ax4]


Trace for this task is: 
pad_temp_ax0, pad_temp_ax1, pad_temp_ax2, pad_temp_ax3, pad_temp_ax4 = tuple(pad_temp.op.axis) + tuple(pad_temp.op.reduce_axis)
tensor_ax0, tensor_ax1, tensor_ax2, tensor_ax3, tensor_ax4, tensor_rv0, tensor_rv1 = tuple(tensor.op.axis) + tuple(tensor.op.reduce_axis)
s[tensor].compute_root()
s[pad_temp].compute_at(s[tensor], tensor_ax4)
tensor_ax0_ax1_fused = s[tensor].fuse(tensor_ax0, tensor_ax1)
s[tensor].parallel(tensor_ax0_ax1_fused)
s[tensor].pragma(tensor_ax0_ax1_fused, "auto_unroll_max_step", 16)
s[tensor].pragma(tensor_ax0_ax1_fused, "unroll_explicit", True)
pad_temp_ax2_ax3_fused_ax4_fused = s[pad_temp].fuse(pad_temp_ax2, pad_temp_ax3, pad_temp_ax4)
s[pad_temp].vectorize(pad_temp_ax2_ax3_fused_ax4_fused)


The best replacement found is:
@main = primfn(placeholder_1: handle, tensor_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_2: Pointer(float32), float32, [112896], []),
             tensor: Buffer(tensor_2: Pointer(float32), float32, [28224], [])}
  buffer_map = {placeholder_1: placeholder, tensor_1: tensor}
  preflattened_buffer_map = {placeholder_1: placeholder_3: Buffer(placeholder_2, float32, [1, 36, 14, 14, 16], []), tensor_1: tensor_3: Buffer(tensor_2, float32, [1, 36, 7, 7, 16], [])} {
  for (ax0.ax1.fused: int32, 0, 36) "parallel" {
    allocate(pad_temp: Pointer(global float32), float32, [9]), storage_scope = global;
    for (ax2: int32, 0, 7) {
      for (ax3: int32, 0, 7) {
        for (ax4: int32, 0, 16) {
          let cse_var_4: bool = (ax3 < 6)
          let cse_var_3: bool = (ax2 < 6)
          let cse_var_2: int32 = ((((ax0.ax1.fused*784) + (ax2*112)) + (ax3*16)) + ax4)
          let cse_var_1: int32 = ((((ax0.ax1.fused*3136) + (ax2*448)) + (ax3*32)) + ax4)
           {
            pad_temp_1: Buffer(pad_temp, float32, [9], [], align=32)[0] = placeholder[cse_var_1]
            pad_temp_1[1] = placeholder[(cse_var_1 + 16)]
            pad_temp_1[2] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_1 + 32)], -3.40282e+38f32, dtype=float32)
            pad_temp_1[3] = placeholder[(cse_var_1 + 224)]
            pad_temp_1[4] = placeholder[(cse_var_1 + 240)]
            pad_temp_1[5] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_1 + 256)], -3.40282e+38f32, dtype=float32)
            pad_temp_1[6] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_1 + 448)], -3.40282e+38f32, dtype=float32)
            pad_temp_1[7] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_1 + 464)], -3.40282e+38f32, dtype=float32)
            pad_temp_1[8] = @tir.if_then_else((cse_var_3 && cse_var_4), placeholder[(cse_var_1 + 480)], -3.40282e+38f32, dtype=float32)
            tensor[cse_var_2] = -3.40282e+38f32
            tensor[cse_var_2] = max(tensor[cse_var_2], pad_temp_1[0])
            tensor[cse_var_2] = max(tensor[cse_var_2], pad_temp_1[1])
            tensor[cse_var_2] = max(tensor[cse_var_2], pad_temp_1[2])
            tensor[cse_var_2] = max(tensor[cse_var_2], pad_temp_1[3])
            tensor[cse_var_2] = max(tensor[cse_var_2], pad_temp_1[4])
            tensor[cse_var_2] = max(tensor[cse_var_2], pad_temp_1[5])
            tensor[cse_var_2] = max(tensor[cse_var_2], pad_temp_1[6])
            tensor[cse_var_2] = max(tensor[cse_var_2], pad_temp_1[7])
            tensor[cse_var_2] = max(tensor[cse_var_2], pad_temp_1[8])
          }
        }
      }
    }
  }
}


==== Task 18: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu (weight 1 key: ["5ed464b35716e41a42d30187d80b5975", [1, 1, 224, 224, 3], [2, 1, 7, 7, 3, 32], [1, 2, 1, 1, 32], [1, 2, 1, 1, 32], [1, 2, 1, 1, 32], [1, 2, 112, 112, 32]]) =====
placeholder = PLACEHOLDER [1, 1, 224, 224, 3]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 3) && (i2 < 227)) && (i3 >= 3)) && (i3 < 227)), placeholder[i0, i1, (i2 - 3), (i3 - 3), i4], 0f)
placeholder = PLACEHOLDER [2, 1, 7, 7, 3, 32]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 3), ((oh*2) + kh), ((ow*2) + kw), floormod(ic, 3)]*placeholder[oc_chunk, floordiv(ic, 3), kh, kw, floormod(ic, 3), oc_block])
placeholder = PLACEHOLDER [1, 2, 1, 1, 32]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 2, 1, 1, 32]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 2, 1, 1, 32]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3, data_pad_i4 = tuple(data_pad.op.axis) + tuple(data_pad.op.reduce_axis)
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=1)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=7)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=4)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=1)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=2)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=1)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=2)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=1)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=7)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=1)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=7)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=4)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=2)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=1)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=2)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
data_pad_i0_i1_fused_i2_fused_i3_fused = s[data_pad].fuse(data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3)
s[data_pad].parallel(data_pad_i0_i1_fused_i2_fused_i3_fused)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 0)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[data_pad].vectorize(data_pad_i4)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [150528], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [9408], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [64], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [64], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [64], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [802816], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_5: placeholder_15: Buffer(placeholder_10, float32, [1, 1, 224, 224, 3], []), placeholder_8: placeholder_16: Buffer(placeholder_13, float32, [1, 2, 1, 1, 32], []), placeholder_6: placeholder_17: Buffer(placeholder_11, float32, [2, 1, 7, 7, 3, 32], []), placeholder_9: placeholder_18: Buffer(placeholder_14, float32, [1, 2, 1, 1, 32], []), placeholder_7: placeholder_19: Buffer(placeholder_12, float32, [1, 2, 1, 1, 32], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 2, 112, 112, 32], [])} {
  allocate(data_pad: Pointer(global float32), float32, [157323]), storage_scope = global {
    for (i0.i1.fused.i2.fused.i3.fused: int32, 0, 52441) "parallel" {
      let cse_var_1: int32 = floormod(i0.i1.fused.i2.fused.i3.fused, 229)
      data_pad_1: Buffer(data_pad, float32, [157323], [])[ramp((i0.i1.fused.i2.fused.i3.fused*3), 1, 3)] = @tir.if_then_else(((((687 <= i0.i1.fused.i2.fused.i3.fused) && (i0.i1.fused.i2.fused.i3.fused < 51983)) && (3 <= cse_var_1)) && (cse_var_1 < 227)), placeholder[ramp((((floordiv(i0.i1.fused.i2.fused.i3.fused, 229)*672) + (cse_var_1*3)) - 2025), 1, 3)], broadcast(0f32, 3), dtype=float32x3)
    }
    for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused: int32, 0, 1792) "parallel" {
      allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global;
      for (ax4.outer.inner: int32, 0, 2) {
        for (ow.outer.inner.init: int32, 0, 2) {
          for (oh.inner.init: int32, 0, 7) {
            conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[((oh.inner.init*2) + ow.outer.inner.init)] = broadcast(0f32, 16)
          }
        }
        for (ic.outer: int32, 0, 3) {
          for (kw.outer: int32, 0, 7) {
            for (ow.outer.inner: int32, 0, 2) {
              for (kh.inner: int32, 0, 7) {
                for (oh.inner: int32, 0, 7) {
                  let cse_var_2: int32 = ((oh.inner*2) + ow.outer.inner)
                  conv2d_NCHWc_1[cse_var_2] = (conv2d_NCHWc_1[cse_var_2] + (broadcast(data_pad_1[((((((((floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 896), 224)*38472) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 4)*9618)) + (oh.inner*1374)) + (kh.inner*687)) + (floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 224), 4)*12)) + (ow.outer.inner*6)) + (kw.outer*3)) + ic.outer)], 16)*placeholder_1[ramp((((((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 896)*4704) + (kh.inner*672)) + (kw.outer*96)) + (ic.outer*32)) + (ax4.outer.inner*16)), 1, 16)]))
                }
              }
            }
          }
        }
        for (ax2.inner: int32, 0, 7) {
          for (ax3.inner: int32, 0, 2) {
            let cse_var_4: int32 = (ax4.outer.inner*16)
            let cse_var_3: int32 = ((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 896)*32) + cse_var_4)
            T_relu[ramp(((((((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 224)*100352) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 4)*25088)) + (ax2.inner*3584)) + (floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 224), 4)*64)) + (ax3.inner*32)) + cse_var_4), 1, 16)] = max((((conv2d_NCHWc_1[((ax2.inner*2) + ax3.inner)] + placeholder_2[ramp(cse_var_3, 1, 16)])*placeholder_3[ramp(cse_var_3, 1, 16)]) + placeholder_4[ramp(cse_var_3, 1, 16)]), broadcast(0f32, 16))
          }
        }
      }
    }
  }
}


==== Task 19: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_19 (weight 3 key: ["9db1fd34470fc877a2c0431d681f01a4", [1, 36, 14, 14, 16], [6, 36, 1, 1, 16, 16], [1, 6, 1, 1, 16], [1, 6, 1, 1, 16], [1, 6, 1, 1, 16], [1, 6, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 36, 14, 14, 16]
placeholder = PLACEHOLDER [6, 36, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=2)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=2)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=8)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=2)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=2)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 16)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [112896], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [55296], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [96], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [96], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [96], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [18816], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 6, 14, 14, 16], []), placeholder_6: placeholder_15: Buffer(placeholder_11, float32, [6, 36, 1, 1, 16, 16], []), placeholder_8: placeholder_16: Buffer(placeholder_13, float32, [1, 6, 1, 1, 16], []), placeholder_9: placeholder_17: Buffer(placeholder_14, float32, [1, 6, 1, 1, 16], []), placeholder_5: placeholder_18: Buffer(placeholder_10, float32, [1, 36, 14, 14, 16], []), placeholder_7: placeholder_19: Buffer(placeholder_12, float32, [1, 6, 1, 1, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 84) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 72) {
        for (ic.inner: int32, 0, 8) {
          let cse_var_9: int32 = (((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)*18432) + (ic.outer*128)) + (ic.inner*16))
          let cse_var_8: int32 = (cse_var_9 + 9216)
          let cse_var_7: int32 = ((((floordiv(ic.outer, 2)*3136) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)*112)) + (floormod(ic.outer, 2)*8)) + ic.inner)
          let cse_var_6: int32 = (cse_var_7 + 96)
          let cse_var_5: int32 = (cse_var_7 + 80)
          let cse_var_4: int32 = (cse_var_7 + 64)
          let cse_var_3: int32 = (cse_var_7 + 48)
          let cse_var_2: int32 = (cse_var_7 + 32)
          let cse_var_1: int32 = (cse_var_7 + 16)
           {
            conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_11: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)
          let cse_var_10: int32 = ((cse_var_11*32) + (ax1.inner*16))
          T_relu[ramp(((((cse_var_11*6272) + (ax1.inner*3136)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)*112)) + (ax3.inner*16)), 1, 16)] = max((((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(cse_var_10, 1, 16)])*placeholder_3[ramp(cse_var_10, 1, 16)]) + placeholder_4[ramp(cse_var_10, 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 20: vm_mod_fused_nn_softmax (weight 1 key: ["d7b65649a4dd54becea0a52aabbc5af5", [1, 1000], [1, 1000]]) =====
placeholder = PLACEHOLDER [1, 1000]
T_softmax_maxelem(i0) max= placeholder[i0, k]
T_softmax_exp(i0, i1) = tir.exp((placeholder[i0, i1] - T_softmax_maxelem[i0]))
T_softmax_expsum(i0) += T_softmax_exp[i0, k]
T_softmax_norm(i0, i1) = (T_softmax_exp[i0, i1]/T_softmax_expsum[i0])


Trace for this task is: 
T_softmax_maxelem_i0, T_softmax_maxelem_k = tuple(T_softmax_maxelem.op.axis) + tuple(T_softmax_maxelem.op.reduce_axis)
T_softmax_exp_i0, T_softmax_exp_i1 = tuple(T_softmax_exp.op.axis) + tuple(T_softmax_exp.op.reduce_axis)
T_softmax_expsum_i0, T_softmax_expsum_k = tuple(T_softmax_expsum.op.axis) + tuple(T_softmax_expsum.op.reduce_axis)
T_softmax_norm_i0, T_softmax_norm_i1 = tuple(T_softmax_norm.op.axis) + tuple(T_softmax_norm.op.reduce_axis)
T_softmax_expsum_k_o, T_softmax_expsum_k_i = s[T_softmax_expsum].split(T_softmax_expsum_k, factor=8)
T_softmax_expsum_rf = s.rfactor(T_softmax_expsum, k_i, 1)
T_softmax_expsum_rf_i0, T_softmax_expsum_rf_k_i, T_softmax_expsum_rf_k_o = tuple(T_softmax_expsum_rf.op.axis) + tuple(T_softmax_expsum_rf.op.reduce_axis)
T_softmax_expsum_repl_ax0, T_softmax_expsum_repl_k_i_v = tuple(s[T_softmax_expsum_repl].op.axis) + tuple(s[T_softmax_expsum_repl].op.reduce_axis)
s[T_softmax_expsum_rf].reorder(T_softmax_expsum_rf_i0, T_softmax_expsum_rf_k_o, T_softmax_expsum_rf_k_i)
T_softmax_maxelem_k_o, T_softmax_maxelem_k_i = s[T_softmax_maxelem].split(T_softmax_maxelem_k, factor=20)
T_softmax_maxelem_rf = s.rfactor(T_softmax_maxelem, k_i, 1)
T_softmax_maxelem_rf_i0, T_softmax_maxelem_rf_k_i, T_softmax_maxelem_rf_k_o = tuple(T_softmax_maxelem_rf.op.axis) + tuple(T_softmax_maxelem_rf.op.reduce_axis)
T_softmax_maxelem_repl_ax0, T_softmax_maxelem_repl_k_i_v = tuple(s[T_softmax_maxelem_repl].op.axis) + tuple(s[T_softmax_maxelem_repl].op.reduce_axis)
s[T_softmax_maxelem_rf].reorder(T_softmax_maxelem_rf_i0, T_softmax_maxelem_rf_k_o, T_softmax_maxelem_rf_k_i)
s[T_softmax_norm].compute_root()
s[T_softmax_expsum_repl].compute_at(s[T_softmax_norm], T_softmax_norm_i1)
s[T_softmax_maxelem_repl].compute_root()
s[T_softmax_maxelem_rf].parallel(T_softmax_maxelem_rf_i0)
s[T_softmax_maxelem_repl].parallel(T_softmax_maxelem_repl_ax0)
T_softmax_exp_i0_i1_fused = s[T_softmax_exp].fuse(T_softmax_exp_i0, T_softmax_exp_i1)
s[T_softmax_exp].parallel(T_softmax_exp_i0_i1_fused)
s[T_softmax_expsum_rf].parallel(T_softmax_expsum_rf_i0)
T_softmax_norm_i0_i1_fused = s[T_softmax_norm].fuse(T_softmax_norm_i0, T_softmax_norm_i1)
s[T_softmax_norm].parallel(T_softmax_norm_i0_i1_fused)
s[T_softmax_maxelem_rf].pragma(T_softmax_maxelem_rf_i0, "auto_unroll_max_step", 512)
s[T_softmax_maxelem_rf].pragma(T_softmax_maxelem_rf_i0, "unroll_explicit", True)
s[T_softmax_maxelem_repl].pragma(T_softmax_maxelem_repl_ax0, "auto_unroll_max_step", 16)
s[T_softmax_maxelem_repl].pragma(T_softmax_maxelem_repl_ax0, "unroll_explicit", True)
s[T_softmax_expsum_rf].pragma(T_softmax_expsum_rf_i0, "auto_unroll_max_step", 512)
s[T_softmax_expsum_rf].pragma(T_softmax_expsum_rf_i0, "unroll_explicit", True)
s[T_softmax_expsum_repl].pragma(T_softmax_expsum_repl_ax0, "auto_unroll_max_step", 512)
s[T_softmax_expsum_repl].pragma(T_softmax_expsum_repl_ax0, "unroll_explicit", True)
s[T_softmax_expsum_rf].vectorize(T_softmax_expsum_rf_k_i)


The best replacement found is:
@main = primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_2: Pointer(float32), float32, [1000], []),
             T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [1000], [])}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm}
  preflattened_buffer_map = {placeholder_1: placeholder_3: Buffer(placeholder_2, float32, [1, 1000], []), T_softmax_norm_1: T_softmax_norm_3: Buffer(T_softmax_norm_2, float32, [1, 1000], [])} {
  allocate(T_softmax_maxelem.rf: Pointer(global float32), float32, [20]), storage_scope = global;
  allocate(T_softmax_maxelem: Pointer(global float32), float32, [1]), storage_scope = global;
  allocate(T_softmax_exp: Pointer(global float32), float32, [1000]), storage_scope = global {
    T_softmax_maxelem.rf_1: Buffer(T_softmax_maxelem.rf, float32, [20], [], align=64)[0] = -3.40282e+38f32
    T_softmax_maxelem.rf_1[1] = -3.40282e+38f32
    T_softmax_maxelem.rf_1[2] = -3.40282e+38f32
    T_softmax_maxelem.rf_1[3] = -3.40282e+38f32
    T_softmax_maxelem.rf_1[4] = -3.40282e+38f32
    T_softmax_maxelem.rf_1[5] = -3.40282e+38f32
    T_softmax_maxelem.rf_1[6] = -3.40282e+38f32
    T_softmax_maxelem.rf_1[7] = -3.40282e+38f32
    T_softmax_maxelem.rf_1[8] = -3.40282e+38f32
    T_softmax_maxelem.rf_1[9] = -3.40282e+38f32
    T_softmax_maxelem.rf_1[10] = -3.40282e+38f32
    T_softmax_maxelem.rf_1[11] = -3.40282e+38f32
    T_softmax_maxelem.rf_1[12] = -3.40282e+38f32
    T_softmax_maxelem.rf_1[13] = -3.40282e+38f32
    T_softmax_maxelem.rf_1[14] = -3.40282e+38f32
    T_softmax_maxelem.rf_1[15] = -3.40282e+38f32
    T_softmax_maxelem.rf_1[16] = -3.40282e+38f32
    T_softmax_maxelem.rf_1[17] = -3.40282e+38f32
    T_softmax_maxelem.rf_1[18] = -3.40282e+38f32
    T_softmax_maxelem.rf_1[19] = -3.40282e+38f32
    for (k.outer: int32, 0, 50) {
      let cse_var_1: int32 = (k.outer*20)
       {
        T_softmax_maxelem.rf_1[0] = max(T_softmax_maxelem.rf_1[0], placeholder[cse_var_1])
        T_softmax_maxelem.rf_1[1] = max(T_softmax_maxelem.rf_1[1], placeholder[(cse_var_1 + 1)])
        T_softmax_maxelem.rf_1[2] = max(T_softmax_maxelem.rf_1[2], placeholder[(cse_var_1 + 2)])
        T_softmax_maxelem.rf_1[3] = max(T_softmax_maxelem.rf_1[3], placeholder[(cse_var_1 + 3)])
        T_softmax_maxelem.rf_1[4] = max(T_softmax_maxelem.rf_1[4], placeholder[(cse_var_1 + 4)])
        T_softmax_maxelem.rf_1[5] = max(T_softmax_maxelem.rf_1[5], placeholder[(cse_var_1 + 5)])
        T_softmax_maxelem.rf_1[6] = max(T_softmax_maxelem.rf_1[6], placeholder[(cse_var_1 + 6)])
        T_softmax_maxelem.rf_1[7] = max(T_softmax_maxelem.rf_1[7], placeholder[(cse_var_1 + 7)])
        T_softmax_maxelem.rf_1[8] = max(T_softmax_maxelem.rf_1[8], placeholder[(cse_var_1 + 8)])
        T_softmax_maxelem.rf_1[9] = max(T_softmax_maxelem.rf_1[9], placeholder[(cse_var_1 + 9)])
        T_softmax_maxelem.rf_1[10] = max(T_softmax_maxelem.rf_1[10], placeholder[(cse_var_1 + 10)])
        T_softmax_maxelem.rf_1[11] = max(T_softmax_maxelem.rf_1[11], placeholder[(cse_var_1 + 11)])
        T_softmax_maxelem.rf_1[12] = max(T_softmax_maxelem.rf_1[12], placeholder[(cse_var_1 + 12)])
        T_softmax_maxelem.rf_1[13] = max(T_softmax_maxelem.rf_1[13], placeholder[(cse_var_1 + 13)])
        T_softmax_maxelem.rf_1[14] = max(T_softmax_maxelem.rf_1[14], placeholder[(cse_var_1 + 14)])
        T_softmax_maxelem.rf_1[15] = max(T_softmax_maxelem.rf_1[15], placeholder[(cse_var_1 + 15)])
        T_softmax_maxelem.rf_1[16] = max(T_softmax_maxelem.rf_1[16], placeholder[(cse_var_1 + 16)])
        T_softmax_maxelem.rf_1[17] = max(T_softmax_maxelem.rf_1[17], placeholder[(cse_var_1 + 17)])
        T_softmax_maxelem.rf_1[18] = max(T_softmax_maxelem.rf_1[18], placeholder[(cse_var_1 + 18)])
        T_softmax_maxelem.rf_1[19] = max(T_softmax_maxelem.rf_1[19], placeholder[(cse_var_1 + 19)])
      }
    }
    T_softmax_maxelem_1: Buffer(T_softmax_maxelem, float32, [1], [], align=4)[0] = -3.40282e+38f32
    for (k.inner.v: int32, 0, 20) {
      T_softmax_maxelem_1[0] = max(T_softmax_maxelem_1[0], T_softmax_maxelem.rf_1[k.inner.v])
    }
    for (i0.i1.fused: int32, 0, 1000) "parallel" {
      T_softmax_exp_1: Buffer(T_softmax_exp, float32, [1000], [])[i0.i1.fused] = @tir.exp((placeholder[i0.i1.fused] - T_softmax_maxelem_1[0]), dtype=float32)
    }
    T_softmax_maxelem.rf_2: Buffer(T_softmax_maxelem.rf, float32, [8], [], align=32)[ramp(0, 1, 8)] = broadcast(0f32, 8)
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(0, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(8, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(16, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(24, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(32, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(40, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(48, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(56, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(64, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(72, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(80, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(88, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(96, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(104, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(112, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(120, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(128, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(136, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(144, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(152, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(160, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(168, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(176, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(184, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(192, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(200, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(208, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(216, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(224, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(232, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(240, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(248, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(256, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(264, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(272, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(280, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(288, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(296, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(304, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(312, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(320, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(328, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(336, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(344, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(352, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(360, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(368, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(376, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(384, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(392, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(400, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(408, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(416, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(424, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(432, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(440, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(448, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(456, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(464, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(472, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(480, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(488, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(496, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(504, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(512, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(520, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(528, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(536, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(544, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(552, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(560, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(568, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(576, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(584, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(592, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(600, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(608, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(616, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(624, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(632, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(640, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(648, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(656, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(664, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(672, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(680, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(688, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(696, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(704, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(712, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(720, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(728, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(736, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(744, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(752, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(760, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(768, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(776, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(784, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(792, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(800, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(808, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(816, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(824, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(832, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(840, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(848, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(856, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(864, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(872, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(880, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(888, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(896, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(904, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(912, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(920, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(928, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(936, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(944, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(952, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(960, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(968, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(976, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(984, 1, 8)])
    T_softmax_maxelem.rf_2[ramp(0, 1, 8)] = (T_softmax_maxelem.rf_2[ramp(0, 1, 8)] + T_softmax_exp_1[ramp(992, 1, 8)])
    for (i0.i1.fused_1: int32, 0, 1000) "parallel" {
      allocate(T_softmax_expsum: Pointer(global float32), float32, [1]), storage_scope = global {
        T_softmax_expsum_1: Buffer(T_softmax_expsum, float32, [1], [], align=4)[0] = 0f32
        T_softmax_expsum_1[0] = (T_softmax_expsum_1[0] + T_softmax_maxelem.rf_2[0])
        T_softmax_expsum_1[0] = (T_softmax_expsum_1[0] + T_softmax_maxelem.rf_2[1])
        T_softmax_expsum_1[0] = (T_softmax_expsum_1[0] + T_softmax_maxelem.rf_2[2])
        T_softmax_expsum_1[0] = (T_softmax_expsum_1[0] + T_softmax_maxelem.rf_2[3])
        T_softmax_expsum_1[0] = (T_softmax_expsum_1[0] + T_softmax_maxelem.rf_2[4])
        T_softmax_expsum_1[0] = (T_softmax_expsum_1[0] + T_softmax_maxelem.rf_2[5])
        T_softmax_expsum_1[0] = (T_softmax_expsum_1[0] + T_softmax_maxelem.rf_2[6])
        T_softmax_expsum_1[0] = (T_softmax_expsum_1[0] + T_softmax_maxelem.rf_2[7])
        T_softmax_norm[i0.i1.fused_1] = (T_softmax_exp_1[i0.i1.fused_1] / T_softmax_expsum_1[0])
      }
    }
  }
}


==== Task 21: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_25 (weight 2 key: ["6b0d226afab7de584e086dc68f47c79a", [1, 12, 7, 7, 16], [20, 12, 3, 3, 16, 16], [1, 20, 1, 1, 16], [1, 20, 1, 1, 16], [1, 20, 1, 1, 16], [1, 20, 7, 7, 16]]) =====
placeholder = PLACEHOLDER [1, 12, 7, 7, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 8)) && (i3 >= 1)) && (i3 < 8)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [20, 12, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 20, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 20, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 20, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3, data_pad_i4 = tuple(data_pad.op.axis) + tuple(data_pad.op.reduce_axis)
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=1)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=3)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=1)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=1)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
s[data_pad].compute_at(s[conv2d_NCHWc], conv2d_NCHWc_kw_o)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 64)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[data_pad].vectorize(data_pad_i4)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [9408], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [552960], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [320], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [320], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [320], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [15680], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_8: placeholder_15: Buffer(placeholder_13, float32, [1, 20, 1, 1, 16], []), placeholder_5: placeholder_16: Buffer(placeholder_10, float32, [1, 12, 7, 7, 16], []), placeholder_9: placeholder_17: Buffer(placeholder_14, float32, [1, 20, 1, 1, 16], []), placeholder_6: placeholder_18: Buffer(placeholder_11, float32, [20, 12, 3, 3, 16, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 20, 7, 7, 16], []), placeholder_7: placeholder_19: Buffer(placeholder_12, float32, [1, 20, 1, 1, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 70) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global;
    allocate(data_pad: Pointer(global float32), float32, [144]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 12) {
        for (kh.outer: int32, 0, 3) {
          let cse_var_4: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)
          let cse_var_3: int32 = (kh.outer + cse_var_4)
          let cse_var_2: int32 = (((ic.outer*784) + (kh.outer*112)) + (cse_var_4*112))
          let cse_var_1: bool = ((1 <= cse_var_3) && (cse_var_3 < 8))
           {
            data_pad_1: Buffer(data_pad, float32, [144], [])[ramp(0, 1, 16)] = broadcast(0f32, 16)
            data_pad_1[ramp(16, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 112), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(32, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 96), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(48, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 80), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(64, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 64), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(80, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 48), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(96, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 32), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(112, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 16), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(128, 1, 16)] = broadcast(0f32, 16)
            for (ic.inner: int32, 0, 16) {
              let cse_var_18: int32 = (ic.inner + 96)
              let cse_var_17: int32 = (ic.inner + 80)
              let cse_var_16: int32 = (ic.inner + 64)
              let cse_var_15: int32 = (ic.inner + 48)
              let cse_var_14: int32 = (ic.inner + 32)
              let cse_var_13: int32 = (ic.inner + 16)
              let cse_var_12: int32 = (ic.inner + 128)
              let cse_var_11: int32 = (ic.inner + 112)
              let cse_var_10: int32 = ((((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)*55296) + (ic.outer*2304)) + (kh.outer*768)) + (ic.inner*16))
              let cse_var_9: int32 = (cse_var_10 + 512)
              let cse_var_8: int32 = (cse_var_10 + 28160)
              let cse_var_7: int32 = (cse_var_10 + 27904)
              let cse_var_6: int32 = (cse_var_10 + 27648)
              let cse_var_5: int32 = (cse_var_10 + 256)
               {
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_11], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_11], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_11], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_11], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
              }
            }
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_20: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)
          let cse_var_19: int32 = ((cse_var_20*32) + (ax1.inner*16))
          T_relu[ramp(((((cse_var_20*1568) + (ax1.inner*784)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)*112)) + (ax3.inner*16)), 1, 16)] = max((((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(cse_var_19, 1, 16)])*placeholder_3[ramp(cse_var_19, 1, 16)]) + placeholder_4[ramp(cse_var_19, 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 22: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_16 (weight 1 key: ["9db1fd34470fc877a2c0431d681f01a4", [1, 36, 14, 14, 16], [10, 36, 1, 1, 16, 16], [1, 10, 1, 1, 16], [1, 10, 1, 1, 16], [1, 10, 1, 1, 16], [1, 10, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 36, 14, 14, 16]
placeholder = PLACEHOLDER [10, 36, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=7)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=2)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=7)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=2)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 512)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [112896], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [92160], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [160], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [160], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [160], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [31360], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_5: placeholder_15: Buffer(placeholder_10, float32, [1, 36, 14, 14, 16], []), placeholder_9: placeholder_16: Buffer(placeholder_14, float32, [1, 10, 1, 1, 16], []), placeholder_7: placeholder_17: Buffer(placeholder_12, float32, [1, 10, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 10, 14, 14, 16], []), placeholder_6: placeholder_18: Buffer(placeholder_11, float32, [10, 36, 1, 1, 16, 16], []), placeholder_8: placeholder_19: Buffer(placeholder_13, float32, [1, 10, 1, 1, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused: int32, 0, 140) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 36) {
        let cse_var_144: int32 = ((ic.outer*3136) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 28)*112))
        let cse_var_143: int32 = ((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 28)*18432) + (ic.outer*256))
        let cse_var_142: int32 = (cse_var_144 + 19)
        let cse_var_141: int32 = (cse_var_144 + 17)
        let cse_var_140: int32 = (cse_var_144 + 16)
        let cse_var_139: int32 = (cse_var_144 + 15)
        let cse_var_138: int32 = (cse_var_144 + 14)
        let cse_var_137: int32 = (cse_var_144 + 13)
        let cse_var_136: int32 = (cse_var_144 + 12)
        let cse_var_135: int32 = (cse_var_144 + 111)
        let cse_var_134: int32 = (cse_var_144 + 110)
        let cse_var_133: int32 = (cse_var_144 + 11)
        let cse_var_132: int32 = (cse_var_144 + 109)
        let cse_var_131: int32 = (cse_var_144 + 108)
        let cse_var_130: int32 = (cse_var_144 + 107)
        let cse_var_129: int32 = (cse_var_144 + 106)
        let cse_var_128: int32 = (cse_var_144 + 105)
        let cse_var_127: int32 = (cse_var_144 + 103)
        let cse_var_126: int32 = (cse_var_144 + 18)
        let cse_var_125: int32 = (cse_var_144 + 35)
        let cse_var_124: int32 = (cse_var_144 + 33)
        let cse_var_123: int32 = (cse_var_144 + 32)
        let cse_var_122: int32 = (cse_var_144 + 31)
        let cse_var_121: int32 = (cse_var_144 + 30)
        let cse_var_120: int32 = (cse_var_144 + 3)
        let cse_var_119: int32 = (cse_var_144 + 29)
        let cse_var_118: int32 = (cse_var_144 + 28)
        let cse_var_117: int32 = (cse_var_144 + 104)
        let cse_var_116: int32 = (cse_var_144 + 26)
        let cse_var_115: int32 = (cse_var_144 + 25)
        let cse_var_114: int32 = (cse_var_144 + 24)
        let cse_var_113: int32 = (cse_var_144 + 23)
        let cse_var_112: int32 = (cse_var_144 + 22)
        let cse_var_111: int32 = (cse_var_144 + 21)
        let cse_var_110: int32 = (cse_var_144 + 20)
        let cse_var_109: int32 = (cse_var_144 + 2)
        let cse_var_108: int32 = (cse_var_144 + 27)
        let cse_var_107: int32 = (cse_var_143 + 9264)
        let cse_var_106: int32 = (cse_var_143 + 9248)
        let cse_var_105: int32 = (cse_var_143 + 9232)
        let cse_var_104: int32 = (cse_var_143 + 9216)
        let cse_var_103: int32 = (cse_var_143 + 80)
        let cse_var_102: int32 = (cse_var_143 + 64)
        let cse_var_101: int32 = (cse_var_143 + 48)
        let cse_var_100: int32 = (cse_var_143 + 32)
        let cse_var_99: int32 = (cse_var_144 + 34)
        let cse_var_98: int32 = (cse_var_143 + 224)
        let cse_var_97: int32 = (cse_var_143 + 208)
        let cse_var_96: int32 = (cse_var_143 + 192)
        let cse_var_95: int32 = (cse_var_143 + 176)
        let cse_var_94: int32 = (cse_var_143 + 160)
        let cse_var_93: int32 = (cse_var_143 + 16)
        let cse_var_92: int32 = (cse_var_143 + 144)
        let cse_var_91: int32 = (cse_var_143 + 112)
        let cse_var_90: int32 = (cse_var_143 + 240)
        let cse_var_89: int32 = (cse_var_144 + 102)
        let cse_var_88: int32 = (cse_var_144 + 101)
        let cse_var_87: int32 = (cse_var_144 + 100)
        let cse_var_86: int32 = (cse_var_144 + 10)
        let cse_var_85: int32 = (cse_var_144 + 1)
        let cse_var_84: int32 = (cse_var_143 + 96)
        let cse_var_83: int32 = (cse_var_143 + 9456)
        let cse_var_82: int32 = (cse_var_143 + 9440)
        let cse_var_81: int32 = (cse_var_143 + 9280)
        let cse_var_80: int32 = (cse_var_143 + 9408)
        let cse_var_79: int32 = (cse_var_143 + 9392)
        let cse_var_78: int32 = (cse_var_143 + 9376)
        let cse_var_77: int32 = (cse_var_143 + 9360)
        let cse_var_76: int32 = (cse_var_143 + 9344)
        let cse_var_75: int32 = (cse_var_143 + 9328)
        let cse_var_74: int32 = (cse_var_143 + 9312)
        let cse_var_73: int32 = (cse_var_143 + 9296)
        let cse_var_72: int32 = (cse_var_143 + 9424)
        let cse_var_71: int32 = (cse_var_144 + 82)
        let cse_var_70: int32 = (cse_var_144 + 81)
        let cse_var_69: int32 = (cse_var_144 + 80)
        let cse_var_68: int32 = (cse_var_144 + 8)
        let cse_var_67: int32 = (cse_var_144 + 79)
        let cse_var_66: int32 = (cse_var_144 + 78)
        let cse_var_65: int32 = (cse_var_144 + 77)
        let cse_var_64: int32 = (cse_var_143 + 128)
        let cse_var_63: int32 = (cse_var_144 + 75)
        let cse_var_62: int32 = (cse_var_144 + 74)
        let cse_var_61: int32 = (cse_var_144 + 73)
        let cse_var_60: int32 = (cse_var_144 + 72)
        let cse_var_59: int32 = (cse_var_144 + 71)
        let cse_var_58: int32 = (cse_var_144 + 70)
        let cse_var_57: int32 = (cse_var_144 + 7)
        let cse_var_56: int32 = (cse_var_144 + 69)
        let cse_var_55: int32 = (cse_var_144 + 76)
        let cse_var_54: int32 = (cse_var_144 + 99)
        let cse_var_53: int32 = (cse_var_144 + 98)
        let cse_var_52: int32 = (cse_var_144 + 97)
        let cse_var_51: int32 = (cse_var_144 + 96)
        let cse_var_50: int32 = (cse_var_144 + 95)
        let cse_var_49: int32 = (cse_var_144 + 94)
        let cse_var_48: int32 = (cse_var_144 + 93)
        let cse_var_47: int32 = (cse_var_144 + 92)
        let cse_var_46: int32 = (cse_var_144 + 83)
        let cse_var_45: int32 = (cse_var_144 + 90)
        let cse_var_44: int32 = (cse_var_144 + 9)
        let cse_var_43: int32 = (cse_var_144 + 89)
        let cse_var_42: int32 = (cse_var_144 + 88)
        let cse_var_41: int32 = (cse_var_144 + 87)
        let cse_var_40: int32 = (cse_var_144 + 86)
        let cse_var_39: int32 = (cse_var_144 + 85)
        let cse_var_38: int32 = (cse_var_144 + 84)
        let cse_var_37: int32 = (cse_var_144 + 91)
        let cse_var_36: int32 = (cse_var_144 + 50)
        let cse_var_35: int32 = (cse_var_144 + 5)
        let cse_var_34: int32 = (cse_var_144 + 49)
        let cse_var_33: int32 = (cse_var_144 + 48)
        let cse_var_32: int32 = (cse_var_144 + 47)
        let cse_var_31: int32 = (cse_var_144 + 46)
        let cse_var_30: int32 = (cse_var_144 + 45)
        let cse_var_29: int32 = (cse_var_144 + 44)
        let cse_var_28: int32 = (cse_var_144 + 68)
        let cse_var_27: int32 = (cse_var_144 + 42)
        let cse_var_26: int32 = (cse_var_144 + 41)
        let cse_var_25: int32 = (cse_var_144 + 40)
        let cse_var_24: int32 = (cse_var_144 + 4)
        let cse_var_23: int32 = (cse_var_144 + 39)
        let cse_var_22: int32 = (cse_var_144 + 38)
        let cse_var_21: int32 = (cse_var_144 + 37)
        let cse_var_20: int32 = (cse_var_144 + 36)
        let cse_var_19: int32 = (cse_var_144 + 43)
        let cse_var_18: int32 = (cse_var_144 + 67)
        let cse_var_17: int32 = (cse_var_144 + 66)
        let cse_var_16: int32 = (cse_var_144 + 65)
        let cse_var_15: int32 = (cse_var_144 + 64)
        let cse_var_14: int32 = (cse_var_144 + 63)
        let cse_var_13: int32 = (cse_var_144 + 62)
        let cse_var_12: int32 = (cse_var_144 + 61)
        let cse_var_11: int32 = (cse_var_144 + 60)
        let cse_var_10: int32 = (cse_var_144 + 51)
        let cse_var_9: int32 = (cse_var_144 + 59)
        let cse_var_8: int32 = (cse_var_144 + 58)
        let cse_var_7: int32 = (cse_var_144 + 57)
        let cse_var_6: int32 = (cse_var_144 + 56)
        let cse_var_5: int32 = (cse_var_144 + 55)
        let cse_var_4: int32 = (cse_var_144 + 54)
        let cse_var_3: int32 = (cse_var_144 + 53)
        let cse_var_2: int32 = (cse_var_144 + 52)
        let cse_var_1: int32 = (cse_var_144 + 6)
         {
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_144], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_140], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_123], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_33], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_15], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_69], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_51], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_144], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_140], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_123], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_33], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_15], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_69], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_51], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_85], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_141], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_124], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_34], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_16], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_70], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_52], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_85], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_141], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_124], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_34], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_16], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_70], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_52], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_109], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_126], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_99], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_36], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_17], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_71], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_53], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_109], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_126], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_99], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_36], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_17], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_71], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_53], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_120], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_142], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_125], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_10], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_18], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_46], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_54], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_120], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_142], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_125], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_10], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_18], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_46], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_54], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_24], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_110], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_20], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_28], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_38], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_87], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_24], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_110], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_20], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_28], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_38], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_87], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_35], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_111], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_21], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_56], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_39], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_88], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_35], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_111], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_21], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_56], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_39], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_88], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_112], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_22], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_58], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_40], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_89], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_112], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_22], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_58], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_40], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_89], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_57], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_113], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_23], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_59], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_41], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_127], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_57], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_113], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_23], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_59], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_41], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_127], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_68], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_114], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_25], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_60], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_42], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_117], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_68], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_114], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_25], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_60], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_42], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_117], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_44], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_115], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_26], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_61], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_43], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_128], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_44], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_115], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_26], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_61], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_43], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_128], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_86], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_116], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_27], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_62], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_45], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_129], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_86], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_116], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_27], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_62], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_45], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_129], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_133], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_108], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_19], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_9], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_63], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_37], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_130], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_133], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_108], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_19], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_9], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_63], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_37], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_130], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_136], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_118], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_29], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_11], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_55], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_47], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_131], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_136], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_118], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_29], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_11], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_55], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_47], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_131], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_137], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_119], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_30], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_12], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_65], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_48], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_132], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_137], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_119], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_30], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_12], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_65], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_48], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_132], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_138], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_121], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_31], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_13], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_66], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_49], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_134], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_138], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_121], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_31], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_13], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_66], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_49], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_134], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_139], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_122], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_32], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_14], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_67], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_50], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_135], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_139], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_122], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_32], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_14], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_67], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_50], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_135], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_146: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 28)
          let cse_var_145: int32 = ((cse_var_146*32) + (ax1.inner*16))
          T_relu[ramp(((((cse_var_146*6272) + (ax1.inner*3136)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 28)*112)) + (ax3.inner*16)), 1, 16)] = max((((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(cse_var_145, 1, 16)])*placeholder_3[ramp(cse_var_145, 1, 16)]) + placeholder_4[ramp(cse_var_145, 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 23: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 (weight 2 key: ["f6615ae9259e3b2add2908c0cd980cb6", [1, 12, 28, 28, 16], [4, 12, 1, 1, 16, 16], [1, 4, 1, 1, 16], [1, 4, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 12, 28, 28, 16]
placeholder = PLACEHOLDER [4, 12, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=1)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=2)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=1)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=7)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=1)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=4)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=1)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=1)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 512)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_6: Pointer(float32), float32, [150528], []),
             placeholder_1: Buffer(placeholder_7: Pointer(float32), float32, [12288], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [64], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [50176], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_3: placeholder_9: Buffer(placeholder_6, float32, [1, 12, 28, 28, 16], []), placeholder_4: placeholder_10: Buffer(placeholder_7, float32, [4, 12, 1, 1, 16, 16], []), placeholder_5: placeholder_11: Buffer(placeholder_8, float32, [1, 4, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 4, 28, 28, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 224) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 48) {
        let cse_var_36: int32 = ((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 112)*6144) + (ic.outer*64))
        let cse_var_35: int32 = (cse_var_36 + 48)
        let cse_var_34: int32 = (cse_var_36 + 32)
        let cse_var_33: int32 = (cse_var_36 + 3120)
        let cse_var_32: int32 = (cse_var_36 + 3104)
        let cse_var_31: int32 = (cse_var_36 + 3088)
        let cse_var_30: int32 = (cse_var_36 + 3072)
        let cse_var_29: int32 = (cse_var_36 + 16)
        let cse_var_28: int32 = (((floordiv(ic.outer, 4)*12544) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 112)*112)) + (floormod(ic.outer, 4)*4))
        let cse_var_27: int32 = (cse_var_28 + 50)
        let cse_var_26: int32 = (cse_var_28 + 48)
        let cse_var_25: int32 = (cse_var_28 + 35)
        let cse_var_24: int32 = (cse_var_28 + 34)
        let cse_var_23: int32 = (cse_var_28 + 33)
        let cse_var_22: int32 = (cse_var_28 + 32)
        let cse_var_21: int32 = (cse_var_28 + 3)
        let cse_var_20: int32 = (cse_var_28 + 2)
        let cse_var_19: int32 = (cse_var_28 + 19)
        let cse_var_18: int32 = (cse_var_28 + 18)
        let cse_var_17: int32 = (cse_var_28 + 17)
        let cse_var_16: int32 = (cse_var_28 + 1)
        let cse_var_15: int32 = (cse_var_28 + 49)
        let cse_var_14: int32 = (cse_var_28 + 51)
        let cse_var_13: int32 = (cse_var_28 + 64)
        let cse_var_12: int32 = (cse_var_28 + 65)
        let cse_var_11: int32 = (cse_var_28 + 66)
        let cse_var_10: int32 = (cse_var_28 + 67)
        let cse_var_9: int32 = (cse_var_28 + 80)
        let cse_var_8: int32 = (cse_var_28 + 81)
        let cse_var_7: int32 = (cse_var_28 + 82)
        let cse_var_6: int32 = (cse_var_28 + 83)
        let cse_var_5: int32 = (cse_var_28 + 96)
        let cse_var_4: int32 = (cse_var_28 + 97)
        let cse_var_3: int32 = (cse_var_28 + 98)
        let cse_var_2: int32 = (cse_var_28 + 99)
        let cse_var_1: int32 = (cse_var_28 + 16)
         {
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_28], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_16], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_20], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_21], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_17], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_18], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_19], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_22], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_23], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_24], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_25], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_26], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_15], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_27], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_14], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_13], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_12], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_11], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_10], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_9], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_28], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_16], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_20], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_21], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_17], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_18], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_19], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_22], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_23], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_24], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_25], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_26], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_15], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_27], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_14], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_13], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_12], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_11], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_10], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_9], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_37: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 112)
          T_relu[ramp(((((cse_var_37*25088) + (ax1.inner*12544)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 112)*112)) + (ax3.inner*16)), 1, 16)] = max((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(((cse_var_37*32) + (ax1.inner*16)), 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 24: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11 (weight 1 key: ["f6615ae9259e3b2add2908c0cd980cb6", [1, 36, 14, 14, 16], [10, 36, 1, 1, 16, 16], [1, 10, 1, 1, 16], [1, 10, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 36, 14, 14, 16]
placeholder = PLACEHOLDER [10, 36, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=14)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=2)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=4)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=14)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=2)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 16)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_6: Pointer(float32), float32, [112896], []),
             placeholder_1: Buffer(placeholder_7: Pointer(float32), float32, [92160], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [160], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [31360], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_3: placeholder_9: Buffer(placeholder_6, float32, [1, 36, 14, 14, 16], []), placeholder_4: placeholder_10: Buffer(placeholder_7, float32, [10, 36, 1, 1, 16, 16], []), placeholder_5: placeholder_11: Buffer(placeholder_8, float32, [1, 10, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 10, 14, 14, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 140) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 144) {
        for (ic.inner: int32, 0, 4) {
          let cse_var_9: int32 = (((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)*18432) + (ic.outer*64)) + (ic.inner*16))
          let cse_var_8: int32 = (cse_var_9 + 9216)
          let cse_var_7: int32 = ((((floordiv(ic.outer, 4)*3136) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)*112)) + (floormod(ic.outer, 4)*4)) + ic.inner)
          let cse_var_6: int32 = (cse_var_7 + 96)
          let cse_var_5: int32 = (cse_var_7 + 80)
          let cse_var_4: int32 = (cse_var_7 + 64)
          let cse_var_3: int32 = (cse_var_7 + 48)
          let cse_var_2: int32 = (cse_var_7 + 32)
          let cse_var_1: int32 = (cse_var_7 + 16)
           {
            conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_10: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)
          T_relu[ramp(((((cse_var_10*6272) + (ax1.inner*3136)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)*112)) + (ax3.inner*16)), 1, 16)] = max((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(((cse_var_10*32) + (ax1.inner*16)), 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 25: vm_mod_fused_nn_max_pool2d_2 (weight 1 key: ["840abcf4051ab92cd9ec49f77358d7e7", [1, 20, 28, 28, 16], [1, 20, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 20, 28, 28, 16]
pad_temp(ax0, ax1, ax2, ax3, ax4) = tir.if_then_else(((ax2 < 28) && (ax3 < 28)), placeholder[ax0, ax1, ax2, ax3, ax4], -3.40282e+38f)
tensor(ax0, ax1, ax2, ax3, ax4) max= pad_temp[ax0, ax1, ((ax2*2) + rv0), ((ax3*2) + rv1), ax4]


Trace for this task is: 
pad_temp_ax0, pad_temp_ax1, pad_temp_ax2, pad_temp_ax3, pad_temp_ax4 = tuple(pad_temp.op.axis) + tuple(pad_temp.op.reduce_axis)
tensor_ax0, tensor_ax1, tensor_ax2, tensor_ax3, tensor_ax4, tensor_rv0, tensor_rv1 = tuple(tensor.op.axis) + tuple(tensor.op.reduce_axis)
s[tensor].compute_root()
s[pad_temp].compute_at(s[tensor], tensor_ax4)
tensor_ax0_ax1_fused_ax2_fused = s[tensor].fuse(tensor_ax0, tensor_ax1, tensor_ax2)
s[tensor].parallel(tensor_ax0_ax1_fused_ax2_fused)
s[tensor].pragma(tensor_ax0_ax1_fused_ax2_fused, "auto_unroll_max_step", 64)
s[tensor].pragma(tensor_ax0_ax1_fused_ax2_fused, "unroll_explicit", True)
s[pad_temp].vectorize(pad_temp_ax4)


The best replacement found is:
@main = primfn(placeholder_1: handle, tensor_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_2: Pointer(float32), float32, [250880], []),
             tensor: Buffer(tensor_2: Pointer(float32), float32, [62720], [])}
  buffer_map = {placeholder_1: placeholder, tensor_1: tensor}
  preflattened_buffer_map = {placeholder_1: placeholder_3: Buffer(placeholder_2, float32, [1, 20, 28, 28, 16], []), tensor_1: tensor_3: Buffer(tensor_2, float32, [1, 20, 14, 14, 16], [])} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 280) "parallel" {
    allocate(pad_temp: Pointer(global float32), float32, [9]), storage_scope = global;
    for (ax3: int32, 0, 14) {
      for (ax4: int32, 0, 16) {
        let cse_var_4: bool = (ax3 < 13)
        let cse_var_3: bool = (floormod(ax0.ax1.fused.ax2.fused, 14) < 13)
        let cse_var_2: int32 = (((ax0.ax1.fused.ax2.fused*896) + (ax3*32)) + ax4)
        let cse_var_1: int32 = (((ax0.ax1.fused.ax2.fused*224) + (ax3*16)) + ax4)
         {
          pad_temp_1: Buffer(pad_temp, float32, [9], [], align=32)[0] = placeholder[cse_var_2]
          pad_temp_1[1] = placeholder[(cse_var_2 + 16)]
          pad_temp_1[2] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_2 + 32)], -3.40282e+38f32, dtype=float32)
          pad_temp_1[3] = placeholder[(cse_var_2 + 448)]
          pad_temp_1[4] = placeholder[(cse_var_2 + 464)]
          pad_temp_1[5] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_2 + 480)], -3.40282e+38f32, dtype=float32)
          pad_temp_1[6] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_2 + 896)], -3.40282e+38f32, dtype=float32)
          pad_temp_1[7] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_2 + 912)], -3.40282e+38f32, dtype=float32)
          pad_temp_1[8] = @tir.if_then_else((cse_var_3 && cse_var_4), placeholder[(cse_var_2 + 928)], -3.40282e+38f32, dtype=float32)
          tensor[cse_var_1] = -3.40282e+38f32
          tensor[cse_var_1] = max(tensor[cse_var_1], pad_temp_1[0])
          tensor[cse_var_1] = max(tensor[cse_var_1], pad_temp_1[1])
          tensor[cse_var_1] = max(tensor[cse_var_1], pad_temp_1[2])
          tensor[cse_var_1] = max(tensor[cse_var_1], pad_temp_1[3])
          tensor[cse_var_1] = max(tensor[cse_var_1], pad_temp_1[4])
          tensor[cse_var_1] = max(tensor[cse_var_1], pad_temp_1[5])
          tensor[cse_var_1] = max(tensor[cse_var_1], pad_temp_1[6])
          tensor[cse_var_1] = max(tensor[cse_var_1], pad_temp_1[7])
          tensor[cse_var_1] = max(tensor[cse_var_1], pad_temp_1[8])
        }
      }
    }
  }
}


==== Task 26: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18 (weight 1 key: ["ce1b4a245fb9b3a0526fcd7e77d29d3f", [1, 12, 7, 7, 16], [14, 12, 3, 3, 16, 16], [1, 14, 1, 1, 16], [1, 14, 7, 7, 16]]) =====
placeholder = PLACEHOLDER [1, 12, 7, 7, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 8)) && (i3 >= 1)) && (i3 < 8)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [14, 12, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 14, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3, data_pad_i4 = tuple(data_pad.op.axis) + tuple(data_pad.op.reduce_axis)
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=1)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=2)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=1)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=2)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=3)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax1_o, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax2_o, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax3_o, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax4_o, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
s[T_relu].reorder(T_relu_ax0_o, T_relu_ax1_o, T_relu_ax2_o, T_relu_ax3_o, T_relu_ax4_o, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o)
s[data_pad].compute_at(s[conv2d_NCHWc], conv2d_NCHWc_oh_o_o_i)
T_relu_ax0_o_ax1_o_fused_ax2_o_fused_ax3_o_fused_ax4_o_fused = s[T_relu].fuse(T_relu_ax0_o, T_relu_ax1_o, T_relu_ax2_o, T_relu_ax3_o, T_relu_ax4_o)
s[T_relu].parallel(T_relu_ax0_o_ax1_o_fused_ax2_o_fused_ax3_o_fused_ax4_o_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 512)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[data_pad].vectorize(data_pad_i4)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_6: Pointer(float32), float32, [9408], []),
             placeholder_1: Buffer(placeholder_7: Pointer(float32), float32, [387072], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [224], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [10976], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_3: placeholder_9: Buffer(placeholder_6, float32, [1, 12, 7, 7, 16], []), placeholder_4: placeholder_10: Buffer(placeholder_7, float32, [14, 12, 3, 3, 16, 16], []), placeholder_5: placeholder_11: Buffer(placeholder_8, float32, [1, 14, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 14, 7, 7, 16], [])} {
  for (ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused.ax4.outer.fused: int32, 0, 49) "parallel" {
    let cse_var_4: int32 = floormod(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused.ax4.outer.fused, 7)
    let cse_var_3: int32 = (cse_var_4*112)
    let cse_var_2: bool = (cse_var_4 < 6)
    let cse_var_1: bool = (1 <= cse_var_4)
    allocate(data_pad: Pointer(global float32), float32, [5184]), storage_scope = global;
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global {
      data_pad_1: Buffer(data_pad, float32, [5184], [])[ramp(0, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(16, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 - 112), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(32, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 - 96), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(48, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 - 80), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(64, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 - 64), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(80, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 - 48), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(96, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 - 32), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(112, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 - 16), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(128, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(144, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(160, 1, 16)] = placeholder[ramp(cse_var_3, 1, 16)]
      data_pad_1[ramp(176, 1, 16)] = placeholder[ramp((cse_var_3 + 16), 1, 16)]
      data_pad_1[ramp(192, 1, 16)] = placeholder[ramp((cse_var_3 + 32), 1, 16)]
      data_pad_1[ramp(208, 1, 16)] = placeholder[ramp((cse_var_3 + 48), 1, 16)]
      data_pad_1[ramp(224, 1, 16)] = placeholder[ramp((cse_var_3 + 64), 1, 16)]
      data_pad_1[ramp(240, 1, 16)] = placeholder[ramp((cse_var_3 + 80), 1, 16)]
      data_pad_1[ramp(256, 1, 16)] = placeholder[ramp((cse_var_3 + 96), 1, 16)]
      data_pad_1[ramp(272, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(288, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(304, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 112), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(320, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 128), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(336, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 144), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(352, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 160), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(368, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 176), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(384, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 192), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(400, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 208), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(416, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(432, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(448, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 672), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(464, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 688), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(480, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 704), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(496, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 720), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(512, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 736), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(528, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 752), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(544, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 768), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(560, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(576, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(592, 1, 16)] = placeholder[ramp((cse_var_3 + 784), 1, 16)]
      data_pad_1[ramp(608, 1, 16)] = placeholder[ramp((cse_var_3 + 800), 1, 16)]
      data_pad_1[ramp(624, 1, 16)] = placeholder[ramp((cse_var_3 + 816), 1, 16)]
      data_pad_1[ramp(640, 1, 16)] = placeholder[ramp((cse_var_3 + 832), 1, 16)]
      data_pad_1[ramp(656, 1, 16)] = placeholder[ramp((cse_var_3 + 848), 1, 16)]
      data_pad_1[ramp(672, 1, 16)] = placeholder[ramp((cse_var_3 + 864), 1, 16)]
      data_pad_1[ramp(688, 1, 16)] = placeholder[ramp((cse_var_3 + 880), 1, 16)]
      data_pad_1[ramp(704, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(720, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(736, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 896), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(752, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 912), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(768, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 928), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(784, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 944), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(800, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 960), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(816, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 976), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(832, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 992), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(848, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(864, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(880, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 1456), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(896, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 1472), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(912, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 1488), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(928, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 1504), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(944, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 1520), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(960, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 1536), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(976, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 1552), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(992, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1008, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1024, 1, 16)] = placeholder[ramp((cse_var_3 + 1568), 1, 16)]
      data_pad_1[ramp(1040, 1, 16)] = placeholder[ramp((cse_var_3 + 1584), 1, 16)]
      data_pad_1[ramp(1056, 1, 16)] = placeholder[ramp((cse_var_3 + 1600), 1, 16)]
      data_pad_1[ramp(1072, 1, 16)] = placeholder[ramp((cse_var_3 + 1616), 1, 16)]
      data_pad_1[ramp(1088, 1, 16)] = placeholder[ramp((cse_var_3 + 1632), 1, 16)]
      data_pad_1[ramp(1104, 1, 16)] = placeholder[ramp((cse_var_3 + 1648), 1, 16)]
      data_pad_1[ramp(1120, 1, 16)] = placeholder[ramp((cse_var_3 + 1664), 1, 16)]
      data_pad_1[ramp(1136, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1152, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1168, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 1680), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1184, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 1696), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1200, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 1712), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1216, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 1728), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1232, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 1744), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1248, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 1760), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1264, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 1776), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1280, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1296, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1312, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 2240), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1328, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 2256), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1344, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 2272), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1360, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 2288), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1376, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 2304), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1392, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 2320), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1408, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 2336), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1424, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1440, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1456, 1, 16)] = placeholder[ramp((cse_var_3 + 2352), 1, 16)]
      data_pad_1[ramp(1472, 1, 16)] = placeholder[ramp((cse_var_3 + 2368), 1, 16)]
      data_pad_1[ramp(1488, 1, 16)] = placeholder[ramp((cse_var_3 + 2384), 1, 16)]
      data_pad_1[ramp(1504, 1, 16)] = placeholder[ramp((cse_var_3 + 2400), 1, 16)]
      data_pad_1[ramp(1520, 1, 16)] = placeholder[ramp((cse_var_3 + 2416), 1, 16)]
      data_pad_1[ramp(1536, 1, 16)] = placeholder[ramp((cse_var_3 + 2432), 1, 16)]
      data_pad_1[ramp(1552, 1, 16)] = placeholder[ramp((cse_var_3 + 2448), 1, 16)]
      data_pad_1[ramp(1568, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1584, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1600, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 2464), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1616, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 2480), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1632, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 2496), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1648, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 2512), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1664, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 2528), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1680, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 2544), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1696, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 2560), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1712, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1728, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1744, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3024), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1760, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3040), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1776, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3056), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1792, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3072), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1808, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3088), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1824, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3104), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1840, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3120), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1856, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1872, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1888, 1, 16)] = placeholder[ramp((cse_var_3 + 3136), 1, 16)]
      data_pad_1[ramp(1904, 1, 16)] = placeholder[ramp((cse_var_3 + 3152), 1, 16)]
      data_pad_1[ramp(1920, 1, 16)] = placeholder[ramp((cse_var_3 + 3168), 1, 16)]
      data_pad_1[ramp(1936, 1, 16)] = placeholder[ramp((cse_var_3 + 3184), 1, 16)]
      data_pad_1[ramp(1952, 1, 16)] = placeholder[ramp((cse_var_3 + 3200), 1, 16)]
      data_pad_1[ramp(1968, 1, 16)] = placeholder[ramp((cse_var_3 + 3216), 1, 16)]
      data_pad_1[ramp(1984, 1, 16)] = placeholder[ramp((cse_var_3 + 3232), 1, 16)]
      data_pad_1[ramp(2000, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2016, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2032, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 3248), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2048, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 3264), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2064, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 3280), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2080, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 3296), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2096, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 3312), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2112, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 3328), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2128, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 3344), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2144, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2160, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2176, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3808), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2192, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3824), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2208, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3840), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2224, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3856), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2240, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3872), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2256, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3888), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2272, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3904), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2288, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2304, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2320, 1, 16)] = placeholder[ramp((cse_var_3 + 3920), 1, 16)]
      data_pad_1[ramp(2336, 1, 16)] = placeholder[ramp((cse_var_3 + 3936), 1, 16)]
      data_pad_1[ramp(2352, 1, 16)] = placeholder[ramp((cse_var_3 + 3952), 1, 16)]
      data_pad_1[ramp(2368, 1, 16)] = placeholder[ramp((cse_var_3 + 3968), 1, 16)]
      data_pad_1[ramp(2384, 1, 16)] = placeholder[ramp((cse_var_3 + 3984), 1, 16)]
      data_pad_1[ramp(2400, 1, 16)] = placeholder[ramp((cse_var_3 + 4000), 1, 16)]
      data_pad_1[ramp(2416, 1, 16)] = placeholder[ramp((cse_var_3 + 4016), 1, 16)]
      data_pad_1[ramp(2432, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2448, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2464, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4032), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2480, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4048), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2496, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4064), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2512, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4080), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2528, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4096), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2544, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4112), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2560, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4128), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2576, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2592, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2608, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 4592), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2624, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 4608), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2640, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 4624), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2656, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 4640), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2672, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 4656), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2688, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 4672), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2704, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 4688), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2720, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2736, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2752, 1, 16)] = placeholder[ramp((cse_var_3 + 4704), 1, 16)]
      data_pad_1[ramp(2768, 1, 16)] = placeholder[ramp((cse_var_3 + 4720), 1, 16)]
      data_pad_1[ramp(2784, 1, 16)] = placeholder[ramp((cse_var_3 + 4736), 1, 16)]
      data_pad_1[ramp(2800, 1, 16)] = placeholder[ramp((cse_var_3 + 4752), 1, 16)]
      data_pad_1[ramp(2816, 1, 16)] = placeholder[ramp((cse_var_3 + 4768), 1, 16)]
      data_pad_1[ramp(2832, 1, 16)] = placeholder[ramp((cse_var_3 + 4784), 1, 16)]
      data_pad_1[ramp(2848, 1, 16)] = placeholder[ramp((cse_var_3 + 4800), 1, 16)]
      data_pad_1[ramp(2864, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2880, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2896, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4816), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2912, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4832), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2928, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4848), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2944, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4864), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2960, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4880), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2976, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4896), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2992, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4912), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3008, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3024, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3040, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 5376), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3056, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 5392), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3072, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 5408), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3088, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 5424), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3104, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 5440), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3120, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 5456), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3136, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 5472), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3152, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3168, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3184, 1, 16)] = placeholder[ramp((cse_var_3 + 5488), 1, 16)]
      data_pad_1[ramp(3200, 1, 16)] = placeholder[ramp((cse_var_3 + 5504), 1, 16)]
      data_pad_1[ramp(3216, 1, 16)] = placeholder[ramp((cse_var_3 + 5520), 1, 16)]
      data_pad_1[ramp(3232, 1, 16)] = placeholder[ramp((cse_var_3 + 5536), 1, 16)]
      data_pad_1[ramp(3248, 1, 16)] = placeholder[ramp((cse_var_3 + 5552), 1, 16)]
      data_pad_1[ramp(3264, 1, 16)] = placeholder[ramp((cse_var_3 + 5568), 1, 16)]
      data_pad_1[ramp(3280, 1, 16)] = placeholder[ramp((cse_var_3 + 5584), 1, 16)]
      data_pad_1[ramp(3296, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3312, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3328, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 5600), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3344, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 5616), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3360, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 5632), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3376, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 5648), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3392, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 5664), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3408, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 5680), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3424, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 5696), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3440, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3456, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3472, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 6160), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3488, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 6176), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3504, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 6192), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3520, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 6208), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3536, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 6224), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3552, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 6240), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3568, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 6256), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3584, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3600, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3616, 1, 16)] = placeholder[ramp((cse_var_3 + 6272), 1, 16)]
      data_pad_1[ramp(3632, 1, 16)] = placeholder[ramp((cse_var_3 + 6288), 1, 16)]
      data_pad_1[ramp(3648, 1, 16)] = placeholder[ramp((cse_var_3 + 6304), 1, 16)]
      data_pad_1[ramp(3664, 1, 16)] = placeholder[ramp((cse_var_3 + 6320), 1, 16)]
      data_pad_1[ramp(3680, 1, 16)] = placeholder[ramp((cse_var_3 + 6336), 1, 16)]
      data_pad_1[ramp(3696, 1, 16)] = placeholder[ramp((cse_var_3 + 6352), 1, 16)]
      data_pad_1[ramp(3712, 1, 16)] = placeholder[ramp((cse_var_3 + 6368), 1, 16)]
      data_pad_1[ramp(3728, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3744, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3760, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 6384), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3776, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 6400), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3792, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 6416), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3808, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 6432), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3824, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 6448), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3840, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 6464), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3856, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 6480), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3872, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3888, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3904, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 6944), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3920, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 6960), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3936, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 6976), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3952, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 6992), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3968, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 7008), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3984, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 7024), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4000, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 7040), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4016, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4032, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4048, 1, 16)] = placeholder[ramp((cse_var_3 + 7056), 1, 16)]
      data_pad_1[ramp(4064, 1, 16)] = placeholder[ramp((cse_var_3 + 7072), 1, 16)]
      data_pad_1[ramp(4080, 1, 16)] = placeholder[ramp((cse_var_3 + 7088), 1, 16)]
      data_pad_1[ramp(4096, 1, 16)] = placeholder[ramp((cse_var_3 + 7104), 1, 16)]
      data_pad_1[ramp(4112, 1, 16)] = placeholder[ramp((cse_var_3 + 7120), 1, 16)]
      data_pad_1[ramp(4128, 1, 16)] = placeholder[ramp((cse_var_3 + 7136), 1, 16)]
      data_pad_1[ramp(4144, 1, 16)] = placeholder[ramp((cse_var_3 + 7152), 1, 16)]
      data_pad_1[ramp(4160, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4176, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4192, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 7168), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4208, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 7184), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4224, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 7200), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4240, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 7216), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4256, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 7232), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4272, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 7248), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4288, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 7264), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4304, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4320, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4336, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 7728), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4352, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 7744), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4368, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 7760), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4384, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 7776), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4400, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 7792), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4416, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 7808), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4432, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 7824), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4448, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4464, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4480, 1, 16)] = placeholder[ramp((cse_var_3 + 7840), 1, 16)]
      data_pad_1[ramp(4496, 1, 16)] = placeholder[ramp((cse_var_3 + 7856), 1, 16)]
      data_pad_1[ramp(4512, 1, 16)] = placeholder[ramp((cse_var_3 + 7872), 1, 16)]
      data_pad_1[ramp(4528, 1, 16)] = placeholder[ramp((cse_var_3 + 7888), 1, 16)]
      data_pad_1[ramp(4544, 1, 16)] = placeholder[ramp((cse_var_3 + 7904), 1, 16)]
      data_pad_1[ramp(4560, 1, 16)] = placeholder[ramp((cse_var_3 + 7920), 1, 16)]
      data_pad_1[ramp(4576, 1, 16)] = placeholder[ramp((cse_var_3 + 7936), 1, 16)]
      data_pad_1[ramp(4592, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4608, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4624, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 7952), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4640, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 7968), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4656, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 7984), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4672, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 8000), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4688, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 8016), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4704, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 8032), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4720, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 8048), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4736, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4752, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4768, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 8512), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4784, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 8528), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4800, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 8544), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4816, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 8560), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4832, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 8576), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4848, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 8592), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4864, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 8608), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4880, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4896, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4912, 1, 16)] = placeholder[ramp((cse_var_3 + 8624), 1, 16)]
      data_pad_1[ramp(4928, 1, 16)] = placeholder[ramp((cse_var_3 + 8640), 1, 16)]
      data_pad_1[ramp(4944, 1, 16)] = placeholder[ramp((cse_var_3 + 8656), 1, 16)]
      data_pad_1[ramp(4960, 1, 16)] = placeholder[ramp((cse_var_3 + 8672), 1, 16)]
      data_pad_1[ramp(4976, 1, 16)] = placeholder[ramp((cse_var_3 + 8688), 1, 16)]
      data_pad_1[ramp(4992, 1, 16)] = placeholder[ramp((cse_var_3 + 8704), 1, 16)]
      data_pad_1[ramp(5008, 1, 16)] = placeholder[ramp((cse_var_3 + 8720), 1, 16)]
      data_pad_1[ramp(5024, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(5040, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(5056, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 8736), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5072, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 8752), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5088, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 8768), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5104, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 8784), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5120, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 8800), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5136, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 8816), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5152, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 8832), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5168, 1, 16)] = broadcast(0f32, 16)
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 96) {
        let cse_var_96: int32 = floordiv(ic.outer, 8)
        let cse_var_95: int32 = floormod(ic.outer, 8)
        let cse_var_94: int32 = ((cse_var_96*432) + (cse_var_95*2))
        let cse_var_93: int32 = (cse_var_94 + 289)
        let cse_var_92: int32 = (cse_var_94 + 273)
        let cse_var_91: int32 = (cse_var_94 + 272)
        let cse_var_90: int32 = (cse_var_94 + 257)
        let cse_var_89: int32 = (cse_var_94 + 256)
        let cse_var_88: int32 = (cse_var_94 + 241)
        let cse_var_87: int32 = (cse_var_94 + 240)
        let cse_var_86: int32 = (cse_var_94 + 225)
        let cse_var_85: int32 = (cse_var_94 + 224)
        let cse_var_84: int32 = (cse_var_94 + 209)
        let cse_var_83: int32 = (cse_var_94 + 208)
        let cse_var_82: int32 = (cse_var_94 + 193)
        let cse_var_81: int32 = (cse_var_94 + 192)
        let cse_var_80: int32 = (cse_var_94 + 177)
        let cse_var_79: int32 = (cse_var_94 + 176)
        let cse_var_78: int32 = (cse_var_94 + 17)
        let cse_var_77: int32 = (cse_var_94 + 160)
        let cse_var_76: int32 = (cse_var_94 + 16)
        let cse_var_75: int32 = (cse_var_94 + 145)
        let cse_var_74: int32 = (cse_var_94 + 144)
        let cse_var_73: int32 = (cse_var_94 + 129)
        let cse_var_72: int32 = (cse_var_94 + 128)
        let cse_var_71: int32 = (cse_var_94 + 113)
        let cse_var_70: int32 = (cse_var_94 + 112)
        let cse_var_69: int32 = (cse_var_94 + 1)
        let cse_var_68: int32 = (cse_var_94 + 288)
        let cse_var_67: int32 = (cse_var_94 + 97)
        let cse_var_66: int32 = (cse_var_94 + 96)
        let cse_var_65: int32 = (cse_var_94 + 81)
        let cse_var_64: int32 = (cse_var_94 + 80)
        let cse_var_63: int32 = (cse_var_94 + 65)
        let cse_var_62: int32 = (cse_var_94 + 64)
        let cse_var_61: int32 = (cse_var_94 + 49)
        let cse_var_60: int32 = (cse_var_94 + 48)
        let cse_var_59: int32 = (cse_var_94 + 417)
        let cse_var_58: int32 = (cse_var_94 + 161)
        let cse_var_57: int32 = (cse_var_94 + 416)
        let cse_var_56: int32 = (cse_var_94 + 401)
        let cse_var_55: int32 = (cse_var_94 + 400)
        let cse_var_54: int32 = (cse_var_94 + 385)
        let cse_var_53: int32 = (cse_var_94 + 304)
        let cse_var_52: int32 = (cse_var_94 + 305)
        let cse_var_51: int32 = (cse_var_94 + 32)
        let cse_var_50: int32 = (cse_var_94 + 320)
        let cse_var_49: int32 = (cse_var_94 + 321)
        let cse_var_48: int32 = (cse_var_94 + 33)
        let cse_var_47: int32 = (cse_var_94 + 336)
        let cse_var_46: int32 = (cse_var_94 + 337)
        let cse_var_45: int32 = (cse_var_94 + 352)
        let cse_var_44: int32 = (cse_var_94 + 353)
        let cse_var_43: int32 = (cse_var_94 + 368)
        let cse_var_42: int32 = (cse_var_94 + 369)
        let cse_var_41: int32 = (cse_var_94 + 384)
        let cse_var_40: int32 = (((floordiv(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused.ax4.outer.fused, 7)*55296) + (cse_var_96*2304)) + (cse_var_95*32))
        let cse_var_39: int32 = (cse_var_40 + 2048)
        let cse_var_38: int32 = (cse_var_40 + 27920)
        let cse_var_37: int32 = (cse_var_40 + 27904)
        let cse_var_36: int32 = (cse_var_40 + 27664)
        let cse_var_35: int32 = (cse_var_40 + 27648)
        let cse_var_34: int32 = (cse_var_40 + 272)
        let cse_var_33: int32 = (cse_var_40 + 256)
        let cse_var_32: int32 = (cse_var_40 + 2064)
        let cse_var_31: int32 = (cse_var_40 + 1808)
        let cse_var_30: int32 = (cse_var_40 + 1792)
        let cse_var_29: int32 = (cse_var_40 + 16)
        let cse_var_28: int32 = (cse_var_40 + 1552)
        let cse_var_27: int32 = (cse_var_40 + 1536)
        let cse_var_26: int32 = (cse_var_40 + 1296)
        let cse_var_25: int32 = (cse_var_40 + 1280)
        let cse_var_24: int32 = (cse_var_40 + 28176)
        let cse_var_23: int32 = (cse_var_40 + 28160)
        let cse_var_22: int32 = (cse_var_40 + 1024)
        let cse_var_21: int32 = (cse_var_40 + 784)
        let cse_var_20: int32 = (cse_var_40 + 768)
        let cse_var_19: int32 = (cse_var_40 + 528)
        let cse_var_18: int32 = (cse_var_40 + 512)
        let cse_var_17: int32 = (cse_var_40 + 29712)
        let cse_var_16: int32 = (cse_var_40 + 29696)
        let cse_var_15: int32 = (cse_var_40 + 29456)
        let cse_var_14: int32 = (cse_var_40 + 1040)
        let cse_var_13: int32 = (cse_var_40 + 29200)
        let cse_var_12: int32 = (cse_var_40 + 29184)
        let cse_var_11: int32 = (cse_var_40 + 28944)
        let cse_var_10: int32 = (cse_var_40 + 28928)
        let cse_var_9: int32 = (cse_var_40 + 28688)
        let cse_var_8: int32 = (cse_var_40 + 28672)
        let cse_var_7: int32 = (cse_var_40 + 28432)
        let cse_var_6: int32 = (cse_var_40 + 28416)
        let cse_var_5: int32 = (cse_var_40 + 29440)
         {
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_94], 16)*placeholder_1[ramp(cse_var_40, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_76], 16)*placeholder_1[ramp(cse_var_40, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_51], 16)*placeholder_1[ramp(cse_var_40, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_60], 16)*placeholder_1[ramp(cse_var_40, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_62], 16)*placeholder_1[ramp(cse_var_40, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_64], 16)*placeholder_1[ramp(cse_var_40, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_66], 16)*placeholder_1[ramp(cse_var_40, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_76], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_51], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_60], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_62], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_64], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_66], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_70], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_51], 16)*placeholder_1[ramp(cse_var_18, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_60], 16)*placeholder_1[ramp(cse_var_18, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_62], 16)*placeholder_1[ramp(cse_var_18, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_64], 16)*placeholder_1[ramp(cse_var_18, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_66], 16)*placeholder_1[ramp(cse_var_18, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_70], 16)*placeholder_1[ramp(cse_var_18, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_72], 16)*placeholder_1[ramp(cse_var_18, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_69], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_78], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_48], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_61], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_63], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_65], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_67], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_78], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_48], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_61], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_63], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_65], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_67], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_71], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_48], 16)*placeholder_1[ramp(cse_var_19, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_61], 16)*placeholder_1[ramp(cse_var_19, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_63], 16)*placeholder_1[ramp(cse_var_19, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_65], 16)*placeholder_1[ramp(cse_var_19, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_67], 16)*placeholder_1[ramp(cse_var_19, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_71], 16)*placeholder_1[ramp(cse_var_19, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_73], 16)*placeholder_1[ramp(cse_var_19, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_94], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_76], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_51], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_60], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_62], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_64], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_66], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_76], 16)*placeholder_1[ramp(cse_var_37, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_51], 16)*placeholder_1[ramp(cse_var_37, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_60], 16)*placeholder_1[ramp(cse_var_37, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_62], 16)*placeholder_1[ramp(cse_var_37, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_64], 16)*placeholder_1[ramp(cse_var_37, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_66], 16)*placeholder_1[ramp(cse_var_37, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_70], 16)*placeholder_1[ramp(cse_var_37, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_51], 16)*placeholder_1[ramp(cse_var_23, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_60], 16)*placeholder_1[ramp(cse_var_23, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_62], 16)*placeholder_1[ramp(cse_var_23, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_64], 16)*placeholder_1[ramp(cse_var_23, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_66], 16)*placeholder_1[ramp(cse_var_23, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_70], 16)*placeholder_1[ramp(cse_var_23, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_72], 16)*placeholder_1[ramp(cse_var_23, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_69], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_78], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_48], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_61], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_63], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_65], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_67], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_78], 16)*placeholder_1[ramp(cse_var_38, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_48], 16)*placeholder_1[ramp(cse_var_38, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_61], 16)*placeholder_1[ramp(cse_var_38, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_63], 16)*placeholder_1[ramp(cse_var_38, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_65], 16)*placeholder_1[ramp(cse_var_38, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_67], 16)*placeholder_1[ramp(cse_var_38, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_71], 16)*placeholder_1[ramp(cse_var_38, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_48], 16)*placeholder_1[ramp(cse_var_24, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_61], 16)*placeholder_1[ramp(cse_var_24, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_63], 16)*placeholder_1[ramp(cse_var_24, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_65], 16)*placeholder_1[ramp(cse_var_24, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_67], 16)*placeholder_1[ramp(cse_var_24, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_71], 16)*placeholder_1[ramp(cse_var_24, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_73], 16)*placeholder_1[ramp(cse_var_24, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_74], 16)*placeholder_1[ramp(cse_var_20, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_77], 16)*placeholder_1[ramp(cse_var_20, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_79], 16)*placeholder_1[ramp(cse_var_20, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_81], 16)*placeholder_1[ramp(cse_var_20, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_83], 16)*placeholder_1[ramp(cse_var_20, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_85], 16)*placeholder_1[ramp(cse_var_20, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_87], 16)*placeholder_1[ramp(cse_var_20, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_77], 16)*placeholder_1[ramp(cse_var_22, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_79], 16)*placeholder_1[ramp(cse_var_22, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_81], 16)*placeholder_1[ramp(cse_var_22, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_83], 16)*placeholder_1[ramp(cse_var_22, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_85], 16)*placeholder_1[ramp(cse_var_22, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_87], 16)*placeholder_1[ramp(cse_var_22, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_89], 16)*placeholder_1[ramp(cse_var_22, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_79], 16)*placeholder_1[ramp(cse_var_25, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_81], 16)*placeholder_1[ramp(cse_var_25, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_83], 16)*placeholder_1[ramp(cse_var_25, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_85], 16)*placeholder_1[ramp(cse_var_25, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_87], 16)*placeholder_1[ramp(cse_var_25, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_89], 16)*placeholder_1[ramp(cse_var_25, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_91], 16)*placeholder_1[ramp(cse_var_25, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_75], 16)*placeholder_1[ramp(cse_var_21, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_58], 16)*placeholder_1[ramp(cse_var_21, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_80], 16)*placeholder_1[ramp(cse_var_21, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_82], 16)*placeholder_1[ramp(cse_var_21, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_84], 16)*placeholder_1[ramp(cse_var_21, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_86], 16)*placeholder_1[ramp(cse_var_21, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_88], 16)*placeholder_1[ramp(cse_var_21, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_58], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_80], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_82], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_84], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_86], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_88], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_90], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_80], 16)*placeholder_1[ramp(cse_var_26, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_82], 16)*placeholder_1[ramp(cse_var_26, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_84], 16)*placeholder_1[ramp(cse_var_26, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_86], 16)*placeholder_1[ramp(cse_var_26, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_88], 16)*placeholder_1[ramp(cse_var_26, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_90], 16)*placeholder_1[ramp(cse_var_26, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_92], 16)*placeholder_1[ramp(cse_var_26, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_74], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_77], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_79], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_81], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_83], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_85], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_87], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_77], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_79], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_81], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_83], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_85], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_87], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_89], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_79], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_81], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_83], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_85], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_87], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_89], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_91], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_75], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_58], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_80], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_82], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_84], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_86], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_88], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_58], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_80], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_82], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_84], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_86], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_88], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_90], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_80], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_82], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_84], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_86], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_88], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_90], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_92], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_68], 16)*placeholder_1[ramp(cse_var_27, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_53], 16)*placeholder_1[ramp(cse_var_27, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_50], 16)*placeholder_1[ramp(cse_var_27, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_47], 16)*placeholder_1[ramp(cse_var_27, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_45], 16)*placeholder_1[ramp(cse_var_27, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_43], 16)*placeholder_1[ramp(cse_var_27, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_41], 16)*placeholder_1[ramp(cse_var_27, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_53], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_50], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_47], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_45], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_43], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_41], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_55], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_50], 16)*placeholder_1[ramp(cse_var_39, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_47], 16)*placeholder_1[ramp(cse_var_39, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_45], 16)*placeholder_1[ramp(cse_var_39, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_43], 16)*placeholder_1[ramp(cse_var_39, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_41], 16)*placeholder_1[ramp(cse_var_39, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_55], 16)*placeholder_1[ramp(cse_var_39, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_57], 16)*placeholder_1[ramp(cse_var_39, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_93], 16)*placeholder_1[ramp(cse_var_28, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_52], 16)*placeholder_1[ramp(cse_var_28, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_49], 16)*placeholder_1[ramp(cse_var_28, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_46], 16)*placeholder_1[ramp(cse_var_28, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_44], 16)*placeholder_1[ramp(cse_var_28, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_42], 16)*placeholder_1[ramp(cse_var_28, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_54], 16)*placeholder_1[ramp(cse_var_28, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_52], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_49], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_46], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_44], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_42], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_54], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_56], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_49], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_46], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_44], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_42], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_54], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_56], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_59], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_68], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_53], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_50], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_47], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_45], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_43], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_41], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_53], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_50], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_47], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_45], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_43], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_41], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_55], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_50], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_47], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_45], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_43], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_41], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_55], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_57], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_93], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_52], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_49], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_46], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_44], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_42], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_54], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_52], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_49], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_46], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_44], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_42], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_54], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_56], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_49], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_46], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_44], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_42], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_54], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_56], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_59], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_97: int32 = floordiv(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused.ax4.outer.fused, 7)
          T_relu[ramp(((((cse_var_97*1568) + (ax1.inner*784)) + cse_var_3) + (ax3.inner*16)), 1, 16)] = max((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(((cse_var_97*32) + (ax1.inner*16)), 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 27: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_4 (weight 2 key: ["6b0d226afab7de584e086dc68f47c79a", [1, 6, 28, 28, 16], [6, 6, 3, 3, 16, 16], [1, 6, 1, 1, 16], [1, 6, 1, 1, 16], [1, 6, 1, 1, 16], [1, 6, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 6, 28, 28, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 29)) && (i3 >= 1)) && (i3 < 29)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [6, 6, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3, data_pad_i4 = tuple(data_pad.op.axis) + tuple(data_pad.op.reduce_axis)
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=3)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=4)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=7)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=2)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=14)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=3)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=3)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=4)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=7)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=2)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=14)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
s[data_pad].compute_at(s[conv2d_NCHWc], conv2d_NCHWc_kw_o)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 64)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[data_pad].vectorize(data_pad_i4)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [75264], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [82944], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [96], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [96], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [96], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [75264], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_5: placeholder_15: Buffer(placeholder_10, float32, [1, 6, 28, 28, 16], []), placeholder_8: placeholder_16: Buffer(placeholder_13, float32, [1, 6, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 6, 28, 28, 16], []), placeholder_6: placeholder_17: Buffer(placeholder_11, float32, [6, 6, 3, 3, 16, 16], []), placeholder_9: placeholder_18: Buffer(placeholder_14, float32, [1, 6, 1, 1, 16], []), placeholder_7: placeholder_19: Buffer(placeholder_12, float32, [1, 6, 1, 1, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 294) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [16]), storage_scope = global;
    allocate(data_pad: Pointer(global float32), float32, [192]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [16], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      conv2d_NCHWc_1[14] = broadcast(0f32, 16)
      conv2d_NCHWc_1[15] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 6) {
        for (kw.outer: int32, 0, 3) {
          let cse_var_8: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 14)
          let cse_var_7: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 98)
          let cse_var_6: int32 = ((cse_var_8*2) + kw.outer)
          let cse_var_5: bool = (cse_var_7 < 84)
          let cse_var_4: bool = (14 <= cse_var_7)
          let cse_var_3: bool = (1 <= cse_var_6)
          let cse_var_2: bool = (cse_var_6 < 28)
          let cse_var_1: int32 = ((((ic.outer*12544) + (floordiv(cse_var_7, 14)*1792)) + (cse_var_8*32)) + (kw.outer*16))
           {
            data_pad_1: Buffer(data_pad, float32, [192], [])[ramp(0, 1, 16)] = @tir.if_then_else((cse_var_4 && cse_var_3), placeholder[ramp((cse_var_1 - 464), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(16, 1, 16)] = @tir.if_then_else((cse_var_4 && cse_var_2), placeholder[ramp((cse_var_1 - 448), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(32, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_1 - 16), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(48, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp(cse_var_1, 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(64, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_1 + 432), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(80, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 448), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(96, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_1 + 880), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(112, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 896), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(128, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_1 + 1328), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(144, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 1344), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(160, 1, 16)] = @tir.if_then_else((cse_var_5 && cse_var_3), placeholder[ramp((cse_var_1 + 1776), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(176, 1, 16)] = @tir.if_then_else((cse_var_5 && cse_var_2), placeholder[ramp((cse_var_1 + 1792), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            for (ic.inner: int32, 0, 16) {
              let cse_var_25: int32 = (ic.inner + 112)
              let cse_var_24: int32 = (ic.inner + 128)
              let cse_var_23: int32 = (ic.inner + 144)
              let cse_var_22: int32 = (ic.inner + 16)
              let cse_var_21: int32 = (ic.inner + 160)
              let cse_var_20: int32 = (ic.inner + 176)
              let cse_var_19: int32 = (ic.inner + 32)
              let cse_var_18: int32 = (ic.inner + 48)
              let cse_var_17: int32 = (ic.inner + 64)
              let cse_var_16: int32 = (ic.inner + 80)
              let cse_var_15: int32 = (ic.inner + 96)
              let cse_var_14: int32 = ((((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 98)*27648) + (ic.outer*2304)) + (kw.outer*256)) + (ic.inner*16))
              let cse_var_13: int32 = (cse_var_14 + 13824)
              let cse_var_12: int32 = (cse_var_14 + 768)
              let cse_var_11: int32 = (cse_var_14 + 15360)
              let cse_var_10: int32 = (cse_var_14 + 1536)
              let cse_var_9: int32 = (cse_var_14 + 14592)
               {
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_25], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[14] = (conv2d_NCHWc_1[14] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[15] = (conv2d_NCHWc_1[15] + (broadcast(data_pad_1[cse_var_25], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_25], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_24], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_25], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[14] = (conv2d_NCHWc_1[14] + (broadcast(data_pad_1[cse_var_24], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[15] = (conv2d_NCHWc_1[15] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_25], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_24], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_25], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_24], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[14] = (conv2d_NCHWc_1[14] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[15] = (conv2d_NCHWc_1[15] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
              }
            }
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax2.inner: int32, 0, 4) {
          for (ax3.inner: int32, 0, 2) {
            let cse_var_27: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 98)
            let cse_var_26: int32 = ((cse_var_27*32) + (ax1.inner*16))
            T_relu[ramp(((((((cse_var_27*25088) + (ax1.inner*12544)) + (floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 98), 14)*1792)) + (ax2.inner*448)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 14)*32)) + (ax3.inner*16)), 1, 16)] = max((((conv2d_NCHWc_1[(((ax1.inner*8) + (ax2.inner*2)) + ax3.inner)] + placeholder_2[ramp(cse_var_26, 1, 16)])*placeholder_3[ramp(cse_var_26, 1, 16)]) + placeholder_4[ramp(cse_var_26, 1, 16)]), broadcast(0f32, 16))
          }
        }
      }
    }
  }
}


==== Task 28: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_2 (weight 1 key: ["9db1fd34470fc877a2c0431d681f01a4", [1, 12, 28, 28, 16], [4, 12, 1, 1, 16, 16], [1, 4, 1, 1, 16], [1, 4, 1, 1, 16], [1, 4, 1, 1, 16], [1, 4, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 12, 28, 28, 16]
placeholder = PLACEHOLDER [4, 12, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=4)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=7)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=1)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=2)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=7)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=4)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=4)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=7)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=2)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=7)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 16)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [150528], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [12288], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [64], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [64], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [64], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [50176], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_5: placeholder_15: Buffer(placeholder_10, float32, [1, 12, 28, 28, 16], []), placeholder_6: placeholder_16: Buffer(placeholder_11, float32, [4, 12, 1, 1, 16, 16], []), placeholder_8: placeholder_17: Buffer(placeholder_13, float32, [1, 4, 1, 1, 16], []), placeholder_9: placeholder_18: Buffer(placeholder_14, float32, [1, 4, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 4, 28, 28, 16], []), placeholder_7: placeholder_19: Buffer(placeholder_12, float32, [1, 4, 1, 1, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 196) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [16]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [16], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[14] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      conv2d_NCHWc_1[15] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 48) {
        for (ow.outer.inner: int32, 0, 2) {
          for (ic.inner: int32, 0, 4) {
            let cse_var_13: int32 = (ow.outer.inner + 8)
            let cse_var_12: int32 = (ow.outer.inner + 6)
            let cse_var_11: int32 = (ow.outer.inner + 4)
            let cse_var_10: int32 = (ow.outer.inner + 2)
            let cse_var_9: int32 = (ow.outer.inner + 14)
            let cse_var_8: int32 = (ow.outer.inner + 12)
            let cse_var_7: int32 = (ow.outer.inner + 10)
            let cse_var_6: int32 = (((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 98)*6144) + (ic.outer*64)) + (ic.inner*16))
            let cse_var_5: int32 = (cse_var_6 + 3072)
            let cse_var_4: int32 = (((((((floordiv(ic.outer, 4)*12544) + (floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 49), 7)*1792)) + (floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 98), 49)*224)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)*32)) + (ow.outer.inner*16)) + (floormod(ic.outer, 4)*4)) + ic.inner)
            let cse_var_3: int32 = (cse_var_4 + 896)
            let cse_var_2: int32 = (cse_var_4 + 448)
            let cse_var_1: int32 = (cse_var_4 + 1344)
             {
              conv2d_NCHWc_1[ow.outer.inner] = (conv2d_NCHWc_1[ow.outer.inner] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
              conv2d_NCHWc_1[cse_var_10] = (conv2d_NCHWc_1[cse_var_10] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
              conv2d_NCHWc_1[cse_var_11] = (conv2d_NCHWc_1[cse_var_11] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
              conv2d_NCHWc_1[cse_var_12] = (conv2d_NCHWc_1[cse_var_12] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
              conv2d_NCHWc_1[cse_var_13] = (conv2d_NCHWc_1[cse_var_13] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
              conv2d_NCHWc_1[cse_var_7] = (conv2d_NCHWc_1[cse_var_7] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
              conv2d_NCHWc_1[cse_var_8] = (conv2d_NCHWc_1[cse_var_8] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
              conv2d_NCHWc_1[cse_var_9] = (conv2d_NCHWc_1[cse_var_9] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
            }
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax2.inner: int32, 0, 4) {
          for (ax3.inner: int32, 0, 2) {
            let cse_var_15: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 98)
            let cse_var_14: int32 = ((cse_var_15*32) + (ax1.inner*16))
            T_relu[ramp((((((((cse_var_15*25088) + (ax1.inner*12544)) + (floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 49), 7)*1792)) + (ax2.inner*448)) + (floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 98), 49)*224)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)*32)) + (ax3.inner*16)), 1, 16)] = max((((conv2d_NCHWc_1[(((ax1.inner*8) + (ax2.inner*2)) + ax3.inner)] + placeholder_2[ramp(cse_var_14, 1, 16)])*placeholder_3[ramp(cse_var_14, 1, 16)]) + placeholder_4[ramp(cse_var_14, 1, 16)]), broadcast(0f32, 16))
          }
        }
      }
    }
  }
}


==== Task 29: vm_mod_fused_nn_avg_pool2d_3 (weight 1 key: ["720f4ce2919e6f5776d2f884eaae37a7", [1, 64, 7, 7, 16], [1, 64, 7, 7, 16]]) =====
placeholder = PLACEHOLDER [1, 64, 7, 7, 16]
pad_temp(ax0, ax1, ax2, ax3, ax4) = tir.if_then_else(((((ax2 >= 1) && (ax2 < 8)) && (ax3 >= 1)) && (ax3 < 8)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)
tensor(ax0, ax1, ax2, ax3, ax4) += pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]
tensor(ax0, ax1, ax2, ax3, ax4) = (tensor[ax0, ax1, ax2, ax3, ax4]/float32(max((((min(((ax2 - 1) + 2), 6) - ((ax2 - 1) + max((0 - (ax2 - 1)), 0))) + 1)*((min(((ax3 - 1) + 2), 6) - ((ax3 - 1) + max((0 - (ax3 - 1)), 0))) + 1)), 1)))


Trace for this task is: 
pad_temp_ax0, pad_temp_ax1, pad_temp_ax2, pad_temp_ax3, pad_temp_ax4 = tuple(pad_temp.op.axis) + tuple(pad_temp.op.reduce_axis)
tensor_ax0, tensor_ax1, tensor_ax2, tensor_ax3, tensor_ax4, tensor_rv0, tensor_rv1 = tuple(tensor.op.axis) + tuple(tensor.op.reduce_axis)
tensor_ax0, tensor_ax1, tensor_ax2, tensor_ax3, tensor_ax4 = tuple(tensor.op.axis) + tuple(tensor.op.reduce_axis)
s[tensor].compute_at(s[tensor], tensor_ax4)
s[pad_temp].compute_at(s[tensor], tensor_ax1)
tensor_ax0_ax1_fused = s[tensor].fuse(tensor_ax0, tensor_ax1)
s[tensor].parallel(tensor_ax0_ax1_fused)
s[tensor].pragma(tensor_ax0, "auto_unroll_max_step", 512)
s[tensor].pragma(tensor_ax0, "unroll_explicit", True)
s[pad_temp].vectorize(pad_temp_ax4)


The best replacement found is:
@main = primfn(placeholder_1: handle, tensor_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_2: Pointer(float32), float32, [50176], []),
             tensor: Buffer(tensor_2: Pointer(float32), float32, [50176], [])}
  buffer_map = {placeholder_1: placeholder, tensor_1: tensor}
  preflattened_buffer_map = {placeholder_1: placeholder_3: Buffer(placeholder_2, float32, [1, 64, 7, 7, 16], []), tensor_1: tensor_3: Buffer(tensor_2, float32, [1, 64, 7, 7, 16], [])} {
  for (ax0.ax1.fused: int32, 0, 64) "parallel" {
    allocate(pad_temp: Pointer(global float32), float32, [1296]), storage_scope = global;
    allocate(tensor_4: Pointer(global float32), float32, [1]), storage_scope = global {
      for (ax2: int32, 0, 9) {
        for (ax3: int32, 0, 9) {
          let cse_var_1: int32 = (ax3*16)
          pad_temp_1: Buffer(pad_temp, float32, [1296], [])[ramp(((ax2*144) + cse_var_1), 1, 16)] = @tir.if_then_else(((((1 <= ax2) && (ax2 < 8)) && (1 <= ax3)) && (ax3 < 8)), placeholder[ramp(((((ax0.ax1.fused*784) + (ax2*112)) + cse_var_1) - 128), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
        }
      }
      for (ax2_1: int32, 0, 7) {
        for (ax3_1: int32, 0, 7) {
          for (ax4: int32, 0, 16) {
            let cse_var_3: int32 = (ax3_1*16)
            let cse_var_2: int32 = (((ax2_1*144) + cse_var_3) + ax4)
             {
              tensor_5: Buffer(tensor_4, float32, [1], [], align=4)[0] = 0f32
              tensor_5[0] = (tensor_5[0] + pad_temp_1[cse_var_2])
              tensor_5[0] = (tensor_5[0] + pad_temp_1[(cse_var_2 + 16)])
              tensor_5[0] = (tensor_5[0] + pad_temp_1[(cse_var_2 + 32)])
              tensor_5[0] = (tensor_5[0] + pad_temp_1[(cse_var_2 + 144)])
              tensor_5[0] = (tensor_5[0] + pad_temp_1[(cse_var_2 + 160)])
              tensor_5[0] = (tensor_5[0] + pad_temp_1[(cse_var_2 + 176)])
              tensor_5[0] = (tensor_5[0] + pad_temp_1[(cse_var_2 + 288)])
              tensor_5[0] = (tensor_5[0] + pad_temp_1[(cse_var_2 + 304)])
              tensor_5[0] = (tensor_5[0] + pad_temp_1[(cse_var_2 + 320)])
              tensor[((((ax0.ax1.fused*784) + (ax2_1*112)) + cse_var_3) + ax4)] = (tensor_5[0] / cast(float32, max(((((min((ax2_1 + 1), 6) + 2) - max((1 - ax2_1), 0)) - ax2_1)*(((min((ax3_1 + 1), 6) + 2) - max((1 - ax3_1), 0)) - ax3_1)), 1)))
            }
          }
        }
      }
    }
  }
}


==== Task 30: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_9 (weight 4 key: ["f6615ae9259e3b2add2908c0cd980cb6", [1, 36, 14, 14, 16], [8, 36, 1, 1, 16, 16], [1, 8, 1, 1, 16], [1, 8, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 36, 14, 14, 16]
placeholder = PLACEHOLDER [8, 36, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=1)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=2)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=4)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=7)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=2)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=4)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=4)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=7)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=2)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 64)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_6: Pointer(float32), float32, [112896], []),
             placeholder_1: Buffer(placeholder_7: Pointer(float32), float32, [73728], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [128], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [25088], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_3: placeholder_9: Buffer(placeholder_6, float32, [1, 36, 14, 14, 16], []), placeholder_4: placeholder_10: Buffer(placeholder_7, float32, [8, 36, 1, 1, 16, 16], []), placeholder_5: placeholder_11: Buffer(placeholder_8, float32, [1, 8, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 8, 14, 14, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 112) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 144) {
        let cse_var_36: int32 = ((floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 56), 14)*18432) + (ic.outer*64))
        let cse_var_35: int32 = (cse_var_36 + 9264)
        let cse_var_34: int32 = (cse_var_36 + 9248)
        let cse_var_33: int32 = (cse_var_36 + 9232)
        let cse_var_32: int32 = (cse_var_36 + 9216)
        let cse_var_31: int32 = (cse_var_36 + 48)
        let cse_var_30: int32 = (cse_var_36 + 32)
        let cse_var_29: int32 = (cse_var_36 + 16)
        let cse_var_28: int32 = ((((floordiv(ic.outer, 4)*3136) + (floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 56)*1568)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 14)*112)) + (floormod(ic.outer, 4)*4))
        let cse_var_27: int32 = (cse_var_28 + 50)
        let cse_var_26: int32 = (cse_var_28 + 48)
        let cse_var_25: int32 = (cse_var_28 + 35)
        let cse_var_24: int32 = (cse_var_28 + 34)
        let cse_var_23: int32 = (cse_var_28 + 33)
        let cse_var_22: int32 = (cse_var_28 + 32)
        let cse_var_21: int32 = (cse_var_28 + 3)
        let cse_var_20: int32 = (cse_var_28 + 2)
        let cse_var_19: int32 = (cse_var_28 + 19)
        let cse_var_18: int32 = (cse_var_28 + 18)
        let cse_var_17: int32 = (cse_var_28 + 17)
        let cse_var_16: int32 = (cse_var_28 + 1)
        let cse_var_15: int32 = (cse_var_28 + 49)
        let cse_var_14: int32 = (cse_var_28 + 51)
        let cse_var_13: int32 = (cse_var_28 + 64)
        let cse_var_12: int32 = (cse_var_28 + 65)
        let cse_var_11: int32 = (cse_var_28 + 66)
        let cse_var_10: int32 = (cse_var_28 + 67)
        let cse_var_9: int32 = (cse_var_28 + 80)
        let cse_var_8: int32 = (cse_var_28 + 81)
        let cse_var_7: int32 = (cse_var_28 + 82)
        let cse_var_6: int32 = (cse_var_28 + 83)
        let cse_var_5: int32 = (cse_var_28 + 96)
        let cse_var_4: int32 = (cse_var_28 + 97)
        let cse_var_3: int32 = (cse_var_28 + 98)
        let cse_var_2: int32 = (cse_var_28 + 99)
        let cse_var_1: int32 = (cse_var_28 + 16)
         {
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_28], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_22], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_26], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_13], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_9], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_16], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_17], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_23], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_15], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_12], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_20], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_18], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_24], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_27], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_11], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_21], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_19], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_25], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_14], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_10], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_28], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_22], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_26], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_13], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_9], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_16], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_17], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_23], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_15], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_12], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_20], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_18], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_24], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_27], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_11], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_21], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_19], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_25], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_14], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_10], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_37: int32 = floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 56), 14)
          T_relu[ramp((((((cse_var_37*6272) + (ax1.inner*3136)) + (floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 56)*1568)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 14)*112)) + (ax3.inner*16)), 1, 16)] = max((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(((cse_var_37*32) + (ax1.inner*16)), 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 31: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_12 (weight 1 key: ["ce1b4a245fb9b3a0526fcd7e77d29d3f", [1, 10, 14, 14, 16], [12, 10, 3, 3, 16, 16], [1, 12, 1, 1, 16], [1, 12, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 10, 14, 14, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 15)) && (i3 >= 1)) && (i3 < 15)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [12, 10, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3, data_pad_i4 = tuple(data_pad.op.axis) + tuple(data_pad.op.reduce_axis)
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=14)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=2)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=3)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=14)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=2)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
s[data_pad].compute_at(s[conv2d_NCHWc], conv2d_NCHWc_kh_o)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 512)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[data_pad].vectorize(data_pad_i4)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_6: Pointer(float32), float32, [31360], []),
             placeholder_1: Buffer(placeholder_7: Pointer(float32), float32, [276480], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [192], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [37632], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_3: placeholder_9: Buffer(placeholder_6, float32, [1, 10, 14, 14, 16], []), placeholder_4: placeholder_10: Buffer(placeholder_7, float32, [12, 10, 3, 3, 16, 16], []), placeholder_5: placeholder_11: Buffer(placeholder_8, float32, [1, 12, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 12, 14, 14, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused: int32, 0, 168) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global;
    allocate(data_pad: Pointer(global float32), float32, [144]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 10) {
        for (kh.outer: int32, 0, 3) {
          let cse_var_5: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 28)
          let cse_var_4: int32 = (floordiv(cse_var_5, 2) + kh.outer)
          let cse_var_3: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 2)
          let cse_var_2: int32 = (((ic.outer*3136) + (kh.outer*224)) + (cse_var_5*112))
          let cse_var_1: bool = ((1 <= cse_var_4) && (cse_var_4 < 15))
           {
            data_pad_1: Buffer(data_pad, float32, [144], [])[ramp(0, 1, 16)] = @tir.if_then_else((cse_var_1 && (1 <= cse_var_3)), placeholder[ramp((cse_var_2 - 240), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(16, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 224), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(32, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 208), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(48, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 192), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(64, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 176), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(80, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 160), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(96, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 144), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(112, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 128), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(128, 1, 16)] = @tir.if_then_else((cse_var_1 && (cse_var_3 < 1)), placeholder[ramp((cse_var_2 - 112), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            for (ic.inner: int32, 0, 16) {
              let cse_var_19: int32 = (ic.inner + 96)
              let cse_var_18: int32 = (ic.inner + 80)
              let cse_var_17: int32 = (ic.inner + 64)
              let cse_var_16: int32 = (ic.inner + 48)
              let cse_var_15: int32 = (ic.inner + 32)
              let cse_var_14: int32 = (ic.inner + 16)
              let cse_var_13: int32 = (ic.inner + 128)
              let cse_var_12: int32 = (ic.inner + 112)
              let cse_var_11: int32 = ((((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 28)*46080) + (ic.outer*2304)) + (kh.outer*768)) + (ic.inner*16))
              let cse_var_10: int32 = (cse_var_11 + 512)
              let cse_var_9: int32 = (cse_var_11 + 256)
              let cse_var_8: int32 = (cse_var_11 + 23552)
              let cse_var_7: int32 = (cse_var_11 + 23296)
              let cse_var_6: int32 = (cse_var_11 + 23040)
               {
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
              }
            }
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_20: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 28)
          T_relu[ramp(((((cse_var_20*6272) + (ax1.inner*3136)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 28)*112)) + (ax3.inner*16)), 1, 16)] = max((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(((cse_var_20*32) + (ax1.inner*16)), 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 32: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_21 (weight 1 key: ["6b0d226afab7de584e086dc68f47c79a", [1, 12, 14, 14, 16], [12, 12, 3, 3, 16, 16], [1, 12, 1, 1, 16], [1, 12, 1, 1, 16], [1, 12, 1, 1, 16], [1, 12, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 12, 14, 14, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 15)) && (i3 >= 1)) && (i3 < 15)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [12, 12, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3, data_pad_i4 = tuple(data_pad.op.axis) + tuple(data_pad.op.reduce_axis)
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=1)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=7)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=2)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=1)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=3)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=1)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=7)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=1)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=2)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=1)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
s[data_pad].compute_at(s[conv2d_NCHWc], conv2d_NCHWc_ic_o)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 64)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[data_pad].vectorize(data_pad_i4)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [37632], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [331776], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [192], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [192], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [192], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [37632], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_7: placeholder_15: Buffer(placeholder_12, float32, [1, 12, 1, 1, 16], []), placeholder_8: placeholder_16: Buffer(placeholder_13, float32, [1, 12, 1, 1, 16], []), placeholder_9: placeholder_17: Buffer(placeholder_14, float32, [1, 12, 1, 1, 16], []), placeholder_6: placeholder_18: Buffer(placeholder_11, float32, [12, 12, 3, 3, 16, 16], []), placeholder_5: placeholder_19: Buffer(placeholder_10, float32, [1, 12, 14, 14, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 12, 14, 14, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 168) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global;
    allocate(data_pad: Pointer(global float32), float32, [576]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 12) {
        let cse_var_7: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 14)
        let cse_var_6: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)
        let cse_var_5: bool = (cse_var_6 < 6)
        let cse_var_4: bool = (cse_var_7 < 7)
        let cse_var_3: bool = (7 <= cse_var_7)
        let cse_var_2: bool = (1 <= cse_var_6)
        let cse_var_1: int32 = (((ic.outer*3136) + (floordiv(cse_var_7, 7)*1568)) + (cse_var_6*32))
         {
          data_pad_1: Buffer(data_pad, float32, [576], [])[ramp(0, 1, 16)] = @tir.if_then_else((cse_var_3 && cse_var_2), placeholder[ramp((cse_var_1 - 240), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(16, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_1 - 224), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(32, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_1 - 208), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(48, 1, 16)] = @tir.if_then_else((cse_var_3 && cse_var_5), placeholder[ramp((cse_var_1 - 192), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(64, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 16), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(80, 1, 16)] = placeholder[ramp(cse_var_1, 1, 16)]
          data_pad_1[ramp(96, 1, 16)] = placeholder[ramp((cse_var_1 + 16), 1, 16)]
          data_pad_1[ramp(112, 1, 16)] = @tir.if_then_else(cse_var_5, placeholder[ramp((cse_var_1 + 32), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(128, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 208), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(144, 1, 16)] = placeholder[ramp((cse_var_1 + 224), 1, 16)]
          data_pad_1[ramp(160, 1, 16)] = placeholder[ramp((cse_var_1 + 240), 1, 16)]
          data_pad_1[ramp(176, 1, 16)] = @tir.if_then_else(cse_var_5, placeholder[ramp((cse_var_1 + 256), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(192, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 432), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(208, 1, 16)] = placeholder[ramp((cse_var_1 + 448), 1, 16)]
          data_pad_1[ramp(224, 1, 16)] = placeholder[ramp((cse_var_1 + 464), 1, 16)]
          data_pad_1[ramp(240, 1, 16)] = @tir.if_then_else(cse_var_5, placeholder[ramp((cse_var_1 + 480), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(256, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 656), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(272, 1, 16)] = placeholder[ramp((cse_var_1 + 672), 1, 16)]
          data_pad_1[ramp(288, 1, 16)] = placeholder[ramp((cse_var_1 + 688), 1, 16)]
          data_pad_1[ramp(304, 1, 16)] = @tir.if_then_else(cse_var_5, placeholder[ramp((cse_var_1 + 704), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(320, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 880), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(336, 1, 16)] = placeholder[ramp((cse_var_1 + 896), 1, 16)]
          data_pad_1[ramp(352, 1, 16)] = placeholder[ramp((cse_var_1 + 912), 1, 16)]
          data_pad_1[ramp(368, 1, 16)] = @tir.if_then_else(cse_var_5, placeholder[ramp((cse_var_1 + 928), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(384, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 1104), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(400, 1, 16)] = placeholder[ramp((cse_var_1 + 1120), 1, 16)]
          data_pad_1[ramp(416, 1, 16)] = placeholder[ramp((cse_var_1 + 1136), 1, 16)]
          data_pad_1[ramp(432, 1, 16)] = @tir.if_then_else(cse_var_5, placeholder[ramp((cse_var_1 + 1152), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(448, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 1328), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(464, 1, 16)] = placeholder[ramp((cse_var_1 + 1344), 1, 16)]
          data_pad_1[ramp(480, 1, 16)] = placeholder[ramp((cse_var_1 + 1360), 1, 16)]
          data_pad_1[ramp(496, 1, 16)] = @tir.if_then_else(cse_var_5, placeholder[ramp((cse_var_1 + 1376), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(512, 1, 16)] = @tir.if_then_else((cse_var_4 && cse_var_2), placeholder[ramp((cse_var_1 + 1552), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(528, 1, 16)] = @tir.if_then_else(cse_var_4, placeholder[ramp((cse_var_1 + 1568), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(544, 1, 16)] = @tir.if_then_else(cse_var_4, placeholder[ramp((cse_var_1 + 1584), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(560, 1, 16)] = @tir.if_then_else((cse_var_4 && cse_var_5), placeholder[ramp((cse_var_1 + 1600), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          for (kw.outer: int32, 0, 3) {
            for (ic.inner: int32, 0, 16) {
              let cse_var_25: int32 = ((kw.outer*16) + ic.inner)
              let cse_var_24: int32 = (cse_var_25 + 128)
              let cse_var_23: int32 = (cse_var_25 + 144)
              let cse_var_22: int32 = (cse_var_25 + 192)
              let cse_var_21: int32 = (cse_var_25 + 208)
              let cse_var_20: int32 = (cse_var_25 + 256)
              let cse_var_19: int32 = (cse_var_25 + 272)
              let cse_var_18: int32 = (cse_var_25 + 336)
              let cse_var_17: int32 = (cse_var_25 + 384)
              let cse_var_16: int32 = (cse_var_25 + 400)
              let cse_var_15: int32 = (cse_var_25 + 448)
              let cse_var_14: int32 = (cse_var_25 + 464)
              let cse_var_13: int32 = (cse_var_25 + 64)
              let cse_var_12: int32 = (cse_var_25 + 80)
              let cse_var_11: int32 = (cse_var_25 + 320)
              let cse_var_10: int32 = ((((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 14)*27648) + (ic.outer*2304)) + (kw.outer*256)) + (ic.inner*16))
              let cse_var_9: int32 = (cse_var_10 + 1536)
              let cse_var_8: int32 = (cse_var_10 + 768)
               {
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_25], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[(cse_var_25 + 16)], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_24], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_11], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_24], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_11], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_24], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_11], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[(cse_var_25 + 512)], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[(cse_var_25 + 528)], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
              }
            }
          }
        }
      }
      for (ax2.inner: int32, 0, 7) {
        for (ax3.inner: int32, 0, 2) {
          let cse_var_26: int32 = (floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 14)*16)
          T_relu[ramp(((((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)*1568) + (ax2.inner*224)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)*32)) + (ax3.inner*16)), 1, 16)] = max((((conv2d_NCHWc_1[((ax2.inner*2) + ax3.inner)] + placeholder_2[ramp(cse_var_26, 1, 16)])*placeholder_3[ramp(cse_var_26, 1, 16)]) + placeholder_4[ramp(cse_var_26, 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 33: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_15 (weight 1 key: ["6b0d226afab7de584e086dc68f47c79a", [1, 6, 14, 14, 16], [8, 6, 3, 3, 16, 16], [1, 8, 1, 1, 16], [1, 8, 1, 1, 16], [1, 8, 1, 1, 16], [1, 8, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 6, 14, 14, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 15)) && (i3 >= 1)) && (i3 < 15)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [8, 6, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3, data_pad_i4 = tuple(data_pad.op.axis) + tuple(data_pad.op.reduce_axis)
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=7)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=1)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=2)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=3)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=7)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=1)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=1)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=2)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
s[data_pad].compute_at(s[conv2d_NCHWc], conv2d_NCHWc_kw_o)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 64)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[data_pad].vectorize(data_pad_i4)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [18816], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [110592], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [128], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [128], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [128], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [25088], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_8: placeholder_15: Buffer(placeholder_13, float32, [1, 8, 1, 1, 16], []), placeholder_6: placeholder_16: Buffer(placeholder_11, float32, [8, 6, 3, 3, 16, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 8, 14, 14, 16], []), placeholder_7: placeholder_17: Buffer(placeholder_12, float32, [1, 8, 1, 1, 16], []), placeholder_9: placeholder_18: Buffer(placeholder_14, float32, [1, 8, 1, 1, 16], []), placeholder_5: placeholder_19: Buffer(placeholder_10, float32, [1, 6, 14, 14, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 112) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global;
    allocate(data_pad: Pointer(global float32), float32, [144]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 6) {
        for (kw.outer: int32, 0, 3) {
          let cse_var_7: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 14)
          let cse_var_6: int32 = (kw.outer + cse_var_7)
          let cse_var_5: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)
          let cse_var_4: bool = (1 <= cse_var_6)
          let cse_var_3: bool = (cse_var_6 < 15)
          let cse_var_2: bool = (cse_var_4 && cse_var_3)
          let cse_var_1: int32 = ((((ic.outer*3136) + (floordiv(cse_var_5, 14)*1568)) + (kw.outer*16)) + (cse_var_7*16))
           {
            data_pad_1: Buffer(data_pad, float32, [144], [])[ramp(0, 1, 16)] = @tir.if_then_else((((14 <= cse_var_5) && cse_var_4) && cse_var_3), placeholder[ramp((cse_var_1 - 240), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(16, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 16), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(32, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 208), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(48, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 432), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(64, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 656), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(80, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 880), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(96, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 1104), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(112, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 1328), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(128, 1, 16)] = @tir.if_then_else((((cse_var_5 < 14) && cse_var_4) && cse_var_3), placeholder[ramp((cse_var_1 + 1552), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            for (ic.inner: int32, 0, 16) {
              let cse_var_21: int32 = (ic.inner + 96)
              let cse_var_20: int32 = (ic.inner + 80)
              let cse_var_19: int32 = (ic.inner + 64)
              let cse_var_18: int32 = (ic.inner + 48)
              let cse_var_17: int32 = (ic.inner + 32)
              let cse_var_16: int32 = (ic.inner + 16)
              let cse_var_15: int32 = (ic.inner + 128)
              let cse_var_14: int32 = (ic.inner + 112)
              let cse_var_13: int32 = ((((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)*27648) + (ic.outer*2304)) + (kw.outer*256)) + (ic.inner*16))
              let cse_var_12: int32 = (cse_var_13 + 768)
              let cse_var_11: int32 = (cse_var_13 + 15360)
              let cse_var_10: int32 = (cse_var_13 + 1536)
              let cse_var_9: int32 = (cse_var_13 + 14592)
              let cse_var_8: int32 = (cse_var_13 + 13824)
               {
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
              }
            }
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax2.inner: int32, 0, 7) {
          let cse_var_23: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)
          let cse_var_22: int32 = ((cse_var_23*32) + (ax1.inner*16))
          T_relu[ramp((((((cse_var_23*6272) + (ax1.inner*3136)) + (floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28), 14)*1568)) + (ax2.inner*224)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 14)*16)), 1, 16)] = max((((conv2d_NCHWc_1[((ax1.inner*7) + ax2.inner)] + placeholder_2[ramp(cse_var_22, 1, 16)])*placeholder_3[ramp(cse_var_22, 1, 16)]) + placeholder_4[ramp(cse_var_22, 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 34: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_5 (weight 1 key: ["9db1fd34470fc877a2c0431d681f01a4", [1, 12, 28, 28, 16], [2, 12, 1, 1, 16, 16], [1, 2, 1, 1, 16], [1, 2, 1, 1, 16], [1, 2, 1, 1, 16], [1, 2, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 12, 28, 28, 16]
placeholder = PLACEHOLDER [2, 12, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 2, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 2, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 2, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=4)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=7)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=1)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=28)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=2)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=4)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=7)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=1)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=28)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 512)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [150528], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [6144], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [32], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [32], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [32], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [25088], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_7: placeholder_15: Buffer(placeholder_12, float32, [1, 2, 1, 1, 16], []), placeholder_9: placeholder_16: Buffer(placeholder_14, float32, [1, 2, 1, 1, 16], []), placeholder_8: placeholder_17: Buffer(placeholder_13, float32, [1, 2, 1, 1, 16], []), placeholder_5: placeholder_18: Buffer(placeholder_10, float32, [1, 12, 28, 28, 16], []), placeholder_6: placeholder_19: Buffer(placeholder_11, float32, [2, 12, 1, 1, 16, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 2, 28, 28, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 196) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [8]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [8], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 96) {
        let cse_var_12: int32 = (ic.outer*32)
        let cse_var_11: int32 = (cse_var_12 + 3088)
        let cse_var_10: int32 = (cse_var_12 + 3072)
        let cse_var_9: int32 = (cse_var_12 + 16)
        let cse_var_8: int32 = ((((floordiv(ic.outer, 8)*12544) + (floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)*1792)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)*16)) + (floormod(ic.outer, 8)*2))
        let cse_var_7: int32 = (cse_var_8 + 897)
        let cse_var_6: int32 = (cse_var_8 + 896)
        let cse_var_5: int32 = (cse_var_8 + 449)
        let cse_var_4: int32 = (cse_var_8 + 448)
        let cse_var_3: int32 = (cse_var_8 + 1345)
        let cse_var_2: int32 = (cse_var_8 + 1344)
        let cse_var_1: int32 = (cse_var_8 + 1)
         {
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax2.inner: int32, 0, 4) {
          let cse_var_13: int32 = (ax1.inner*16)
          T_relu[ramp(((((ax1.inner*12544) + (floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)*1792)) + (ax2.inner*448)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)*16)), 1, 16)] = max((((conv2d_NCHWc_1[((ax1.inner*4) + ax2.inner)] + placeholder_2[ramp(cse_var_13, 1, 16)])*placeholder_3[ramp(cse_var_13, 1, 16)]) + placeholder_4[ramp(cse_var_13, 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 35: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 (weight 3 key: ["f6615ae9259e3b2add2908c0cd980cb6", [1, 36, 14, 14, 16], [6, 36, 1, 1, 16, 16], [1, 6, 1, 1, 16], [1, 6, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 36, 14, 14, 16]
placeholder = PLACEHOLDER [6, 36, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=1)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=2)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=1)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=4)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=1)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=1)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 512)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_6: Pointer(float32), float32, [112896], []),
             placeholder_1: Buffer(placeholder_7: Pointer(float32), float32, [55296], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [96], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [18816], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_3: placeholder_9: Buffer(placeholder_6, float32, [1, 36, 14, 14, 16], []), placeholder_4: placeholder_10: Buffer(placeholder_7, float32, [6, 36, 1, 1, 16, 16], []), placeholder_5: placeholder_11: Buffer(placeholder_8, float32, [1, 6, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 6, 14, 14, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused: int32, 0, 84) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 144) {
        let cse_var_36: int32 = ((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 28)*18432) + (ic.outer*64))
        let cse_var_35: int32 = (cse_var_36 + 9264)
        let cse_var_34: int32 = (cse_var_36 + 9248)
        let cse_var_33: int32 = (cse_var_36 + 9232)
        let cse_var_32: int32 = (cse_var_36 + 9216)
        let cse_var_31: int32 = (cse_var_36 + 48)
        let cse_var_30: int32 = (cse_var_36 + 32)
        let cse_var_29: int32 = (cse_var_36 + 16)
        let cse_var_28: int32 = (((floordiv(ic.outer, 4)*3136) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 28)*112)) + (floormod(ic.outer, 4)*4))
        let cse_var_27: int32 = (cse_var_28 + 50)
        let cse_var_26: int32 = (cse_var_28 + 48)
        let cse_var_25: int32 = (cse_var_28 + 35)
        let cse_var_24: int32 = (cse_var_28 + 34)
        let cse_var_23: int32 = (cse_var_28 + 33)
        let cse_var_22: int32 = (cse_var_28 + 32)
        let cse_var_21: int32 = (cse_var_28 + 3)
        let cse_var_20: int32 = (cse_var_28 + 2)
        let cse_var_19: int32 = (cse_var_28 + 19)
        let cse_var_18: int32 = (cse_var_28 + 18)
        let cse_var_17: int32 = (cse_var_28 + 17)
        let cse_var_16: int32 = (cse_var_28 + 1)
        let cse_var_15: int32 = (cse_var_28 + 49)
        let cse_var_14: int32 = (cse_var_28 + 51)
        let cse_var_13: int32 = (cse_var_28 + 64)
        let cse_var_12: int32 = (cse_var_28 + 65)
        let cse_var_11: int32 = (cse_var_28 + 66)
        let cse_var_10: int32 = (cse_var_28 + 67)
        let cse_var_9: int32 = (cse_var_28 + 80)
        let cse_var_8: int32 = (cse_var_28 + 81)
        let cse_var_7: int32 = (cse_var_28 + 82)
        let cse_var_6: int32 = (cse_var_28 + 83)
        let cse_var_5: int32 = (cse_var_28 + 96)
        let cse_var_4: int32 = (cse_var_28 + 97)
        let cse_var_3: int32 = (cse_var_28 + 98)
        let cse_var_2: int32 = (cse_var_28 + 99)
        let cse_var_1: int32 = (cse_var_28 + 16)
         {
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_28], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_22], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_26], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_13], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_9], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_16], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_17], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_23], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_15], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_12], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_20], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_18], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_24], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_27], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_11], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_21], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_19], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_25], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_14], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_10], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_28], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_22], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_26], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_13], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_9], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_16], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_17], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_23], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_15], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_12], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_20], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_18], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_24], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_27], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_11], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_21], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_19], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_25], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_14], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_10], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_37: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 28)
          T_relu[ramp(((((cse_var_37*6272) + (ax1.inner*3136)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 28)*112)) + (ax3.inner*16)), 1, 16)] = max((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(((cse_var_37*32) + (ax1.inner*16)), 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 36: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_7 (weight 1 key: ["6b0d226afab7de584e086dc68f47c79a", [1, 4, 28, 28, 16], [6, 4, 3, 3, 16, 16], [1, 6, 1, 1, 16], [1, 6, 1, 1, 16], [1, 6, 1, 1, 16], [1, 6, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 4, 28, 28, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 29)) && (i3 >= 1)) && (i3 < 29)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [6, 4, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3, data_pad_i4 = tuple(data_pad.op.axis) + tuple(data_pad.op.reduce_axis)
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=1)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=3)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=1)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=1)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
s[data_pad].compute_at(s[conv2d_NCHWc], conv2d_NCHWc_kh_o)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 512)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[data_pad].vectorize(data_pad_i4)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [50176], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [55296], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [96], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [96], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [96], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [75264], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_5: placeholder_15: Buffer(placeholder_10, float32, [1, 4, 28, 28, 16], []), placeholder_8: placeholder_16: Buffer(placeholder_13, float32, [1, 6, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 6, 28, 28, 16], []), placeholder_6: placeholder_17: Buffer(placeholder_11, float32, [6, 4, 3, 3, 16, 16], []), placeholder_7: placeholder_18: Buffer(placeholder_12, float32, [1, 6, 1, 1, 16], []), placeholder_9: placeholder_19: Buffer(placeholder_14, float32, [1, 6, 1, 1, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused: int32, 0, 336) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global;
    allocate(data_pad: Pointer(global float32), float32, [144]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 4) {
        for (kh.outer: int32, 0, 3) {
          let cse_var_5: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 112)
          let cse_var_4: int32 = (floordiv(cse_var_5, 4) + kh.outer)
          let cse_var_3: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 4)
          let cse_var_2: int32 = (((ic.outer*12544) + (kh.outer*448)) + (cse_var_5*112))
          let cse_var_1: bool = ((1 <= cse_var_4) && (cse_var_4 < 29))
           {
            data_pad_1: Buffer(data_pad, float32, [144], [])[ramp(0, 1, 16)] = @tir.if_then_else((cse_var_1 && (1 <= cse_var_3)), placeholder[ramp((cse_var_2 - 464), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(16, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 448), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(32, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 432), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(48, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 416), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(64, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 400), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(80, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 384), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(96, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 368), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(112, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 352), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(128, 1, 16)] = @tir.if_then_else((cse_var_1 && (cse_var_3 < 3)), placeholder[ramp((cse_var_2 - 336), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            for (ic.inner: int32, 0, 16) {
              let cse_var_19: int32 = (ic.inner + 96)
              let cse_var_18: int32 = (ic.inner + 80)
              let cse_var_17: int32 = (ic.inner + 64)
              let cse_var_16: int32 = (ic.inner + 48)
              let cse_var_15: int32 = (ic.inner + 32)
              let cse_var_14: int32 = (ic.inner + 16)
              let cse_var_13: int32 = (ic.inner + 128)
              let cse_var_12: int32 = (ic.inner + 112)
              let cse_var_11: int32 = ((((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 112)*18432) + (ic.outer*2304)) + (kh.outer*768)) + (ic.inner*16))
              let cse_var_10: int32 = (cse_var_11 + 9728)
              let cse_var_9: int32 = (cse_var_11 + 9472)
              let cse_var_8: int32 = (cse_var_11 + 9216)
              let cse_var_7: int32 = (cse_var_11 + 512)
              let cse_var_6: int32 = (cse_var_11 + 256)
               {
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
              }
            }
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_21: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 112)
          let cse_var_20: int32 = ((cse_var_21*32) + (ax1.inner*16))
          T_relu[ramp(((((cse_var_21*25088) + (ax1.inner*12544)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 112)*112)) + (ax3.inner*16)), 1, 16)] = max((((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(cse_var_20, 1, 16)])*placeholder_3[ramp(cse_var_20, 1, 16)]) + placeholder_4[ramp(cse_var_20, 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 37: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_1 (weight 1 key: ["6b0d226afab7de584e086dc68f47c79a", [1, 4, 56, 56, 16], [12, 4, 3, 3, 16, 16], [1, 12, 1, 1, 16], [1, 12, 1, 1, 16], [1, 12, 1, 1, 16], [1, 12, 56, 56, 16]]) =====
placeholder = PLACEHOLDER [1, 4, 56, 56, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 57)) && (i3 >= 1)) && (i3 < 57)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [12, 4, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3, data_pad_i4 = tuple(data_pad.op.axis) + tuple(data_pad.op.reduce_axis)
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=3)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=4)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=3)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax1_o, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=3)
T_relu_ax2_o, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax3_o, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=28)
T_relu_ax4_o, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
s[T_relu].reorder(T_relu_ax0_o, T_relu_ax1_o, T_relu_ax2_o, T_relu_ax3_o, T_relu_ax4_o, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o)
s[data_pad].compute_at(s[conv2d_NCHWc], conv2d_NCHWc_ic_o)
T_relu_ax0_o_ax1_o_fused_ax2_o_fused_ax3_o_fused_ax4_o_fused = s[T_relu].fuse(T_relu_ax0_o, T_relu_ax1_o, T_relu_ax2_o, T_relu_ax3_o, T_relu_ax4_o)
s[T_relu].parallel(T_relu_ax0_o_ax1_o_fused_ax2_o_fused_ax3_o_fused_ax4_o_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 512)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[data_pad].vectorize(data_pad_i4)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [200704], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [110592], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [192], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [192], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [192], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [602112], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 12, 56, 56, 16], []), placeholder_9: placeholder_15: Buffer(placeholder_14, float32, [1, 12, 1, 1, 16], []), placeholder_8: placeholder_16: Buffer(placeholder_13, float32, [1, 12, 1, 1, 16], []), placeholder_5: placeholder_17: Buffer(placeholder_10, float32, [1, 4, 56, 56, 16], []), placeholder_7: placeholder_18: Buffer(placeholder_12, float32, [1, 12, 1, 1, 16], []), placeholder_6: placeholder_19: Buffer(placeholder_11, float32, [12, 4, 3, 3, 16, 16], [])} {
  for (ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused.ax4.outer.fused: int32, 0, 448) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [84]), storage_scope = global;
    allocate(data_pad: Pointer(global float32), float32, [432]), storage_scope = global {
      for (ow.outer.outer.inner: int32, 0, 4) {
        let cse_var_1: int32 = (ow.outer.outer.inner*7)
         {
          conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [84], [])[cse_var_1] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 1)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 2)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 3)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 4)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 5)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 6)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 28)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 29)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 30)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 31)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 32)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 33)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 34)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 56)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 57)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 58)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 59)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 60)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 61)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 62)] = broadcast(0f32, 16)
          for (ic.outer: int32, 0, 4) {
            let cse_var_8: int32 = floormod(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused.ax4.outer.fused, 112)
            let cse_var_7: int32 = ((floormod(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused.ax4.outer.fused, 2)*28) + cse_var_1)
            let cse_var_6: bool = (cse_var_8 < 110)
            let cse_var_5: bool = (2 <= cse_var_8)
            let cse_var_4: bool = (1 <= cse_var_7)
            let cse_var_3: bool = (cse_var_7 < 49)
            let cse_var_2: int32 = (((ic.outer*50176) + (cse_var_8*448)) + (ow.outer.outer.inner*112))
             {
              data_pad_1: Buffer(data_pad, float32, [432], [])[ramp(0, 1, 16)] = @tir.if_then_else((cse_var_5 && cse_var_4), placeholder[ramp((cse_var_2 - 912), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(16, 1, 16)] = @tir.if_then_else(cse_var_5, placeholder[ramp((cse_var_2 - 896), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(32, 1, 16)] = @tir.if_then_else(cse_var_5, placeholder[ramp((cse_var_2 - 880), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(48, 1, 16)] = @tir.if_then_else(cse_var_5, placeholder[ramp((cse_var_2 - 864), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(64, 1, 16)] = @tir.if_then_else(cse_var_5, placeholder[ramp((cse_var_2 - 848), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(80, 1, 16)] = @tir.if_then_else(cse_var_5, placeholder[ramp((cse_var_2 - 832), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(96, 1, 16)] = @tir.if_then_else(cse_var_5, placeholder[ramp((cse_var_2 - 816), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(112, 1, 16)] = @tir.if_then_else(cse_var_5, placeholder[ramp((cse_var_2 - 800), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(128, 1, 16)] = @tir.if_then_else((cse_var_5 && cse_var_3), placeholder[ramp((cse_var_2 - 784), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(144, 1, 16)] = @tir.if_then_else(cse_var_4, placeholder[ramp((cse_var_2 - 16), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(160, 1, 16)] = placeholder[ramp(cse_var_2, 1, 16)]
              data_pad_1[ramp(176, 1, 16)] = placeholder[ramp((cse_var_2 + 16), 1, 16)]
              data_pad_1[ramp(192, 1, 16)] = placeholder[ramp((cse_var_2 + 32), 1, 16)]
              data_pad_1[ramp(208, 1, 16)] = placeholder[ramp((cse_var_2 + 48), 1, 16)]
              data_pad_1[ramp(224, 1, 16)] = placeholder[ramp((cse_var_2 + 64), 1, 16)]
              data_pad_1[ramp(240, 1, 16)] = placeholder[ramp((cse_var_2 + 80), 1, 16)]
              data_pad_1[ramp(256, 1, 16)] = placeholder[ramp((cse_var_2 + 96), 1, 16)]
              data_pad_1[ramp(272, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_2 + 112), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(288, 1, 16)] = @tir.if_then_else((cse_var_6 && cse_var_4), placeholder[ramp((cse_var_2 + 880), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(304, 1, 16)] = @tir.if_then_else(cse_var_6, placeholder[ramp((cse_var_2 + 896), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(320, 1, 16)] = @tir.if_then_else(cse_var_6, placeholder[ramp((cse_var_2 + 912), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(336, 1, 16)] = @tir.if_then_else(cse_var_6, placeholder[ramp((cse_var_2 + 928), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(352, 1, 16)] = @tir.if_then_else(cse_var_6, placeholder[ramp((cse_var_2 + 944), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(368, 1, 16)] = @tir.if_then_else(cse_var_6, placeholder[ramp((cse_var_2 + 960), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(384, 1, 16)] = @tir.if_then_else(cse_var_6, placeholder[ramp((cse_var_2 + 976), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(400, 1, 16)] = @tir.if_then_else(cse_var_6, placeholder[ramp((cse_var_2 + 992), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              data_pad_1[ramp(416, 1, 16)] = @tir.if_then_else((cse_var_6 && cse_var_3), placeholder[ramp((cse_var_2 + 1008), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
              for (kh.outer: int32, 0, 3) {
                for (ic.inner: int32, 0, 16) {
                  let cse_var_46: int32 = (cse_var_1 + 1)
                  let cse_var_45: int32 = (cse_var_1 + 2)
                  let cse_var_44: int32 = (cse_var_1 + 28)
                  let cse_var_43: int32 = (cse_var_1 + 29)
                  let cse_var_42: int32 = (cse_var_1 + 3)
                  let cse_var_41: int32 = (cse_var_1 + 30)
                  let cse_var_40: int32 = (cse_var_1 + 31)
                  let cse_var_39: int32 = (cse_var_1 + 32)
                  let cse_var_38: int32 = (cse_var_1 + 33)
                  let cse_var_37: int32 = (cse_var_1 + 34)
                  let cse_var_36: int32 = (cse_var_1 + 4)
                  let cse_var_35: int32 = (cse_var_1 + 5)
                  let cse_var_34: int32 = (cse_var_1 + 56)
                  let cse_var_33: int32 = (cse_var_1 + 57)
                  let cse_var_32: int32 = (cse_var_1 + 58)
                  let cse_var_31: int32 = (cse_var_1 + 59)
                  let cse_var_30: int32 = (cse_var_1 + 6)
                  let cse_var_29: int32 = (cse_var_1 + 60)
                  let cse_var_28: int32 = (cse_var_1 + 61)
                  let cse_var_27: int32 = (cse_var_1 + 62)
                  let cse_var_26: int32 = ((kh.outer*144) + ic.inner)
                  let cse_var_25: int32 = (cse_var_26 + 112)
                  let cse_var_24: int32 = (cse_var_26 + 128)
                  let cse_var_23: int32 = (cse_var_26 + 16)
                  let cse_var_22: int32 = (cse_var_26 + 32)
                  let cse_var_21: int32 = (cse_var_26 + 48)
                  let cse_var_20: int32 = (cse_var_26 + 80)
                  let cse_var_19: int32 = (cse_var_26 + 96)
                  let cse_var_18: int32 = (cse_var_26 + 64)
                  let cse_var_17: int32 = ((((floordiv(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused.ax4.outer.fused, 112)*27648) + (ic.outer*2304)) + (kh.outer*768)) + (ic.inner*16))
                  let cse_var_16: int32 = (cse_var_17 + 18432)
                  let cse_var_15: int32 = (cse_var_17 + 9728)
                  let cse_var_14: int32 = (cse_var_17 + 9472)
                  let cse_var_13: int32 = (cse_var_17 + 9216)
                  let cse_var_12: int32 = (cse_var_17 + 512)
                  let cse_var_11: int32 = (cse_var_17 + 256)
                  let cse_var_10: int32 = (cse_var_17 + 18944)
                  let cse_var_9: int32 = (cse_var_17 + 18688)
                   {
                    conv2d_NCHWc_1[cse_var_1] = (conv2d_NCHWc_1[cse_var_1] + (broadcast(data_pad_1[cse_var_26], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_46] = (conv2d_NCHWc_1[cse_var_46] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_45] = (conv2d_NCHWc_1[cse_var_45] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_42] = (conv2d_NCHWc_1[cse_var_42] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_36] = (conv2d_NCHWc_1[cse_var_36] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_35] = (conv2d_NCHWc_1[cse_var_35] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_30] = (conv2d_NCHWc_1[cse_var_30] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_44] = (conv2d_NCHWc_1[cse_var_44] + (broadcast(data_pad_1[cse_var_26], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_43] = (conv2d_NCHWc_1[cse_var_43] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_41] = (conv2d_NCHWc_1[cse_var_41] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_40] = (conv2d_NCHWc_1[cse_var_40] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_39] = (conv2d_NCHWc_1[cse_var_39] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_38] = (conv2d_NCHWc_1[cse_var_38] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_37] = (conv2d_NCHWc_1[cse_var_37] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_34] = (conv2d_NCHWc_1[cse_var_34] + (broadcast(data_pad_1[cse_var_26], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_33] = (conv2d_NCHWc_1[cse_var_33] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_32] = (conv2d_NCHWc_1[cse_var_32] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_31] = (conv2d_NCHWc_1[cse_var_31] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_29] = (conv2d_NCHWc_1[cse_var_29] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_28] = (conv2d_NCHWc_1[cse_var_28] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_27] = (conv2d_NCHWc_1[cse_var_27] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_1] = (conv2d_NCHWc_1[cse_var_1] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_46] = (conv2d_NCHWc_1[cse_var_46] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_45] = (conv2d_NCHWc_1[cse_var_45] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_42] = (conv2d_NCHWc_1[cse_var_42] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_36] = (conv2d_NCHWc_1[cse_var_36] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_35] = (conv2d_NCHWc_1[cse_var_35] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_30] = (conv2d_NCHWc_1[cse_var_30] + (broadcast(data_pad_1[cse_var_25], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_44] = (conv2d_NCHWc_1[cse_var_44] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_43] = (conv2d_NCHWc_1[cse_var_43] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_41] = (conv2d_NCHWc_1[cse_var_41] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_40] = (conv2d_NCHWc_1[cse_var_40] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_39] = (conv2d_NCHWc_1[cse_var_39] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_38] = (conv2d_NCHWc_1[cse_var_38] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_37] = (conv2d_NCHWc_1[cse_var_37] + (broadcast(data_pad_1[cse_var_25], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_34] = (conv2d_NCHWc_1[cse_var_34] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_33] = (conv2d_NCHWc_1[cse_var_33] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_32] = (conv2d_NCHWc_1[cse_var_32] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_31] = (conv2d_NCHWc_1[cse_var_31] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_29] = (conv2d_NCHWc_1[cse_var_29] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_28] = (conv2d_NCHWc_1[cse_var_28] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_27] = (conv2d_NCHWc_1[cse_var_27] + (broadcast(data_pad_1[cse_var_25], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_1] = (conv2d_NCHWc_1[cse_var_1] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_46] = (conv2d_NCHWc_1[cse_var_46] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_45] = (conv2d_NCHWc_1[cse_var_45] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_42] = (conv2d_NCHWc_1[cse_var_42] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_36] = (conv2d_NCHWc_1[cse_var_36] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_35] = (conv2d_NCHWc_1[cse_var_35] + (broadcast(data_pad_1[cse_var_25], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_30] = (conv2d_NCHWc_1[cse_var_30] + (broadcast(data_pad_1[cse_var_24], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_44] = (conv2d_NCHWc_1[cse_var_44] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_43] = (conv2d_NCHWc_1[cse_var_43] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_41] = (conv2d_NCHWc_1[cse_var_41] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_40] = (conv2d_NCHWc_1[cse_var_40] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_39] = (conv2d_NCHWc_1[cse_var_39] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_38] = (conv2d_NCHWc_1[cse_var_38] + (broadcast(data_pad_1[cse_var_25], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_37] = (conv2d_NCHWc_1[cse_var_37] + (broadcast(data_pad_1[cse_var_24], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_34] = (conv2d_NCHWc_1[cse_var_34] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_33] = (conv2d_NCHWc_1[cse_var_33] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_32] = (conv2d_NCHWc_1[cse_var_32] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_31] = (conv2d_NCHWc_1[cse_var_31] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_29] = (conv2d_NCHWc_1[cse_var_29] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_28] = (conv2d_NCHWc_1[cse_var_28] + (broadcast(data_pad_1[cse_var_25], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                    conv2d_NCHWc_1[cse_var_27] = (conv2d_NCHWc_1[cse_var_27] + (broadcast(data_pad_1[cse_var_24], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                  }
                }
              }
            }
          }
        }
      }
      for (ax1.inner: int32, 0, 3) {
        for (ax3.inner: int32, 0, 28) {
          let cse_var_48: int32 = floordiv(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused.ax4.outer.fused, 112)
          let cse_var_47: int32 = ((cse_var_48*48) + (ax1.inner*16))
          T_relu[ramp(((((cse_var_48*150528) + (ax1.inner*50176)) + (floormod(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused.ax4.outer.fused, 112)*448)) + (ax3.inner*16)), 1, 16)] = max((((conv2d_NCHWc_1[((ax1.inner*28) + ax3.inner)] + placeholder_2[ramp(cse_var_47, 1, 16)])*placeholder_3[ramp(cse_var_47, 1, 16)]) + placeholder_4[ramp(cse_var_47, 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 38: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_10 (weight 1 key: ["9db1fd34470fc877a2c0431d681f01a4", [1, 36, 14, 14, 16], [14, 36, 1, 1, 16, 16], [1, 14, 1, 1, 16], [1, 14, 1, 1, 16], [1, 14, 1, 1, 16], [1, 14, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 36, 14, 14, 16]
placeholder = PLACEHOLDER [14, 36, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 14, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 14, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 14, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=1)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=4)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=1)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=1)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 16)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [112896], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [129024], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [224], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [224], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [224], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [43904], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_6: placeholder_15: Buffer(placeholder_11, float32, [14, 36, 1, 1, 16, 16], []), placeholder_8: placeholder_16: Buffer(placeholder_13, float32, [1, 14, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 14, 14, 14, 16], []), placeholder_5: placeholder_17: Buffer(placeholder_10, float32, [1, 36, 14, 14, 16], []), placeholder_7: placeholder_18: Buffer(placeholder_12, float32, [1, 14, 1, 1, 16], []), placeholder_9: placeholder_19: Buffer(placeholder_14, float32, [1, 14, 1, 1, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 196) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 144) {
        for (ic.inner: int32, 0, 4) {
          let cse_var_9: int32 = (((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)*18432) + (ic.outer*64)) + (ic.inner*16))
          let cse_var_8: int32 = (cse_var_9 + 9216)
          let cse_var_7: int32 = ((((floordiv(ic.outer, 4)*3136) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)*112)) + (floormod(ic.outer, 4)*4)) + ic.inner)
          let cse_var_6: int32 = (cse_var_7 + 96)
          let cse_var_5: int32 = (cse_var_7 + 80)
          let cse_var_4: int32 = (cse_var_7 + 64)
          let cse_var_3: int32 = (cse_var_7 + 48)
          let cse_var_2: int32 = (cse_var_7 + 32)
          let cse_var_1: int32 = (cse_var_7 + 16)
           {
            conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_11: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)
          let cse_var_10: int32 = ((cse_var_11*32) + (ax1.inner*16))
          T_relu[ramp(((((cse_var_11*6272) + (ax1.inner*3136)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)*112)) + (ax3.inner*16)), 1, 16)] = max((((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(cse_var_10, 1, 16)])*placeholder_3[ramp(cse_var_10, 1, 16)]) + placeholder_4[ramp(cse_var_10, 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 39: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 (weight 1 key: ["f6615ae9259e3b2add2908c0cd980cb6", [1, 36, 14, 14, 16], [4, 36, 1, 1, 16, 16], [1, 4, 1, 1, 16], [1, 4, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 36, 14, 14, 16]
placeholder = PLACEHOLDER [4, 36, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=4)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=2)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=1)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=2)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=7)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=2)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=4)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=2)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=1)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=2)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=7)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 512)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_6: Pointer(float32), float32, [112896], []),
             placeholder_1: Buffer(placeholder_7: Pointer(float32), float32, [36864], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [64], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [12544], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_3: placeholder_9: Buffer(placeholder_6, float32, [1, 36, 14, 14, 16], []), placeholder_4: placeholder_10: Buffer(placeholder_7, float32, [4, 36, 1, 1, 16, 16], []), placeholder_5: placeholder_11: Buffer(placeholder_8, float32, [1, 4, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 4, 14, 14, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 49) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [16]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [16], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[14] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      conv2d_NCHWc_1[15] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 288) {
        let cse_var_16: int32 = (ic.outer*32)
        let cse_var_15: int32 = (cse_var_16 + 9232)
        let cse_var_14: int32 = (cse_var_16 + 9216)
        let cse_var_13: int32 = (cse_var_16 + 27664)
        let cse_var_12: int32 = (cse_var_16 + 27648)
        let cse_var_11: int32 = (cse_var_16 + 18448)
        let cse_var_10: int32 = (cse_var_16 + 18432)
        let cse_var_9: int32 = (cse_var_16 + 16)
        let cse_var_8: int32 = ((((floordiv(ic.outer, 8)*3136) + (floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)*448)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)*32)) + (floormod(ic.outer, 8)*2))
        let cse_var_7: int32 = (cse_var_8 + 241)
        let cse_var_6: int32 = (cse_var_8 + 240)
        let cse_var_5: int32 = (cse_var_8 + 225)
        let cse_var_4: int32 = (cse_var_8 + 224)
        let cse_var_3: int32 = (cse_var_8 + 17)
        let cse_var_2: int32 = (cse_var_8 + 16)
        let cse_var_1: int32 = (cse_var_8 + 1)
         {
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
          conv2d_NCHWc_1[14] = (conv2d_NCHWc_1[14] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
          conv2d_NCHWc_1[14] = (conv2d_NCHWc_1[14] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
          conv2d_NCHWc_1[15] = (conv2d_NCHWc_1[15] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
          conv2d_NCHWc_1[15] = (conv2d_NCHWc_1[15] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
        }
      }
      for (ax1.inner: int32, 0, 4) {
        for (ax2.inner: int32, 0, 2) {
          for (ax3.inner: int32, 0, 2) {
            T_relu[ramp((((((ax1.inner*3136) + (floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)*448)) + (ax2.inner*224)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)*32)) + (ax3.inner*16)), 1, 16)] = max((conv2d_NCHWc_1[(((ax1.inner*4) + (ax2.inner*2)) + ax3.inner)] + placeholder_2[ramp((ax1.inner*16), 1, 16)]), broadcast(0f32, 16))
          }
        }
      }
    }
  }
}


==== Task 40: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 (weight 3 key: ["ce1b4a245fb9b3a0526fcd7e77d29d3f", [1, 4, 28, 28, 16], [6, 4, 3, 3, 16, 16], [1, 6, 1, 1, 16], [1, 6, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 4, 28, 28, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 29)) && (i3 >= 1)) && (i3 < 29)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [6, 4, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3, data_pad_i4 = tuple(data_pad.op.axis) + tuple(data_pad.op.reduce_axis)
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=1)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=3)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=1)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=1)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
s[data_pad].compute_at(s[conv2d_NCHWc], conv2d_NCHWc_kh_o)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 512)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[data_pad].vectorize(data_pad_i4)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_6: Pointer(float32), float32, [50176], []),
             placeholder_1: Buffer(placeholder_7: Pointer(float32), float32, [55296], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [96], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [75264], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_3: placeholder_9: Buffer(placeholder_6, float32, [1, 4, 28, 28, 16], []), placeholder_4: placeholder_10: Buffer(placeholder_7, float32, [6, 4, 3, 3, 16, 16], []), placeholder_5: placeholder_11: Buffer(placeholder_8, float32, [1, 6, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 6, 28, 28, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 336) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global;
    allocate(data_pad: Pointer(global float32), float32, [144]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 4) {
        for (kh.outer: int32, 0, 3) {
          let cse_var_5: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 112)
          let cse_var_4: int32 = (floordiv(cse_var_5, 4) + kh.outer)
          let cse_var_3: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 4)
          let cse_var_2: int32 = (((ic.outer*12544) + (kh.outer*448)) + (cse_var_5*112))
          let cse_var_1: bool = ((1 <= cse_var_4) && (cse_var_4 < 29))
           {
            data_pad_1: Buffer(data_pad, float32, [144], [])[ramp(0, 1, 16)] = @tir.if_then_else((cse_var_1 && (1 <= cse_var_3)), placeholder[ramp((cse_var_2 - 464), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(16, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 448), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(32, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 432), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(48, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 416), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(64, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 400), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(80, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 384), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(96, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 368), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(112, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 352), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(128, 1, 16)] = @tir.if_then_else((cse_var_1 && (cse_var_3 < 3)), placeholder[ramp((cse_var_2 - 336), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            for (ic.inner: int32, 0, 16) {
              let cse_var_19: int32 = (ic.inner + 96)
              let cse_var_18: int32 = (ic.inner + 80)
              let cse_var_17: int32 = (ic.inner + 64)
              let cse_var_16: int32 = (ic.inner + 48)
              let cse_var_15: int32 = (ic.inner + 32)
              let cse_var_14: int32 = (ic.inner + 16)
              let cse_var_13: int32 = (ic.inner + 128)
              let cse_var_12: int32 = (ic.inner + 112)
              let cse_var_11: int32 = ((((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 112)*18432) + (ic.outer*2304)) + (kh.outer*768)) + (ic.inner*16))
              let cse_var_10: int32 = (cse_var_11 + 9728)
              let cse_var_9: int32 = (cse_var_11 + 9472)
              let cse_var_8: int32 = (cse_var_11 + 9216)
              let cse_var_7: int32 = (cse_var_11 + 512)
              let cse_var_6: int32 = (cse_var_11 + 256)
               {
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
              }
            }
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_20: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 112)
          T_relu[ramp(((((cse_var_20*25088) + (ax1.inner*12544)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 112)*112)) + (ax3.inner*16)), 1, 16)] = max((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(((cse_var_20*32) + (ax1.inner*16)), 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 41: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_12 (weight 2 key: ["6b0d226afab7de584e086dc68f47c79a", [1, 8, 14, 14, 16], [8, 8, 3, 3, 16, 16], [1, 8, 1, 1, 16], [1, 8, 1, 1, 16], [1, 8, 1, 1, 16], [1, 8, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 8, 14, 14, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 15)) && (i3 >= 1)) && (i3 < 15)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [8, 8, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3, data_pad_i4 = tuple(data_pad.op.axis) + tuple(data_pad.op.reduce_axis)
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=1)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=3)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=1)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=1)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
s[data_pad].compute_at(s[conv2d_NCHWc], conv2d_NCHWc_kh_o)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 64)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[data_pad].vectorize(data_pad_i4)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [25088], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [147456], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [128], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [128], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [128], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [25088], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_6: placeholder_15: Buffer(placeholder_11, float32, [8, 8, 3, 3, 16, 16], []), placeholder_5: placeholder_16: Buffer(placeholder_10, float32, [1, 8, 14, 14, 16], []), placeholder_7: placeholder_17: Buffer(placeholder_12, float32, [1, 8, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 8, 14, 14, 16], []), placeholder_9: placeholder_18: Buffer(placeholder_14, float32, [1, 8, 1, 1, 16], []), placeholder_8: placeholder_19: Buffer(placeholder_13, float32, [1, 8, 1, 1, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused: int32, 0, 112) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global;
    allocate(data_pad: Pointer(global float32), float32, [144]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 8) {
        for (kh.outer: int32, 0, 3) {
          let cse_var_5: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 28)
          let cse_var_4: int32 = (floordiv(cse_var_5, 2) + kh.outer)
          let cse_var_3: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 2)
          let cse_var_2: int32 = (((ic.outer*3136) + (kh.outer*224)) + (cse_var_5*112))
          let cse_var_1: bool = ((1 <= cse_var_4) && (cse_var_4 < 15))
           {
            data_pad_1: Buffer(data_pad, float32, [144], [])[ramp(0, 1, 16)] = @tir.if_then_else((cse_var_1 && (1 <= cse_var_3)), placeholder[ramp((cse_var_2 - 240), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(16, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 224), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(32, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 208), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(48, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 192), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(64, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 176), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(80, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 160), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(96, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 144), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(112, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 128), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(128, 1, 16)] = @tir.if_then_else((cse_var_1 && (cse_var_3 < 1)), placeholder[ramp((cse_var_2 - 112), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            for (ic.inner: int32, 0, 16) {
              let cse_var_19: int32 = (ic.inner + 96)
              let cse_var_18: int32 = (ic.inner + 80)
              let cse_var_17: int32 = (ic.inner + 64)
              let cse_var_16: int32 = (ic.inner + 48)
              let cse_var_15: int32 = (ic.inner + 32)
              let cse_var_14: int32 = (ic.inner + 16)
              let cse_var_13: int32 = (ic.inner + 128)
              let cse_var_12: int32 = (ic.inner + 112)
              let cse_var_11: int32 = ((((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 28)*36864) + (ic.outer*2304)) + (kh.outer*768)) + (ic.inner*16))
              let cse_var_10: int32 = (cse_var_11 + 512)
              let cse_var_9: int32 = (cse_var_11 + 256)
              let cse_var_8: int32 = (cse_var_11 + 18944)
              let cse_var_7: int32 = (cse_var_11 + 18688)
              let cse_var_6: int32 = (cse_var_11 + 18432)
               {
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
              }
            }
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_21: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 28)
          let cse_var_20: int32 = ((cse_var_21*32) + (ax1.inner*16))
          T_relu[ramp(((((cse_var_21*6272) + (ax1.inner*3136)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused, 28)*112)) + (ax3.inner*16)), 1, 16)] = max((((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(cse_var_20, 1, 16)])*placeholder_3[ramp(cse_var_20, 1, 16)]) + placeholder_4[ramp(cse_var_20, 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 42: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_23 (weight 1 key: ["d85f86643f68d4261269b8274457244f", [1, 16, 14, 14, 16], [16, 16, 3, 3, 16, 16], [1, 16, 1, 1, 16], [1, 16, 1, 1, 16], [1, 16, 1, 1, 16], [1, 16, 7, 7, 16]]) =====
placeholder = PLACEHOLDER [1, 16, 14, 14, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 15)) && (i3 >= 1)) && (i3 < 15)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [16, 16, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), ((oh*2) + kh), ((ow*2) + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 16, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 16, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 16, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3, data_pad_i4 = tuple(data_pad.op.axis) + tuple(data_pad.op.reduce_axis)
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=2)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=7)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=1)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=3)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=2)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=7)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=1)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
s[data_pad].compute_at(s[conv2d_NCHWc], conv2d_NCHWc_ic_o)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 64)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[data_pad].vectorize(data_pad_i4)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [50176], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [589824], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [256], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [256], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [256], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [12544], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_8: placeholder_15: Buffer(placeholder_13, float32, [1, 16, 1, 1, 16], []), placeholder_5: placeholder_16: Buffer(placeholder_10, float32, [1, 16, 14, 14, 16], []), placeholder_7: placeholder_17: Buffer(placeholder_12, float32, [1, 16, 1, 1, 16], []), placeholder_6: placeholder_18: Buffer(placeholder_11, float32, [16, 16, 3, 3, 16, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 16, 7, 7, 16], []), placeholder_9: placeholder_19: Buffer(placeholder_14, float32, [1, 16, 1, 1, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused: int32, 0, 56) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global;
    allocate(data_pad: Pointer(global float32), float32, [720]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 16) {
        let cse_var_3: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 7)
        let cse_var_2: bool = (1 <= cse_var_3)
        let cse_var_1: int32 = ((ic.outer*3136) + (cse_var_3*448))
         {
          data_pad_1: Buffer(data_pad, float32, [720], [])[ramp(0, 1, 16)] = broadcast(0f32, 16)
          data_pad_1[ramp(16, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 224), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(32, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 208), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(48, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 192), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(64, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 176), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(80, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 160), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(96, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 144), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(112, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 128), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(128, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 112), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(144, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 96), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(160, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 80), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(176, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 64), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(192, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 48), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(208, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 32), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(224, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 16), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(240, 1, 16)] = broadcast(0f32, 16)
          data_pad_1[ramp(256, 1, 16)] = placeholder[ramp(cse_var_1, 1, 16)]
          data_pad_1[ramp(272, 1, 16)] = placeholder[ramp((cse_var_1 + 16), 1, 16)]
          data_pad_1[ramp(288, 1, 16)] = placeholder[ramp((cse_var_1 + 32), 1, 16)]
          data_pad_1[ramp(304, 1, 16)] = placeholder[ramp((cse_var_1 + 48), 1, 16)]
          data_pad_1[ramp(320, 1, 16)] = placeholder[ramp((cse_var_1 + 64), 1, 16)]
          data_pad_1[ramp(336, 1, 16)] = placeholder[ramp((cse_var_1 + 80), 1, 16)]
          data_pad_1[ramp(352, 1, 16)] = placeholder[ramp((cse_var_1 + 96), 1, 16)]
          data_pad_1[ramp(368, 1, 16)] = placeholder[ramp((cse_var_1 + 112), 1, 16)]
          data_pad_1[ramp(384, 1, 16)] = placeholder[ramp((cse_var_1 + 128), 1, 16)]
          data_pad_1[ramp(400, 1, 16)] = placeholder[ramp((cse_var_1 + 144), 1, 16)]
          data_pad_1[ramp(416, 1, 16)] = placeholder[ramp((cse_var_1 + 160), 1, 16)]
          data_pad_1[ramp(432, 1, 16)] = placeholder[ramp((cse_var_1 + 176), 1, 16)]
          data_pad_1[ramp(448, 1, 16)] = placeholder[ramp((cse_var_1 + 192), 1, 16)]
          data_pad_1[ramp(464, 1, 16)] = placeholder[ramp((cse_var_1 + 208), 1, 16)]
          data_pad_1[ramp(480, 1, 16)] = broadcast(0f32, 16)
          data_pad_1[ramp(496, 1, 16)] = placeholder[ramp((cse_var_1 + 224), 1, 16)]
          data_pad_1[ramp(512, 1, 16)] = placeholder[ramp((cse_var_1 + 240), 1, 16)]
          data_pad_1[ramp(528, 1, 16)] = placeholder[ramp((cse_var_1 + 256), 1, 16)]
          data_pad_1[ramp(544, 1, 16)] = placeholder[ramp((cse_var_1 + 272), 1, 16)]
          data_pad_1[ramp(560, 1, 16)] = placeholder[ramp((cse_var_1 + 288), 1, 16)]
          data_pad_1[ramp(576, 1, 16)] = placeholder[ramp((cse_var_1 + 304), 1, 16)]
          data_pad_1[ramp(592, 1, 16)] = placeholder[ramp((cse_var_1 + 320), 1, 16)]
          data_pad_1[ramp(608, 1, 16)] = placeholder[ramp((cse_var_1 + 336), 1, 16)]
          data_pad_1[ramp(624, 1, 16)] = placeholder[ramp((cse_var_1 + 352), 1, 16)]
          data_pad_1[ramp(640, 1, 16)] = placeholder[ramp((cse_var_1 + 368), 1, 16)]
          data_pad_1[ramp(656, 1, 16)] = placeholder[ramp((cse_var_1 + 384), 1, 16)]
          data_pad_1[ramp(672, 1, 16)] = placeholder[ramp((cse_var_1 + 400), 1, 16)]
          data_pad_1[ramp(688, 1, 16)] = placeholder[ramp((cse_var_1 + 416), 1, 16)]
          data_pad_1[ramp(704, 1, 16)] = placeholder[ramp((cse_var_1 + 432), 1, 16)]
          for (kw.outer: int32, 0, 3) {
            for (ic.inner: int32, 0, 16) {
              let cse_var_30: int32 = ((kw.outer*16) + ic.inner)
              let cse_var_29: int32 = (cse_var_30 + 128)
              let cse_var_28: int32 = (cse_var_30 + 160)
              let cse_var_27: int32 = (cse_var_30 + 192)
              let cse_var_26: int32 = (cse_var_30 + 240)
              let cse_var_25: int32 = (cse_var_30 + 272)
              let cse_var_24: int32 = (cse_var_30 + 304)
              let cse_var_23: int32 = (cse_var_30 + 32)
              let cse_var_22: int32 = (cse_var_30 + 368)
              let cse_var_21: int32 = (cse_var_30 + 400)
              let cse_var_20: int32 = (cse_var_30 + 432)
              let cse_var_19: int32 = (cse_var_30 + 480)
              let cse_var_18: int32 = (cse_var_30 + 512)
              let cse_var_17: int32 = (cse_var_30 + 544)
              let cse_var_16: int32 = (cse_var_30 + 576)
              let cse_var_15: int32 = (cse_var_30 + 608)
              let cse_var_14: int32 = (cse_var_30 + 64)
              let cse_var_13: int32 = (cse_var_30 + 640)
              let cse_var_12: int32 = (cse_var_30 + 672)
              let cse_var_11: int32 = (cse_var_30 + 96)
              let cse_var_10: int32 = (cse_var_30 + 336)
              let cse_var_9: int32 = ((((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 7)*73728) + (ic.outer*2304)) + (kw.outer*256)) + (ic.inner*16))
              let cse_var_8: int32 = (cse_var_9 + 1536)
              let cse_var_7: int32 = (cse_var_9 + 768)
              let cse_var_6: int32 = (cse_var_9 + 38400)
              let cse_var_5: int32 = (cse_var_9 + 37632)
              let cse_var_4: int32 = (cse_var_9 + 36864)
               {
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_30], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_11], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_29], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_28], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_27], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_30], 16)*placeholder_1[ramp(cse_var_4, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_4, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_4, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_11], 16)*placeholder_1[ramp(cse_var_4, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_29], 16)*placeholder_1[ramp(cse_var_4, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_28], 16)*placeholder_1[ramp(cse_var_4, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_27], 16)*placeholder_1[ramp(cse_var_4, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_26], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_25], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_24], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_10], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_26], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_25], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_24], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_10], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
              }
            }
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_32: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 7)
          let cse_var_31: int32 = ((cse_var_32*32) + (ax1.inner*16))
          T_relu[ramp(((((cse_var_32*1568) + (ax1.inner*784)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 7)*112)) + (ax3.inner*16)), 1, 16)] = max((((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(cse_var_31, 1, 16)])*placeholder_3[ramp(cse_var_31, 1, 16)]) + placeholder_4[ramp(cse_var_31, 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 43: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_27 (weight 2 key: ["9db1fd34470fc877a2c0431d681f01a4", [1, 64, 7, 7, 16], [8, 64, 1, 1, 16, 16], [1, 8, 1, 1, 16], [1, 8, 1, 1, 16], [1, 8, 1, 1, 16], [1, 8, 7, 7, 16]]) =====
placeholder = PLACEHOLDER [1, 64, 7, 7, 16]
placeholder = PLACEHOLDER [8, 64, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=1)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=1)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=1)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 512)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [50176], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [131072], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [128], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [128], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [128], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [6272], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_8: placeholder_15: Buffer(placeholder_13, float32, [1, 8, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 8, 7, 7, 16], []), placeholder_6: placeholder_16: Buffer(placeholder_11, float32, [8, 64, 1, 1, 16, 16], []), placeholder_9: placeholder_17: Buffer(placeholder_14, float32, [1, 8, 1, 1, 16], []), placeholder_5: placeholder_18: Buffer(placeholder_10, float32, [1, 64, 7, 7, 16], []), placeholder_7: placeholder_19: Buffer(placeholder_12, float32, [1, 8, 1, 1, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 28) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 64) {
        let cse_var_144: int32 = ((ic.outer*784) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)*112))
        let cse_var_143: int32 = ((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)*32768) + (ic.outer*256))
        let cse_var_142: int32 = (cse_var_144 + 19)
        let cse_var_141: int32 = (cse_var_144 + 17)
        let cse_var_140: int32 = (cse_var_144 + 16)
        let cse_var_139: int32 = (cse_var_144 + 15)
        let cse_var_138: int32 = (cse_var_144 + 14)
        let cse_var_137: int32 = (cse_var_144 + 13)
        let cse_var_136: int32 = (cse_var_144 + 12)
        let cse_var_135: int32 = (cse_var_144 + 111)
        let cse_var_134: int32 = (cse_var_144 + 110)
        let cse_var_133: int32 = (cse_var_144 + 11)
        let cse_var_132: int32 = (cse_var_144 + 109)
        let cse_var_131: int32 = (cse_var_144 + 108)
        let cse_var_130: int32 = (cse_var_144 + 107)
        let cse_var_129: int32 = (cse_var_144 + 106)
        let cse_var_128: int32 = (cse_var_144 + 105)
        let cse_var_127: int32 = (cse_var_144 + 103)
        let cse_var_126: int32 = (cse_var_144 + 18)
        let cse_var_125: int32 = (cse_var_144 + 35)
        let cse_var_124: int32 = (cse_var_144 + 33)
        let cse_var_123: int32 = (cse_var_144 + 32)
        let cse_var_122: int32 = (cse_var_144 + 31)
        let cse_var_121: int32 = (cse_var_144 + 30)
        let cse_var_120: int32 = (cse_var_144 + 3)
        let cse_var_119: int32 = (cse_var_144 + 29)
        let cse_var_118: int32 = (cse_var_144 + 28)
        let cse_var_117: int32 = (cse_var_144 + 104)
        let cse_var_116: int32 = (cse_var_144 + 26)
        let cse_var_115: int32 = (cse_var_144 + 25)
        let cse_var_114: int32 = (cse_var_144 + 24)
        let cse_var_113: int32 = (cse_var_144 + 23)
        let cse_var_112: int32 = (cse_var_144 + 22)
        let cse_var_111: int32 = (cse_var_144 + 21)
        let cse_var_110: int32 = (cse_var_144 + 20)
        let cse_var_109: int32 = (cse_var_144 + 2)
        let cse_var_108: int32 = (cse_var_144 + 27)
        let cse_var_107: int32 = (cse_var_143 + 16576)
        let cse_var_106: int32 = (cse_var_143 + 16560)
        let cse_var_105: int32 = (cse_var_143 + 16544)
        let cse_var_104: int32 = (cse_var_143 + 16528)
        let cse_var_103: int32 = (cse_var_143 + 16512)
        let cse_var_102: int32 = (cse_var_143 + 16496)
        let cse_var_101: int32 = (cse_var_143 + 16480)
        let cse_var_100: int32 = (cse_var_143 + 16464)
        let cse_var_99: int32 = (cse_var_144 + 34)
        let cse_var_98: int32 = (cse_var_143 + 16432)
        let cse_var_97: int32 = (cse_var_143 + 16416)
        let cse_var_96: int32 = (cse_var_143 + 16400)
        let cse_var_95: int32 = (cse_var_143 + 16384)
        let cse_var_94: int32 = (cse_var_143 + 160)
        let cse_var_93: int32 = (cse_var_143 + 16)
        let cse_var_92: int32 = (cse_var_143 + 144)
        let cse_var_91: int32 = (cse_var_143 + 112)
        let cse_var_90: int32 = (cse_var_143 + 16448)
        let cse_var_89: int32 = (cse_var_144 + 102)
        let cse_var_88: int32 = (cse_var_144 + 101)
        let cse_var_87: int32 = (cse_var_144 + 100)
        let cse_var_86: int32 = (cse_var_144 + 10)
        let cse_var_85: int32 = (cse_var_144 + 1)
        let cse_var_84: int32 = (cse_var_143 + 96)
        let cse_var_83: int32 = (cse_var_143 + 80)
        let cse_var_82: int32 = (cse_var_143 + 64)
        let cse_var_81: int32 = (cse_var_143 + 16592)
        let cse_var_80: int32 = (cse_var_143 + 32)
        let cse_var_79: int32 = (cse_var_143 + 240)
        let cse_var_78: int32 = (cse_var_143 + 224)
        let cse_var_77: int32 = (cse_var_143 + 208)
        let cse_var_76: int32 = (cse_var_143 + 192)
        let cse_var_75: int32 = (cse_var_143 + 176)
        let cse_var_74: int32 = (cse_var_143 + 16624)
        let cse_var_73: int32 = (cse_var_143 + 16608)
        let cse_var_72: int32 = (cse_var_143 + 48)
        let cse_var_71: int32 = (cse_var_144 + 82)
        let cse_var_70: int32 = (cse_var_144 + 81)
        let cse_var_69: int32 = (cse_var_144 + 80)
        let cse_var_68: int32 = (cse_var_144 + 8)
        let cse_var_67: int32 = (cse_var_144 + 79)
        let cse_var_66: int32 = (cse_var_144 + 78)
        let cse_var_65: int32 = (cse_var_144 + 77)
        let cse_var_64: int32 = (cse_var_143 + 128)
        let cse_var_63: int32 = (cse_var_144 + 75)
        let cse_var_62: int32 = (cse_var_144 + 74)
        let cse_var_61: int32 = (cse_var_144 + 73)
        let cse_var_60: int32 = (cse_var_144 + 72)
        let cse_var_59: int32 = (cse_var_144 + 71)
        let cse_var_58: int32 = (cse_var_144 + 70)
        let cse_var_57: int32 = (cse_var_144 + 7)
        let cse_var_56: int32 = (cse_var_144 + 69)
        let cse_var_55: int32 = (cse_var_144 + 76)
        let cse_var_54: int32 = (cse_var_144 + 99)
        let cse_var_53: int32 = (cse_var_144 + 98)
        let cse_var_52: int32 = (cse_var_144 + 97)
        let cse_var_51: int32 = (cse_var_144 + 96)
        let cse_var_50: int32 = (cse_var_144 + 95)
        let cse_var_49: int32 = (cse_var_144 + 94)
        let cse_var_48: int32 = (cse_var_144 + 93)
        let cse_var_47: int32 = (cse_var_144 + 92)
        let cse_var_46: int32 = (cse_var_144 + 83)
        let cse_var_45: int32 = (cse_var_144 + 90)
        let cse_var_44: int32 = (cse_var_144 + 9)
        let cse_var_43: int32 = (cse_var_144 + 89)
        let cse_var_42: int32 = (cse_var_144 + 88)
        let cse_var_41: int32 = (cse_var_144 + 87)
        let cse_var_40: int32 = (cse_var_144 + 86)
        let cse_var_39: int32 = (cse_var_144 + 85)
        let cse_var_38: int32 = (cse_var_144 + 84)
        let cse_var_37: int32 = (cse_var_144 + 91)
        let cse_var_36: int32 = (cse_var_144 + 50)
        let cse_var_35: int32 = (cse_var_144 + 5)
        let cse_var_34: int32 = (cse_var_144 + 49)
        let cse_var_33: int32 = (cse_var_144 + 48)
        let cse_var_32: int32 = (cse_var_144 + 47)
        let cse_var_31: int32 = (cse_var_144 + 46)
        let cse_var_30: int32 = (cse_var_144 + 45)
        let cse_var_29: int32 = (cse_var_144 + 44)
        let cse_var_28: int32 = (cse_var_144 + 68)
        let cse_var_27: int32 = (cse_var_144 + 42)
        let cse_var_26: int32 = (cse_var_144 + 41)
        let cse_var_25: int32 = (cse_var_144 + 40)
        let cse_var_24: int32 = (cse_var_144 + 4)
        let cse_var_23: int32 = (cse_var_144 + 39)
        let cse_var_22: int32 = (cse_var_144 + 38)
        let cse_var_21: int32 = (cse_var_144 + 37)
        let cse_var_20: int32 = (cse_var_144 + 36)
        let cse_var_19: int32 = (cse_var_144 + 43)
        let cse_var_18: int32 = (cse_var_144 + 67)
        let cse_var_17: int32 = (cse_var_144 + 66)
        let cse_var_16: int32 = (cse_var_144 + 65)
        let cse_var_15: int32 = (cse_var_144 + 64)
        let cse_var_14: int32 = (cse_var_144 + 63)
        let cse_var_13: int32 = (cse_var_144 + 62)
        let cse_var_12: int32 = (cse_var_144 + 61)
        let cse_var_11: int32 = (cse_var_144 + 60)
        let cse_var_10: int32 = (cse_var_144 + 51)
        let cse_var_9: int32 = (cse_var_144 + 59)
        let cse_var_8: int32 = (cse_var_144 + 58)
        let cse_var_7: int32 = (cse_var_144 + 57)
        let cse_var_6: int32 = (cse_var_144 + 56)
        let cse_var_5: int32 = (cse_var_144 + 55)
        let cse_var_4: int32 = (cse_var_144 + 54)
        let cse_var_3: int32 = (cse_var_144 + 53)
        let cse_var_2: int32 = (cse_var_144 + 52)
        let cse_var_1: int32 = (cse_var_144 + 6)
         {
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_144], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_140], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_123], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_33], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_15], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_69], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_51], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_144], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_140], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_123], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_33], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_15], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_69], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_51], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_85], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_141], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_124], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_34], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_16], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_70], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_52], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_85], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_141], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_124], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_34], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_16], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_70], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_52], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_109], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_126], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_99], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_36], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_17], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_71], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_53], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_109], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_126], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_99], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_36], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_17], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_71], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_53], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_120], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_142], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_125], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_10], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_18], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_46], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_54], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_120], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_142], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_125], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_10], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_18], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_46], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_54], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_24], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_110], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_20], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_28], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_38], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_87], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_24], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_110], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_20], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_28], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_38], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_87], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_35], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_111], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_21], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_56], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_39], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_88], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_35], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_111], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_21], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_56], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_39], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_88], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_112], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_22], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_58], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_40], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_89], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_112], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_22], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_58], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_40], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_89], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_57], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_113], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_23], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_59], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_41], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_127], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_57], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_113], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_23], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_59], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_41], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_127], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_68], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_114], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_25], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_60], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_42], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_117], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_68], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_114], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_25], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_60], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_42], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_117], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_44], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_115], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_26], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_61], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_43], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_128], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_44], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_115], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_26], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_61], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_43], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_128], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_86], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_116], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_27], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_62], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_45], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_129], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_86], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_116], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_27], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_62], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_45], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_129], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_133], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_108], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_19], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_9], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_63], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_37], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_130], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_133], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_108], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_19], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_9], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_63], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_37], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_130], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_136], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_118], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_29], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_11], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_55], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_47], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_131], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_136], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_118], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_29], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_11], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_55], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_47], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_131], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_137], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_119], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_30], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_12], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_65], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_48], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_132], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_137], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_119], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_30], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_12], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_65], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_48], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_132], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_138], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_121], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_31], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_13], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_66], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_49], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_134], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_138], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_121], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_31], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_13], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_66], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_49], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_134], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_139], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_122], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_32], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_14], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_67], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_50], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_135], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_139], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_122], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_32], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_14], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_67], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_50], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_135], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_146: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)
          let cse_var_145: int32 = ((cse_var_146*32) + (ax1.inner*16))
          T_relu[ramp(((((cse_var_146*1568) + (ax1.inner*784)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)*112)) + (ax3.inner*16)), 1, 16)] = max((((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(cse_var_145, 1, 16)])*placeholder_3[ramp(cse_var_145, 1, 16)]) + placeholder_4[ramp(cse_var_145, 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 44: vm_mod_fused_nn_avg_pool2d_4 (weight 1 key: ["712badddce997fd3a780b8d35d27ba51", [1, 64, 7, 7, 16], [1, 64, 1, 1, 16]]) =====
placeholder = PLACEHOLDER [1, 64, 7, 7, 16]
tensor(ax0, ax1, ax2, ax3, ax4) += placeholder[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]
tensor(ax0, ax1, ax2, ax3, ax4) = (tensor[ax0, ax1, ax2, ax3, ax4]/float32(max((((min((ax2 + 6), 6) - (ax2 + max((0 - ax2), 0))) + 1)*((min((ax3 + 6), 6) - (ax3 + max((0 - ax3), 0))) + 1)), 1)))


Trace for this task is: 
tensor_ax0, tensor_ax1, tensor_ax2, tensor_ax3, tensor_ax4, tensor_rv0, tensor_rv1 = tuple(tensor.op.axis) + tuple(tensor.op.reduce_axis)
tensor_ax0, tensor_ax1, tensor_ax2, tensor_ax3, tensor_ax4 = tuple(tensor.op.axis) + tuple(tensor.op.reduce_axis)
s[tensor].compute_root()
s[tensor].compute_at(s[tensor], tensor_ax2)
tensor_ax0_ax1_fused_ax2_fused = s[tensor].fuse(tensor_ax0, tensor_ax1, tensor_ax2)
s[tensor].parallel(tensor_ax0_ax1_fused_ax2_fused)
s[tensor].pragma(tensor_ax0, "auto_unroll_max_step", 512)
s[tensor].pragma(tensor_ax0, "unroll_explicit", True)
s[tensor].vectorize(tensor_ax4)


The best replacement found is:
@main = primfn(placeholder_1: handle, tensor_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_2: Pointer(float32), float32, [50176], []),
             tensor: Buffer(tensor_2: Pointer(float32), float32, [1024], [])}
  buffer_map = {placeholder_1: placeholder, tensor_1: tensor}
  preflattened_buffer_map = {placeholder_1: placeholder_3: Buffer(placeholder_2, float32, [1, 64, 7, 7, 16], []), tensor_1: tensor_3: Buffer(tensor_2, float32, [1, 64, 1, 1, 16], [])} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 64) "parallel" {
    allocate(tensor_4: Pointer(global float32), float32, [16]), storage_scope = global {
      for (ax4: int32, 0, 16) {
        let cse_var_1: int32 = ((ax0.ax1.fused.ax2.fused*784) + ax4)
         {
          tensor_5: Buffer(tensor_4, float32, [16], [], align=64)[ax4] = 0f32
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[cse_var_1])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 16)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 32)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 48)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 64)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 80)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 96)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 112)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 128)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 144)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 160)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 176)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 192)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 208)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 224)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 240)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 256)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 272)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 288)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 304)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 320)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 336)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 352)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 368)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 384)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 400)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 416)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 432)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 448)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 464)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 480)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 496)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 512)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 528)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 544)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 560)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 576)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 592)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 608)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 624)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 640)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 656)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 672)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 688)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 704)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 720)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 736)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 752)])
          tensor_5[ax4] = (tensor_5[ax4] + placeholder[(cse_var_1 + 768)])
        }
      }
      tensor[ramp((ax0.ax1.fused.ax2.fused*16), 1, 16)] = (tensor_5[ramp(0, 1, 16)]*broadcast(0.0204082f32, 16))
    }
  }
}


==== Task 45: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15 (weight 3 key: ["f6615ae9259e3b2add2908c0cd980cb6", [1, 64, 7, 7, 16], [12, 64, 1, 1, 16, 16], [1, 12, 1, 1, 16], [1, 12, 7, 7, 16]]) =====
placeholder = PLACEHOLDER [1, 64, 7, 7, 16]
placeholder = PLACEHOLDER [12, 64, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=1)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=1)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=1)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 512)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_6: Pointer(float32), float32, [50176], []),
             placeholder_1: Buffer(placeholder_7: Pointer(float32), float32, [196608], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [192], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [9408], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_3: placeholder_9: Buffer(placeholder_6, float32, [1, 64, 7, 7, 16], []), placeholder_4: placeholder_10: Buffer(placeholder_7, float32, [12, 64, 1, 1, 16, 16], []), placeholder_5: placeholder_11: Buffer(placeholder_8, float32, [1, 12, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 12, 7, 7, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused: int32, 0, 42) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 64) {
        let cse_var_144: int32 = ((ic.outer*784) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused, 7)*112))
        let cse_var_143: int32 = ((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused, 7)*32768) + (ic.outer*256))
        let cse_var_142: int32 = (cse_var_144 + 19)
        let cse_var_141: int32 = (cse_var_144 + 17)
        let cse_var_140: int32 = (cse_var_144 + 16)
        let cse_var_139: int32 = (cse_var_144 + 15)
        let cse_var_138: int32 = (cse_var_144 + 14)
        let cse_var_137: int32 = (cse_var_144 + 13)
        let cse_var_136: int32 = (cse_var_144 + 12)
        let cse_var_135: int32 = (cse_var_144 + 111)
        let cse_var_134: int32 = (cse_var_144 + 110)
        let cse_var_133: int32 = (cse_var_144 + 11)
        let cse_var_132: int32 = (cse_var_144 + 109)
        let cse_var_131: int32 = (cse_var_144 + 108)
        let cse_var_130: int32 = (cse_var_144 + 107)
        let cse_var_129: int32 = (cse_var_144 + 106)
        let cse_var_128: int32 = (cse_var_144 + 105)
        let cse_var_127: int32 = (cse_var_144 + 103)
        let cse_var_126: int32 = (cse_var_144 + 18)
        let cse_var_125: int32 = (cse_var_144 + 35)
        let cse_var_124: int32 = (cse_var_144 + 33)
        let cse_var_123: int32 = (cse_var_144 + 32)
        let cse_var_122: int32 = (cse_var_144 + 31)
        let cse_var_121: int32 = (cse_var_144 + 30)
        let cse_var_120: int32 = (cse_var_144 + 3)
        let cse_var_119: int32 = (cse_var_144 + 29)
        let cse_var_118: int32 = (cse_var_144 + 28)
        let cse_var_117: int32 = (cse_var_144 + 104)
        let cse_var_116: int32 = (cse_var_144 + 26)
        let cse_var_115: int32 = (cse_var_144 + 25)
        let cse_var_114: int32 = (cse_var_144 + 24)
        let cse_var_113: int32 = (cse_var_144 + 23)
        let cse_var_112: int32 = (cse_var_144 + 22)
        let cse_var_111: int32 = (cse_var_144 + 21)
        let cse_var_110: int32 = (cse_var_144 + 20)
        let cse_var_109: int32 = (cse_var_144 + 2)
        let cse_var_108: int32 = (cse_var_144 + 27)
        let cse_var_107: int32 = (cse_var_143 + 16576)
        let cse_var_106: int32 = (cse_var_143 + 16560)
        let cse_var_105: int32 = (cse_var_143 + 16544)
        let cse_var_104: int32 = (cse_var_143 + 16528)
        let cse_var_103: int32 = (cse_var_143 + 16512)
        let cse_var_102: int32 = (cse_var_143 + 16496)
        let cse_var_101: int32 = (cse_var_143 + 16480)
        let cse_var_100: int32 = (cse_var_143 + 16464)
        let cse_var_99: int32 = (cse_var_144 + 34)
        let cse_var_98: int32 = (cse_var_143 + 16432)
        let cse_var_97: int32 = (cse_var_143 + 16416)
        let cse_var_96: int32 = (cse_var_143 + 16400)
        let cse_var_95: int32 = (cse_var_143 + 16384)
        let cse_var_94: int32 = (cse_var_143 + 160)
        let cse_var_93: int32 = (cse_var_143 + 16)
        let cse_var_92: int32 = (cse_var_143 + 144)
        let cse_var_91: int32 = (cse_var_143 + 112)
        let cse_var_90: int32 = (cse_var_143 + 16448)
        let cse_var_89: int32 = (cse_var_144 + 102)
        let cse_var_88: int32 = (cse_var_144 + 101)
        let cse_var_87: int32 = (cse_var_144 + 100)
        let cse_var_86: int32 = (cse_var_144 + 10)
        let cse_var_85: int32 = (cse_var_144 + 1)
        let cse_var_84: int32 = (cse_var_143 + 96)
        let cse_var_83: int32 = (cse_var_143 + 80)
        let cse_var_82: int32 = (cse_var_143 + 64)
        let cse_var_81: int32 = (cse_var_143 + 16592)
        let cse_var_80: int32 = (cse_var_143 + 32)
        let cse_var_79: int32 = (cse_var_143 + 240)
        let cse_var_78: int32 = (cse_var_143 + 224)
        let cse_var_77: int32 = (cse_var_143 + 208)
        let cse_var_76: int32 = (cse_var_143 + 192)
        let cse_var_75: int32 = (cse_var_143 + 176)
        let cse_var_74: int32 = (cse_var_143 + 16624)
        let cse_var_73: int32 = (cse_var_143 + 16608)
        let cse_var_72: int32 = (cse_var_143 + 48)
        let cse_var_71: int32 = (cse_var_144 + 82)
        let cse_var_70: int32 = (cse_var_144 + 81)
        let cse_var_69: int32 = (cse_var_144 + 80)
        let cse_var_68: int32 = (cse_var_144 + 8)
        let cse_var_67: int32 = (cse_var_144 + 79)
        let cse_var_66: int32 = (cse_var_144 + 78)
        let cse_var_65: int32 = (cse_var_144 + 77)
        let cse_var_64: int32 = (cse_var_143 + 128)
        let cse_var_63: int32 = (cse_var_144 + 75)
        let cse_var_62: int32 = (cse_var_144 + 74)
        let cse_var_61: int32 = (cse_var_144 + 73)
        let cse_var_60: int32 = (cse_var_144 + 72)
        let cse_var_59: int32 = (cse_var_144 + 71)
        let cse_var_58: int32 = (cse_var_144 + 70)
        let cse_var_57: int32 = (cse_var_144 + 7)
        let cse_var_56: int32 = (cse_var_144 + 69)
        let cse_var_55: int32 = (cse_var_144 + 76)
        let cse_var_54: int32 = (cse_var_144 + 99)
        let cse_var_53: int32 = (cse_var_144 + 98)
        let cse_var_52: int32 = (cse_var_144 + 97)
        let cse_var_51: int32 = (cse_var_144 + 96)
        let cse_var_50: int32 = (cse_var_144 + 95)
        let cse_var_49: int32 = (cse_var_144 + 94)
        let cse_var_48: int32 = (cse_var_144 + 93)
        let cse_var_47: int32 = (cse_var_144 + 92)
        let cse_var_46: int32 = (cse_var_144 + 83)
        let cse_var_45: int32 = (cse_var_144 + 90)
        let cse_var_44: int32 = (cse_var_144 + 9)
        let cse_var_43: int32 = (cse_var_144 + 89)
        let cse_var_42: int32 = (cse_var_144 + 88)
        let cse_var_41: int32 = (cse_var_144 + 87)
        let cse_var_40: int32 = (cse_var_144 + 86)
        let cse_var_39: int32 = (cse_var_144 + 85)
        let cse_var_38: int32 = (cse_var_144 + 84)
        let cse_var_37: int32 = (cse_var_144 + 91)
        let cse_var_36: int32 = (cse_var_144 + 50)
        let cse_var_35: int32 = (cse_var_144 + 5)
        let cse_var_34: int32 = (cse_var_144 + 49)
        let cse_var_33: int32 = (cse_var_144 + 48)
        let cse_var_32: int32 = (cse_var_144 + 47)
        let cse_var_31: int32 = (cse_var_144 + 46)
        let cse_var_30: int32 = (cse_var_144 + 45)
        let cse_var_29: int32 = (cse_var_144 + 44)
        let cse_var_28: int32 = (cse_var_144 + 68)
        let cse_var_27: int32 = (cse_var_144 + 42)
        let cse_var_26: int32 = (cse_var_144 + 41)
        let cse_var_25: int32 = (cse_var_144 + 40)
        let cse_var_24: int32 = (cse_var_144 + 4)
        let cse_var_23: int32 = (cse_var_144 + 39)
        let cse_var_22: int32 = (cse_var_144 + 38)
        let cse_var_21: int32 = (cse_var_144 + 37)
        let cse_var_20: int32 = (cse_var_144 + 36)
        let cse_var_19: int32 = (cse_var_144 + 43)
        let cse_var_18: int32 = (cse_var_144 + 67)
        let cse_var_17: int32 = (cse_var_144 + 66)
        let cse_var_16: int32 = (cse_var_144 + 65)
        let cse_var_15: int32 = (cse_var_144 + 64)
        let cse_var_14: int32 = (cse_var_144 + 63)
        let cse_var_13: int32 = (cse_var_144 + 62)
        let cse_var_12: int32 = (cse_var_144 + 61)
        let cse_var_11: int32 = (cse_var_144 + 60)
        let cse_var_10: int32 = (cse_var_144 + 51)
        let cse_var_9: int32 = (cse_var_144 + 59)
        let cse_var_8: int32 = (cse_var_144 + 58)
        let cse_var_7: int32 = (cse_var_144 + 57)
        let cse_var_6: int32 = (cse_var_144 + 56)
        let cse_var_5: int32 = (cse_var_144 + 55)
        let cse_var_4: int32 = (cse_var_144 + 54)
        let cse_var_3: int32 = (cse_var_144 + 53)
        let cse_var_2: int32 = (cse_var_144 + 52)
        let cse_var_1: int32 = (cse_var_144 + 6)
         {
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_144], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_140], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_123], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_33], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_15], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_69], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_51], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_144], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_140], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_123], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_33], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_15], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_69], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_51], 16)*placeholder_1[ramp(cse_var_95, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_85], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_141], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_124], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_34], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_16], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_70], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_52], 16)*placeholder_1[ramp(cse_var_93, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_85], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_141], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_124], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_34], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_16], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_70], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_52], 16)*placeholder_1[ramp(cse_var_96, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_109], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_126], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_99], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_36], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_17], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_71], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_53], 16)*placeholder_1[ramp(cse_var_80, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_109], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_126], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_99], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_36], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_17], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_71], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_53], 16)*placeholder_1[ramp(cse_var_97, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_120], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_142], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_125], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_10], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_18], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_46], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_54], 16)*placeholder_1[ramp(cse_var_72, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_120], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_142], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_125], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_10], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_18], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_46], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_54], 16)*placeholder_1[ramp(cse_var_98, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_24], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_110], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_20], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_28], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_38], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_87], 16)*placeholder_1[ramp(cse_var_82, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_24], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_110], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_20], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_28], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_38], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_87], 16)*placeholder_1[ramp(cse_var_90, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_35], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_111], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_21], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_56], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_39], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_88], 16)*placeholder_1[ramp(cse_var_83, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_35], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_111], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_21], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_56], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_39], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_88], 16)*placeholder_1[ramp(cse_var_100, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_112], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_22], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_58], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_40], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_89], 16)*placeholder_1[ramp(cse_var_84, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_112], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_22], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_58], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_40], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_89], 16)*placeholder_1[ramp(cse_var_101, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_57], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_113], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_23], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_59], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_41], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_127], 16)*placeholder_1[ramp(cse_var_91, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_57], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_113], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_23], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_59], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_41], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_127], 16)*placeholder_1[ramp(cse_var_102, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_68], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_114], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_25], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_60], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_42], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_117], 16)*placeholder_1[ramp(cse_var_64, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_68], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_114], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_25], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_60], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_42], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_117], 16)*placeholder_1[ramp(cse_var_103, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_44], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_115], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_26], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_61], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_43], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_128], 16)*placeholder_1[ramp(cse_var_92, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_44], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_115], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_26], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_61], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_43], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_128], 16)*placeholder_1[ramp(cse_var_104, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_86], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_116], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_27], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_62], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_45], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_129], 16)*placeholder_1[ramp(cse_var_94, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_86], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_116], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_27], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_62], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_45], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_129], 16)*placeholder_1[ramp(cse_var_105, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_133], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_108], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_19], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_9], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_63], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_37], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_130], 16)*placeholder_1[ramp(cse_var_75, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_133], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_108], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_19], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_9], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_63], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_37], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_130], 16)*placeholder_1[ramp(cse_var_106, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_136], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_118], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_29], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_11], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_55], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_47], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_131], 16)*placeholder_1[ramp(cse_var_76, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_136], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_118], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_29], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_11], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_55], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_47], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_131], 16)*placeholder_1[ramp(cse_var_107, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_137], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_119], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_30], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_12], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_65], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_48], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_132], 16)*placeholder_1[ramp(cse_var_77, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_137], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_119], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_30], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_12], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_65], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_48], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_132], 16)*placeholder_1[ramp(cse_var_81, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_138], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_121], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_31], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_13], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_66], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_49], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_134], 16)*placeholder_1[ramp(cse_var_78, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_138], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_121], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_31], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_13], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_66], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_49], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_134], 16)*placeholder_1[ramp(cse_var_73, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_139], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_122], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_32], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_14], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_67], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_50], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_135], 16)*placeholder_1[ramp(cse_var_79, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_139], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_122], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_32], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_14], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_67], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_50], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_135], 16)*placeholder_1[ramp(cse_var_74, 1, 16)]))
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_145: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused, 7)
          T_relu[ramp(((((cse_var_145*1568) + (ax1.inner*784)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused, 7)*112)) + (ax3.inner*16)), 1, 16)] = max((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(((cse_var_145*32) + (ax1.inner*16)), 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 46: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_20 (weight 1 key: ["6b0d226afab7de584e086dc68f47c79a", [1, 8, 14, 14, 16], [12, 8, 3, 3, 16, 16], [1, 12, 1, 1, 16], [1, 12, 1, 1, 16], [1, 12, 1, 1, 16], [1, 12, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 8, 14, 14, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 15)) && (i3 >= 1)) && (i3 < 15)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [12, 8, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3, data_pad_i4 = tuple(data_pad.op.axis) + tuple(data_pad.op.reduce_axis)
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=6)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=14)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=2)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=3)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=6)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=14)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=2)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
s[data_pad].compute_at(s[conv2d_NCHWc], conv2d_NCHWc_kh_o)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 64)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[data_pad].vectorize(data_pad_i4)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [25088], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [221184], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [192], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [192], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [192], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [37632], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_8: placeholder_15: Buffer(placeholder_13, float32, [1, 12, 1, 1, 16], []), placeholder_9: placeholder_16: Buffer(placeholder_14, float32, [1, 12, 1, 1, 16], []), placeholder_6: placeholder_17: Buffer(placeholder_11, float32, [12, 8, 3, 3, 16, 16], []), placeholder_5: placeholder_18: Buffer(placeholder_10, float32, [1, 8, 14, 14, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 12, 14, 14, 16], []), placeholder_7: placeholder_19: Buffer(placeholder_12, float32, [1, 12, 1, 1, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 168) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global;
    allocate(data_pad: Pointer(global float32), float32, [144]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 8) {
        for (kh.outer: int32, 0, 3) {
          let cse_var_5: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)
          let cse_var_4: int32 = (floordiv(cse_var_5, 2) + kh.outer)
          let cse_var_3: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 2)
          let cse_var_2: int32 = (((ic.outer*3136) + (kh.outer*224)) + (cse_var_5*112))
          let cse_var_1: bool = ((1 <= cse_var_4) && (cse_var_4 < 15))
           {
            data_pad_1: Buffer(data_pad, float32, [144], [])[ramp(0, 1, 16)] = @tir.if_then_else((cse_var_1 && (1 <= cse_var_3)), placeholder[ramp((cse_var_2 - 240), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(16, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 224), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(32, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 208), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(48, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 192), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(64, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 176), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(80, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 160), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(96, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 144), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(112, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 128), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(128, 1, 16)] = @tir.if_then_else((cse_var_1 && (cse_var_3 < 1)), placeholder[ramp((cse_var_2 - 112), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            for (ic.inner: int32, 0, 16) {
              let cse_var_19: int32 = (ic.inner + 96)
              let cse_var_18: int32 = (ic.inner + 80)
              let cse_var_17: int32 = (ic.inner + 64)
              let cse_var_16: int32 = (ic.inner + 48)
              let cse_var_15: int32 = (ic.inner + 32)
              let cse_var_14: int32 = (ic.inner + 16)
              let cse_var_13: int32 = (ic.inner + 128)
              let cse_var_12: int32 = (ic.inner + 112)
              let cse_var_11: int32 = ((((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)*36864) + (ic.outer*2304)) + (kh.outer*768)) + (ic.inner*16))
              let cse_var_10: int32 = (cse_var_11 + 512)
              let cse_var_9: int32 = (cse_var_11 + 256)
              let cse_var_8: int32 = (cse_var_11 + 18944)
              let cse_var_7: int32 = (cse_var_11 + 18688)
              let cse_var_6: int32 = (cse_var_11 + 18432)
               {
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
              }
            }
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_21: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)
          let cse_var_20: int32 = ((cse_var_21*32) + (ax1.inner*16))
          T_relu[ramp(((((cse_var_21*6272) + (ax1.inner*3136)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)*112)) + (ax3.inner*16)), 1, 16)] = max((((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(cse_var_20, 1, 16)])*placeholder_3[ramp(cse_var_20, 1, 16)]) + placeholder_4[ramp(cse_var_20, 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 47: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_13 (weight 2 key: ["9db1fd34470fc877a2c0431d681f01a4", [1, 36, 14, 14, 16], [8, 36, 1, 1, 16, 16], [1, 8, 1, 1, 16], [1, 8, 1, 1, 16], [1, 8, 1, 1, 16], [1, 8, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 36, 14, 14, 16]
placeholder = PLACEHOLDER [8, 36, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 8, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=4)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=14)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=2)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=8)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=4)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=14)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=2)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 16)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [112896], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [73728], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [128], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [128], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [128], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [25088], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_5: placeholder_15: Buffer(placeholder_10, float32, [1, 36, 14, 14, 16], []), placeholder_9: placeholder_16: Buffer(placeholder_14, float32, [1, 8, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 8, 14, 14, 16], []), placeholder_7: placeholder_17: Buffer(placeholder_12, float32, [1, 8, 1, 1, 16], []), placeholder_6: placeholder_18: Buffer(placeholder_11, float32, [8, 36, 1, 1, 16, 16], []), placeholder_8: placeholder_19: Buffer(placeholder_13, float32, [1, 8, 1, 1, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 112) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 72) {
        for (ic.inner: int32, 0, 8) {
          let cse_var_9: int32 = (((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)*18432) + (ic.outer*128)) + (ic.inner*16))
          let cse_var_8: int32 = (cse_var_9 + 9216)
          let cse_var_7: int32 = ((((floordiv(ic.outer, 2)*3136) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)*112)) + (floormod(ic.outer, 2)*8)) + ic.inner)
          let cse_var_6: int32 = (cse_var_7 + 96)
          let cse_var_5: int32 = (cse_var_7 + 80)
          let cse_var_4: int32 = (cse_var_7 + 64)
          let cse_var_3: int32 = (cse_var_7 + 48)
          let cse_var_2: int32 = (cse_var_7 + 32)
          let cse_var_1: int32 = (cse_var_7 + 16)
           {
            conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
            conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_11: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)
          let cse_var_10: int32 = ((cse_var_11*32) + (ax1.inner*16))
          T_relu[ramp(((((cse_var_11*6272) + (ax1.inner*3136)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)*112)) + (ax3.inner*16)), 1, 16)] = max((((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(cse_var_10, 1, 16)])*placeholder_3[ramp(cse_var_10, 1, 16)]) + placeholder_4[ramp(cse_var_10, 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 48: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_3 (weight 1 key: ["6b0d226afab7de584e086dc68f47c79a", [1, 4, 28, 28, 16], [4, 4, 3, 3, 16, 16], [1, 4, 1, 1, 16], [1, 4, 1, 1, 16], [1, 4, 1, 1, 16], [1, 4, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 4, 28, 28, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 29)) && (i3 >= 1)) && (i3 < 29)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [4, 4, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3, data_pad_i4 = tuple(data_pad.op.axis) + tuple(data_pad.op.reduce_axis)
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=2)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=3)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=1)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=2)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
s[data_pad].compute_at(s[conv2d_NCHWc], conv2d_NCHWc_kh_o)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 64)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[data_pad].vectorize(data_pad_i4)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [50176], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [36864], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [64], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [64], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [64], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [50176], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_6: placeholder_15: Buffer(placeholder_11, float32, [4, 4, 3, 3, 16, 16], []), placeholder_5: placeholder_16: Buffer(placeholder_10, float32, [1, 4, 28, 28, 16], []), placeholder_7: placeholder_17: Buffer(placeholder_12, float32, [1, 4, 1, 1, 16], []), placeholder_9: placeholder_18: Buffer(placeholder_14, float32, [1, 4, 1, 1, 16], []), placeholder_8: placeholder_19: Buffer(placeholder_13, float32, [1, 4, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 4, 28, 28, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 224) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global;
    allocate(data_pad: Pointer(global float32), float32, [144]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 4) {
        for (kh.outer: int32, 0, 3) {
          let cse_var_5: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 112)
          let cse_var_4: int32 = (floordiv(cse_var_5, 4) + kh.outer)
          let cse_var_3: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 4)
          let cse_var_2: int32 = (((ic.outer*12544) + (kh.outer*448)) + (cse_var_5*112))
          let cse_var_1: bool = ((1 <= cse_var_4) && (cse_var_4 < 29))
           {
            data_pad_1: Buffer(data_pad, float32, [144], [])[ramp(0, 1, 16)] = @tir.if_then_else((cse_var_1 && (1 <= cse_var_3)), placeholder[ramp((cse_var_2 - 464), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(16, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 448), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(32, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 432), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(48, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 416), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(64, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 400), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(80, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 384), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(96, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 368), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(112, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 352), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(128, 1, 16)] = @tir.if_then_else((cse_var_1 && (cse_var_3 < 3)), placeholder[ramp((cse_var_2 - 336), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            for (ic.inner: int32, 0, 16) {
              let cse_var_19: int32 = (ic.inner + 96)
              let cse_var_18: int32 = (ic.inner + 80)
              let cse_var_17: int32 = (ic.inner + 64)
              let cse_var_16: int32 = (ic.inner + 48)
              let cse_var_15: int32 = (ic.inner + 32)
              let cse_var_14: int32 = (ic.inner + 16)
              let cse_var_13: int32 = (ic.inner + 128)
              let cse_var_12: int32 = (ic.inner + 112)
              let cse_var_11: int32 = ((((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 112)*18432) + (ic.outer*2304)) + (kh.outer*768)) + (ic.inner*16))
              let cse_var_10: int32 = (cse_var_11 + 9728)
              let cse_var_9: int32 = (cse_var_11 + 9472)
              let cse_var_8: int32 = (cse_var_11 + 9216)
              let cse_var_7: int32 = (cse_var_11 + 512)
              let cse_var_6: int32 = (cse_var_11 + 256)
               {
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
              }
            }
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_21: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 112)
          let cse_var_20: int32 = ((cse_var_21*32) + (ax1.inner*16))
          T_relu[ramp(((((cse_var_21*25088) + (ax1.inner*12544)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 112)*112)) + (ax3.inner*16)), 1, 16)] = max((((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(cse_var_20, 1, 16)])*placeholder_3[ramp(cse_var_20, 1, 16)]) + placeholder_4[ramp(cse_var_20, 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 49: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_26 (weight 2 key: ["6b0d226afab7de584e086dc68f47c79a", [1, 14, 7, 7, 16], [14, 14, 3, 3, 16, 16], [1, 14, 1, 1, 16], [1, 14, 1, 1, 16], [1, 14, 1, 1, 16], [1, 14, 7, 7, 16]]) =====
placeholder = PLACEHOLDER [1, 14, 7, 7, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 8)) && (i3 >= 1)) && (i3 < 8)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [14, 14, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 14, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 14, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 14, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3, data_pad_i4 = tuple(data_pad.op.axis) + tuple(data_pad.op.reduce_axis)
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=1)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=3)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=1)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=1)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
s[data_pad].compute_at(s[conv2d_NCHWc], conv2d_NCHWc_n_o_o_i)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 512)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[data_pad].vectorize(data_pad_i4)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [10976], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [451584], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [224], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [224], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [224], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [10976], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_8: placeholder_15: Buffer(placeholder_13, float32, [1, 14, 1, 1, 16], []), placeholder_7: placeholder_16: Buffer(placeholder_12, float32, [1, 14, 1, 1, 16], []), placeholder_5: placeholder_17: Buffer(placeholder_10, float32, [1, 14, 7, 7, 16], []), placeholder_9: placeholder_18: Buffer(placeholder_14, float32, [1, 14, 1, 1, 16], []), placeholder_6: placeholder_19: Buffer(placeholder_11, float32, [14, 14, 3, 3, 16, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 14, 7, 7, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 49) "parallel" {
    let cse_var_4: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)
    let cse_var_3: int32 = (cse_var_4*112)
    let cse_var_2: bool = (cse_var_4 < 6)
    let cse_var_1: bool = (1 <= cse_var_4)
    allocate(data_pad: Pointer(global float32), float32, [6048]), storage_scope = global;
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global {
      data_pad_1: Buffer(data_pad, float32, [6048], [])[ramp(0, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(16, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 - 112), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(32, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 - 96), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(48, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 - 80), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(64, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 - 64), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(80, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 - 48), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(96, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 - 32), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(112, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 - 16), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(128, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(144, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(160, 1, 16)] = placeholder[ramp(cse_var_3, 1, 16)]
      data_pad_1[ramp(176, 1, 16)] = placeholder[ramp((cse_var_3 + 16), 1, 16)]
      data_pad_1[ramp(192, 1, 16)] = placeholder[ramp((cse_var_3 + 32), 1, 16)]
      data_pad_1[ramp(208, 1, 16)] = placeholder[ramp((cse_var_3 + 48), 1, 16)]
      data_pad_1[ramp(224, 1, 16)] = placeholder[ramp((cse_var_3 + 64), 1, 16)]
      data_pad_1[ramp(240, 1, 16)] = placeholder[ramp((cse_var_3 + 80), 1, 16)]
      data_pad_1[ramp(256, 1, 16)] = placeholder[ramp((cse_var_3 + 96), 1, 16)]
      data_pad_1[ramp(272, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(288, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(304, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 112), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(320, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 128), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(336, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 144), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(352, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 160), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(368, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 176), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(384, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 192), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(400, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 208), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(416, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(432, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(448, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 672), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(464, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 688), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(480, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 704), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(496, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 720), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(512, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 736), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(528, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 752), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(544, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 768), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(560, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(576, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(592, 1, 16)] = placeholder[ramp((cse_var_3 + 784), 1, 16)]
      data_pad_1[ramp(608, 1, 16)] = placeholder[ramp((cse_var_3 + 800), 1, 16)]
      data_pad_1[ramp(624, 1, 16)] = placeholder[ramp((cse_var_3 + 816), 1, 16)]
      data_pad_1[ramp(640, 1, 16)] = placeholder[ramp((cse_var_3 + 832), 1, 16)]
      data_pad_1[ramp(656, 1, 16)] = placeholder[ramp((cse_var_3 + 848), 1, 16)]
      data_pad_1[ramp(672, 1, 16)] = placeholder[ramp((cse_var_3 + 864), 1, 16)]
      data_pad_1[ramp(688, 1, 16)] = placeholder[ramp((cse_var_3 + 880), 1, 16)]
      data_pad_1[ramp(704, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(720, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(736, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 896), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(752, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 912), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(768, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 928), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(784, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 944), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(800, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 960), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(816, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 976), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(832, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 992), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(848, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(864, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(880, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 1456), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(896, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 1472), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(912, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 1488), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(928, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 1504), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(944, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 1520), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(960, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 1536), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(976, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 1552), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(992, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1008, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1024, 1, 16)] = placeholder[ramp((cse_var_3 + 1568), 1, 16)]
      data_pad_1[ramp(1040, 1, 16)] = placeholder[ramp((cse_var_3 + 1584), 1, 16)]
      data_pad_1[ramp(1056, 1, 16)] = placeholder[ramp((cse_var_3 + 1600), 1, 16)]
      data_pad_1[ramp(1072, 1, 16)] = placeholder[ramp((cse_var_3 + 1616), 1, 16)]
      data_pad_1[ramp(1088, 1, 16)] = placeholder[ramp((cse_var_3 + 1632), 1, 16)]
      data_pad_1[ramp(1104, 1, 16)] = placeholder[ramp((cse_var_3 + 1648), 1, 16)]
      data_pad_1[ramp(1120, 1, 16)] = placeholder[ramp((cse_var_3 + 1664), 1, 16)]
      data_pad_1[ramp(1136, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1152, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1168, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 1680), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1184, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 1696), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1200, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 1712), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1216, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 1728), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1232, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 1744), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1248, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 1760), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1264, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 1776), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1280, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1296, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1312, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 2240), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1328, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 2256), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1344, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 2272), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1360, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 2288), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1376, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 2304), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1392, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 2320), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1408, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 2336), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1424, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1440, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1456, 1, 16)] = placeholder[ramp((cse_var_3 + 2352), 1, 16)]
      data_pad_1[ramp(1472, 1, 16)] = placeholder[ramp((cse_var_3 + 2368), 1, 16)]
      data_pad_1[ramp(1488, 1, 16)] = placeholder[ramp((cse_var_3 + 2384), 1, 16)]
      data_pad_1[ramp(1504, 1, 16)] = placeholder[ramp((cse_var_3 + 2400), 1, 16)]
      data_pad_1[ramp(1520, 1, 16)] = placeholder[ramp((cse_var_3 + 2416), 1, 16)]
      data_pad_1[ramp(1536, 1, 16)] = placeholder[ramp((cse_var_3 + 2432), 1, 16)]
      data_pad_1[ramp(1552, 1, 16)] = placeholder[ramp((cse_var_3 + 2448), 1, 16)]
      data_pad_1[ramp(1568, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1584, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1600, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 2464), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1616, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 2480), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1632, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 2496), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1648, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 2512), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1664, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 2528), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1680, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 2544), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1696, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 2560), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1712, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1728, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1744, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3024), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1760, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3040), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1776, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3056), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1792, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3072), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1808, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3088), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1824, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3104), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1840, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3120), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(1856, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1872, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(1888, 1, 16)] = placeholder[ramp((cse_var_3 + 3136), 1, 16)]
      data_pad_1[ramp(1904, 1, 16)] = placeholder[ramp((cse_var_3 + 3152), 1, 16)]
      data_pad_1[ramp(1920, 1, 16)] = placeholder[ramp((cse_var_3 + 3168), 1, 16)]
      data_pad_1[ramp(1936, 1, 16)] = placeholder[ramp((cse_var_3 + 3184), 1, 16)]
      data_pad_1[ramp(1952, 1, 16)] = placeholder[ramp((cse_var_3 + 3200), 1, 16)]
      data_pad_1[ramp(1968, 1, 16)] = placeholder[ramp((cse_var_3 + 3216), 1, 16)]
      data_pad_1[ramp(1984, 1, 16)] = placeholder[ramp((cse_var_3 + 3232), 1, 16)]
      data_pad_1[ramp(2000, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2016, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2032, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 3248), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2048, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 3264), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2064, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 3280), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2080, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 3296), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2096, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 3312), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2112, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 3328), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2128, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 3344), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2144, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2160, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2176, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3808), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2192, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3824), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2208, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3840), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2224, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3856), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2240, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3872), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2256, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3888), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2272, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 3904), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2288, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2304, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2320, 1, 16)] = placeholder[ramp((cse_var_3 + 3920), 1, 16)]
      data_pad_1[ramp(2336, 1, 16)] = placeholder[ramp((cse_var_3 + 3936), 1, 16)]
      data_pad_1[ramp(2352, 1, 16)] = placeholder[ramp((cse_var_3 + 3952), 1, 16)]
      data_pad_1[ramp(2368, 1, 16)] = placeholder[ramp((cse_var_3 + 3968), 1, 16)]
      data_pad_1[ramp(2384, 1, 16)] = placeholder[ramp((cse_var_3 + 3984), 1, 16)]
      data_pad_1[ramp(2400, 1, 16)] = placeholder[ramp((cse_var_3 + 4000), 1, 16)]
      data_pad_1[ramp(2416, 1, 16)] = placeholder[ramp((cse_var_3 + 4016), 1, 16)]
      data_pad_1[ramp(2432, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2448, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2464, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4032), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2480, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4048), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2496, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4064), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2512, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4080), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2528, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4096), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2544, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4112), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2560, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4128), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2576, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2592, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2608, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 4592), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2624, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 4608), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2640, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 4624), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2656, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 4640), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2672, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 4656), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2688, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 4672), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2704, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 4688), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2720, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2736, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2752, 1, 16)] = placeholder[ramp((cse_var_3 + 4704), 1, 16)]
      data_pad_1[ramp(2768, 1, 16)] = placeholder[ramp((cse_var_3 + 4720), 1, 16)]
      data_pad_1[ramp(2784, 1, 16)] = placeholder[ramp((cse_var_3 + 4736), 1, 16)]
      data_pad_1[ramp(2800, 1, 16)] = placeholder[ramp((cse_var_3 + 4752), 1, 16)]
      data_pad_1[ramp(2816, 1, 16)] = placeholder[ramp((cse_var_3 + 4768), 1, 16)]
      data_pad_1[ramp(2832, 1, 16)] = placeholder[ramp((cse_var_3 + 4784), 1, 16)]
      data_pad_1[ramp(2848, 1, 16)] = placeholder[ramp((cse_var_3 + 4800), 1, 16)]
      data_pad_1[ramp(2864, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2880, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(2896, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4816), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2912, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4832), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2928, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4848), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2944, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4864), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2960, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4880), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2976, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4896), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(2992, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 4912), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3008, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3024, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3040, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 5376), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3056, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 5392), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3072, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 5408), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3088, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 5424), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3104, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 5440), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3120, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 5456), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3136, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 5472), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3152, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3168, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3184, 1, 16)] = placeholder[ramp((cse_var_3 + 5488), 1, 16)]
      data_pad_1[ramp(3200, 1, 16)] = placeholder[ramp((cse_var_3 + 5504), 1, 16)]
      data_pad_1[ramp(3216, 1, 16)] = placeholder[ramp((cse_var_3 + 5520), 1, 16)]
      data_pad_1[ramp(3232, 1, 16)] = placeholder[ramp((cse_var_3 + 5536), 1, 16)]
      data_pad_1[ramp(3248, 1, 16)] = placeholder[ramp((cse_var_3 + 5552), 1, 16)]
      data_pad_1[ramp(3264, 1, 16)] = placeholder[ramp((cse_var_3 + 5568), 1, 16)]
      data_pad_1[ramp(3280, 1, 16)] = placeholder[ramp((cse_var_3 + 5584), 1, 16)]
      data_pad_1[ramp(3296, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3312, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3328, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 5600), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3344, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 5616), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3360, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 5632), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3376, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 5648), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3392, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 5664), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3408, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 5680), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3424, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 5696), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3440, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3456, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3472, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 6160), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3488, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 6176), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3504, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 6192), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3520, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 6208), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3536, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 6224), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3552, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 6240), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3568, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 6256), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3584, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3600, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3616, 1, 16)] = placeholder[ramp((cse_var_3 + 6272), 1, 16)]
      data_pad_1[ramp(3632, 1, 16)] = placeholder[ramp((cse_var_3 + 6288), 1, 16)]
      data_pad_1[ramp(3648, 1, 16)] = placeholder[ramp((cse_var_3 + 6304), 1, 16)]
      data_pad_1[ramp(3664, 1, 16)] = placeholder[ramp((cse_var_3 + 6320), 1, 16)]
      data_pad_1[ramp(3680, 1, 16)] = placeholder[ramp((cse_var_3 + 6336), 1, 16)]
      data_pad_1[ramp(3696, 1, 16)] = placeholder[ramp((cse_var_3 + 6352), 1, 16)]
      data_pad_1[ramp(3712, 1, 16)] = placeholder[ramp((cse_var_3 + 6368), 1, 16)]
      data_pad_1[ramp(3728, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3744, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3760, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 6384), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3776, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 6400), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3792, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 6416), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3808, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 6432), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3824, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 6448), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3840, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 6464), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3856, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 6480), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3872, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3888, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(3904, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 6944), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3920, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 6960), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3936, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 6976), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3952, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 6992), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3968, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 7008), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(3984, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 7024), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4000, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 7040), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4016, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4032, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4048, 1, 16)] = placeholder[ramp((cse_var_3 + 7056), 1, 16)]
      data_pad_1[ramp(4064, 1, 16)] = placeholder[ramp((cse_var_3 + 7072), 1, 16)]
      data_pad_1[ramp(4080, 1, 16)] = placeholder[ramp((cse_var_3 + 7088), 1, 16)]
      data_pad_1[ramp(4096, 1, 16)] = placeholder[ramp((cse_var_3 + 7104), 1, 16)]
      data_pad_1[ramp(4112, 1, 16)] = placeholder[ramp((cse_var_3 + 7120), 1, 16)]
      data_pad_1[ramp(4128, 1, 16)] = placeholder[ramp((cse_var_3 + 7136), 1, 16)]
      data_pad_1[ramp(4144, 1, 16)] = placeholder[ramp((cse_var_3 + 7152), 1, 16)]
      data_pad_1[ramp(4160, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4176, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4192, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 7168), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4208, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 7184), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4224, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 7200), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4240, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 7216), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4256, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 7232), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4272, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 7248), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4288, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 7264), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4304, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4320, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4336, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 7728), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4352, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 7744), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4368, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 7760), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4384, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 7776), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4400, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 7792), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4416, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 7808), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4432, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 7824), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4448, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4464, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4480, 1, 16)] = placeholder[ramp((cse_var_3 + 7840), 1, 16)]
      data_pad_1[ramp(4496, 1, 16)] = placeholder[ramp((cse_var_3 + 7856), 1, 16)]
      data_pad_1[ramp(4512, 1, 16)] = placeholder[ramp((cse_var_3 + 7872), 1, 16)]
      data_pad_1[ramp(4528, 1, 16)] = placeholder[ramp((cse_var_3 + 7888), 1, 16)]
      data_pad_1[ramp(4544, 1, 16)] = placeholder[ramp((cse_var_3 + 7904), 1, 16)]
      data_pad_1[ramp(4560, 1, 16)] = placeholder[ramp((cse_var_3 + 7920), 1, 16)]
      data_pad_1[ramp(4576, 1, 16)] = placeholder[ramp((cse_var_3 + 7936), 1, 16)]
      data_pad_1[ramp(4592, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4608, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4624, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 7952), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4640, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 7968), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4656, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 7984), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4672, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 8000), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4688, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 8016), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4704, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 8032), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4720, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 8048), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4736, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4752, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4768, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 8512), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4784, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 8528), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4800, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 8544), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4816, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 8560), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4832, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 8576), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4848, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 8592), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4864, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 8608), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(4880, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4896, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(4912, 1, 16)] = placeholder[ramp((cse_var_3 + 8624), 1, 16)]
      data_pad_1[ramp(4928, 1, 16)] = placeholder[ramp((cse_var_3 + 8640), 1, 16)]
      data_pad_1[ramp(4944, 1, 16)] = placeholder[ramp((cse_var_3 + 8656), 1, 16)]
      data_pad_1[ramp(4960, 1, 16)] = placeholder[ramp((cse_var_3 + 8672), 1, 16)]
      data_pad_1[ramp(4976, 1, 16)] = placeholder[ramp((cse_var_3 + 8688), 1, 16)]
      data_pad_1[ramp(4992, 1, 16)] = placeholder[ramp((cse_var_3 + 8704), 1, 16)]
      data_pad_1[ramp(5008, 1, 16)] = placeholder[ramp((cse_var_3 + 8720), 1, 16)]
      data_pad_1[ramp(5024, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(5040, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(5056, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 8736), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5072, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 8752), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5088, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 8768), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5104, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 8784), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5120, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 8800), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5136, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 8816), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5152, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 8832), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5168, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(5184, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(5200, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 9296), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5216, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 9312), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5232, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 9328), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5248, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 9344), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5264, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 9360), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5280, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 9376), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5296, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 9392), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5312, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(5328, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(5344, 1, 16)] = placeholder[ramp((cse_var_3 + 9408), 1, 16)]
      data_pad_1[ramp(5360, 1, 16)] = placeholder[ramp((cse_var_3 + 9424), 1, 16)]
      data_pad_1[ramp(5376, 1, 16)] = placeholder[ramp((cse_var_3 + 9440), 1, 16)]
      data_pad_1[ramp(5392, 1, 16)] = placeholder[ramp((cse_var_3 + 9456), 1, 16)]
      data_pad_1[ramp(5408, 1, 16)] = placeholder[ramp((cse_var_3 + 9472), 1, 16)]
      data_pad_1[ramp(5424, 1, 16)] = placeholder[ramp((cse_var_3 + 9488), 1, 16)]
      data_pad_1[ramp(5440, 1, 16)] = placeholder[ramp((cse_var_3 + 9504), 1, 16)]
      data_pad_1[ramp(5456, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(5472, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(5488, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 9520), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5504, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 9536), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5520, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 9552), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5536, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 9568), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5552, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 9584), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5568, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 9600), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5584, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 9616), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5600, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(5616, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(5632, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 10080), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5648, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 10096), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5664, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 10112), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5680, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 10128), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5696, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 10144), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5712, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 10160), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5728, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_3 + 10176), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5744, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(5760, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(5776, 1, 16)] = placeholder[ramp((cse_var_3 + 10192), 1, 16)]
      data_pad_1[ramp(5792, 1, 16)] = placeholder[ramp((cse_var_3 + 10208), 1, 16)]
      data_pad_1[ramp(5808, 1, 16)] = placeholder[ramp((cse_var_3 + 10224), 1, 16)]
      data_pad_1[ramp(5824, 1, 16)] = placeholder[ramp((cse_var_3 + 10240), 1, 16)]
      data_pad_1[ramp(5840, 1, 16)] = placeholder[ramp((cse_var_3 + 10256), 1, 16)]
      data_pad_1[ramp(5856, 1, 16)] = placeholder[ramp((cse_var_3 + 10272), 1, 16)]
      data_pad_1[ramp(5872, 1, 16)] = placeholder[ramp((cse_var_3 + 10288), 1, 16)]
      data_pad_1[ramp(5888, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(5904, 1, 16)] = broadcast(0f32, 16)
      data_pad_1[ramp(5920, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 10304), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5936, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 10320), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5952, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 10336), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5968, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 10352), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(5984, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 10368), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(6000, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 10384), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(6016, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_3 + 10400), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
      data_pad_1[ramp(6032, 1, 16)] = broadcast(0f32, 16)
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 14) {
        for (kh.outer: int32, 0, 3) {
          for (ic.inner: int32, 0, 16) {
            let cse_var_19: int32 = (((ic.outer*432) + (kh.outer*144)) + ic.inner)
            let cse_var_18: int32 = (cse_var_19 + 96)
            let cse_var_17: int32 = (cse_var_19 + 80)
            let cse_var_16: int32 = (cse_var_19 + 64)
            let cse_var_15: int32 = (cse_var_19 + 48)
            let cse_var_14: int32 = (cse_var_19 + 32)
            let cse_var_13: int32 = (cse_var_19 + 16)
            let cse_var_12: int32 = (cse_var_19 + 128)
            let cse_var_11: int32 = (cse_var_19 + 112)
            let cse_var_10: int32 = ((((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)*64512) + (ic.outer*2304)) + (kh.outer*768)) + (ic.inner*16))
            let cse_var_9: int32 = (cse_var_10 + 512)
            let cse_var_8: int32 = (cse_var_10 + 32768)
            let cse_var_7: int32 = (cse_var_10 + 32512)
            let cse_var_6: int32 = (cse_var_10 + 32256)
            let cse_var_5: int32 = (cse_var_10 + 256)
             {
              conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
              conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
              conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
              conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
              conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
              conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
              conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
              conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
              conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
              conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
              conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
              conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
              conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
              conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
              conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
              conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
              conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
              conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
              conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
              conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
              conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_11], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
              conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
              conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
              conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
              conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
              conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
              conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
              conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_11], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
              conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
              conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
              conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
              conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
              conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
              conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_11], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
              conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
              conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
              conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
              conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
              conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
              conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
              conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_11], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
              conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
            }
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_21: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)
          let cse_var_20: int32 = ((cse_var_21*32) + (ax1.inner*16))
          T_relu[ramp(((((cse_var_21*1568) + (ax1.inner*784)) + cse_var_3) + (ax3.inner*16)), 1, 16)] = max((((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(cse_var_20, 1, 16)])*placeholder_3[ramp(cse_var_20, 1, 16)]) + placeholder_4[ramp(cse_var_20, 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 50: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_22 (weight 1 key: ["d85f86643f68d4261269b8274457244f", [1, 8, 14, 14, 16], [12, 8, 3, 3, 16, 16], [1, 12, 1, 1, 16], [1, 12, 1, 1, 16], [1, 12, 1, 1, 16], [1, 12, 7, 7, 16]]) =====
placeholder = PLACEHOLDER [1, 8, 14, 14, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 15)) && (i3 >= 1)) && (i3 < 15)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [12, 8, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), ((oh*2) + kh), ((ow*2) + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 12, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3, data_pad_i4 = tuple(data_pad.op.axis) + tuple(data_pad.op.reduce_axis)
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=7)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=1)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=7)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=3)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=7)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=1)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=1)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=7)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
s[data_pad].compute_at(s[conv2d_NCHWc], conv2d_NCHWc_ic_o)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 64)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[data_pad].vectorize(data_pad_i4)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [25088], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [221184], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [192], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [192], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [192], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [9408], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_6: placeholder_15: Buffer(placeholder_11, float32, [12, 8, 3, 3, 16, 16], []), placeholder_9: placeholder_16: Buffer(placeholder_14, float32, [1, 12, 1, 1, 16], []), placeholder_7: placeholder_17: Buffer(placeholder_12, float32, [1, 12, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 12, 7, 7, 16], []), placeholder_5: placeholder_18: Buffer(placeholder_10, float32, [1, 8, 14, 14, 16], []), placeholder_8: placeholder_19: Buffer(placeholder_13, float32, [1, 12, 1, 1, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 42) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global;
    allocate(data_pad: Pointer(global float32), float32, [720]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 8) {
        let cse_var_3: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)
        let cse_var_2: bool = (1 <= cse_var_3)
        let cse_var_1: int32 = ((ic.outer*3136) + (cse_var_3*32))
         {
          data_pad_1: Buffer(data_pad, float32, [720], [])[ramp(0, 1, 16)] = broadcast(0f32, 16)
          data_pad_1[ramp(16, 1, 16)] = broadcast(0f32, 16)
          data_pad_1[ramp(32, 1, 16)] = broadcast(0f32, 16)
          data_pad_1[ramp(48, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 16), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(64, 1, 16)] = placeholder[ramp(cse_var_1, 1, 16)]
          data_pad_1[ramp(80, 1, 16)] = placeholder[ramp((cse_var_1 + 16), 1, 16)]
          data_pad_1[ramp(96, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 208), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(112, 1, 16)] = placeholder[ramp((cse_var_1 + 224), 1, 16)]
          data_pad_1[ramp(128, 1, 16)] = placeholder[ramp((cse_var_1 + 240), 1, 16)]
          data_pad_1[ramp(144, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 432), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(160, 1, 16)] = placeholder[ramp((cse_var_1 + 448), 1, 16)]
          data_pad_1[ramp(176, 1, 16)] = placeholder[ramp((cse_var_1 + 464), 1, 16)]
          data_pad_1[ramp(192, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 656), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(208, 1, 16)] = placeholder[ramp((cse_var_1 + 672), 1, 16)]
          data_pad_1[ramp(224, 1, 16)] = placeholder[ramp((cse_var_1 + 688), 1, 16)]
          data_pad_1[ramp(240, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 880), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(256, 1, 16)] = placeholder[ramp((cse_var_1 + 896), 1, 16)]
          data_pad_1[ramp(272, 1, 16)] = placeholder[ramp((cse_var_1 + 912), 1, 16)]
          data_pad_1[ramp(288, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 1104), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(304, 1, 16)] = placeholder[ramp((cse_var_1 + 1120), 1, 16)]
          data_pad_1[ramp(320, 1, 16)] = placeholder[ramp((cse_var_1 + 1136), 1, 16)]
          data_pad_1[ramp(336, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 1328), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(352, 1, 16)] = placeholder[ramp((cse_var_1 + 1344), 1, 16)]
          data_pad_1[ramp(368, 1, 16)] = placeholder[ramp((cse_var_1 + 1360), 1, 16)]
          data_pad_1[ramp(384, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 1552), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(400, 1, 16)] = placeholder[ramp((cse_var_1 + 1568), 1, 16)]
          data_pad_1[ramp(416, 1, 16)] = placeholder[ramp((cse_var_1 + 1584), 1, 16)]
          data_pad_1[ramp(432, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 1776), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(448, 1, 16)] = placeholder[ramp((cse_var_1 + 1792), 1, 16)]
          data_pad_1[ramp(464, 1, 16)] = placeholder[ramp((cse_var_1 + 1808), 1, 16)]
          data_pad_1[ramp(480, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 2000), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(496, 1, 16)] = placeholder[ramp((cse_var_1 + 2016), 1, 16)]
          data_pad_1[ramp(512, 1, 16)] = placeholder[ramp((cse_var_1 + 2032), 1, 16)]
          data_pad_1[ramp(528, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 2224), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(544, 1, 16)] = placeholder[ramp((cse_var_1 + 2240), 1, 16)]
          data_pad_1[ramp(560, 1, 16)] = placeholder[ramp((cse_var_1 + 2256), 1, 16)]
          data_pad_1[ramp(576, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 2448), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(592, 1, 16)] = placeholder[ramp((cse_var_1 + 2464), 1, 16)]
          data_pad_1[ramp(608, 1, 16)] = placeholder[ramp((cse_var_1 + 2480), 1, 16)]
          data_pad_1[ramp(624, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 2672), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(640, 1, 16)] = placeholder[ramp((cse_var_1 + 2688), 1, 16)]
          data_pad_1[ramp(656, 1, 16)] = placeholder[ramp((cse_var_1 + 2704), 1, 16)]
          data_pad_1[ramp(672, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 2896), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(688, 1, 16)] = placeholder[ramp((cse_var_1 + 2912), 1, 16)]
          data_pad_1[ramp(704, 1, 16)] = placeholder[ramp((cse_var_1 + 2928), 1, 16)]
          for (kw.outer: int32, 0, 3) {
            for (ic.inner: int32, 0, 16) {
              let cse_var_24: int32 = ((kw.outer*16) + ic.inner)
              let cse_var_23: int32 = (cse_var_24 + 144)
              let cse_var_22: int32 = (cse_var_24 + 192)
              let cse_var_21: int32 = (cse_var_24 + 240)
              let cse_var_20: int32 = (cse_var_24 + 288)
              let cse_var_19: int32 = (cse_var_24 + 384)
              let cse_var_18: int32 = (cse_var_24 + 432)
              let cse_var_17: int32 = (cse_var_24 + 48)
              let cse_var_16: int32 = (cse_var_24 + 480)
              let cse_var_15: int32 = (cse_var_24 + 528)
              let cse_var_14: int32 = (cse_var_24 + 576)
              let cse_var_13: int32 = (cse_var_24 + 624)
              let cse_var_12: int32 = (cse_var_24 + 672)
              let cse_var_11: int32 = (cse_var_24 + 96)
              let cse_var_10: int32 = (cse_var_24 + 336)
              let cse_var_9: int32 = ((((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)*36864) + (ic.outer*2304)) + (kw.outer*256)) + (ic.inner*16))
              let cse_var_8: int32 = (cse_var_9 + 1536)
              let cse_var_7: int32 = (cse_var_9 + 768)
              let cse_var_6: int32 = (cse_var_9 + 19968)
              let cse_var_5: int32 = (cse_var_9 + 19200)
              let cse_var_4: int32 = (cse_var_9 + 18432)
               {
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_24], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_11], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_24], 16)*placeholder_1[ramp(cse_var_4, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_11], 16)*placeholder_1[ramp(cse_var_4, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_4, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_4, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_4, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_4, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_4, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_10], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_10], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_11], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_11], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
              }
            }
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax2.inner: int32, 0, 7) {
          let cse_var_26: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)
          let cse_var_25: int32 = ((cse_var_26*32) + (ax1.inner*16))
          T_relu[ramp(((((cse_var_26*1568) + (ax1.inner*784)) + (ax2.inner*112)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)*16)), 1, 16)] = max((((conv2d_NCHWc_1[((ax1.inner*7) + ax2.inner)] + placeholder_2[ramp(cse_var_25, 1, 16)])*placeholder_3[ramp(cse_var_25, 1, 16)]) + placeholder_4[ramp(cse_var_25, 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 51: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_18 (weight 1 key: ["6b0d226afab7de584e086dc68f47c79a", [1, 10, 14, 14, 16], [10, 10, 3, 3, 16, 16], [1, 10, 1, 1, 16], [1, 10, 1, 1, 16], [1, 10, 1, 1, 16], [1, 10, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 10, 14, 14, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 15)) && (i3 >= 1)) && (i3 < 15)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [10, 10, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3, data_pad_i4 = tuple(data_pad.op.axis) + tuple(data_pad.op.reduce_axis)
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=7)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=1)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=1)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=3)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax1_o, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax2_o, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=7)
T_relu_ax3_o, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=1)
T_relu_ax4_o, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
s[T_relu].reorder(T_relu_ax0_o, T_relu_ax1_o, T_relu_ax2_o, T_relu_ax3_o, T_relu_ax4_o, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o)
s[data_pad].compute_at(s[conv2d_NCHWc], conv2d_NCHWc_kw_o)
T_relu_ax0_o_ax1_o_fused_ax2_o_fused_ax3_o_fused = s[T_relu].fuse(T_relu_ax0_o, T_relu_ax1_o, T_relu_ax2_o, T_relu_ax3_o)
s[T_relu].parallel(T_relu_ax0_o_ax1_o_fused_ax2_o_fused_ax3_o_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 512)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[data_pad].vectorize(data_pad_i4)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [31360], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [230400], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [160], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [160], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [160], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [31360], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_7: placeholder_15: Buffer(placeholder_12, float32, [1, 10, 1, 1, 16], []), placeholder_5: placeholder_16: Buffer(placeholder_10, float32, [1, 10, 14, 14, 16], []), placeholder_9: placeholder_17: Buffer(placeholder_14, float32, [1, 10, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 10, 14, 14, 16], []), placeholder_6: placeholder_18: Buffer(placeholder_11, float32, [10, 10, 3, 3, 16, 16], []), placeholder_8: placeholder_19: Buffer(placeholder_13, float32, [1, 10, 1, 1, 16], [])} {
  for (ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused: int32, 0, 140) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global;
    allocate(data_pad: Pointer(global float32), float32, [144]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 10) {
        for (kw.outer: int32, 0, 3) {
          let cse_var_7: int32 = floormod(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused, 14)
          let cse_var_6: int32 = (kw.outer + cse_var_7)
          let cse_var_5: int32 = floormod(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused, 28)
          let cse_var_4: bool = (1 <= cse_var_6)
          let cse_var_3: bool = (cse_var_6 < 15)
          let cse_var_2: bool = (cse_var_4 && cse_var_3)
          let cse_var_1: int32 = ((((ic.outer*3136) + (floordiv(cse_var_5, 14)*1568)) + (kw.outer*16)) + (cse_var_7*16))
           {
            data_pad_1: Buffer(data_pad, float32, [144], [])[ramp(0, 1, 16)] = @tir.if_then_else((((14 <= cse_var_5) && cse_var_4) && cse_var_3), placeholder[ramp((cse_var_1 - 240), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(16, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 16), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(32, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 208), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(48, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 432), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(64, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 656), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(80, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 880), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(96, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 1104), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(112, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 + 1328), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(128, 1, 16)] = @tir.if_then_else((((cse_var_5 < 14) && cse_var_4) && cse_var_3), placeholder[ramp((cse_var_1 + 1552), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            for (ic.inner: int32, 0, 16) {
              let cse_var_21: int32 = (ic.inner + 96)
              let cse_var_20: int32 = (ic.inner + 80)
              let cse_var_19: int32 = (ic.inner + 64)
              let cse_var_18: int32 = (ic.inner + 48)
              let cse_var_17: int32 = (ic.inner + 32)
              let cse_var_16: int32 = (ic.inner + 16)
              let cse_var_15: int32 = (ic.inner + 128)
              let cse_var_14: int32 = (ic.inner + 112)
              let cse_var_13: int32 = ((((floordiv(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused, 28)*46080) + (ic.outer*2304)) + (kw.outer*256)) + (ic.inner*16))
              let cse_var_12: int32 = (cse_var_13 + 768)
              let cse_var_11: int32 = (cse_var_13 + 24576)
              let cse_var_10: int32 = (cse_var_13 + 23808)
              let cse_var_9: int32 = (cse_var_13 + 23040)
              let cse_var_8: int32 = (cse_var_13 + 1536)
               {
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
              }
            }
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax2.inner: int32, 0, 7) {
          let cse_var_23: int32 = floordiv(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused, 28)
          let cse_var_22: int32 = ((cse_var_23*32) + (ax1.inner*16))
          T_relu[ramp((((((cse_var_23*6272) + (ax1.inner*3136)) + (floordiv(floormod(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused, 28), 14)*1568)) + (ax2.inner*224)) + (floormod(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused, 14)*16)), 1, 16)] = max((((conv2d_NCHWc_1[((ax1.inner*7) + ax2.inner)] + placeholder_2[ramp(cse_var_22, 1, 16)])*placeholder_3[ramp(cse_var_22, 1, 16)]) + placeholder_4[ramp(cse_var_22, 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 52: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 (weight 1 key: ["f6615ae9259e3b2add2908c0cd980cb6", [1, 20, 28, 28, 16], [4, 20, 1, 1, 16, 16], [1, 4, 1, 1, 16], [1, 4, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 20, 28, 28, 16]
placeholder = PLACEHOLDER [4, 20, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=1)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=2)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=2)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=14)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=4)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=4)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=2)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=14)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=4)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 64)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_6: Pointer(float32), float32, [250880], []),
             placeholder_1: Buffer(placeholder_7: Pointer(float32), float32, [20480], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [64], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [50176], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_3: placeholder_9: Buffer(placeholder_6, float32, [1, 20, 28, 28, 16], []), placeholder_4: placeholder_10: Buffer(placeholder_7, float32, [4, 20, 1, 1, 16, 16], []), placeholder_5: placeholder_11: Buffer(placeholder_8, float32, [1, 4, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 4, 28, 28, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 224) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 80) {
        let cse_var_36: int32 = ((floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 112), 56)*10240) + (ic.outer*64))
        let cse_var_35: int32 = (cse_var_36 + 5168)
        let cse_var_34: int32 = (cse_var_36 + 5152)
        let cse_var_33: int32 = (cse_var_36 + 5136)
        let cse_var_32: int32 = (cse_var_36 + 5120)
        let cse_var_31: int32 = (cse_var_36 + 48)
        let cse_var_30: int32 = (cse_var_36 + 32)
        let cse_var_29: int32 = (cse_var_36 + 16)
        let cse_var_28: int32 = ((((floordiv(ic.outer, 4)*12544) + (floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 112)*6272)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 56)*112)) + (floormod(ic.outer, 4)*4))
        let cse_var_27: int32 = (cse_var_28 + 50)
        let cse_var_26: int32 = (cse_var_28 + 48)
        let cse_var_25: int32 = (cse_var_28 + 35)
        let cse_var_24: int32 = (cse_var_28 + 34)
        let cse_var_23: int32 = (cse_var_28 + 33)
        let cse_var_22: int32 = (cse_var_28 + 32)
        let cse_var_21: int32 = (cse_var_28 + 3)
        let cse_var_20: int32 = (cse_var_28 + 2)
        let cse_var_19: int32 = (cse_var_28 + 19)
        let cse_var_18: int32 = (cse_var_28 + 18)
        let cse_var_17: int32 = (cse_var_28 + 17)
        let cse_var_16: int32 = (cse_var_28 + 1)
        let cse_var_15: int32 = (cse_var_28 + 49)
        let cse_var_14: int32 = (cse_var_28 + 51)
        let cse_var_13: int32 = (cse_var_28 + 64)
        let cse_var_12: int32 = (cse_var_28 + 65)
        let cse_var_11: int32 = (cse_var_28 + 66)
        let cse_var_10: int32 = (cse_var_28 + 67)
        let cse_var_9: int32 = (cse_var_28 + 80)
        let cse_var_8: int32 = (cse_var_28 + 81)
        let cse_var_7: int32 = (cse_var_28 + 82)
        let cse_var_6: int32 = (cse_var_28 + 83)
        let cse_var_5: int32 = (cse_var_28 + 96)
        let cse_var_4: int32 = (cse_var_28 + 97)
        let cse_var_3: int32 = (cse_var_28 + 98)
        let cse_var_2: int32 = (cse_var_28 + 99)
        let cse_var_1: int32 = (cse_var_28 + 16)
         {
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_28], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_22], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_26], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_13], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_9], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_16], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_17], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_23], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_15], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_12], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_20], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_18], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_24], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_27], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_11], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_21], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_19], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_25], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_14], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_10], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_28], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_22], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_26], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_13], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_9], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_16], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_17], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_23], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_15], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_12], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_20], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_18], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_24], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_27], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_11], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_21], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_19], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_25], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_14], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_10], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_37: int32 = floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 112), 56)
          T_relu[ramp((((((cse_var_37*25088) + (ax1.inner*12544)) + (floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 112)*6272)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 56)*112)) + (ax3.inner*16)), 1, 16)] = max((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(((cse_var_37*32) + (ax1.inner*16)), 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 53: vm_mod_fused_nn_dense_add (weight 1 key: ["7d44c6e3c81cd80f61ff2265b2bae89a", [1, 1024], [1000, 1024], [1, 1000], [1, 1000]]) =====
placeholder = PLACEHOLDER [1, 1024]
placeholder = PLACEHOLDER [1000, 1024]
T_matmul_NT(i, j) += (placeholder[i, k]*placeholder[j, k])
placeholder = PLACEHOLDER [1, 1000]
T_add(ax0, ax1) = (T_matmul_NT[ax0, ax1] + placeholder[ax0, ax1])


Trace for this task is: 
T_matmul_NT_i, T_matmul_NT_j, T_matmul_NT_k = tuple(T_matmul_NT.op.axis) + tuple(T_matmul_NT.op.reduce_axis)
T_add_ax0, T_add_ax1 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_matmul_NT_i_o_i, T_matmul_NT_i_i = s[T_matmul_NT].split(T_matmul_NT_i, factor=1)
T_matmul_NT_i_o_o_i, T_matmul_NT_i_o_i = s[T_matmul_NT].split(T_matmul_NT_i_o_i, factor=1)
T_matmul_NT_i_o_o_o, T_matmul_NT_i_o_o_i = s[T_matmul_NT].split(T_matmul_NT_i_o_o_i, factor=1)
T_matmul_NT_j_o_i, T_matmul_NT_j_i = s[T_matmul_NT].split(T_matmul_NT_j, factor=40)
T_matmul_NT_j_o_o_i, T_matmul_NT_j_o_i = s[T_matmul_NT].split(T_matmul_NT_j_o_i, factor=1)
T_matmul_NT_j_o_o_o, T_matmul_NT_j_o_o_i = s[T_matmul_NT].split(T_matmul_NT_j_o_o_i, factor=25)
T_matmul_NT_k_o, T_matmul_NT_k_i = s[T_matmul_NT].split(T_matmul_NT_k, factor=1)
s[T_matmul_NT].reorder(T_matmul_NT_i_o_o_o, T_matmul_NT_j_o_o_o, T_matmul_NT_i_o_o_i, T_matmul_NT_j_o_o_i, T_matmul_NT_k_o, T_matmul_NT_i_o_i, T_matmul_NT_j_o_i, T_matmul_NT_k_i, T_matmul_NT_i_i, T_matmul_NT_j_i)
T_add_ax0_o_i, T_add_ax0_i = s[T_add].split(T_add_ax0, factor=1)
T_add_ax0_o_o, T_add_ax0_o_i = s[T_add].split(T_add_ax0_o_i, factor=1)
T_add_ax1_o_i, T_add_ax1_i = s[T_add].split(T_add_ax1, factor=40)
T_add_ax1_o_o, T_add_ax1_o_i = s[T_add].split(T_add_ax1_o_i, factor=25)
s[T_add].reorder(T_add_ax0_o_o, T_add_ax1_o_o, T_add_ax0_o_i, T_add_ax1_o_i, T_add_ax0_i, T_add_ax1_i)
s[T_matmul_NT].compute_at(s[T_add], T_add_ax1_o_i)
T_add_ax0_o_o_ax1_o_o_fused_ax0_o_i_fused_ax1_o_i_fused = s[T_add].fuse(T_add_ax0_o_o, T_add_ax1_o_o, T_add_ax0_o_i, T_add_ax1_o_i)
s[T_add].parallel(T_add_ax0_o_o_ax1_o_o_fused_ax0_o_i_fused_ax1_o_i_fused)
s[T_matmul_NT].pragma(T_matmul_NT_i_o_o_o, "auto_unroll_max_step", 64)
s[T_matmul_NT].pragma(T_matmul_NT_i_o_o_o, "unroll_explicit", True)


The best replacement found is:
@main = primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_add_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_6: Pointer(float32), float32, [1024], []),
             placeholder_1: Buffer(placeholder_7: Pointer(float32), float32, [1024000], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [1000], []),
             T_add: Buffer(T_add_2: Pointer(float32), float32, [1000], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_add_1: T_add}
  preflattened_buffer_map = {placeholder_3: placeholder_9: Buffer(placeholder_6, float32, [1, 1024], []), placeholder_4: placeholder_10: Buffer(placeholder_7, float32, [1, 25, 1, 1, 1024, 1, 1, 40], []), placeholder_5: placeholder_11: Buffer(placeholder_8, float32, [1, 1000], []), T_add_1: T_add_3: Buffer(T_add_2, float32, [1, 1000], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused: int32, 0, 25) "parallel" {
    allocate(T_matmul_NT: Pointer(global float32), float32, [40]), storage_scope = global {
      T_matmul_NT_1: Buffer(T_matmul_NT, float32, [40], [])[0] = 0f32
      T_matmul_NT_1[1] = 0f32
      T_matmul_NT_1[2] = 0f32
      T_matmul_NT_1[3] = 0f32
      T_matmul_NT_1[4] = 0f32
      T_matmul_NT_1[5] = 0f32
      T_matmul_NT_1[6] = 0f32
      T_matmul_NT_1[7] = 0f32
      T_matmul_NT_1[8] = 0f32
      T_matmul_NT_1[9] = 0f32
      T_matmul_NT_1[10] = 0f32
      T_matmul_NT_1[11] = 0f32
      T_matmul_NT_1[12] = 0f32
      T_matmul_NT_1[13] = 0f32
      T_matmul_NT_1[14] = 0f32
      T_matmul_NT_1[15] = 0f32
      T_matmul_NT_1[16] = 0f32
      T_matmul_NT_1[17] = 0f32
      T_matmul_NT_1[18] = 0f32
      T_matmul_NT_1[19] = 0f32
      T_matmul_NT_1[20] = 0f32
      T_matmul_NT_1[21] = 0f32
      T_matmul_NT_1[22] = 0f32
      T_matmul_NT_1[23] = 0f32
      T_matmul_NT_1[24] = 0f32
      T_matmul_NT_1[25] = 0f32
      T_matmul_NT_1[26] = 0f32
      T_matmul_NT_1[27] = 0f32
      T_matmul_NT_1[28] = 0f32
      T_matmul_NT_1[29] = 0f32
      T_matmul_NT_1[30] = 0f32
      T_matmul_NT_1[31] = 0f32
      T_matmul_NT_1[32] = 0f32
      T_matmul_NT_1[33] = 0f32
      T_matmul_NT_1[34] = 0f32
      T_matmul_NT_1[35] = 0f32
      T_matmul_NT_1[36] = 0f32
      T_matmul_NT_1[37] = 0f32
      T_matmul_NT_1[38] = 0f32
      T_matmul_NT_1[39] = 0f32
      for (k.outer: int32, 0, 1024) {
        let cse_var_1: int32 = ((ax0.outer.outer.ax1.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused*40960) + (k.outer*40))
         {
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[k.outer]*placeholder_1[cse_var_1]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 1)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 2)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 3)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 4)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 5)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 6)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 7)]))
          T_matmul_NT_1[8] = (T_matmul_NT_1[8] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 8)]))
          T_matmul_NT_1[9] = (T_matmul_NT_1[9] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 9)]))
          T_matmul_NT_1[10] = (T_matmul_NT_1[10] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 10)]))
          T_matmul_NT_1[11] = (T_matmul_NT_1[11] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 11)]))
          T_matmul_NT_1[12] = (T_matmul_NT_1[12] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 12)]))
          T_matmul_NT_1[13] = (T_matmul_NT_1[13] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 13)]))
          T_matmul_NT_1[14] = (T_matmul_NT_1[14] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 14)]))
          T_matmul_NT_1[15] = (T_matmul_NT_1[15] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 15)]))
          T_matmul_NT_1[16] = (T_matmul_NT_1[16] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 16)]))
          T_matmul_NT_1[17] = (T_matmul_NT_1[17] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 17)]))
          T_matmul_NT_1[18] = (T_matmul_NT_1[18] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 18)]))
          T_matmul_NT_1[19] = (T_matmul_NT_1[19] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 19)]))
          T_matmul_NT_1[20] = (T_matmul_NT_1[20] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 20)]))
          T_matmul_NT_1[21] = (T_matmul_NT_1[21] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 21)]))
          T_matmul_NT_1[22] = (T_matmul_NT_1[22] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 22)]))
          T_matmul_NT_1[23] = (T_matmul_NT_1[23] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 23)]))
          T_matmul_NT_1[24] = (T_matmul_NT_1[24] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 24)]))
          T_matmul_NT_1[25] = (T_matmul_NT_1[25] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 25)]))
          T_matmul_NT_1[26] = (T_matmul_NT_1[26] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 26)]))
          T_matmul_NT_1[27] = (T_matmul_NT_1[27] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 27)]))
          T_matmul_NT_1[28] = (T_matmul_NT_1[28] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 28)]))
          T_matmul_NT_1[29] = (T_matmul_NT_1[29] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 29)]))
          T_matmul_NT_1[30] = (T_matmul_NT_1[30] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 30)]))
          T_matmul_NT_1[31] = (T_matmul_NT_1[31] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 31)]))
          T_matmul_NT_1[32] = (T_matmul_NT_1[32] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 32)]))
          T_matmul_NT_1[33] = (T_matmul_NT_1[33] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 33)]))
          T_matmul_NT_1[34] = (T_matmul_NT_1[34] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 34)]))
          T_matmul_NT_1[35] = (T_matmul_NT_1[35] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 35)]))
          T_matmul_NT_1[36] = (T_matmul_NT_1[36] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 36)]))
          T_matmul_NT_1[37] = (T_matmul_NT_1[37] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 37)]))
          T_matmul_NT_1[38] = (T_matmul_NT_1[38] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 38)]))
          T_matmul_NT_1[39] = (T_matmul_NT_1[39] + (placeholder[k.outer]*placeholder_1[(cse_var_1 + 39)]))
        }
      }
      for (ax1.inner: int32, 0, 40) {
        let cse_var_2: int32 = ((ax0.outer.outer.ax1.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused*40) + ax1.inner)
        T_add[cse_var_2] = (T_matmul_NT_1[ax1.inner] + placeholder_2[cse_var_2])
      }
    }
  }
}


==== Task 54: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10 (weight 1 key: ["ce1b4a245fb9b3a0526fcd7e77d29d3f", [1, 8, 14, 14, 16], [10, 8, 3, 3, 16, 16], [1, 10, 1, 1, 16], [1, 10, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 8, 14, 14, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 15)) && (i3 >= 1)) && (i3 < 15)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [10, 8, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 10, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3, data_pad_i4 = tuple(data_pad.op.axis) + tuple(data_pad.op.reduce_axis)
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=2)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=1)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=3)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=2)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=1)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
s[data_pad].compute_at(s[conv2d_NCHWc], conv2d_NCHWc_kh_o)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 512)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[data_pad].vectorize(data_pad_i4)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_6: Pointer(float32), float32, [25088], []),
             placeholder_1: Buffer(placeholder_7: Pointer(float32), float32, [184320], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [160], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [31360], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_3: placeholder_9: Buffer(placeholder_6, float32, [1, 8, 14, 14, 16], []), placeholder_4: placeholder_10: Buffer(placeholder_7, float32, [10, 8, 3, 3, 16, 16], []), placeholder_5: placeholder_11: Buffer(placeholder_8, float32, [1, 10, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 10, 14, 14, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 140) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global;
    allocate(data_pad: Pointer(global float32), float32, [144]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 8) {
        for (kh.outer: int32, 0, 3) {
          let cse_var_6: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 2)
          let cse_var_5: int32 = floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28), 4)
          let cse_var_4: int32 = (((cse_var_5*2) + kh.outer) + cse_var_6)
          let cse_var_3: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 4)
          let cse_var_2: int32 = (((((ic.outer*3136) + (cse_var_5*448)) + (kh.outer*224)) + (cse_var_6*224)) + (floordiv(cse_var_3, 2)*112))
          let cse_var_1: bool = ((1 <= cse_var_4) && (cse_var_4 < 15))
           {
            data_pad_1: Buffer(data_pad, float32, [144], [])[ramp(0, 1, 16)] = @tir.if_then_else((cse_var_1 && (2 <= cse_var_3)), placeholder[ramp((cse_var_2 - 240), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(16, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 224), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(32, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 208), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(48, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 192), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(64, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 176), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(80, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 160), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(96, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 144), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(112, 1, 16)] = @tir.if_then_else(cse_var_1, placeholder[ramp((cse_var_2 - 128), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(128, 1, 16)] = @tir.if_then_else((cse_var_1 && (cse_var_3 < 2)), placeholder[ramp((cse_var_2 - 112), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            for (ic.inner: int32, 0, 16) {
              let cse_var_20: int32 = (ic.inner + 96)
              let cse_var_19: int32 = (ic.inner + 80)
              let cse_var_18: int32 = (ic.inner + 64)
              let cse_var_17: int32 = (ic.inner + 48)
              let cse_var_16: int32 = (ic.inner + 32)
              let cse_var_15: int32 = (ic.inner + 16)
              let cse_var_14: int32 = (ic.inner + 128)
              let cse_var_13: int32 = (ic.inner + 112)
              let cse_var_12: int32 = ((((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)*36864) + (ic.outer*2304)) + (kh.outer*768)) + (ic.inner*16))
              let cse_var_11: int32 = (cse_var_12 + 512)
              let cse_var_10: int32 = (cse_var_12 + 256)
              let cse_var_9: int32 = (cse_var_12 + 18944)
              let cse_var_8: int32 = (cse_var_12 + 18688)
              let cse_var_7: int32 = (cse_var_12 + 18432)
               {
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
              }
            }
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_21: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)
          T_relu[ramp(((((((cse_var_21*6272) + (ax1.inner*3136)) + (floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28), 4)*448)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 2)*224)) + (floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 4), 2)*112)) + (ax3.inner*16)), 1, 16)] = max((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(((cse_var_21*32) + (ax1.inner*16)), 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 55: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 (weight 2 key: ["f6615ae9259e3b2add2908c0cd980cb6", [1, 16, 28, 28, 16], [4, 16, 1, 1, 16, 16], [1, 4, 1, 1, 16], [1, 4, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 16, 28, 28, 16]
placeholder = PLACEHOLDER [4, 16, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=2)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=2)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=1)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=4)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=2)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=2)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=1)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 512)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_6: Pointer(float32), float32, [200704], []),
             placeholder_1: Buffer(placeholder_7: Pointer(float32), float32, [16384], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [64], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [50176], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_3: placeholder_9: Buffer(placeholder_6, float32, [1, 16, 28, 28, 16], []), placeholder_4: placeholder_10: Buffer(placeholder_7, float32, [4, 16, 1, 1, 16, 16], []), placeholder_5: placeholder_11: Buffer(placeholder_8, float32, [1, 4, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 4, 28, 28, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused: int32, 0, 224) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 64) {
        let cse_var_36: int32 = ((floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 4), 2)*8192) + (ic.outer*64))
        let cse_var_35: int32 = (cse_var_36 + 48)
        let cse_var_34: int32 = (cse_var_36 + 4144)
        let cse_var_33: int32 = (cse_var_36 + 4128)
        let cse_var_32: int32 = (cse_var_36 + 4112)
        let cse_var_31: int32 = (cse_var_36 + 4096)
        let cse_var_30: int32 = (cse_var_36 + 32)
        let cse_var_29: int32 = (cse_var_36 + 16)
        let cse_var_28: int32 = (((((floordiv(ic.outer, 4)*12544) + (floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 16)*896)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 2)*448)) + (floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 16), 4)*112)) + (floormod(ic.outer, 4)*4))
        let cse_var_27: int32 = (cse_var_28 + 50)
        let cse_var_26: int32 = (cse_var_28 + 48)
        let cse_var_25: int32 = (cse_var_28 + 35)
        let cse_var_24: int32 = (cse_var_28 + 34)
        let cse_var_23: int32 = (cse_var_28 + 33)
        let cse_var_22: int32 = (cse_var_28 + 32)
        let cse_var_21: int32 = (cse_var_28 + 3)
        let cse_var_20: int32 = (cse_var_28 + 2)
        let cse_var_19: int32 = (cse_var_28 + 19)
        let cse_var_18: int32 = (cse_var_28 + 18)
        let cse_var_17: int32 = (cse_var_28 + 17)
        let cse_var_16: int32 = (cse_var_28 + 1)
        let cse_var_15: int32 = (cse_var_28 + 49)
        let cse_var_14: int32 = (cse_var_28 + 51)
        let cse_var_13: int32 = (cse_var_28 + 64)
        let cse_var_12: int32 = (cse_var_28 + 65)
        let cse_var_11: int32 = (cse_var_28 + 66)
        let cse_var_10: int32 = (cse_var_28 + 67)
        let cse_var_9: int32 = (cse_var_28 + 80)
        let cse_var_8: int32 = (cse_var_28 + 81)
        let cse_var_7: int32 = (cse_var_28 + 82)
        let cse_var_6: int32 = (cse_var_28 + 83)
        let cse_var_5: int32 = (cse_var_28 + 96)
        let cse_var_4: int32 = (cse_var_28 + 97)
        let cse_var_3: int32 = (cse_var_28 + 98)
        let cse_var_2: int32 = (cse_var_28 + 99)
        let cse_var_1: int32 = (cse_var_28 + 16)
         {
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_28], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_22], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_26], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_13], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_9], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_36, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_28], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_22], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_26], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_13], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_9], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_16], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_17], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_23], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_15], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_12], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_16], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_17], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_23], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_15], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_12], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_20], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_18], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_24], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_27], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_11], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_20], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_18], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_24], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_27], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_11], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_21], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_19], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_25], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_14], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_10], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_21], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_19], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_25], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_14], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_10], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_37: int32 = floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 4), 2)
          T_relu[ramp(((((((cse_var_37*25088) + (ax1.inner*12544)) + (floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 16)*896)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 2)*448)) + (floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused, 16), 4)*112)) + (ax3.inner*16)), 1, 16)] = max((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(((cse_var_37*32) + (ax1.inner*16)), 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 56: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_6 (weight 2 key: ["9db1fd34470fc877a2c0431d681f01a4", [1, 16, 28, 28, 16], [4, 16, 1, 1, 16, 16], [1, 4, 1, 1, 16], [1, 4, 1, 1, 16], [1, 4, 1, 1, 16], [1, 4, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 16, 28, 28, 16]
placeholder = PLACEHOLDER [4, 16, 1, 1, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 4, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=2)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=14)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=4)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=7)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=2)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=14)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=4)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=7)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 512)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [200704], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [16384], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [64], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [64], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [64], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [50176], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_9: placeholder_15: Buffer(placeholder_14, float32, [1, 4, 1, 1, 16], []), placeholder_8: placeholder_16: Buffer(placeholder_13, float32, [1, 4, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 4, 28, 28, 16], []), placeholder_6: placeholder_17: Buffer(placeholder_11, float32, [4, 16, 1, 1, 16, 16], []), placeholder_5: placeholder_18: Buffer(placeholder_10, float32, [1, 16, 28, 28, 16], []), placeholder_7: placeholder_19: Buffer(placeholder_12, float32, [1, 4, 1, 1, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 196) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [16]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [16], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      conv2d_NCHWc_1[14] = broadcast(0f32, 16)
      conv2d_NCHWc_1[15] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 16) {
        let cse_var_160: int32 = ((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 98)*8192) + (ic.outer*256))
        let cse_var_159: int32 = (cse_var_160 + 4176)
        let cse_var_158: int32 = (cse_var_160 + 4144)
        let cse_var_157: int32 = (cse_var_160 + 4128)
        let cse_var_156: int32 = (cse_var_160 + 4112)
        let cse_var_155: int32 = (cse_var_160 + 4096)
        let cse_var_154: int32 = (cse_var_160 + 32)
        let cse_var_153: int32 = (cse_var_160 + 240)
        let cse_var_152: int32 = (cse_var_160 + 224)
        let cse_var_151: int32 = (cse_var_160 + 208)
        let cse_var_150: int32 = (cse_var_160 + 192)
        let cse_var_149: int32 = (cse_var_160 + 176)
        let cse_var_148: int32 = (cse_var_160 + 160)
        let cse_var_147: int32 = (cse_var_160 + 16)
        let cse_var_146: int32 = (cse_var_160 + 144)
        let cse_var_145: int32 = (cse_var_160 + 112)
        let cse_var_144: int32 = (cse_var_160 + 4160)
        let cse_var_143: int32 = (cse_var_160 + 4192)
        let cse_var_142: int32 = (cse_var_160 + 4208)
        let cse_var_141: int32 = (cse_var_160 + 4224)
        let cse_var_140: int32 = (cse_var_160 + 4240)
        let cse_var_139: int32 = (cse_var_160 + 4256)
        let cse_var_138: int32 = (cse_var_160 + 4272)
        let cse_var_137: int32 = (cse_var_160 + 4288)
        let cse_var_136: int32 = (cse_var_160 + 4304)
        let cse_var_135: int32 = (cse_var_160 + 4320)
        let cse_var_134: int32 = (cse_var_160 + 4336)
        let cse_var_133: int32 = (cse_var_160 + 48)
        let cse_var_132: int32 = (cse_var_160 + 64)
        let cse_var_131: int32 = (cse_var_160 + 80)
        let cse_var_130: int32 = (cse_var_160 + 96)
        let cse_var_129: int32 = (cse_var_160 + 128)
        let cse_var_128: int32 = (((ic.outer*12544) + (floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 98), 7)*896)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)*64))
        let cse_var_127: int32 = (cse_var_128 + 456)
        let cse_var_126: int32 = (cse_var_128 + 40)
        let cse_var_125: int32 = (cse_var_128 + 41)
        let cse_var_124: int32 = (cse_var_128 + 42)
        let cse_var_123: int32 = (cse_var_128 + 43)
        let cse_var_122: int32 = (cse_var_128 + 44)
        let cse_var_121: int32 = (cse_var_128 + 448)
        let cse_var_120: int32 = (cse_var_128 + 449)
        let cse_var_119: int32 = (cse_var_128 + 45)
        let cse_var_118: int32 = (cse_var_128 + 450)
        let cse_var_117: int32 = (cse_var_128 + 451)
        let cse_var_116: int32 = (cse_var_128 + 452)
        let cse_var_115: int32 = (cse_var_128 + 453)
        let cse_var_114: int32 = (cse_var_128 + 454)
        let cse_var_113: int32 = (cse_var_128 + 455)
        let cse_var_112: int32 = (cse_var_128 + 457)
        let cse_var_111: int32 = (cse_var_128 + 458)
        let cse_var_110: int32 = (cse_var_128 + 459)
        let cse_var_109: int32 = (cse_var_128 + 46)
        let cse_var_108: int32 = (cse_var_128 + 460)
        let cse_var_107: int32 = (cse_var_128 + 461)
        let cse_var_106: int32 = (cse_var_128 + 462)
        let cse_var_105: int32 = (cse_var_128 + 463)
        let cse_var_104: int32 = (cse_var_128 + 464)
        let cse_var_103: int32 = (cse_var_128 + 465)
        let cse_var_102: int32 = (cse_var_128 + 466)
        let cse_var_101: int32 = (cse_var_128 + 467)
        let cse_var_100: int32 = (cse_var_128 + 468)
        let cse_var_99: int32 = (cse_var_128 + 47)
        let cse_var_98: int32 = (cse_var_128 + 39)
        let cse_var_97: int32 = (cse_var_128 + 4)
        let cse_var_96: int32 = (cse_var_128 + 1)
        let cse_var_95: int32 = (cse_var_128 + 11)
        let cse_var_94: int32 = (cse_var_128 + 12)
        let cse_var_93: int32 = (cse_var_128 + 13)
        let cse_var_92: int32 = (cse_var_128 + 14)
        let cse_var_91: int32 = (cse_var_128 + 15)
        let cse_var_90: int32 = (cse_var_128 + 16)
        let cse_var_89: int32 = (cse_var_128 + 17)
        let cse_var_88: int32 = (cse_var_128 + 18)
        let cse_var_87: int32 = (cse_var_128 + 19)
        let cse_var_86: int32 = (cse_var_128 + 2)
        let cse_var_85: int32 = (cse_var_128 + 20)
        let cse_var_84: int32 = (cse_var_128 + 21)
        let cse_var_83: int32 = (cse_var_128 + 22)
        let cse_var_82: int32 = (cse_var_128 + 23)
        let cse_var_81: int32 = (cse_var_128 + 469)
        let cse_var_80: int32 = (cse_var_128 + 25)
        let cse_var_79: int32 = (cse_var_128 + 26)
        let cse_var_78: int32 = (cse_var_128 + 27)
        let cse_var_77: int32 = (cse_var_128 + 28)
        let cse_var_76: int32 = (cse_var_128 + 29)
        let cse_var_75: int32 = (cse_var_128 + 3)
        let cse_var_74: int32 = (cse_var_128 + 30)
        let cse_var_73: int32 = (cse_var_128 + 31)
        let cse_var_72: int32 = (cse_var_128 + 32)
        let cse_var_71: int32 = (cse_var_128 + 33)
        let cse_var_70: int32 = (cse_var_128 + 34)
        let cse_var_69: int32 = (cse_var_128 + 35)
        let cse_var_68: int32 = (cse_var_128 + 36)
        let cse_var_67: int32 = (cse_var_128 + 37)
        let cse_var_66: int32 = (cse_var_128 + 38)
        let cse_var_65: int32 = (cse_var_128 + 24)
        let cse_var_64: int32 = (cse_var_128 + 5)
        let cse_var_63: int32 = (cse_var_128 + 50)
        let cse_var_62: int32 = (cse_var_128 + 500)
        let cse_var_61: int32 = (cse_var_128 + 501)
        let cse_var_60: int32 = (cse_var_128 + 502)
        let cse_var_59: int32 = (cse_var_128 + 503)
        let cse_var_58: int32 = (cse_var_128 + 504)
        let cse_var_57: int32 = (cse_var_128 + 505)
        let cse_var_56: int32 = (cse_var_128 + 506)
        let cse_var_55: int32 = (cse_var_128 + 507)
        let cse_var_54: int32 = (cse_var_128 + 508)
        let cse_var_53: int32 = (cse_var_128 + 509)
        let cse_var_52: int32 = (cse_var_128 + 51)
        let cse_var_51: int32 = (cse_var_128 + 510)
        let cse_var_50: int32 = (cse_var_128 + 511)
        let cse_var_49: int32 = (cse_var_128 + 10)
        let cse_var_48: int32 = (cse_var_128 + 53)
        let cse_var_47: int32 = (cse_var_128 + 54)
        let cse_var_46: int32 = (cse_var_128 + 55)
        let cse_var_45: int32 = (cse_var_128 + 56)
        let cse_var_44: int32 = (cse_var_128 + 57)
        let cse_var_43: int32 = (cse_var_128 + 58)
        let cse_var_42: int32 = (cse_var_128 + 59)
        let cse_var_41: int32 = (cse_var_128 + 6)
        let cse_var_40: int32 = (cse_var_128 + 60)
        let cse_var_39: int32 = (cse_var_128 + 61)
        let cse_var_38: int32 = (cse_var_128 + 62)
        let cse_var_37: int32 = (cse_var_128 + 63)
        let cse_var_36: int32 = (cse_var_128 + 7)
        let cse_var_35: int32 = (cse_var_128 + 8)
        let cse_var_34: int32 = (cse_var_128 + 9)
        let cse_var_33: int32 = (cse_var_128 + 52)
        let cse_var_32: int32 = (cse_var_128 + 470)
        let cse_var_31: int32 = (cse_var_128 + 471)
        let cse_var_30: int32 = (cse_var_128 + 472)
        let cse_var_29: int32 = (cse_var_128 + 473)
        let cse_var_28: int32 = (cse_var_128 + 474)
        let cse_var_27: int32 = (cse_var_128 + 475)
        let cse_var_26: int32 = (cse_var_128 + 476)
        let cse_var_25: int32 = (cse_var_128 + 477)
        let cse_var_24: int32 = (cse_var_128 + 478)
        let cse_var_23: int32 = (cse_var_128 + 479)
        let cse_var_22: int32 = (cse_var_128 + 48)
        let cse_var_21: int32 = (cse_var_128 + 480)
        let cse_var_20: int32 = (cse_var_128 + 481)
        let cse_var_19: int32 = (cse_var_128 + 482)
        let cse_var_18: int32 = (cse_var_128 + 483)
        let cse_var_17: int32 = (cse_var_128 + 499)
        let cse_var_16: int32 = (cse_var_128 + 485)
        let cse_var_15: int32 = (cse_var_128 + 486)
        let cse_var_14: int32 = (cse_var_128 + 487)
        let cse_var_13: int32 = (cse_var_128 + 488)
        let cse_var_12: int32 = (cse_var_128 + 489)
        let cse_var_11: int32 = (cse_var_128 + 49)
        let cse_var_10: int32 = (cse_var_128 + 490)
        let cse_var_9: int32 = (cse_var_128 + 491)
        let cse_var_8: int32 = (cse_var_128 + 492)
        let cse_var_7: int32 = (cse_var_128 + 493)
        let cse_var_6: int32 = (cse_var_128 + 494)
        let cse_var_5: int32 = (cse_var_128 + 495)
        let cse_var_4: int32 = (cse_var_128 + 496)
        let cse_var_3: int32 = (cse_var_128 + 497)
        let cse_var_2: int32 = (cse_var_128 + 498)
        let cse_var_1: int32 = (cse_var_128 + 484)
         {
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_128], 16)*placeholder_1[ramp(cse_var_160, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_90], 16)*placeholder_1[ramp(cse_var_160, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_72], 16)*placeholder_1[ramp(cse_var_160, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_22], 16)*placeholder_1[ramp(cse_var_160, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_121], 16)*placeholder_1[ramp(cse_var_160, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_104], 16)*placeholder_1[ramp(cse_var_160, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_21], 16)*placeholder_1[ramp(cse_var_160, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_160, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_128], 16)*placeholder_1[ramp(cse_var_155, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_90], 16)*placeholder_1[ramp(cse_var_155, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_72], 16)*placeholder_1[ramp(cse_var_155, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_22], 16)*placeholder_1[ramp(cse_var_155, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_121], 16)*placeholder_1[ramp(cse_var_155, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_104], 16)*placeholder_1[ramp(cse_var_155, 1, 16)]))
          conv2d_NCHWc_1[14] = (conv2d_NCHWc_1[14] + (broadcast(placeholder[cse_var_21], 16)*placeholder_1[ramp(cse_var_155, 1, 16)]))
          conv2d_NCHWc_1[15] = (conv2d_NCHWc_1[15] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_155, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_96], 16)*placeholder_1[ramp(cse_var_147, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_89], 16)*placeholder_1[ramp(cse_var_147, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_71], 16)*placeholder_1[ramp(cse_var_147, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_11], 16)*placeholder_1[ramp(cse_var_147, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_120], 16)*placeholder_1[ramp(cse_var_147, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_103], 16)*placeholder_1[ramp(cse_var_147, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_20], 16)*placeholder_1[ramp(cse_var_147, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_147, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_96], 16)*placeholder_1[ramp(cse_var_156, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_89], 16)*placeholder_1[ramp(cse_var_156, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_71], 16)*placeholder_1[ramp(cse_var_156, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_11], 16)*placeholder_1[ramp(cse_var_156, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_120], 16)*placeholder_1[ramp(cse_var_156, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_103], 16)*placeholder_1[ramp(cse_var_156, 1, 16)]))
          conv2d_NCHWc_1[14] = (conv2d_NCHWc_1[14] + (broadcast(placeholder[cse_var_20], 16)*placeholder_1[ramp(cse_var_156, 1, 16)]))
          conv2d_NCHWc_1[15] = (conv2d_NCHWc_1[15] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_156, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_86], 16)*placeholder_1[ramp(cse_var_154, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_88], 16)*placeholder_1[ramp(cse_var_154, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_70], 16)*placeholder_1[ramp(cse_var_154, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_63], 16)*placeholder_1[ramp(cse_var_154, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_118], 16)*placeholder_1[ramp(cse_var_154, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_102], 16)*placeholder_1[ramp(cse_var_154, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_19], 16)*placeholder_1[ramp(cse_var_154, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_154, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_86], 16)*placeholder_1[ramp(cse_var_157, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_88], 16)*placeholder_1[ramp(cse_var_157, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_70], 16)*placeholder_1[ramp(cse_var_157, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_63], 16)*placeholder_1[ramp(cse_var_157, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_118], 16)*placeholder_1[ramp(cse_var_157, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_102], 16)*placeholder_1[ramp(cse_var_157, 1, 16)]))
          conv2d_NCHWc_1[14] = (conv2d_NCHWc_1[14] + (broadcast(placeholder[cse_var_19], 16)*placeholder_1[ramp(cse_var_157, 1, 16)]))
          conv2d_NCHWc_1[15] = (conv2d_NCHWc_1[15] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_157, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_75], 16)*placeholder_1[ramp(cse_var_133, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_87], 16)*placeholder_1[ramp(cse_var_133, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_69], 16)*placeholder_1[ramp(cse_var_133, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_52], 16)*placeholder_1[ramp(cse_var_133, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_117], 16)*placeholder_1[ramp(cse_var_133, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_101], 16)*placeholder_1[ramp(cse_var_133, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_18], 16)*placeholder_1[ramp(cse_var_133, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_17], 16)*placeholder_1[ramp(cse_var_133, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_75], 16)*placeholder_1[ramp(cse_var_158, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_87], 16)*placeholder_1[ramp(cse_var_158, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_69], 16)*placeholder_1[ramp(cse_var_158, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_52], 16)*placeholder_1[ramp(cse_var_158, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_117], 16)*placeholder_1[ramp(cse_var_158, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_101], 16)*placeholder_1[ramp(cse_var_158, 1, 16)]))
          conv2d_NCHWc_1[14] = (conv2d_NCHWc_1[14] + (broadcast(placeholder[cse_var_18], 16)*placeholder_1[ramp(cse_var_158, 1, 16)]))
          conv2d_NCHWc_1[15] = (conv2d_NCHWc_1[15] + (broadcast(placeholder[cse_var_17], 16)*placeholder_1[ramp(cse_var_158, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_97], 16)*placeholder_1[ramp(cse_var_132, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_85], 16)*placeholder_1[ramp(cse_var_132, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_68], 16)*placeholder_1[ramp(cse_var_132, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_33], 16)*placeholder_1[ramp(cse_var_132, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_116], 16)*placeholder_1[ramp(cse_var_132, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_100], 16)*placeholder_1[ramp(cse_var_132, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_132, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_62], 16)*placeholder_1[ramp(cse_var_132, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_97], 16)*placeholder_1[ramp(cse_var_144, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_85], 16)*placeholder_1[ramp(cse_var_144, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_68], 16)*placeholder_1[ramp(cse_var_144, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_33], 16)*placeholder_1[ramp(cse_var_144, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_116], 16)*placeholder_1[ramp(cse_var_144, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_100], 16)*placeholder_1[ramp(cse_var_144, 1, 16)]))
          conv2d_NCHWc_1[14] = (conv2d_NCHWc_1[14] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_144, 1, 16)]))
          conv2d_NCHWc_1[15] = (conv2d_NCHWc_1[15] + (broadcast(placeholder[cse_var_62], 16)*placeholder_1[ramp(cse_var_144, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_64], 16)*placeholder_1[ramp(cse_var_131, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_84], 16)*placeholder_1[ramp(cse_var_131, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_67], 16)*placeholder_1[ramp(cse_var_131, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_48], 16)*placeholder_1[ramp(cse_var_131, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_115], 16)*placeholder_1[ramp(cse_var_131, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_81], 16)*placeholder_1[ramp(cse_var_131, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_16], 16)*placeholder_1[ramp(cse_var_131, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_61], 16)*placeholder_1[ramp(cse_var_131, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_64], 16)*placeholder_1[ramp(cse_var_159, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_84], 16)*placeholder_1[ramp(cse_var_159, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_67], 16)*placeholder_1[ramp(cse_var_159, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_48], 16)*placeholder_1[ramp(cse_var_159, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_115], 16)*placeholder_1[ramp(cse_var_159, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_81], 16)*placeholder_1[ramp(cse_var_159, 1, 16)]))
          conv2d_NCHWc_1[14] = (conv2d_NCHWc_1[14] + (broadcast(placeholder[cse_var_16], 16)*placeholder_1[ramp(cse_var_159, 1, 16)]))
          conv2d_NCHWc_1[15] = (conv2d_NCHWc_1[15] + (broadcast(placeholder[cse_var_61], 16)*placeholder_1[ramp(cse_var_159, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_41], 16)*placeholder_1[ramp(cse_var_130, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_83], 16)*placeholder_1[ramp(cse_var_130, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_66], 16)*placeholder_1[ramp(cse_var_130, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_47], 16)*placeholder_1[ramp(cse_var_130, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_114], 16)*placeholder_1[ramp(cse_var_130, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_32], 16)*placeholder_1[ramp(cse_var_130, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_15], 16)*placeholder_1[ramp(cse_var_130, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_60], 16)*placeholder_1[ramp(cse_var_130, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_41], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_83], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_66], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_47], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_114], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_32], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[14] = (conv2d_NCHWc_1[14] + (broadcast(placeholder[cse_var_15], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[15] = (conv2d_NCHWc_1[15] + (broadcast(placeholder[cse_var_60], 16)*placeholder_1[ramp(cse_var_143, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_36], 16)*placeholder_1[ramp(cse_var_145, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_82], 16)*placeholder_1[ramp(cse_var_145, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_98], 16)*placeholder_1[ramp(cse_var_145, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_46], 16)*placeholder_1[ramp(cse_var_145, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_113], 16)*placeholder_1[ramp(cse_var_145, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_31], 16)*placeholder_1[ramp(cse_var_145, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_14], 16)*placeholder_1[ramp(cse_var_145, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_59], 16)*placeholder_1[ramp(cse_var_145, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_36], 16)*placeholder_1[ramp(cse_var_142, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_82], 16)*placeholder_1[ramp(cse_var_142, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_98], 16)*placeholder_1[ramp(cse_var_142, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_46], 16)*placeholder_1[ramp(cse_var_142, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_113], 16)*placeholder_1[ramp(cse_var_142, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_31], 16)*placeholder_1[ramp(cse_var_142, 1, 16)]))
          conv2d_NCHWc_1[14] = (conv2d_NCHWc_1[14] + (broadcast(placeholder[cse_var_14], 16)*placeholder_1[ramp(cse_var_142, 1, 16)]))
          conv2d_NCHWc_1[15] = (conv2d_NCHWc_1[15] + (broadcast(placeholder[cse_var_59], 16)*placeholder_1[ramp(cse_var_142, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_35], 16)*placeholder_1[ramp(cse_var_129, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_65], 16)*placeholder_1[ramp(cse_var_129, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_126], 16)*placeholder_1[ramp(cse_var_129, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_45], 16)*placeholder_1[ramp(cse_var_129, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_127], 16)*placeholder_1[ramp(cse_var_129, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_30], 16)*placeholder_1[ramp(cse_var_129, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_13], 16)*placeholder_1[ramp(cse_var_129, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_58], 16)*placeholder_1[ramp(cse_var_129, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_35], 16)*placeholder_1[ramp(cse_var_141, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_65], 16)*placeholder_1[ramp(cse_var_141, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_126], 16)*placeholder_1[ramp(cse_var_141, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_45], 16)*placeholder_1[ramp(cse_var_141, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_127], 16)*placeholder_1[ramp(cse_var_141, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_30], 16)*placeholder_1[ramp(cse_var_141, 1, 16)]))
          conv2d_NCHWc_1[14] = (conv2d_NCHWc_1[14] + (broadcast(placeholder[cse_var_13], 16)*placeholder_1[ramp(cse_var_141, 1, 16)]))
          conv2d_NCHWc_1[15] = (conv2d_NCHWc_1[15] + (broadcast(placeholder[cse_var_58], 16)*placeholder_1[ramp(cse_var_141, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_34], 16)*placeholder_1[ramp(cse_var_146, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_80], 16)*placeholder_1[ramp(cse_var_146, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_125], 16)*placeholder_1[ramp(cse_var_146, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_44], 16)*placeholder_1[ramp(cse_var_146, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_112], 16)*placeholder_1[ramp(cse_var_146, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_29], 16)*placeholder_1[ramp(cse_var_146, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_12], 16)*placeholder_1[ramp(cse_var_146, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_57], 16)*placeholder_1[ramp(cse_var_146, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_34], 16)*placeholder_1[ramp(cse_var_140, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_80], 16)*placeholder_1[ramp(cse_var_140, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_125], 16)*placeholder_1[ramp(cse_var_140, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_44], 16)*placeholder_1[ramp(cse_var_140, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_112], 16)*placeholder_1[ramp(cse_var_140, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_29], 16)*placeholder_1[ramp(cse_var_140, 1, 16)]))
          conv2d_NCHWc_1[14] = (conv2d_NCHWc_1[14] + (broadcast(placeholder[cse_var_12], 16)*placeholder_1[ramp(cse_var_140, 1, 16)]))
          conv2d_NCHWc_1[15] = (conv2d_NCHWc_1[15] + (broadcast(placeholder[cse_var_57], 16)*placeholder_1[ramp(cse_var_140, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_49], 16)*placeholder_1[ramp(cse_var_148, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_79], 16)*placeholder_1[ramp(cse_var_148, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_124], 16)*placeholder_1[ramp(cse_var_148, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_43], 16)*placeholder_1[ramp(cse_var_148, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_111], 16)*placeholder_1[ramp(cse_var_148, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_28], 16)*placeholder_1[ramp(cse_var_148, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_10], 16)*placeholder_1[ramp(cse_var_148, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_56], 16)*placeholder_1[ramp(cse_var_148, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_49], 16)*placeholder_1[ramp(cse_var_139, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_79], 16)*placeholder_1[ramp(cse_var_139, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_124], 16)*placeholder_1[ramp(cse_var_139, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_43], 16)*placeholder_1[ramp(cse_var_139, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_111], 16)*placeholder_1[ramp(cse_var_139, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_28], 16)*placeholder_1[ramp(cse_var_139, 1, 16)]))
          conv2d_NCHWc_1[14] = (conv2d_NCHWc_1[14] + (broadcast(placeholder[cse_var_10], 16)*placeholder_1[ramp(cse_var_139, 1, 16)]))
          conv2d_NCHWc_1[15] = (conv2d_NCHWc_1[15] + (broadcast(placeholder[cse_var_56], 16)*placeholder_1[ramp(cse_var_139, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_95], 16)*placeholder_1[ramp(cse_var_149, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_78], 16)*placeholder_1[ramp(cse_var_149, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_123], 16)*placeholder_1[ramp(cse_var_149, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_42], 16)*placeholder_1[ramp(cse_var_149, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_110], 16)*placeholder_1[ramp(cse_var_149, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_27], 16)*placeholder_1[ramp(cse_var_149, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_9], 16)*placeholder_1[ramp(cse_var_149, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_55], 16)*placeholder_1[ramp(cse_var_149, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_95], 16)*placeholder_1[ramp(cse_var_138, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_78], 16)*placeholder_1[ramp(cse_var_138, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_123], 16)*placeholder_1[ramp(cse_var_138, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_42], 16)*placeholder_1[ramp(cse_var_138, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_110], 16)*placeholder_1[ramp(cse_var_138, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_27], 16)*placeholder_1[ramp(cse_var_138, 1, 16)]))
          conv2d_NCHWc_1[14] = (conv2d_NCHWc_1[14] + (broadcast(placeholder[cse_var_9], 16)*placeholder_1[ramp(cse_var_138, 1, 16)]))
          conv2d_NCHWc_1[15] = (conv2d_NCHWc_1[15] + (broadcast(placeholder[cse_var_55], 16)*placeholder_1[ramp(cse_var_138, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_94], 16)*placeholder_1[ramp(cse_var_150, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_77], 16)*placeholder_1[ramp(cse_var_150, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_122], 16)*placeholder_1[ramp(cse_var_150, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_40], 16)*placeholder_1[ramp(cse_var_150, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_108], 16)*placeholder_1[ramp(cse_var_150, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_26], 16)*placeholder_1[ramp(cse_var_150, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_150, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_54], 16)*placeholder_1[ramp(cse_var_150, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_94], 16)*placeholder_1[ramp(cse_var_137, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_77], 16)*placeholder_1[ramp(cse_var_137, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_122], 16)*placeholder_1[ramp(cse_var_137, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_40], 16)*placeholder_1[ramp(cse_var_137, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_108], 16)*placeholder_1[ramp(cse_var_137, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_26], 16)*placeholder_1[ramp(cse_var_137, 1, 16)]))
          conv2d_NCHWc_1[14] = (conv2d_NCHWc_1[14] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_137, 1, 16)]))
          conv2d_NCHWc_1[15] = (conv2d_NCHWc_1[15] + (broadcast(placeholder[cse_var_54], 16)*placeholder_1[ramp(cse_var_137, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_93], 16)*placeholder_1[ramp(cse_var_151, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_76], 16)*placeholder_1[ramp(cse_var_151, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_119], 16)*placeholder_1[ramp(cse_var_151, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_39], 16)*placeholder_1[ramp(cse_var_151, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_107], 16)*placeholder_1[ramp(cse_var_151, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_25], 16)*placeholder_1[ramp(cse_var_151, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_151, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_53], 16)*placeholder_1[ramp(cse_var_151, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_93], 16)*placeholder_1[ramp(cse_var_136, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_76], 16)*placeholder_1[ramp(cse_var_136, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_119], 16)*placeholder_1[ramp(cse_var_136, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_39], 16)*placeholder_1[ramp(cse_var_136, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_107], 16)*placeholder_1[ramp(cse_var_136, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_25], 16)*placeholder_1[ramp(cse_var_136, 1, 16)]))
          conv2d_NCHWc_1[14] = (conv2d_NCHWc_1[14] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_136, 1, 16)]))
          conv2d_NCHWc_1[15] = (conv2d_NCHWc_1[15] + (broadcast(placeholder[cse_var_53], 16)*placeholder_1[ramp(cse_var_136, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_92], 16)*placeholder_1[ramp(cse_var_152, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_74], 16)*placeholder_1[ramp(cse_var_152, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_109], 16)*placeholder_1[ramp(cse_var_152, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_38], 16)*placeholder_1[ramp(cse_var_152, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_106], 16)*placeholder_1[ramp(cse_var_152, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_24], 16)*placeholder_1[ramp(cse_var_152, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_152, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_51], 16)*placeholder_1[ramp(cse_var_152, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_92], 16)*placeholder_1[ramp(cse_var_135, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_74], 16)*placeholder_1[ramp(cse_var_135, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_109], 16)*placeholder_1[ramp(cse_var_135, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_38], 16)*placeholder_1[ramp(cse_var_135, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_106], 16)*placeholder_1[ramp(cse_var_135, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_24], 16)*placeholder_1[ramp(cse_var_135, 1, 16)]))
          conv2d_NCHWc_1[14] = (conv2d_NCHWc_1[14] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_135, 1, 16)]))
          conv2d_NCHWc_1[15] = (conv2d_NCHWc_1[15] + (broadcast(placeholder[cse_var_51], 16)*placeholder_1[ramp(cse_var_135, 1, 16)]))
          conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_91], 16)*placeholder_1[ramp(cse_var_153, 1, 16)]))
          conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_73], 16)*placeholder_1[ramp(cse_var_153, 1, 16)]))
          conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_99], 16)*placeholder_1[ramp(cse_var_153, 1, 16)]))
          conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_37], 16)*placeholder_1[ramp(cse_var_153, 1, 16)]))
          conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_105], 16)*placeholder_1[ramp(cse_var_153, 1, 16)]))
          conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_23], 16)*placeholder_1[ramp(cse_var_153, 1, 16)]))
          conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_153, 1, 16)]))
          conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_50], 16)*placeholder_1[ramp(cse_var_153, 1, 16)]))
          conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_91], 16)*placeholder_1[ramp(cse_var_134, 1, 16)]))
          conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_73], 16)*placeholder_1[ramp(cse_var_134, 1, 16)]))
          conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(placeholder[cse_var_99], 16)*placeholder_1[ramp(cse_var_134, 1, 16)]))
          conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(placeholder[cse_var_37], 16)*placeholder_1[ramp(cse_var_134, 1, 16)]))
          conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(placeholder[cse_var_105], 16)*placeholder_1[ramp(cse_var_134, 1, 16)]))
          conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(placeholder[cse_var_23], 16)*placeholder_1[ramp(cse_var_134, 1, 16)]))
          conv2d_NCHWc_1[14] = (conv2d_NCHWc_1[14] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_134, 1, 16)]))
          conv2d_NCHWc_1[15] = (conv2d_NCHWc_1[15] + (broadcast(placeholder[cse_var_50], 16)*placeholder_1[ramp(cse_var_134, 1, 16)]))
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax2.inner: int32, 0, 2) {
          for (ax3.inner: int32, 0, 4) {
            let cse_var_162: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 98)
            let cse_var_161: int32 = ((cse_var_162*32) + (ax1.inner*16))
            T_relu[ramp(((((((cse_var_162*25088) + (ax1.inner*12544)) + (floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 98), 7)*896)) + (ax2.inner*448)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 7)*64)) + (ax3.inner*16)), 1, 16)] = max((((conv2d_NCHWc_1[(((ax1.inner*8) + (ax2.inner*4)) + ax3.inner)] + placeholder_2[ramp(cse_var_161, 1, 16)])*placeholder_3[ramp(cse_var_161, 1, 16)]) + placeholder_4[ramp(cse_var_161, 1, 16)]), broadcast(0f32, 16))
          }
        }
      }
    }
  }
}


==== Task 57: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_9 (weight 1 key: ["d85f86643f68d4261269b8274457244f", [1, 6, 28, 28, 16], [6, 6, 3, 3, 16, 16], [1, 6, 1, 1, 16], [1, 6, 1, 1, 16], [1, 6, 1, 1, 16], [1, 6, 14, 14, 16]]) =====
placeholder = PLACEHOLDER [1, 6, 28, 28, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 29)) && (i3 >= 1)) && (i3 < 29)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [6, 6, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), ((oh*2) + kh), ((ow*2) + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_add[ax0, ax1, ax2, ax3, ax4]*placeholder[ax0, ax1, 0, 0, ax4])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (T_multiply[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3, data_pad_i4 = tuple(data_pad.op.axis) + tuple(data_pad.op.reduce_axis)
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_multiply_ax0, T_multiply_ax1, T_multiply_ax2, T_multiply_ax3, T_multiply_ax4 = tuple(T_multiply.op.axis) + tuple(T_multiply.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
s[T_multiply].compute_inline()
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=7)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=7)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=2)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=3)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=7)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=7)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=2)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
s[data_pad].compute_at(s[conv2d_NCHWc], conv2d_NCHWc_kh_o)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 64)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[data_pad].vectorize(data_pad_i4)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, placeholder_8: handle, placeholder_9: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_10: Pointer(float32), float32, [75264], []),
             placeholder_1: Buffer(placeholder_11: Pointer(float32), float32, [82944], []),
             placeholder_2: Buffer(placeholder_12: Pointer(float32), float32, [96], []),
             placeholder_3: Buffer(placeholder_13: Pointer(float32), float32, [96], []),
             placeholder_4: Buffer(placeholder_14: Pointer(float32), float32, [96], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [18816], [])}
  buffer_map = {placeholder_5: placeholder, placeholder_6: placeholder_1, placeholder_7: placeholder_2, placeholder_8: placeholder_3, placeholder_9: placeholder_4, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_6: placeholder_15: Buffer(placeholder_11, float32, [6, 6, 3, 3, 16, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 6, 14, 14, 16], []), placeholder_9: placeholder_16: Buffer(placeholder_14, float32, [1, 6, 1, 1, 16], []), placeholder_7: placeholder_17: Buffer(placeholder_12, float32, [1, 6, 1, 1, 16], []), placeholder_5: placeholder_18: Buffer(placeholder_10, float32, [1, 6, 28, 28, 16], []), placeholder_8: placeholder_19: Buffer(placeholder_13, float32, [1, 6, 1, 1, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 84) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [14]), storage_scope = global;
    allocate(data_pad: Pointer(global float32), float32, [240]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [14], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 6) {
        for (kh.outer: int32, 0, 3) {
          let cse_var_4: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 2)
          let cse_var_3: int32 = floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28), 2)
          let cse_var_2: bool = (1 <= ((cse_var_3*2) + kh.outer))
          let cse_var_1: int32 = ((((ic.outer*12544) + (cse_var_3*896)) + (kh.outer*448)) + (cse_var_4*224))
           {
            data_pad_1: Buffer(data_pad, float32, [240], [])[ramp(0, 1, 16)] = @tir.if_then_else((cse_var_2 && (1 <= cse_var_4)), placeholder[ramp((cse_var_1 - 464), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(16, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 448), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(32, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 432), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(48, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 416), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(64, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 400), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(80, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 384), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(96, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 368), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(112, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 352), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(128, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 336), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(144, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 320), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(160, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 304), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(176, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 288), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(192, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 272), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(208, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 256), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp(224, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 240), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            for (ic.inner: int32, 0, 16) {
              let cse_var_24: int32 = (ic.inner + 112)
              let cse_var_23: int32 = (ic.inner + 128)
              let cse_var_22: int32 = (ic.inner + 144)
              let cse_var_21: int32 = (ic.inner + 16)
              let cse_var_20: int32 = (ic.inner + 160)
              let cse_var_19: int32 = (ic.inner + 176)
              let cse_var_18: int32 = (ic.inner + 192)
              let cse_var_17: int32 = (ic.inner + 208)
              let cse_var_16: int32 = (ic.inner + 224)
              let cse_var_15: int32 = (ic.inner + 32)
              let cse_var_14: int32 = (ic.inner + 48)
              let cse_var_13: int32 = (ic.inner + 64)
              let cse_var_12: int32 = (ic.inner + 80)
              let cse_var_11: int32 = (ic.inner + 96)
              let cse_var_10: int32 = ((((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)*27648) + (ic.outer*2304)) + (kh.outer*768)) + (ic.inner*16))
              let cse_var_9: int32 = (cse_var_10 + 13824)
              let cse_var_8: int32 = (cse_var_10 + 512)
              let cse_var_7: int32 = (cse_var_10 + 256)
              let cse_var_6: int32 = (cse_var_10 + 14336)
              let cse_var_5: int32 = (cse_var_10 + 14080)
               {
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_11], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[ic.inner], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_11], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_24], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_24], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(data_pad_1[cse_var_11], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(data_pad_1[cse_var_11], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[10] = (conv2d_NCHWc_1[10] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[11] = (conv2d_NCHWc_1[11] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[12] = (conv2d_NCHWc_1[12] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[13] = (conv2d_NCHWc_1[13] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
              }
            }
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 7) {
          let cse_var_26: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)
          let cse_var_25: int32 = ((cse_var_26*32) + (ax1.inner*16))
          T_relu[ramp(((((cse_var_26*6272) + (ax1.inner*3136)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 28)*112)) + (ax3.inner*16)), 1, 16)] = max((((conv2d_NCHWc_1[((ax1.inner*7) + ax3.inner)] + placeholder_2[ramp(cse_var_25, 1, 16)])*placeholder_3[ramp(cse_var_25, 1, 16)]) + placeholder_4[ramp(cse_var_25, 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 58: vm_mod_fused_nn_avg_pool2d (weight 1 key: ["afaae8b373f21045eb860b447beb9f7a", [1, 12, 28, 28, 16], [1, 12, 28, 28, 16]]) =====
placeholder = PLACEHOLDER [1, 12, 28, 28, 16]
pad_temp(ax0, ax1, ax2, ax3, ax4) = tir.if_then_else(((((ax2 >= 1) && (ax2 < 29)) && (ax3 >= 1)) && (ax3 < 29)), placeholder[ax0, ax1, (ax2 - 1), (ax3 - 1), ax4], 0f)
tensor(ax0, ax1, ax2, ax3, ax4) += pad_temp[ax0, ax1, (ax2 + rv0), (ax3 + rv1), ax4]
tensor(ax0, ax1, ax2, ax3, ax4) = (tensor[ax0, ax1, ax2, ax3, ax4]/float32(max((((min(((ax2 - 1) + 2), 27) - ((ax2 - 1) + max((0 - (ax2 - 1)), 0))) + 1)*((min(((ax3 - 1) + 2), 27) - ((ax3 - 1) + max((0 - (ax3 - 1)), 0))) + 1)), 1)))


Trace for this task is: 
pad_temp_ax0, pad_temp_ax1, pad_temp_ax2, pad_temp_ax3, pad_temp_ax4 = tuple(pad_temp.op.axis) + tuple(pad_temp.op.reduce_axis)
tensor_ax0, tensor_ax1, tensor_ax2, tensor_ax3, tensor_ax4, tensor_rv0, tensor_rv1 = tuple(tensor.op.axis) + tuple(tensor.op.reduce_axis)
tensor_ax0, tensor_ax1, tensor_ax2, tensor_ax3, tensor_ax4 = tuple(tensor.op.axis) + tuple(tensor.op.reduce_axis)
s[tensor].compute_root()
s[tensor].compute_at(s[tensor], tensor_ax4)
s[pad_temp].compute_at(s[tensor], tensor_ax2)
tensor_ax0_ax1_fused_ax2_fused = s[tensor].fuse(tensor_ax0, tensor_ax1, tensor_ax2)
s[tensor].parallel(tensor_ax0_ax1_fused_ax2_fused)
s[tensor].pragma(tensor_ax0, "auto_unroll_max_step", 0)
s[tensor].pragma(tensor_ax0, "unroll_explicit", True)
s[pad_temp].vectorize(pad_temp_ax4)


The best replacement found is:
@main = primfn(placeholder_1: handle, tensor_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_2: Pointer(float32), float32, [150528], []),
             tensor: Buffer(tensor_2: Pointer(float32), float32, [150528], [])}
  buffer_map = {placeholder_1: placeholder, tensor_1: tensor}
  preflattened_buffer_map = {placeholder_1: placeholder_3: Buffer(placeholder_2, float32, [1, 12, 28, 28, 16], []), tensor_1: tensor_3: Buffer(tensor_2, float32, [1, 12, 28, 28, 16], [])} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 336) "parallel" {
    allocate(pad_temp: Pointer(global float32), float32, [1440]), storage_scope = global;
    allocate(tensor_4: Pointer(global float32), float32, [1]), storage_scope = global {
      for (ax2: int32, 0, 3) {
        for (ax3: int32, 0, 30) {
          let cse_var_2: int32 = (ax3*16)
          let cse_var_1: int32 = (ax2 + floormod(ax0.ax1.fused.ax2.fused, 28))
          pad_temp_1: Buffer(pad_temp, float32, [1440], [])[ramp(((ax2*480) + cse_var_2), 1, 16)] = @tir.if_then_else(((((1 <= cse_var_1) && (cse_var_1 < 29)) && (1 <= ax3)) && (ax3 < 29)), placeholder[ramp(((((ax2*448) + (ax0.ax1.fused.ax2.fused*448)) + cse_var_2) - 464), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
        }
      }
      for (ax3_1: int32, 0, 28) {
        for (ax4: int32, 0, 16) {
          let cse_var_3: int32 = floormod(ax0.ax1.fused.ax2.fused, 28)
           {
            tensor_5: Buffer(tensor_4, float32, [1], [], align=4)[0] = 0f32
            for (rv0: int32, 0, 3) {
              for (rv1: int32, 0, 3) {
                tensor_5[0] = (tensor_5[0] + pad_temp_1[((((rv0*480) + (ax3_1*16)) + (rv1*16)) + ax4)])
              }
            }
            tensor[(((ax0.ax1.fused.ax2.fused*448) + (ax3_1*16)) + ax4)] = (tensor_5[0] / cast(float32, max(((((min((cse_var_3 + 1), 27) + 2) - max((1 - cse_var_3), 0)) - cse_var_3)*(((min((ax3_1 + 1), 27) + 2) - max((1 - ax3_1), 0)) - ax3_1)), 1)))
          }
        }
      }
    }
  }
}


Running time in time_evaluator:  [3.5988336, 3.691201931034483, 3.728910082758621]
|graph_nodes| =  314
|graph_time| =  314
data_0 : 0.000
tvmgen_default_fused_layout_transform : 0.000
p0 : 0.000
p1 : 0.000
p2 : 0.000
p3 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu : 0.000
tvmgen_default_fused_nn_max_pool2d : 0.000
tvmgen_default_fused_layout_transform_1 : 0.000
p4 : 0.000
p5 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu : 0.000
p6 : 0.000
p7 : 0.000
p8 : 0.000
p9 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_1 : 0.000
tvmgen_default_fused_nn_max_pool2d_1 : 0.000
p10 : 0.000
p11 : 0.000
p12 : 0.000
p13 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_2 : 0.000
p14 : 0.000
p15 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 : 0.000
p16 : 0.000
p17 : 0.000
p18 : 0.000
p19 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_3 : 0.000
p20 : 0.000
p21 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_11 : 0.000
p22 : 0.000
p23 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 : 0.000
p24 : 0.000
p25 : 0.000
p26 : 0.000
p27 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_4 : 0.000
tvmgen_default_fused_nn_avg_pool2d : 0.000
p28 : 0.000
p29 : 0.000
p30 : 0.000
p31 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_5 : 0.000
tvmgen_default_fused_concatenate : 0.000
p32 : 0.000
p33 : 0.000
p34 : 0.000
p35 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_6 : 0.000
p36 : 0.000
p37 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 : 0.000
p38 : 0.000
p39 : 0.000
p40 : 0.000
p41 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_7 : 0.000
p42 : 0.000
p43 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_31 : 0.000
p44 : 0.000
p45 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_21 : 0.000
p46 : 0.000
p47 : 0.000
p48 : 0.000
p49 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_41 : 0.000
tvmgen_default_fused_nn_avg_pool2d_1 : 0.000
p50 : 0.000
p51 : 0.000
p52 : 0.000
p53 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_61 : 0.000
tvmgen_default_fused_concatenate_1 : 0.000
p54 : 0.000
p55 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 : 0.000
p56 : 0.000
p57 : 0.000
p58 : 0.000
p59 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_8 : 0.000
p60 : 0.000
p61 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 : 0.000
p62 : 0.000
p63 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_22 : 0.000
p64 : 0.000
p65 : 0.000
p66 : 0.000
p67 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_9 : 0.000
tvmgen_default_fused_nn_max_pool2d_2 : 0.000
tvmgen_default_fused_concatenate_2 : 0.000
p68 : 0.000
p69 : 0.000
p70 : 0.000
p71 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_10 : 0.000
p72 : 0.000
p73 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 : 0.000
p74 : 0.000
p75 : 0.000
p76 : 0.000
p77 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_11 : 0.000
p78 : 0.000
p79 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 : 0.000
p80 : 0.000
p81 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 : 0.000
p82 : 0.000
p83 : 0.000
p84 : 0.000
p85 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_12 : 0.000
tvmgen_default_fused_nn_avg_pool2d_2 : 0.000
p86 : 0.000
p87 : 0.000
p88 : 0.000
p89 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_13 : 0.000
tvmgen_default_fused_concatenate_3 : 0.000
p90 : 0.000
p91 : 0.000
p92 : 0.000
p93 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_14 : 0.000
p94 : 0.000
p95 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_71 : 0.000
p96 : 0.000
p97 : 0.000
p98 : 0.000
p99 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_15 : 0.000
p100 : 0.000
p101 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_72 : 0.000
p102 : 0.000
p103 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_81 : 0.000
p104 : 0.000
p105 : 0.000
p106 : 0.000
p107 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_121 : 0.000
tvmgen_default_fused_nn_avg_pool2d_21 : 0.000
p108 : 0.000
p109 : 0.000
p110 : 0.000
p111 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_131 : 0.000
tvmgen_default_fused_concatenate_4 : 0.000
p112 : 0.000
p113 : 0.000
p114 : 0.000
p115 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_16 : 0.000
p116 : 0.000
p117 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_9 : 0.000
p118 : 0.000
p119 : 0.000
p120 : 0.000
p121 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_17 : 0.000
p122 : 0.000
p123 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_91 : 0.000
p124 : 0.000
p125 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10 : 0.000
p126 : 0.000
p127 : 0.000
p128 : 0.000
p129 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_18 : 0.000
tvmgen_default_fused_nn_avg_pool2d_22 : 0.000
p130 : 0.000
p131 : 0.000
p132 : 0.000
p133 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_19 : 0.000
tvmgen_default_fused_concatenate_5 : 0.000
p134 : 0.000
p135 : 0.000
p136 : 0.000
p137 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_191 : 0.000
p138 : 0.000
p139 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_92 : 0.000
p140 : 0.000
p141 : 0.000
p142 : 0.000
p143 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_20 : 0.000
p144 : 0.000
p145 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_111 : 0.000
p146 : 0.000
p147 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_12 : 0.000
p148 : 0.000
p149 : 0.000
p150 : 0.000
p151 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_21 : 0.000
tvmgen_default_fused_nn_avg_pool2d_23 : 0.000
p152 : 0.000
p153 : 0.000
p154 : 0.000
p155 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_192 : 0.000
tvmgen_default_fused_concatenate_6 : 0.000
p156 : 0.000
p157 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_93 : 0.000
p158 : 0.000
p159 : 0.000
p160 : 0.000
p161 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_22 : 0.000
p162 : 0.000
p163 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_13 : 0.000
p164 : 0.000
p165 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_14 : 0.000
p166 : 0.000
p167 : 0.000
p168 : 0.000
p169 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_23 : 0.000
tvmgen_default_fused_nn_max_pool2d_3 : 0.000
tvmgen_default_fused_concatenate_7 : 0.000
p170 : 0.000
p171 : 0.000
p172 : 0.000
p173 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_24 : 0.000
p174 : 0.000
p175 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15 : 0.000
p176 : 0.000
p177 : 0.000
p178 : 0.000
p179 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_25 : 0.000
p180 : 0.000
p181 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_16 : 0.000
p182 : 0.000
p183 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_17 : 0.000
p184 : 0.000
p185 : 0.000
p186 : 0.000
p187 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_26 : 0.000
tvmgen_default_fused_nn_avg_pool2d_3 : 0.000
p188 : 0.000
p189 : 0.000
p190 : 0.000
p191 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_27 : 0.000
tvmgen_default_fused_concatenate_8 : 0.000
p192 : 0.000
p193 : 0.000
p194 : 0.000
p195 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_241 : 0.000
p196 : 0.000
p197 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_151 : 0.000
p198 : 0.000
p199 : 0.000
p200 : 0.000
p201 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_251 : 0.000
p202 : 0.000
p203 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_152 : 0.000
p204 : 0.000
p205 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18 : 0.000
p206 : 0.000
p207 : 0.000
p208 : 0.000
p209 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_261 : 0.000
tvmgen_default_fused_nn_max_pool2d_4 : 0.000
p210 : 0.000
p211 : 0.000
p212 : 0.000
p213 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_271 : 0.000
tvmgen_default_fused_concatenate_81 : 0.000
tvmgen_default_fused_nn_avg_pool2d_4 : 0.000
tvmgen_default_fused_layout_transform_reshape : 0.000
p214 : 0.000
p215 : 0.000
tvmgen_default_fused_nn_dense_add : 0.000
tvmgen_default_fused_nn_softmax : 0.000
