nohup: ignoring input
[23:07:43] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #0: "fused_multiply_add_nn_pad_layout_transform"
[23:07:43] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 3, 416, 416), "float32"], placeholder_1: T.Buffer[(1,), "float32"], placeholder_2: T.Buffer[(3, 1, 1), "float32"], T_layout_trans: T.Buffer[(1, 1, 418, 418, 3), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        T_multiply = T.alloc_buffer([1, 3, 416, 416], dtype="float32")
        T_add = T.alloc_buffer([1, 3, 416, 416], dtype="float32")
        compile_engine_const = T.alloc_buffer([], dtype="float32")
        T_cast = T.alloc_buffer([], dtype="float32")
        T_pad = T.alloc_buffer([1, 3, 418, 418], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 3, 416, 416):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[ax0, ax1, ax2, ax3], placeholder_1[0])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = placeholder[ax0, ax1, ax2, ax3] * placeholder_1[0]
        for i0, i1, i2, i3 in T.grid(1, 3, 416, 416):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_2[ax1, 0, 0], T_multiply[ax0, ax1, ax2, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = placeholder_2[ax1, 0, 0] + T_multiply[ax0, ax1, ax2, ax3]
        with T.block("compile_engine_const"):
            T.reads()
            T.writes(compile_engine_const[()])
            compile_engine_const[()] = T.float32(0)
        with T.block("T_cast"):
            T.reads(compile_engine_const[()])
            T.writes(T_cast[()])
            T_cast[()] = compile_engine_const[()]
        for i0, i1, i2, i3 in T.grid(1, 3, 418, 418):
            with T.block("T_pad"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2 - 1, ax3 - 1], T_cast[()])
                T.writes(T_pad[ax0, ax1, ax2, ax3])
                T_pad[ax0, ax1, ax2, ax3] = T.if_then_else(1 <= ax2 and ax2 < 417 and 1 <= ax3 and ax3 < 417, T_add[ax0, ax1, ax2 - 1, ax3 - 1], T_cast[()], dtype="float32")
        for i0, i1, i2, i3, i4 in T.grid(1, 1, 418, 418, 3):
            with T.block("T_layout_trans"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_pad[ax0, ax1 * 3 + ax4, ax2, ax3])
                T.writes(T_layout_trans[ax0, ax1, ax2, ax3, ax4])
                T_layout_trans[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(ax0 < 1 and ax1 * 3 + ax4 < 3 and ax2 < 418 and ax3 < 418, T_pad[ax0, ax1 * 3 + ax4, ax2, ax3], T.float32(0), dtype="float32")
    

[23:07:44] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 1 design space(s) generated
[23:07:44] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 3, 416, 416), "float32"], placeholder_1: T.Buffer[(1,), "float32"], placeholder_2: T.Buffer[(3, 1, 1), "float32"], T_layout_trans: T.Buffer[(1, 1, 418, 418, 3), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            T_pad = T.alloc_buffer([1, 3, 418, 418], dtype="float32")
            for i0, i1, i2, i3 in T.grid(1, 3, 418, 418):
                with T.block("T_pad"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(placeholder_2[ax1, 0, 0], placeholder[ax0, ax1, ax2 - 1, ax3 - 1], placeholder_1[0])
                    T.writes(T_pad[ax0, ax1, ax2, ax3])
                    T_pad[ax0, ax1, ax2, ax3] = T.if_then_else(1 <= ax2 and ax2 < 417 and 1 <= ax3 and ax3 < 417, placeholder_2[ax1, 0, 0] + placeholder[ax0, ax1, ax2 - 1, ax3 - 1] * placeholder_1[0], T.float32(0), dtype="float32")
            for i0, i1, i2, i3, i4 in T.grid(1, 1, 418, 418, 3):
                with T.block("T_layout_trans"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(T_pad[ax0, ax1 * 3 + ax4, ax2, ax3])
                    T.writes(T_layout_trans[ax0, ax1, ax2, ax3, ax4])
                    T_layout_trans[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(ax0 < 1 and ax1 * 3 + ax4 < 3 and ax2 < 418 and ax3 < 418, T_pad[ax0, ax1 * 3 + ax4, ax2, ax3], T.float32(0), dtype="float32")
    

b0 = sch.get_block(name="T_multiply", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="compile_engine_const", func_name="main")
b3 = sch.get_block(name="T_cast", func_name="main")
b4 = sch.get_block(name="T_pad", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.vectorize", ann_val=64)
v6 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v6)
l7 = sch.sample_compute_location(block=b4, decision=-1)
sch.compute_at(block=b4, loop=l7, preserve_unit_loops=True)
[23:07:44] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"
[23:07:44] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1, 418, 418, 3), "float32"], placeholder_1: T.Buffer[(4, 1, 3, 3, 3, 4), "float32"], placeholder_2: T.Buffer[(1, 4, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 4, 416, 416, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 4, 416, 416, 4], dtype="float32")
        T_add = T.alloc_buffer([1, 4, 416, 416, 4], dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6, i7 in T.grid(1, 4, 416, 416, 4, 3, 3, 3):
            with T.block("conv2d_NCHWc"):
                n, oc_chunk, oh, ow, oc_block, ic, kh, kw = T.axis.remap("SSSSSRRR", [i0, i1, i2, i3, i4, i5, i6, i7])
                T.reads(placeholder[n, ic // 3, oh + kh, ow + kw, ic % 3], placeholder_1[oc_chunk, ic // 3, kh, kw, ic % 3, oc_block])
                T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                T.block_attr({"workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1, 418, 418, 3], "float32"], ["TENSOR", [4, 1, 3, 3, 3, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW3c", "NCHW4c", "float32"]})
                with T.init():
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 3, oh + kh, ow + kw, ic % 3] * placeholder_1[oc_chunk, ic // 3, kh, kw, ic % 3, oc_block]
        for i0, i1, i2, i3, i4 in T.grid(1, 4, 416, 416, 4):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                T.writes(T_add[ax0, ax1, ax2, ax3, ax4])
                T_add[ax0, ax1, ax2, ax3, ax4] = conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]
        for i0, i1, i2, i3, i4 in T.grid(1, 4, 416, 416, 4):
            with T.block("T_leaky_relu"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_add[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < T_add[ax0, ax1, ax2, ax3, ax4], T_add[ax0, ax1, ax2, ax3, ax4], T_add[ax0, ax1, ax2, ax3, ax4] * T.float32(0.10000000149011612))
    

[23:07:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 3 design space(s) generated
[23:07:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1, 418, 418, 3), "float32"], placeholder_1: T.Buffer[(4, 1, 3, 3, 3, 4), "float32"], placeholder_2: T.Buffer[(1, 4, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 4, 416, 416, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 4, 416, 416, 4], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0, i0_1, i1_1, i2_1, i3_1, i4_1, i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(1, 1, 1, 1, 2, 1, 2, 2, 13, 1, 3, 3, 1, 1, 1, 208, 32, 1, 1, 1, 3, 1, 2, 1, 1, 2):
                with T.block("conv2d_NCHWc"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(4, i1_1 * 2 + i1_3)
                    oh = T.axis.spatial(416, i2_1 * 208 + i2_2)
                    ow = T.axis.spatial(416, i3_1 * 32 + i3_2)
                    oc_block = T.axis.spatial(4, i4_0 * 2 + i4_3)
                    ic, kh, kw = T.axis.remap("RRR", [i5_0, i6_0, i7_1])
                    T.reads(placeholder[n, ic // 3, oh + kh, ow + kw, ic % 3], placeholder_1[oc_chunk, ic // 3, kh, kw, ic % 3, oc_block])
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1, 418, 418, 3], "float32"], ["TENSOR", [4, 1, 3, 3, 3, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW3c", "NCHW4c", "float32"]})
                    with T.init():
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 3, oh + kh, ow + kw, ic % 3] * placeholder_1[oc_chunk, ic // 3, kh, kw, ic % 3, oc_block]
            for i0, i1, i2, i3, i4 in T.grid(1, 4, 416, 416, 4):
                with T.block("T_leaky_relu"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                    T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                    T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 208, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 13, 32, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[3, 1])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
[23:07:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #1:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1, 418, 418, 3), "float32"], placeholder_1: T.Buffer[(4, 1, 3, 3, 3, 4), "float32"], placeholder_2: T.Buffer[(1, 4, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 4, 416, 416, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":16, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 4, 416, 416, 4], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0, i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 1, 1, 1, 2, 1, 2, 2, 13, 1):
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(3, 3, 1, 1, 1, 208, 32, 1, 1, 1, 3, 1, 2, 1, 1, 2):
                    with T.block("conv2d_NCHWc"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(4, i1_1 * 2 + i1_3)
                        oh = T.axis.spatial(416, i2_1 * 208 + i2_2)
                        ow = T.axis.spatial(416, i3_1 * 32 + i3_2)
                        oc_block = T.axis.spatial(4, i4_0 * 2 + i4_3)
                        ic, kh, kw = T.axis.remap("RRR", [i5_0, i6_0, i7_1])
                        T.reads(placeholder[n, ic // 3, oh + kh, ow + kw, ic % 3], placeholder_1[oc_chunk, ic // 3, kh, kw, ic % 3, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1, 418, 418, 3], "float32"], ["TENSOR", [4, 1, 3, 3, 3, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW3c", "NCHW4c", "float32"]})
                        with T.init():
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 3, oh + kh, ow + kw, ic % 3] * placeholder_1[oc_chunk, ic // 3, kh, kw, ic % 3, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 2, 208, 32, 2):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, ax0)
                        ax1_1 = T.axis.spatial(4, i1_1 * 2 + ax1)
                        ax2_1 = T.axis.spatial(416, i2_1 * 208 + ax2)
                        ax3_1 = T.axis.spatial(416, i3_1 * 32 + ax3)
                        ax4_1 = T.axis.spatial(4, i4_0 * 2 + ax4)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 208, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 13, 32, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[3, 1])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
[23:07:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #2:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1, 418, 418, 3), "float32"], placeholder_1: T.Buffer[(4, 1, 3, 3, 3, 4), "float32"], placeholder_2: T.Buffer[(1, 4, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 4, 416, 416, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":16, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 4, 416, 416, 4], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0 in T.grid(1, 1, 1, 1, 2):
                for i0_1, i1_1, i2_1, i3_1, i4_1, i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(1, 2, 2, 13, 1, 3, 3, 1, 1, 1, 208, 32, 1, 1, 1, 3, 1, 2, 1, 1, 2):
                    with T.block("conv2d_NCHWc"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(4, i1_1 * 2 + i1_3)
                        oh = T.axis.spatial(416, i2_1 * 208 + i2_2)
                        ow = T.axis.spatial(416, i3_1 * 32 + i3_2)
                        oc_block = T.axis.spatial(4, i4_0 * 2 + i4_3)
                        ic, kh, kw = T.axis.remap("RRR", [i5_0, i6_0, i7_1])
                        T.reads(placeholder[n, ic // 3, oh + kh, ow + kw, ic % 3], placeholder_1[oc_chunk, ic // 3, kh, kw, ic % 3, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1, 418, 418, 3], "float32"], ["TENSOR", [4, 1, 3, 3, 3, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW3c", "NCHW4c", "float32"]})
                        with T.init():
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 3, oh + kh, ow + kw, ic % 3] * placeholder_1[oc_chunk, ic // 3, kh, kw, ic % 3, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 4, 416, 416, 2):
                    with T.block("T_leaky_relu"):
                        ax0_1, ax1_1, ax2_1, ax3_1 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                        ax4_1 = T.axis.spatial(4, i4_0 * 2 + ax4)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 208, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 13, 32, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[3, 1])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
[23:07:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #2: "fused_nn_pad"
[23:07:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4, 416, 416, 4), "float32"], T_pad: T.Buffer[(1, 4, 416, 416, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3, i4 in T.grid(1, 4, 416, 416, 4):
            with T.block("T_pad"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(placeholder[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                T_pad[ax0, ax1, ax2, ax3, ax4] = placeholder[ax0, ax1, ax2, ax3, ax4]
    

[23:07:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 1 design space(s) generated
[23:07:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4, 416, 416, 4), "float32"], T_pad: T.Buffer[(1, 4, 416, 416, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":64, "meta_schedule.vectorize":64})
            for i0, i1, i2, i3, i4 in T.grid(1, 4, 416, 416, 4):
                with T.block("T_pad"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(placeholder[ax0, ax1, ax2, ax3, ax4])
                    T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                    T_pad[ax0, ax1, ax2, ax3, ax4] = placeholder[ax0, ax1, ax2, ax3, ax4]
    

b0 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.vectorize", ann_val=64)
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
[23:07:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #3: "fused_nn_max_pool2d"
[23:07:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4, 416, 416, 4), "float32"], tensor: T.Buffer[(1, 4, 208, 208, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 4, 208, 208, 4, 2, 2):
            with T.block("tensor"):
                ax0, ax1, ax2, ax3, ax4, rv0, rv1 = T.axis.remap("SSSSSRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
                T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                with T.init():
                    tensor[ax0, ax1, ax2, ax3, ax4] = T.float32(-3.4028234663852886e+38)
                tensor[ax0, ax1, ax2, ax3, ax4] = T.max(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
    

[23:07:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 1 design space(s) generated
[23:07:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4, 416, 416, 4), "float32"], tensor: T.Buffer[(1, 4, 208, 208, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 4, 208, 208, 4, 2, 2):
                with T.block("tensor"):
                    ax0, ax1, ax2, ax3, ax4, rv0, rv1 = T.axis.remap("SSSSSRR", [i0, i1, i2, i3, i4, i5, i6])
                    T.reads(placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
                    T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                    with T.init():
                        tensor[ax0, ax1, ax2, ax3, ax4] = T.float32(-3.4028234663852886e+38)
                    tensor[ax0, ax1, ax2, ax3, ax4] = T.max(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
    

b0 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.vectorize", ann_val=64)
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
[23:07:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #4: "fused_nn_pad_1"
[23:07:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4, 208, 208, 4), "float32"], T_pad: T.Buffer[(1, 4, 210, 210, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        compile_engine_const = T.alloc_buffer([], dtype="float32")
        T_cast = T.alloc_buffer([], dtype="float32")
        with T.block("compile_engine_const"):
            T.reads()
            T.writes(compile_engine_const[()])
            compile_engine_const[()] = T.float32(0)
        with T.block("T_cast"):
            T.reads(compile_engine_const[()])
            T.writes(T_cast[()])
            T_cast[()] = compile_engine_const[()]
        for i0, i1, i2, i3, i4 in T.grid(1, 4, 210, 210, 4):
            with T.block("T_pad"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T_cast[()])
                T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(1 <= ax2 and ax2 < 209 and 1 <= ax3 and ax3 < 209, placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T_cast[()], dtype="float32")
    

[23:07:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 1 design space(s) generated
[23:07:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4, 208, 208, 4), "float32"], T_pad: T.Buffer[(1, 4, 210, 210, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            for i0, i1, i2, i3, i4 in T.grid(1, 4, 210, 210, 4):
                with T.block("T_pad"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4])
                    T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                    T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(1 <= ax2 and ax2 < 209 and 1 <= ax3 and ax3 < 209, placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T.float32(0), dtype="float32")
    

b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_cast", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v3 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v3)
[23:07:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"
[23:07:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4, 210, 210, 4), "float32"], placeholder_1: T.Buffer[(8, 4, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 8, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 8, 208, 208, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 8, 208, 208, 4], dtype="float32")
        T_add = T.alloc_buffer([1, 8, 208, 208, 4], dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6, i7 in T.grid(1, 8, 208, 208, 4, 16, 3, 3):
            with T.block("conv2d_NCHWc"):
                n, oc_chunk, oh, ow, oc_block, ic, kh, kw = T.axis.remap("SSSSSRRR", [i0, i1, i2, i3, i4, i5, i6, i7])
                T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                T.block_attr({"workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 4, 210, 210, 4], "float32"], ["TENSOR", [8, 4, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                with T.init():
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
        for i0, i1, i2, i3, i4 in T.grid(1, 8, 208, 208, 4):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                T.writes(T_add[ax0, ax1, ax2, ax3, ax4])
                T_add[ax0, ax1, ax2, ax3, ax4] = conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]
        for i0, i1, i2, i3, i4 in T.grid(1, 8, 208, 208, 4):
            with T.block("T_leaky_relu"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_add[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < T_add[ax0, ax1, ax2, ax3, ax4], T_add[ax0, ax1, ax2, ax3, ax4], T_add[ax0, ax1, ax2, ax3, ax4] * T.float32(0.10000000149011612))
    

[23:07:46] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 3 design space(s) generated
[23:07:46] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4, 210, 210, 4), "float32"], placeholder_1: T.Buffer[(8, 4, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 8, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 8, 208, 208, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":16, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 8, 208, 208, 4], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0, i0_1, i1_1, i2_1, i3_1, i4_1, i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(1, 1, 2, 1, 2, 1, 8, 1, 26, 1, 8, 3, 1, 1, 1, 52, 2, 1, 2, 1, 3, 1, 1, 2, 4, 2):
                with T.block("conv2d_NCHWc"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(8, i1_1)
                    oh = T.axis.spatial(208, i2_0 * 104 + i2_2 * 2 + i2_3)
                    ow = T.axis.spatial(208, i3_1 * 8 + i3_2 * 4 + i3_3)
                    oc_block = T.axis.spatial(4, i4_0 * 2 + i4_3)
                    ic = T.axis.reduce(16, i5_0 * 2 + i5_1)
                    kh, kw = T.axis.remap("RR", [i6_0, i7_1])
                    T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 4, 210, 210, 4], "float32"], ["TENSOR", [8, 4, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                    with T.init():
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
            for i0, i1, i2, i3, i4 in T.grid(1, 8, 208, 208, 4):
                with T.block("T_leaky_relu"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                    T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                    T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 8, 1, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 52, 2])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 26, 2, 4])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[8, 2])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
[23:07:46] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #1:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4, 210, 210, 4), "float32"], placeholder_1: T.Buffer[(8, 4, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 8, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 8, 208, 208, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":16, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 8, 208, 208, 4], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0, i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 1, 2, 1, 2, 1, 8, 1, 26, 1):
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(8, 3, 1, 1, 1, 52, 2, 1, 2, 1, 3, 1, 1, 2, 4, 2):
                    with T.block("conv2d_NCHWc"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(8, i1_1)
                        oh = T.axis.spatial(208, i2_0 * 104 + i2_2 * 2 + i2_3)
                        ow = T.axis.spatial(208, i3_1 * 8 + i3_2 * 4 + i3_3)
                        oc_block = T.axis.spatial(4, i4_0 * 2 + i4_3)
                        ic = T.axis.reduce(16, i5_0 * 2 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_0, i7_1])
                        T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 4, 210, 210, 4], "float32"], ["TENSOR", [8, 4, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        with T.init():
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 1, 104, 8, 2):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, ax0)
                        ax1_1 = T.axis.spatial(8, i1_1 + ax1)
                        ax2_1 = T.axis.spatial(208, i2_0 * 104 + ax2)
                        ax3_1 = T.axis.spatial(208, i3_1 * 8 + ax3)
                        ax4_1 = T.axis.spatial(4, i4_0 * 2 + ax4)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 8, 1, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 52, 2])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 26, 2, 4])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[8, 2])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
[23:07:46] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #2:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4, 210, 210, 4), "float32"], placeholder_1: T.Buffer[(8, 4, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 8, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 8, 208, 208, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 8, 208, 208, 4], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0 in T.grid(1, 1, 2, 1, 2):
                for i0_1, i1_1, i2_1, i3_1, i4_1, i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(1, 8, 1, 26, 1, 8, 3, 1, 1, 1, 52, 2, 1, 2, 1, 3, 1, 1, 2, 4, 2):
                    with T.block("conv2d_NCHWc"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(8, i1_1)
                        oh = T.axis.spatial(208, i2_0 * 104 + i2_2 * 2 + i2_3)
                        ow = T.axis.spatial(208, i3_1 * 8 + i3_2 * 4 + i3_3)
                        oc_block = T.axis.spatial(4, i4_0 * 2 + i4_3)
                        ic = T.axis.reduce(16, i5_0 * 2 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_0, i7_1])
                        T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 4, 210, 210, 4], "float32"], ["TENSOR", [8, 4, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        with T.init():
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 8, 104, 208, 2):
                    with T.block("T_leaky_relu"):
                        ax0_1, ax1_1 = T.axis.remap("SS", [ax0, ax1])
                        ax2_1 = T.axis.spatial(208, i2_0 * 104 + ax2)
                        ax3_1 = T.axis.spatial(208, ax3)
                        ax4_1 = T.axis.spatial(4, i4_0 * 2 + ax4)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 8, 1, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 52, 2])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 26, 2, 4])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[8, 2])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
[23:07:46] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #6: "fused_nn_pad_2"
[23:07:46] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 8, 208, 208, 4), "float32"], T_pad: T.Buffer[(1, 8, 208, 208, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3, i4 in T.grid(1, 8, 208, 208, 4):
            with T.block("T_pad"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(placeholder[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                T_pad[ax0, ax1, ax2, ax3, ax4] = placeholder[ax0, ax1, ax2, ax3, ax4]
    

[23:07:46] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 1 design space(s) generated
[23:07:46] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 8, 208, 208, 4), "float32"], T_pad: T.Buffer[(1, 8, 208, 208, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            for i0, i1, i2, i3, i4 in T.grid(1, 8, 208, 208, 4):
                with T.block("T_pad"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(placeholder[ax0, ax1, ax2, ax3, ax4])
                    T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                    T_pad[ax0, ax1, ax2, ax3, ax4] = placeholder[ax0, ax1, ax2, ax3, ax4]
    

b0 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.vectorize", ann_val=64)
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
[23:07:46] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #7: "fused_nn_max_pool2d_1"
[23:07:46] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 8, 208, 208, 4), "float32"], tensor: T.Buffer[(1, 8, 104, 104, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 8, 104, 104, 4, 2, 2):
            with T.block("tensor"):
                ax0, ax1, ax2, ax3, ax4, rv0, rv1 = T.axis.remap("SSSSSRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
                T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                with T.init():
                    tensor[ax0, ax1, ax2, ax3, ax4] = T.float32(-3.4028234663852886e+38)
                tensor[ax0, ax1, ax2, ax3, ax4] = T.max(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
    

[23:07:46] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 1 design space(s) generated
[23:07:46] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 8, 208, 208, 4), "float32"], tensor: T.Buffer[(1, 8, 104, 104, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 8, 104, 104, 4, 2, 2):
                with T.block("tensor"):
                    ax0, ax1, ax2, ax3, ax4, rv0, rv1 = T.axis.remap("SSSSSRR", [i0, i1, i2, i3, i4, i5, i6])
                    T.reads(placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
                    T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                    with T.init():
                        tensor[ax0, ax1, ax2, ax3, ax4] = T.float32(-3.4028234663852886e+38)
                    tensor[ax0, ax1, ax2, ax3, ax4] = T.max(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
    

b0 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.vectorize", ann_val=64)
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
[23:07:46] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #8: "fused_nn_pad_3"
[23:07:46] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 8, 104, 104, 4), "float32"], T_pad: T.Buffer[(1, 8, 106, 106, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        compile_engine_const = T.alloc_buffer([], dtype="float32")
        T_cast = T.alloc_buffer([], dtype="float32")
        with T.block("compile_engine_const"):
            T.reads()
            T.writes(compile_engine_const[()])
            compile_engine_const[()] = T.float32(0)
        with T.block("T_cast"):
            T.reads(compile_engine_const[()])
            T.writes(T_cast[()])
            T_cast[()] = compile_engine_const[()]
        for i0, i1, i2, i3, i4 in T.grid(1, 8, 106, 106, 4):
            with T.block("T_pad"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T_cast[()])
                T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(1 <= ax2 and ax2 < 105 and 1 <= ax3 and ax3 < 105, placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T_cast[()], dtype="float32")
    

[23:07:47] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 1 design space(s) generated
[23:07:47] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 8, 104, 104, 4), "float32"], T_pad: T.Buffer[(1, 8, 106, 106, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":16, "meta_schedule.vectorize":64})
            for i0, i1, i2, i3, i4 in T.grid(1, 8, 106, 106, 4):
                with T.block("T_pad"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4])
                    T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                    T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(1 <= ax2 and ax2 < 105 and 1 <= ax3 and ax3 < 105, placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T.float32(0), dtype="float32")
    

b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_cast", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v3 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v3)
[23:07:47] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"
[23:07:47] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 8, 106, 106, 4), "float32"], placeholder_1: T.Buffer[(16, 8, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 16, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 16, 104, 104, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 16, 104, 104, 4], dtype="float32")
        T_add = T.alloc_buffer([1, 16, 104, 104, 4], dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6, i7 in T.grid(1, 16, 104, 104, 4, 32, 3, 3):
            with T.block("conv2d_NCHWc"):
                n, oc_chunk, oh, ow, oc_block, ic, kh, kw = T.axis.remap("SSSSSRRR", [i0, i1, i2, i3, i4, i5, i6, i7])
                T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                T.block_attr({"workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 106, 106, 4], "float32"], ["TENSOR", [16, 8, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                with T.init():
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
        for i0, i1, i2, i3, i4 in T.grid(1, 16, 104, 104, 4):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                T.writes(T_add[ax0, ax1, ax2, ax3, ax4])
                T_add[ax0, ax1, ax2, ax3, ax4] = conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]
        for i0, i1, i2, i3, i4 in T.grid(1, 16, 104, 104, 4):
            with T.block("T_leaky_relu"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_add[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < T_add[ax0, ax1, ax2, ax3, ax4], T_add[ax0, ax1, ax2, ax3, ax4], T_add[ax0, ax1, ax2, ax3, ax4] * T.float32(0.10000000149011612))
    

[23:07:48] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 3 design space(s) generated
[23:07:48] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 8, 106, 106, 4), "float32"], placeholder_1: T.Buffer[(16, 8, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 16, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 16, 104, 104, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":64, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 16, 104, 104, 4], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0, i0_1, i1_1, i2_1, i3_1, i4_1, i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(1, 4, 13, 104, 1, 1, 2, 1, 1, 1, 2, 3, 1, 1, 2, 4, 1, 1, 16, 1, 3, 1, 1, 2, 1, 4):
                with T.block("conv2d_NCHWc"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(16, i1_0 * 4 + i1_1 * 2 + i1_2)
                    oh = T.axis.spatial(104, i2_0 * 8 + i2_2 * 2 + i2_3)
                    ow, oc_block = T.axis.remap("SS", [i3_0, i4_3])
                    ic = T.axis.reduce(32, i5_0 * 16 + i5_1)
                    kh, kw = T.axis.remap("RR", [i6_0, i7_1])
                    T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 106, 106, 4], "float32"], ["TENSOR", [16, 8, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                    with T.init():
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
            for i0, i1, i2, i3, i4 in T.grid(1, 16, 104, 104, 4):
                with T.block("T_leaky_relu"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                    T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                    T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[4, 2, 2, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[13, 1, 4, 2])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[104, 1, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[2, 16])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
[23:07:48] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #1:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 8, 106, 106, 4), "float32"], placeholder_1: T.Buffer[(16, 8, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 16, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 16, 104, 104, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 16, 104, 104, 4], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0, i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 4, 13, 104, 1, 1, 2, 1, 1, 1):
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(2, 3, 1, 1, 2, 4, 1, 1, 16, 1, 3, 1, 1, 2, 1, 4):
                    with T.block("conv2d_NCHWc"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(16, i1_0 * 4 + i1_1 * 2 + i1_2)
                        oh = T.axis.spatial(104, i2_0 * 8 + i2_2 * 2 + i2_3)
                        ow, oc_block = T.axis.remap("SS", [i3_0, i4_3])
                        ic = T.axis.reduce(32, i5_0 * 16 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_0, i7_1])
                        T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 106, 106, 4], "float32"], ["TENSOR", [16, 8, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        with T.init():
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 2, 8, 1, 4):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, ax0)
                        ax1_1 = T.axis.spatial(16, i1_0 * 4 + i1_1 * 2 + ax1)
                        ax2_1 = T.axis.spatial(104, i2_0 * 8 + ax2)
                        ax3_1 = T.axis.spatial(104, i3_0 + ax3)
                        ax4_1 = T.axis.spatial(4, ax4)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[4, 2, 2, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[13, 1, 4, 2])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[104, 1, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[2, 16])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
[23:07:48] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #2:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 8, 106, 106, 4), "float32"], placeholder_1: T.Buffer[(16, 8, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 16, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 16, 104, 104, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":64, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 16, 104, 104, 4], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0 in T.grid(1, 4, 13, 104, 1):
                for i0_1, i1_1, i2_1, i3_1, i4_1, i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(1, 2, 1, 1, 1, 2, 3, 1, 1, 2, 4, 1, 1, 16, 1, 3, 1, 1, 2, 1, 4):
                    with T.block("conv2d_NCHWc"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(16, i1_0 * 4 + i1_1 * 2 + i1_2)
                        oh = T.axis.spatial(104, i2_0 * 8 + i2_2 * 2 + i2_3)
                        ow, oc_block = T.axis.remap("SS", [i3_0, i4_3])
                        ic = T.axis.reduce(32, i5_0 * 16 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_0, i7_1])
                        T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 106, 106, 4], "float32"], ["TENSOR", [16, 8, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        with T.init():
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 4, 8, 1, 4):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, ax0)
                        ax1_1 = T.axis.spatial(16, i1_0 * 4 + ax1)
                        ax2_1 = T.axis.spatial(104, i2_0 * 8 + ax2)
                        ax3_1 = T.axis.spatial(104, i3_0 + ax3)
                        ax4_1 = T.axis.spatial(4, ax4)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[4, 2, 2, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[13, 1, 4, 2])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[104, 1, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[2, 16])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
[23:07:48] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #10: "fused_nn_pad_4"
[23:07:48] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 104, 104, 4), "float32"], T_pad: T.Buffer[(1, 16, 104, 104, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3, i4 in T.grid(1, 16, 104, 104, 4):
            with T.block("T_pad"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(placeholder[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                T_pad[ax0, ax1, ax2, ax3, ax4] = placeholder[ax0, ax1, ax2, ax3, ax4]
    

[23:07:48] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 1 design space(s) generated
[23:07:48] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 104, 104, 4), "float32"], T_pad: T.Buffer[(1, 16, 104, 104, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":64, "meta_schedule.vectorize":64})
            for i0, i1, i2, i3, i4 in T.grid(1, 16, 104, 104, 4):
                with T.block("T_pad"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(placeholder[ax0, ax1, ax2, ax3, ax4])
                    T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                    T_pad[ax0, ax1, ax2, ax3, ax4] = placeholder[ax0, ax1, ax2, ax3, ax4]
    

b0 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.vectorize", ann_val=64)
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
[23:07:48] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #11: "fused_nn_max_pool2d_2"
[23:07:48] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 104, 104, 4), "float32"], tensor: T.Buffer[(1, 16, 52, 52, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 16, 52, 52, 4, 2, 2):
            with T.block("tensor"):
                ax0, ax1, ax2, ax3, ax4, rv0, rv1 = T.axis.remap("SSSSSRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
                T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                with T.init():
                    tensor[ax0, ax1, ax2, ax3, ax4] = T.float32(-3.4028234663852886e+38)
                tensor[ax0, ax1, ax2, ax3, ax4] = T.max(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
    

[23:07:48] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 1 design space(s) generated
[23:07:48] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 104, 104, 4), "float32"], tensor: T.Buffer[(1, 16, 52, 52, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":16, "meta_schedule.vectorize":64})
            for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 16, 52, 52, 4, 2, 2):
                with T.block("tensor"):
                    ax0, ax1, ax2, ax3, ax4, rv0, rv1 = T.axis.remap("SSSSSRR", [i0, i1, i2, i3, i4, i5, i6])
                    T.reads(placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
                    T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                    with T.init():
                        tensor[ax0, ax1, ax2, ax3, ax4] = T.float32(-3.4028234663852886e+38)
                    tensor[ax0, ax1, ax2, ax3, ax4] = T.max(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
    

b0 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.vectorize", ann_val=64)
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
[23:07:48] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #12: "fused_nn_pad_5"
[23:07:48] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 52, 52, 4), "float32"], T_pad: T.Buffer[(1, 16, 54, 54, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        compile_engine_const = T.alloc_buffer([], dtype="float32")
        T_cast = T.alloc_buffer([], dtype="float32")
        with T.block("compile_engine_const"):
            T.reads()
            T.writes(compile_engine_const[()])
            compile_engine_const[()] = T.float32(0)
        with T.block("T_cast"):
            T.reads(compile_engine_const[()])
            T.writes(T_cast[()])
            T_cast[()] = compile_engine_const[()]
        for i0, i1, i2, i3, i4 in T.grid(1, 16, 54, 54, 4):
            with T.block("T_pad"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T_cast[()])
                T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(1 <= ax2 and ax2 < 53 and 1 <= ax3 and ax3 < 53, placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T_cast[()], dtype="float32")
    

[23:07:48] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 1 design space(s) generated
[23:07:48] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 52, 52, 4), "float32"], T_pad: T.Buffer[(1, 16, 54, 54, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":16, "meta_schedule.vectorize":64})
            for i0, i1, i2, i3, i4 in T.grid(1, 16, 54, 54, 4):
                with T.block("T_pad"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4])
                    T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                    T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(1 <= ax2 and ax2 < 53 and 1 <= ax3 and ax3 < 53, placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T.float32(0), dtype="float32")
    

b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_cast", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v3 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v3)
[23:07:48] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"
[23:07:48] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 54, 54, 4), "float32"], placeholder_1: T.Buffer[(32, 16, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 32, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 32, 52, 52, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 32, 52, 52, 4], dtype="float32")
        T_add = T.alloc_buffer([1, 32, 52, 52, 4], dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6, i7 in T.grid(1, 32, 52, 52, 4, 64, 3, 3):
            with T.block("conv2d_NCHWc"):
                n, oc_chunk, oh, ow, oc_block, ic, kh, kw = T.axis.remap("SSSSSRRR", [i0, i1, i2, i3, i4, i5, i6, i7])
                T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                T.block_attr({"workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 16, 54, 54, 4], "float32"], ["TENSOR", [32, 16, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                with T.init():
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
        for i0, i1, i2, i3, i4 in T.grid(1, 32, 52, 52, 4):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                T.writes(T_add[ax0, ax1, ax2, ax3, ax4])
                T_add[ax0, ax1, ax2, ax3, ax4] = conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]
        for i0, i1, i2, i3, i4 in T.grid(1, 32, 52, 52, 4):
            with T.block("T_leaky_relu"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_add[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < T_add[ax0, ax1, ax2, ax3, ax4], T_add[ax0, ax1, ax2, ax3, ax4], T_add[ax0, ax1, ax2, ax3, ax4] * T.float32(0.10000000149011612))
    

[23:07:49] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 3 design space(s) generated
[23:07:49] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 54, 54, 4), "float32"], placeholder_1: T.Buffer[(32, 16, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 32, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 32, 52, 52, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 32, 52, 52, 4], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0, i0_1, i1_1, i2_1, i3_1, i4_1, i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(1, 2, 1, 13, 4, 1, 2, 13, 1, 1, 4, 1, 3, 1, 4, 2, 4, 1, 16, 3, 1, 1, 2, 2, 1, 1):
                with T.block("conv2d_NCHWc"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(32, i1_0 * 16 + i1_1 * 8 + i1_2 * 2 + i1_3)
                    oh = T.axis.spatial(52, i2_1 * 4 + i2_2 * 2 + i2_3)
                    ow = T.axis.spatial(52, i3_0 * 4 + i3_2)
                    oc_block = T.axis.spatial(4, i4_0)
                    ic = T.axis.reduce(64, i5_0 * 16 + i5_1)
                    kh, kw = T.axis.remap("RR", [i6_1, i7_0])
                    T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 16, 54, 54, 4], "float32"], ["TENSOR", [32, 16, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                    with T.init():
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
            for i0, i1, i2, i3, i4 in T.grid(1, 32, 52, 52, 4):
                with T.block("T_leaky_relu"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                    T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                    T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[2, 2, 4, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 13, 2, 2])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[13, 1, 4, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[4, 16])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
[23:07:49] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #1:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 54, 54, 4), "float32"], placeholder_1: T.Buffer[(32, 16, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 32, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 32, 52, 52, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 32, 52, 52, 4], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0, i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 2, 1, 13, 4, 1, 2, 13, 1, 1):
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(4, 1, 3, 1, 4, 2, 4, 1, 16, 3, 1, 1, 2, 2, 1, 1):
                    with T.block("conv2d_NCHWc"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(32, i1_0 * 16 + i1_1 * 8 + i1_2 * 2 + i1_3)
                        oh = T.axis.spatial(52, i2_1 * 4 + i2_2 * 2 + i2_3)
                        ow = T.axis.spatial(52, i3_0 * 4 + i3_2)
                        oc_block = T.axis.spatial(4, i4_0)
                        ic = T.axis.reduce(64, i5_0 * 16 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_1, i7_0])
                        T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 16, 54, 54, 4], "float32"], ["TENSOR", [32, 16, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        with T.init():
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 8, 4, 4, 1):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, ax0)
                        ax1_1 = T.axis.spatial(32, i1_0 * 16 + i1_1 * 8 + ax1)
                        ax2_1 = T.axis.spatial(52, i2_1 * 4 + ax2)
                        ax3_1 = T.axis.spatial(52, i3_0 * 4 + ax3)
                        ax4_1 = T.axis.spatial(4, i4_0 + ax4)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[2, 2, 4, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 13, 2, 2])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[13, 1, 4, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[4, 16])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
[23:07:49] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #2:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 54, 54, 4), "float32"], placeholder_1: T.Buffer[(32, 16, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 32, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 32, 52, 52, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":16, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 32, 52, 52, 4], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0 in T.grid(1, 2, 1, 13, 4):
                for i0_1, i1_1, i2_1, i3_1, i4_1, i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(1, 2, 13, 1, 1, 4, 1, 3, 1, 4, 2, 4, 1, 16, 3, 1, 1, 2, 2, 1, 1):
                    with T.block("conv2d_NCHWc"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(32, i1_0 * 16 + i1_1 * 8 + i1_2 * 2 + i1_3)
                        oh = T.axis.spatial(52, i2_1 * 4 + i2_2 * 2 + i2_3)
                        ow = T.axis.spatial(52, i3_0 * 4 + i3_2)
                        oc_block = T.axis.spatial(4, i4_0)
                        ic = T.axis.reduce(64, i5_0 * 16 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_1, i7_0])
                        T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 16, 54, 54, 4], "float32"], ["TENSOR", [32, 16, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        with T.init():
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 16, 52, 4, 1):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, ax0)
                        ax1_1 = T.axis.spatial(32, i1_0 * 16 + ax1)
                        ax2_1 = T.axis.spatial(52, ax2)
                        ax3_1 = T.axis.spatial(52, i3_0 * 4 + ax3)
                        ax4_1 = T.axis.spatial(4, i4_0 + ax4)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[2, 2, 4, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 13, 2, 2])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[13, 1, 4, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[4, 16])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
[23:07:49] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #14: "fused_nn_pad_6"
[23:07:49] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 32, 52, 52, 4), "float32"], T_pad: T.Buffer[(1, 32, 52, 52, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3, i4 in T.grid(1, 32, 52, 52, 4):
            with T.block("T_pad"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(placeholder[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                T_pad[ax0, ax1, ax2, ax3, ax4] = placeholder[ax0, ax1, ax2, ax3, ax4]
    

[23:07:49] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 1 design space(s) generated
[23:07:49] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 32, 52, 52, 4), "float32"], T_pad: T.Buffer[(1, 32, 52, 52, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":16, "meta_schedule.vectorize":64})
            for i0, i1, i2, i3, i4 in T.grid(1, 32, 52, 52, 4):
                with T.block("T_pad"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(placeholder[ax0, ax1, ax2, ax3, ax4])
                    T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                    T_pad[ax0, ax1, ax2, ax3, ax4] = placeholder[ax0, ax1, ax2, ax3, ax4]
    

b0 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.vectorize", ann_val=64)
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
[23:07:49] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #15: "fused_nn_max_pool2d_3"
[23:07:49] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 32, 52, 52, 4), "float32"], tensor: T.Buffer[(1, 32, 26, 26, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 32, 26, 26, 4, 2, 2):
            with T.block("tensor"):
                ax0, ax1, ax2, ax3, ax4, rv0, rv1 = T.axis.remap("SSSSSRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
                T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                with T.init():
                    tensor[ax0, ax1, ax2, ax3, ax4] = T.float32(-3.4028234663852886e+38)
                tensor[ax0, ax1, ax2, ax3, ax4] = T.max(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
    

[23:07:49] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 1 design space(s) generated
[23:07:49] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 32, 52, 52, 4), "float32"], tensor: T.Buffer[(1, 32, 26, 26, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 32, 26, 26, 4, 2, 2):
                with T.block("tensor"):
                    ax0, ax1, ax2, ax3, ax4, rv0, rv1 = T.axis.remap("SSSSSRR", [i0, i1, i2, i3, i4, i5, i6])
                    T.reads(placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
                    T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                    with T.init():
                        tensor[ax0, ax1, ax2, ax3, ax4] = T.float32(-3.4028234663852886e+38)
                    tensor[ax0, ax1, ax2, ax3, ax4] = T.max(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
    

b0 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.vectorize", ann_val=64)
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
[23:07:49] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #16: "fused_nn_pad_7"
[23:07:49] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 32, 26, 26, 4), "float32"], T_pad: T.Buffer[(1, 32, 28, 28, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        compile_engine_const = T.alloc_buffer([], dtype="float32")
        T_cast = T.alloc_buffer([], dtype="float32")
        with T.block("compile_engine_const"):
            T.reads()
            T.writes(compile_engine_const[()])
            compile_engine_const[()] = T.float32(0)
        with T.block("T_cast"):
            T.reads(compile_engine_const[()])
            T.writes(T_cast[()])
            T_cast[()] = compile_engine_const[()]
        for i0, i1, i2, i3, i4 in T.grid(1, 32, 28, 28, 4):
            with T.block("T_pad"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T_cast[()])
                T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(1 <= ax2 and ax2 < 27 and 1 <= ax3 and ax3 < 27, placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T_cast[()], dtype="float32")
    

[23:07:50] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 1 design space(s) generated
[23:07:50] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 32, 26, 26, 4), "float32"], T_pad: T.Buffer[(1, 32, 28, 28, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            for i0, i1, i2, i3, i4 in T.grid(1, 32, 28, 28, 4):
                with T.block("T_pad"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4])
                    T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                    T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(1 <= ax2 and ax2 < 27 and 1 <= ax3 and ax3 < 27, placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T.float32(0), dtype="float32")
    

b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_cast", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v3 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v3)
[23:07:50] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"
[23:07:50] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 32, 28, 28, 4), "float32"], placeholder_1: T.Buffer[(64, 32, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 64, 26, 26, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 64, 26, 26, 4], dtype="float32")
        T_add = T.alloc_buffer([1, 64, 26, 26, 4], dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6, i7 in T.grid(1, 64, 26, 26, 4, 128, 3, 3):
            with T.block("conv2d_NCHWc"):
                n, oc_chunk, oh, ow, oc_block, ic, kh, kw = T.axis.remap("SSSSSRRR", [i0, i1, i2, i3, i4, i5, i6, i7])
                T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                T.block_attr({"workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 32, 28, 28, 4], "float32"], ["TENSOR", [64, 32, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                with T.init():
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
        for i0, i1, i2, i3, i4 in T.grid(1, 64, 26, 26, 4):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                T.writes(T_add[ax0, ax1, ax2, ax3, ax4])
                T_add[ax0, ax1, ax2, ax3, ax4] = conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]
        for i0, i1, i2, i3, i4 in T.grid(1, 64, 26, 26, 4):
            with T.block("T_leaky_relu"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_add[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < T_add[ax0, ax1, ax2, ax3, ax4], T_add[ax0, ax1, ax2, ax3, ax4], T_add[ax0, ax1, ax2, ax3, ax4] * T.float32(0.10000000149011612))
    

[23:07:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 3 design space(s) generated
[23:07:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 32, 28, 28, 4), "float32"], placeholder_1: T.Buffer[(64, 32, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 64, 26, 26, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 64, 26, 26, 4], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0, i0_1, i1_1, i2_1, i3_1, i4_1, i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(1, 2, 1, 26, 1, 1, 4, 1, 1, 4, 8, 1, 3, 1, 1, 13, 1, 1, 16, 3, 1, 1, 8, 2, 1, 1):
                with T.block("conv2d_NCHWc"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(64, i1_0 * 32 + i1_1 * 8 + i1_3)
                    oh = T.axis.spatial(26, i2_2 * 2 + i2_3)
                    ow, oc_block = T.axis.remap("SS", [i3_0, i4_1])
                    ic = T.axis.reduce(128, i5_0 * 16 + i5_1)
                    kh, kw = T.axis.remap("RR", [i6_1, i7_0])
                    T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 32, 28, 28, 4], "float32"], ["TENSOR", [64, 32, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                    with T.init():
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
            for i0, i1, i2, i3, i4 in T.grid(1, 64, 26, 26, 4):
                with T.block("T_leaky_relu"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                    T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                    T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[2, 4, 1, 8])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 13, 2])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[26, 1, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 4, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[8, 16])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
[23:07:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #1:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 32, 28, 28, 4), "float32"], placeholder_1: T.Buffer[(64, 32, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 64, 26, 26, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 64, 26, 26, 4], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0, i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 2, 1, 26, 1, 1, 4, 1, 1, 4):
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(8, 1, 3, 1, 1, 13, 1, 1, 16, 3, 1, 1, 8, 2, 1, 1):
                    with T.block("conv2d_NCHWc"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(64, i1_0 * 32 + i1_1 * 8 + i1_3)
                        oh = T.axis.spatial(26, i2_2 * 2 + i2_3)
                        ow, oc_block = T.axis.remap("SS", [i3_0, i4_1])
                        ic = T.axis.reduce(128, i5_0 * 16 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_1, i7_0])
                        T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 32, 28, 28, 4], "float32"], ["TENSOR", [64, 32, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        with T.init():
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 8, 26, 1, 1):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, ax0)
                        ax1_1 = T.axis.spatial(64, i1_0 * 32 + i1_1 * 8 + ax1)
                        ax2_1 = T.axis.spatial(26, ax2)
                        ax3_1 = T.axis.spatial(26, i3_0 + ax3)
                        ax4_1 = T.axis.spatial(4, i4_1 + ax4)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[2, 4, 1, 8])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 13, 2])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[26, 1, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 4, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[8, 16])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
[23:07:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #2:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 32, 28, 28, 4), "float32"], placeholder_1: T.Buffer[(64, 32, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 64, 26, 26, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":16, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 64, 26, 26, 4], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0 in T.grid(1, 2, 1, 26, 1):
                for i0_1, i1_1, i2_1, i3_1, i4_1, i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(1, 4, 1, 1, 4, 8, 1, 3, 1, 1, 13, 1, 1, 16, 3, 1, 1, 8, 2, 1, 1):
                    with T.block("conv2d_NCHWc"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(64, i1_0 * 32 + i1_1 * 8 + i1_3)
                        oh = T.axis.spatial(26, i2_2 * 2 + i2_3)
                        ow, oc_block = T.axis.remap("SS", [i3_0, i4_1])
                        ic = T.axis.reduce(128, i5_0 * 16 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_1, i7_0])
                        T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 32, 28, 28, 4], "float32"], ["TENSOR", [64, 32, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        with T.init():
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 32, 26, 1, 4):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, ax0)
                        ax1_1 = T.axis.spatial(64, i1_0 * 32 + ax1)
                        ax2_1 = T.axis.spatial(26, ax2)
                        ax3_1 = T.axis.spatial(26, i3_0 + ax3)
                        ax4_1 = T.axis.spatial(4, ax4)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[2, 4, 1, 8])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 13, 2])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[26, 1, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 4, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[8, 16])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
[23:07:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #18: "fused_nn_pad_8"
[23:07:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 26, 26, 4), "float32"], T_pad: T.Buffer[(1, 64, 26, 26, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3, i4 in T.grid(1, 64, 26, 26, 4):
            with T.block("T_pad"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(placeholder[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                T_pad[ax0, ax1, ax2, ax3, ax4] = placeholder[ax0, ax1, ax2, ax3, ax4]
    

[23:07:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 1 design space(s) generated
[23:07:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 26, 26, 4), "float32"], T_pad: T.Buffer[(1, 64, 26, 26, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            for i0, i1, i2, i3, i4 in T.grid(1, 64, 26, 26, 4):
                with T.block("T_pad"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(placeholder[ax0, ax1, ax2, ax3, ax4])
                    T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                    T_pad[ax0, ax1, ax2, ax3, ax4] = placeholder[ax0, ax1, ax2, ax3, ax4]
    

b0 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.vectorize", ann_val=64)
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
[23:07:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #19: "fused_nn_max_pool2d_4"
[23:07:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 26, 26, 4), "float32"], tensor: T.Buffer[(1, 64, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 64, 13, 13, 4, 2, 2):
            with T.block("tensor"):
                ax0, ax1, ax2, ax3, ax4, rv0, rv1 = T.axis.remap("SSSSSRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
                T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                with T.init():
                    tensor[ax0, ax1, ax2, ax3, ax4] = T.float32(-3.4028234663852886e+38)
                tensor[ax0, ax1, ax2, ax3, ax4] = T.max(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
    

[23:07:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 1 design space(s) generated
[23:07:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 26, 26, 4), "float32"], tensor: T.Buffer[(1, 64, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 64, 13, 13, 4, 2, 2):
                with T.block("tensor"):
                    ax0, ax1, ax2, ax3, ax4, rv0, rv1 = T.axis.remap("SSSSSRR", [i0, i1, i2, i3, i4, i5, i6])
                    T.reads(placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
                    T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                    with T.init():
                        tensor[ax0, ax1, ax2, ax3, ax4] = T.float32(-3.4028234663852886e+38)
                    tensor[ax0, ax1, ax2, ax3, ax4] = T.max(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
    

b0 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.vectorize", ann_val=64)
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
[23:07:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #20: "fused_nn_pad_9"
[23:07:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 13, 13, 4), "float32"], T_pad: T.Buffer[(1, 64, 15, 15, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        compile_engine_const = T.alloc_buffer([], dtype="float32")
        T_cast = T.alloc_buffer([], dtype="float32")
        with T.block("compile_engine_const"):
            T.reads()
            T.writes(compile_engine_const[()])
            compile_engine_const[()] = T.float32(0)
        with T.block("T_cast"):
            T.reads(compile_engine_const[()])
            T.writes(T_cast[()])
            T_cast[()] = compile_engine_const[()]
        for i0, i1, i2, i3, i4 in T.grid(1, 64, 15, 15, 4):
            with T.block("T_pad"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T_cast[()])
                T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(1 <= ax2 and ax2 < 14 and 1 <= ax3 and ax3 < 14, placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T_cast[()], dtype="float32")
    

[23:07:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 1 design space(s) generated
[23:07:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 13, 13, 4), "float32"], T_pad: T.Buffer[(1, 64, 15, 15, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            for i0, i1, i2, i3, i4 in T.grid(1, 64, 15, 15, 4):
                with T.block("T_pad"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4])
                    T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                    T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(1 <= ax2 and ax2 < 14 and 1 <= ax3 and ax3 < 14, placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T.float32(0), dtype="float32")
    

b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_cast", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v3 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v3)
[23:07:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"
[23:07:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 15, 15, 4), "float32"], placeholder_1: T.Buffer[(128, 64, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 128, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 128, 13, 13, 4], dtype="float32")
        T_add = T.alloc_buffer([1, 128, 13, 13, 4], dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6, i7 in T.grid(1, 128, 13, 13, 4, 256, 3, 3):
            with T.block("conv2d_NCHWc"):
                n, oc_chunk, oh, ow, oc_block, ic, kh, kw = T.axis.remap("SSSSSRRR", [i0, i1, i2, i3, i4, i5, i6, i7])
                T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                T.block_attr({"workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 64, 15, 15, 4], "float32"], ["TENSOR", [128, 64, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                with T.init():
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
        for i0, i1, i2, i3, i4 in T.grid(1, 128, 13, 13, 4):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                T.writes(T_add[ax0, ax1, ax2, ax3, ax4])
                T_add[ax0, ax1, ax2, ax3, ax4] = conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]
        for i0, i1, i2, i3, i4 in T.grid(1, 128, 13, 13, 4):
            with T.block("T_leaky_relu"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_add[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < T_add[ax0, ax1, ax2, ax3, ax4], T_add[ax0, ax1, ax2, ax3, ax4], T_add[ax0, ax1, ax2, ax3, ax4] * T.float32(0.10000000149011612))
    

[23:07:52] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 3 design space(s) generated
[23:07:52] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 15, 15, 4), "float32"], placeholder_1: T.Buffer[(128, 64, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 128, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 128, 13, 13, 4], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0, i0_1, i1_1, i2_1, i3_1, i4_1, i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(1, 8, 1, 1, 2, 1, 1, 13, 1, 1, 64, 3, 1, 1, 8, 1, 13, 1, 4, 1, 3, 1, 2, 1, 1, 2):
                with T.block("conv2d_NCHWc"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(128, i1_0 * 16 + i1_2 * 2 + i1_3)
                    oh, ow = T.axis.remap("SS", [i2_1, i3_2])
                    oc_block = T.axis.spatial(4, i4_0 * 2 + i4_3)
                    ic = T.axis.reduce(256, i5_0 * 4 + i5_1)
                    kh, kw = T.axis.remap("RR", [i6_0, i7_1])
                    T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 64, 15, 15, 4], "float32"], ["TENSOR", [128, 64, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                    with T.init():
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
            for i0, i1, i2, i3, i4 in T.grid(1, 128, 13, 13, 4):
                with T.block("T_leaky_relu"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                    T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                    T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[8, 1, 8, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 13, 1, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[64, 4])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
[23:07:52] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #1:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 15, 15, 4), "float32"], placeholder_1: T.Buffer[(128, 64, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 128, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":16, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 128, 13, 13, 4], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0, i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 8, 1, 1, 2, 1, 1, 13, 1, 1):
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(64, 3, 1, 1, 8, 1, 13, 1, 4, 1, 3, 1, 2, 1, 1, 2):
                    with T.block("conv2d_NCHWc"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(128, i1_0 * 16 + i1_2 * 2 + i1_3)
                        oh, ow = T.axis.remap("SS", [i2_1, i3_2])
                        oc_block = T.axis.spatial(4, i4_0 * 2 + i4_3)
                        ic = T.axis.reduce(256, i5_0 * 4 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_0, i7_1])
                        T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 64, 15, 15, 4], "float32"], ["TENSOR", [128, 64, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        with T.init():
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 16, 1, 13, 2):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, ax0)
                        ax1_1 = T.axis.spatial(128, i1_0 * 16 + ax1)
                        ax2_1 = T.axis.spatial(13, i2_1 + ax2)
                        ax3_1 = T.axis.spatial(13, ax3)
                        ax4_1 = T.axis.spatial(4, i4_0 * 2 + ax4)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[8, 1, 8, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 13, 1, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[64, 4])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
[23:07:52] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #2:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 15, 15, 4), "float32"], placeholder_1: T.Buffer[(128, 64, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 128, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":64, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 128, 13, 13, 4], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0 in T.grid(1, 8, 1, 1, 2):
                for i0_1, i1_1, i2_1, i3_1, i4_1, i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(1, 1, 13, 1, 1, 64, 3, 1, 1, 8, 1, 13, 1, 4, 1, 3, 1, 2, 1, 1, 2):
                    with T.block("conv2d_NCHWc"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(128, i1_0 * 16 + i1_2 * 2 + i1_3)
                        oh, ow = T.axis.remap("SS", [i2_1, i3_2])
                        oc_block = T.axis.spatial(4, i4_0 * 2 + i4_3)
                        ic = T.axis.reduce(256, i5_0 * 4 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_0, i7_1])
                        T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 64, 15, 15, 4], "float32"], ["TENSOR", [128, 64, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        with T.init():
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 16, 13, 13, 2):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, ax0)
                        ax1_1 = T.axis.spatial(128, i1_0 * 16 + ax1)
                        ax2_1, ax3_1 = T.axis.remap("SS", [ax2, ax3])
                        ax4_1 = T.axis.spatial(4, i4_0 * 2 + ax4)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[8, 1, 8, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 13, 1, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[64, 4])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
[23:07:52] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #22: "fused_nn_pad_10"
[23:07:52] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 13, 13, 4), "float32"], T_pad: T.Buffer[(1, 128, 14, 14, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        compile_engine_const = T.alloc_buffer([], dtype="float32")
        T_cast = T.alloc_buffer([], dtype="float32")
        with T.block("compile_engine_const"):
            T.reads()
            T.writes(compile_engine_const[()])
            compile_engine_const[()] = T.float32(-3.4028234663852886e+38)
        with T.block("T_cast"):
            T.reads(compile_engine_const[()])
            T.writes(T_cast[()])
            T_cast[()] = compile_engine_const[()]
        for i0, i1, i2, i3, i4 in T.grid(1, 128, 14, 14, 4):
            with T.block("T_pad"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(placeholder[ax0, ax1, ax2, ax3, ax4], T_cast[()])
                T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(ax2 < 13 and ax3 < 13, placeholder[ax0, ax1, ax2, ax3, ax4], T_cast[()], dtype="float32")
    

[23:07:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 1 design space(s) generated
[23:07:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 13, 13, 4), "float32"], T_pad: T.Buffer[(1, 128, 14, 14, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            for i0, i1, i2, i3, i4 in T.grid(1, 128, 14, 14, 4):
                with T.block("T_pad"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(placeholder[ax0, ax1, ax2, ax3, ax4])
                    T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                    T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(ax2 < 13 and ax3 < 13, placeholder[ax0, ax1, ax2, ax3, ax4], T.float32(-3.4028234663852886e+38), dtype="float32")
    

b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_cast", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v3 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v3)
[23:07:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #23: "fused_nn_max_pool2d_5"
[23:07:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 14, 14, 4), "float32"], tensor: T.Buffer[(1, 128, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 128, 13, 13, 4, 2, 2):
            with T.block("tensor"):
                ax0, ax1, ax2, ax3, ax4, rv0, rv1 = T.axis.remap("SSSSSRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(placeholder[ax0, ax1, ax2 + rv0, ax3 + rv1, ax4])
                T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                with T.init():
                    tensor[ax0, ax1, ax2, ax3, ax4] = T.float32(-3.4028234663852886e+38)
                tensor[ax0, ax1, ax2, ax3, ax4] = T.max(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[ax0, ax1, ax2 + rv0, ax3 + rv1, ax4])
    

[23:07:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 1 design space(s) generated
[23:07:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 14, 14, 4), "float32"], tensor: T.Buffer[(1, 128, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":64, "meta_schedule.vectorize":64})
            for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 128, 13, 13, 4, 2, 2):
                with T.block("tensor"):
                    ax0, ax1, ax2, ax3, ax4, rv0, rv1 = T.axis.remap("SSSSSRR", [i0, i1, i2, i3, i4, i5, i6])
                    T.reads(placeholder[ax0, ax1, ax2 + rv0, ax3 + rv1, ax4])
                    T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                    with T.init():
                        tensor[ax0, ax1, ax2, ax3, ax4] = T.float32(-3.4028234663852886e+38)
                    tensor[ax0, ax1, ax2, ax3, ax4] = T.max(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[ax0, ax1, ax2 + rv0, ax3 + rv1, ax4])
    

b0 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.vectorize", ann_val=64)
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
[23:07:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #24: "fused_nn_pad_11"
[23:07:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 13, 13, 4), "float32"], T_pad: T.Buffer[(1, 128, 15, 15, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        compile_engine_const = T.alloc_buffer([], dtype="float32")
        T_cast = T.alloc_buffer([], dtype="float32")
        with T.block("compile_engine_const"):
            T.reads()
            T.writes(compile_engine_const[()])
            compile_engine_const[()] = T.float32(0)
        with T.block("T_cast"):
            T.reads(compile_engine_const[()])
            T.writes(T_cast[()])
            T_cast[()] = compile_engine_const[()]
        for i0, i1, i2, i3, i4 in T.grid(1, 128, 15, 15, 4):
            with T.block("T_pad"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T_cast[()])
                T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(1 <= ax2 and ax2 < 14 and 1 <= ax3 and ax3 < 14, placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T_cast[()], dtype="float32")
    

[23:07:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 1 design space(s) generated
[23:07:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 13, 13, 4), "float32"], T_pad: T.Buffer[(1, 128, 15, 15, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            for i0, i1, i2, i3, i4 in T.grid(1, 128, 15, 15, 4):
                with T.block("T_pad"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4])
                    T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                    T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(1 <= ax2 and ax2 < 14 and 1 <= ax3 and ax3 < 14, placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T.float32(0), dtype="float32")
    

b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_cast", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v3 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v3)
[23:07:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"
[23:07:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 15, 15, 4), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 256, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 256, 13, 13, 4], dtype="float32")
        T_add = T.alloc_buffer([1, 256, 13, 13, 4], dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6, i7 in T.grid(1, 256, 13, 13, 4, 512, 3, 3):
            with T.block("conv2d_NCHWc"):
                n, oc_chunk, oh, ow, oc_block, ic, kh, kw = T.axis.remap("SSSSSRRR", [i0, i1, i2, i3, i4, i5, i6, i7])
                T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                T.block_attr({"workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 128, 15, 15, 4], "float32"], ["TENSOR", [256, 128, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                with T.init():
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
        for i0, i1, i2, i3, i4 in T.grid(1, 256, 13, 13, 4):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                T.writes(T_add[ax0, ax1, ax2, ax3, ax4])
                T_add[ax0, ax1, ax2, ax3, ax4] = conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]
        for i0, i1, i2, i3, i4 in T.grid(1, 256, 13, 13, 4):
            with T.block("T_leaky_relu"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_add[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < T_add[ax0, ax1, ax2, ax3, ax4], T_add[ax0, ax1, ax2, ax3, ax4], T_add[ax0, ax1, ax2, ax3, ax4] * T.float32(0.10000000149011612))
    

[23:07:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 3 design space(s) generated
[23:07:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 15, 15, 4), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 256, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 256, 13, 13, 4], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0, i0_1, i1_1, i2_1, i3_1, i4_1, i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(1, 8, 13, 1, 2, 1, 32, 1, 1, 2, 256, 3, 3, 1, 1, 1, 13, 1, 2, 1, 1, 1, 1, 1, 1, 1):
                with T.block("conv2d_NCHWc"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(256, i1_0 * 32 + i1_1)
                    oh, ow = T.axis.remap("SS", [i2_0, i3_2])
                    oc_block = T.axis.spatial(4, i4_0 * 2 + i4_1)
                    ic = T.axis.reduce(512, i5_0 * 2 + i5_1)
                    kh, kw = T.axis.remap("RR", [i6_0, i7_0])
                    T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 128, 15, 15, 4], "float32"], ["TENSOR", [256, 128, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                    with T.init():
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
            for i0, i1, i2, i3, i4 in T.grid(1, 256, 13, 13, 4):
                with T.block("T_leaky_relu"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                    T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                    T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[8, 32, 1, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[13, 1, 1, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 2, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[256, 2])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
[23:07:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #1:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 15, 15, 4), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 256, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":64, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 256, 13, 13, 4], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0, i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 8, 13, 1, 2, 1, 32, 1, 1, 2):
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(256, 3, 3, 1, 1, 1, 13, 1, 2, 1, 1, 1, 1, 1, 1, 1):
                    with T.block("conv2d_NCHWc"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(256, i1_0 * 32 + i1_1)
                        oh, ow = T.axis.remap("SS", [i2_0, i3_2])
                        oc_block = T.axis.spatial(4, i4_0 * 2 + i4_1)
                        ic = T.axis.reduce(512, i5_0 * 2 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_0, i7_0])
                        T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 128, 15, 15, 4], "float32"], ["TENSOR", [256, 128, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        with T.init():
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 1, 1, 13, 1):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, ax0)
                        ax1_1 = T.axis.spatial(256, i1_0 * 32 + i1_1 + ax1)
                        ax2_1 = T.axis.spatial(13, i2_0 + ax2)
                        ax3_1 = T.axis.spatial(13, ax3)
                        ax4_1 = T.axis.spatial(4, i4_0 * 2 + i4_1 + ax4)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[8, 32, 1, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[13, 1, 1, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 2, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[256, 2])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
[23:07:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #2:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 15, 15, 4), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 256, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 256, 13, 13, 4], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0 in T.grid(1, 8, 13, 1, 2):
                for i0_1, i1_1, i2_1, i3_1, i4_1, i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(1, 32, 1, 1, 2, 256, 3, 3, 1, 1, 1, 13, 1, 2, 1, 1, 1, 1, 1, 1, 1):
                    with T.block("conv2d_NCHWc"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(256, i1_0 * 32 + i1_1)
                        oh, ow = T.axis.remap("SS", [i2_0, i3_2])
                        oc_block = T.axis.spatial(4, i4_0 * 2 + i4_1)
                        ic = T.axis.reduce(512, i5_0 * 2 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_0, i7_0])
                        T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 128, 15, 15, 4], "float32"], ["TENSOR", [256, 128, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        with T.init():
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 32, 1, 13, 2):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, ax0)
                        ax1_1 = T.axis.spatial(256, i1_0 * 32 + ax1)
                        ax2_1 = T.axis.spatial(13, i2_0 + ax2)
                        ax3_1 = T.axis.spatial(13, ax3)
                        ax4_1 = T.axis.spatial(4, i4_0 * 2 + ax4)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[8, 32, 1, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[13, 1, 1, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 2, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[256, 2])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
[23:07:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #26: "fused_nn_pad_12"
[23:07:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 13, 13, 4), "float32"], T_pad: T.Buffer[(1, 256, 15, 15, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        compile_engine_const = T.alloc_buffer([], dtype="float32")
        T_cast = T.alloc_buffer([], dtype="float32")
        with T.block("compile_engine_const"):
            T.reads()
            T.writes(compile_engine_const[()])
            compile_engine_const[()] = T.float32(0)
        with T.block("T_cast"):
            T.reads(compile_engine_const[()])
            T.writes(T_cast[()])
            T_cast[()] = compile_engine_const[()]
        for i0, i1, i2, i3, i4 in T.grid(1, 256, 15, 15, 4):
            with T.block("T_pad"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T_cast[()])
                T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(1 <= ax2 and ax2 < 14 and 1 <= ax3 and ax3 < 14, placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T_cast[()], dtype="float32")
    

[23:07:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 1 design space(s) generated
[23:07:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 13, 13, 4), "float32"], T_pad: T.Buffer[(1, 256, 15, 15, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":64, "meta_schedule.vectorize":64})
            for i0, i1, i2, i3, i4 in T.grid(1, 256, 15, 15, 4):
                with T.block("T_pad"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4])
                    T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                    T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(1 <= ax2 and ax2 < 14 and 1 <= ax3 and ax3 < 14, placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T.float32(0), dtype="float32")
    

b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_cast", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v3 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v3)
[23:07:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"
[23:07:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 15, 15, 4), "float32"], placeholder_1: T.Buffer[(256, 256, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 256, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 256, 13, 13, 4], dtype="float32")
        T_add = T.alloc_buffer([1, 256, 13, 13, 4], dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6, i7 in T.grid(1, 256, 13, 13, 4, 1024, 3, 3):
            with T.block("conv2d_NCHWc"):
                n, oc_chunk, oh, ow, oc_block, ic, kh, kw = T.axis.remap("SSSSSRRR", [i0, i1, i2, i3, i4, i5, i6, i7])
                T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                T.block_attr({"workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 256, 15, 15, 4], "float32"], ["TENSOR", [256, 256, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                with T.init():
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
        for i0, i1, i2, i3, i4 in T.grid(1, 256, 13, 13, 4):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                T.writes(T_add[ax0, ax1, ax2, ax3, ax4])
                T_add[ax0, ax1, ax2, ax3, ax4] = conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]
        for i0, i1, i2, i3, i4 in T.grid(1, 256, 13, 13, 4):
            with T.block("T_leaky_relu"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_add[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < T_add[ax0, ax1, ax2, ax3, ax4], T_add[ax0, ax1, ax2, ax3, ax4], T_add[ax0, ax1, ax2, ax3, ax4] * T.float32(0.10000000149011612))
    

[23:07:55] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 3 design space(s) generated
[23:07:55] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 15, 15, 4), "float32"], placeholder_1: T.Buffer[(256, 256, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 256, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 256, 13, 13, 4], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0, i0_1, i1_1, i2_1, i3_1, i4_1, i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(1, 1, 1, 1, 1, 1, 4, 13, 13, 2, 1024, 1, 3, 1, 2, 1, 1, 1, 1, 3, 1, 1, 32, 1, 1, 2):
                with T.block("conv2d_NCHWc"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(256, i1_1 * 64 + i1_2 * 32 + i1_3)
                    oh, ow = T.axis.remap("SS", [i2_1, i3_1])
                    oc_block = T.axis.spatial(4, i4_1 * 2 + i4_3)
                    ic, kh, kw = T.axis.remap("RRR", [i5_0, i6_1, i7_0])
                    T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 256, 15, 15, 4], "float32"], ["TENSOR", [256, 256, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                    with T.init():
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
            for i0, i1, i2, i3, i4 in T.grid(1, 256, 13, 13, 4):
                with T.block("T_leaky_relu"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                    T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                    T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 4, 2, 32])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 13, 1, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 13, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1024, 1])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
[23:07:55] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #1:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 15, 15, 4), "float32"], placeholder_1: T.Buffer[(256, 256, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 256, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":64, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 256, 13, 13, 4], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0, i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 1, 1, 1, 1, 1, 4, 13, 13, 2):
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(1024, 1, 3, 1, 2, 1, 1, 1, 1, 3, 1, 1, 32, 1, 1, 2):
                    with T.block("conv2d_NCHWc"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(256, i1_1 * 64 + i1_2 * 32 + i1_3)
                        oh, ow = T.axis.remap("SS", [i2_1, i3_1])
                        oc_block = T.axis.spatial(4, i4_1 * 2 + i4_3)
                        ic, kh, kw = T.axis.remap("RRR", [i5_0, i6_1, i7_0])
                        T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 256, 15, 15, 4], "float32"], ["TENSOR", [256, 256, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        with T.init():
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 64, 1, 1, 2):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, ax0)
                        ax1_1 = T.axis.spatial(256, i1_1 * 64 + ax1)
                        ax2_1 = T.axis.spatial(13, i2_1 + ax2)
                        ax3_1 = T.axis.spatial(13, i3_1 + ax3)
                        ax4_1 = T.axis.spatial(4, i4_1 * 2 + ax4)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 4, 2, 32])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 13, 1, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 13, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1024, 1])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
[23:07:55] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #2:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 15, 15, 4), "float32"], placeholder_1: T.Buffer[(256, 256, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 256, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":64, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 256, 13, 13, 4], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0 in T.grid(1, 1, 1, 1, 1):
                for i0_1, i1_1, i2_1, i3_1, i4_1, i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(1, 4, 13, 13, 2, 1024, 1, 3, 1, 2, 1, 1, 1, 1, 3, 1, 1, 32, 1, 1, 2):
                    with T.block("conv2d_NCHWc"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(256, i1_1 * 64 + i1_2 * 32 + i1_3)
                        oh, ow = T.axis.remap("SS", [i2_1, i3_1])
                        oc_block = T.axis.spatial(4, i4_1 * 2 + i4_3)
                        ic, kh, kw = T.axis.remap("RRR", [i5_0, i6_1, i7_0])
                        T.reads(placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 256, 15, 15, 4], "float32"], ["TENSOR", [256, 256, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        with T.init():
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 256, 13, 13, 4):
                    with T.block("T_leaky_relu"):
                        ax0_1, ax1_1, ax2_1, ax3_1, ax4_1 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 4, 2, 32])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 13, 1, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 13, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1024, 1])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
[23:07:55] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #28: "fused_nn_pad_layout_transform"
[23:07:55] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 13, 13, 4), "float32"], T_layout_trans: T.Buffer[(1, 1024, 13, 13, 1), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        T_pad = T.alloc_buffer([1, 256, 13, 13, 4], dtype="float32")
        for i0, i1, i2, i3, i4 in T.grid(1, 256, 13, 13, 4):
            with T.block("T_pad"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(placeholder[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                T_pad[ax0, ax1, ax2, ax3, ax4] = placeholder[ax0, ax1, ax2, ax3, ax4]
        for i0, i1, i2, i3, i4 in T.grid(1, 1024, 13, 13, 1):
            with T.block("T_layout_trans"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_pad[ax0, (ax1 + ax4) // 4, ax2, ax3, (ax1 + ax4) % 4])
                T.writes(T_layout_trans[ax0, ax1, ax2, ax3, ax4])
                T_layout_trans[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(ax0 < 1 and ax1 + ax4 < 1024 and ax2 < 13 and ax3 < 13, T_pad[ax0, (ax1 + ax4) // 4, ax2, ax3, (ax1 + ax4) % 4], T.float32(0), dtype="float32")
    

[23:07:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 1 design space(s) generated
[23:07:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 13, 13, 4), "float32"], T_layout_trans: T.Buffer[(1, 1024, 13, 13, 1), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            for i0, i1, i2, i3, i4 in T.grid(1, 1024, 13, 13, 1):
                with T.block("T_layout_trans"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(placeholder[ax0, (ax1 + ax4) // 4, ax2, ax3, (ax1 + ax4) % 4])
                    T.writes(T_layout_trans[ax0, ax1, ax2, ax3, ax4])
                    T_layout_trans[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(ax0 < 1 and ax1 + ax4 < 1024 and ax2 < 13 and ax3 < 13, placeholder[ax0, (ax1 + ax4) // 4, ax2, ax3, (ax1 + ax4) % 4], T.float32(0), dtype="float32")
    

b0 = sch.get_block(name="T_pad", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b0)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v2 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v2)
[23:07:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #29: "fused_nn_contrib_conv2d_NCHWc_add"
[23:07:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1024, 13, 13, 1), "float32"], placeholder_1: T.Buffer[(125, 1024, 1, 1, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 125, 1, 1, 1), "float32"], T_add: T.Buffer[(1, 125, 13, 13, 1), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 125, 13, 13, 1], dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6, i7 in T.grid(1, 125, 13, 13, 1, 1024, 1, 1):
            with T.block("conv2d_NCHWc"):
                n, oc_chunk, oh, ow, oc_block, ic, kh, kw = T.axis.remap("SSSSSRRR", [i0, i1, i2, i3, i4, i5, i6, i7])
                T.reads(placeholder[n, ic, oh + kh, ow + kw, 0], placeholder_1[oc_chunk, ic, kh, kw, 0, oc_block])
                T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                T.block_attr({"workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1024, 13, 13, 1], "float32"], ["TENSOR", [125, 1024, 1, 1, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW1c", "NCHW1c", "float32"]})
                with T.init():
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic, oh + kh, ow + kw, 0] * placeholder_1[oc_chunk, ic, kh, kw, 0, oc_block]
        for i0, i1, i2, i3, i4 in T.grid(1, 125, 13, 13, 1):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                T.writes(T_add[ax0, ax1, ax2, ax3, ax4])
                T_add[ax0, ax1, ax2, ax3, ax4] = conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]
    

[23:07:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 3 design space(s) generated
[23:07:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1024, 13, 13, 1), "float32"], placeholder_1: T.Buffer[(125, 1024, 1, 1, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 125, 1, 1, 1), "float32"], T_add: T.Buffer[(1, 125, 13, 13, 1), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":64, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 125, 13, 13, 1], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0, i0_1, i1_1, i2_1, i3_1, i4_1, i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(1, 1, 1, 1, 1, 1, 25, 13, 1, 1, 128, 1, 1, 1, 1, 1, 13, 1, 8, 1, 1, 1, 5, 1, 1, 1):
                with T.block("conv2d_NCHWc"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(125, i1_1 * 5 + i1_3)
                    oh, ow = T.axis.remap("SS", [i2_1, i3_2])
                    oc_block = T.axis.spatial(1, 0)
                    ic = T.axis.reduce(1024, i5_0 * 8 + i5_1)
                    kh = T.axis.reduce(1, 0)
                    kw = T.axis.reduce(1, 0)
                    T.reads(placeholder[n, ic, oh + kh, ow + kw, 0], placeholder_1[oc_chunk, ic, kh, kw, 0, oc_block])
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1024, 13, 13, 1], "float32"], ["TENSOR", [125, 1024, 1, 1, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW1c", "NCHW1c", "float32"]})
                    with T.init():
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic, oh + kh, ow + kw, 0] * placeholder_1[oc_chunk, ic, kh, kw, 0, oc_block]
            for i0, i1, i2, i3, i4 in T.grid(1, 125, 13, 13, 1):
                with T.block("T_add"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                    T.writes(T_add[ax0, ax1, ax2, ax3, ax4])
                    T_add[ax0, ax1, ax2, ax3, ax4] = conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b0)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l2, factors=[v10, v11, v12, v13])
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 25, 1, 5])
l22, l23, l24, l25 = sch.split(loop=l3, factors=[v18, v19, v20, v21])
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 13, 1, 1])
l30, l31, l32, l33 = sch.split(loop=l4, factors=[v26, v27, v28, v29])
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l38, l39, l40, l41 = sch.split(loop=l5, factors=[v34, v35, v36, v37])
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l46, l47, l48, l49 = sch.split(loop=l6, factors=[v42, v43, v44, v45])
v50, v51 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[128, 8])
l52, l53 = sch.split(loop=l7, factors=[v50, v51])
v54, v55 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])
l56, l57 = sch.split(loop=l8, factors=[v54, v55])
v58, v59 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l60, l61 = sch.split(loop=l9, factors=[v58, v59])
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l60, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v62 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v62)
[23:07:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #1:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1024, 13, 13, 1), "float32"], placeholder_1: T.Buffer[(125, 1024, 1, 1, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 125, 1, 1, 1), "float32"], T_add: T.Buffer[(1, 125, 13, 13, 1), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":64, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 125, 13, 13, 1], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0, i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 1, 1, 1, 1, 1, 25, 13, 1, 1):
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(128, 1, 1, 1, 1, 1, 13, 1, 8, 1, 1, 1, 5, 1, 1, 1):
                    with T.block("conv2d_NCHWc"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(125, i1_1 * 5 + i1_3)
                        oh, ow = T.axis.remap("SS", [i2_1, i3_2])
                        oc_block = T.axis.spatial(1, 0)
                        ic = T.axis.reduce(1024, i5_0 * 8 + i5_1)
                        kh = T.axis.reduce(1, 0)
                        kw = T.axis.reduce(1, 0)
                        T.reads(placeholder[n, ic, oh + kh, ow + kw, 0], placeholder_1[oc_chunk, ic, kh, kw, 0, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1024, 13, 13, 1], "float32"], ["TENSOR", [125, 1024, 1, 1, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW1c", "NCHW1c", "float32"]})
                        with T.init():
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic, oh + kh, ow + kw, 0] * placeholder_1[oc_chunk, ic, kh, kw, 0, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 5, 1, 13, 1):
                    with T.block("T_add"):
                        ax0_1 = T.axis.spatial(1, ax0)
                        ax1_1 = T.axis.spatial(125, i1_1 * 5 + ax1)
                        ax2_1 = T.axis.spatial(13, i2_1 + ax2)
                        ax3_1, ax4_1 = T.axis.remap("SS", [ax3, ax4])
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1])
                        T.writes(T_add[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T_add[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1]
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b0)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l2, factors=[v10, v11, v12, v13])
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 25, 1, 5])
l22, l23, l24, l25 = sch.split(loop=l3, factors=[v18, v19, v20, v21])
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 13, 1, 1])
l30, l31, l32, l33 = sch.split(loop=l4, factors=[v26, v27, v28, v29])
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l38, l39, l40, l41 = sch.split(loop=l5, factors=[v34, v35, v36, v37])
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l46, l47, l48, l49 = sch.split(loop=l6, factors=[v42, v43, v44, v45])
v50, v51 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[128, 8])
l52, l53 = sch.split(loop=l7, factors=[v50, v51])
v54, v55 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])
l56, l57 = sch.split(loop=l8, factors=[v54, v55])
v58, v59 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l60, l61 = sch.split(loop=l9, factors=[v58, v59])
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l60, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49)
b62, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b62, loop=l47, preserve_unit_loops=True)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
[23:07:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #2:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1024, 13, 13, 1), "float32"], placeholder_1: T.Buffer[(125, 1024, 1, 1, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 125, 1, 1, 1), "float32"], T_add: T.Buffer[(1, 125, 13, 13, 1), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            conv2d_NCHWc = T.alloc_buffer([1, 125, 13, 13, 1], dtype="float32")
            for i0_0, i1_0, i2_0, i3_0, i4_0 in T.grid(1, 1, 1, 1, 1):
                for i0_1, i1_1, i2_1, i3_1, i4_1, i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(1, 25, 13, 1, 1, 128, 1, 1, 1, 1, 1, 13, 1, 8, 1, 1, 1, 5, 1, 1, 1):
                    with T.block("conv2d_NCHWc"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(125, i1_1 * 5 + i1_3)
                        oh, ow = T.axis.remap("SS", [i2_1, i3_2])
                        oc_block = T.axis.spatial(1, 0)
                        ic = T.axis.reduce(1024, i5_0 * 8 + i5_1)
                        kh = T.axis.reduce(1, 0)
                        kw = T.axis.reduce(1, 0)
                        T.reads(placeholder[n, ic, oh + kh, ow + kw, 0], placeholder_1[oc_chunk, ic, kh, kw, 0, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1024, 13, 13, 1], "float32"], ["TENSOR", [125, 1024, 1, 1, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW1c", "NCHW1c", "float32"]})
                        with T.init():
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic, oh + kh, ow + kw, 0] * placeholder_1[oc_chunk, ic, kh, kw, 0, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 125, 13, 13, 1):
                    with T.block("T_add"):
                        ax0_1, ax1_1, ax2_1, ax3_1, ax4_1 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1])
                        T.writes(T_add[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T_add[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1]
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b0)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l2, factors=[v10, v11, v12, v13])
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 25, 1, 5])
l22, l23, l24, l25 = sch.split(loop=l3, factors=[v18, v19, v20, v21])
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 13, 1, 1])
l30, l31, l32, l33 = sch.split(loop=l4, factors=[v26, v27, v28, v29])
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l38, l39, l40, l41 = sch.split(loop=l5, factors=[v34, v35, v36, v37])
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l46, l47, l48, l49 = sch.split(loop=l6, factors=[v42, v43, v44, v45])
v50, v51 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[128, 8])
l52, l53 = sch.split(loop=l7, factors=[v50, v51])
v54, v55 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])
l56, l57 = sch.split(loop=l8, factors=[v54, v55])
v58, v59 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l60, l61 = sch.split(loop=l9, factors=[v58, v59])
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l60, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49)
b62, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b62, loop=l46, preserve_unit_loops=True)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
[23:07:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:97: Initializing Task #30: "fused_layout_transform"
[23:07:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:103: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 125, 13, 13, 1), "float32"], T_layout_trans: T.Buffer[(1, 125, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3 in T.grid(1, 125, 13, 13):
            with T.block("T_layout_trans"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[ax0, ax1, ax2, ax3, 0])
                T.writes(T_layout_trans[ax0, ax1, ax2, ax3])
                T_layout_trans[ax0, ax1, ax2, ax3] = T.if_then_else(ax0 < 1 and ax1 < 125 and ax2 < 13 and ax3 < 13, placeholder[ax0, ax1, ax2, ax3, 0], T.float32(0), dtype="float32")
    

[23:07:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:107: Total 1 design space(s) generated
[23:07:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:112: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 125, 13, 13, 1), "float32"], T_layout_trans: T.Buffer[(1, 125, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":64, "meta_schedule.vectorize":64})
            for i0, i1, i2, i3 in T.grid(1, 125, 13, 13):
                with T.block("T_layout_trans"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(placeholder[ax0, ax1, ax2, ax3, 0])
                    T.writes(T_layout_trans[ax0, ax1, ax2, ax3])
                    T_layout_trans[ax0, ax1, ax2, ax3] = T.if_then_else(ax0 < 1 and ax1 < 125 and ax2 < 13 and ax3 < 13, placeholder[ax0, ax1, ax2, ax3, 0], T.float32(0), dtype="float32")
    

b0 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.vectorize", ann_val=64)
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
[23:07:56] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:111: 
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |            N/A |          N/A |                   N/A |      0 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |            N/A |          N/A |                   N/A |      0 |            
  2 |                                      fused_nn_pad |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |            N/A |          N/A |                   N/A |      0 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 0
Total latency (us): 0

[23:07:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #0: "fused_multiply_add_nn_pad_layout_transform"
[23:07:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[23:07:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[23:08:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[23:08:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[23:08:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[23:09:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[23:09:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[23:10:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[23:10:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 24 candidates:
[1 : 16]:	0.9952  0.9257  0.7231  0.7149  0.6705  0.6112  0.4791  0.4709  0.4408  0.4327  0.4207  0.4067  0.3797  0.3492  0.2506  0.2013
[17 : 24]:	0.1935  0.1896  0.1395  0.1384  0.0580  0.0457  0.0330  0.0145
[23:10:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 24 candidate(s) with evolutionary search
[23:10:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 24 candidates(s) for measurement
[23:10:38] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 24 sample(s) to builder
[23:10:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 24 sample(s) to runner
[23:11:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"
[23:11:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[23:11:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[23:11:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1904cf8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a664c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dfa78)]: 0 failure(s)
[23:11:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[23:11:48] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1904cf8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a664c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dfa78)]: 0 failure(s)
[23:12:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1904cf8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a664c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dfa78)]: 0 failure(s)
[23:12:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1904cf8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a664c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dfa78)]: 0 failure(s)
[23:12:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1904cf8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a664c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dfa78)]: 0 failure(s)
[23:12:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 32 candidates:
[1 : 16]:	1.0000  0.9999  0.9998  0.9998  0.9998  0.9997  0.9996  0.9995  0.9995  0.9994  0.9992  0.9990  0.9988  0.9987  0.9986  0.9986
[17 : 32]:	0.9983  0.9983  0.9983  0.9982  0.9982  0.9982  0.9982  0.9979  0.9978  0.9976  0.9975  0.9975  0.9974  0.9974  0.9968  0.9966
[23:12:53] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 32 candidate(s) with evolutionary search
[23:12:53] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 32 candidates(s) for measurement
[23:12:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[23:13:25] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 32 sample(s) to runner
[23:13:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #2: "fused_nn_pad"
[23:13:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[23:13:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[23:13:52] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[23:13:52] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[23:13:55] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[23:14:00] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[23:14:03] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[23:14:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[23:14:07] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 8 candidates:
[1 : 8]:	0.8425  0.8266  0.8132  0.7606  0.5160  0.3223  0.2982  0.2568
[23:14:07] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 8 candidate(s) with evolutionary search
[23:14:07] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 8 candidates(s) for measurement
[23:14:07] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 8 sample(s) to builder
[23:14:37] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 8 sample(s) to runner
[23:14:43] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #3: "fused_nn_max_pool2d"
[23:14:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[23:14:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[23:14:46] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[23:14:46] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[23:14:57] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[23:15:08] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[23:15:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[23:15:26] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[23:15:37] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 8 candidates:
[1 : 8]:	0.9384  0.8379  0.7304  0.5565  0.4317  0.3343  0.2428  0.0208
[23:15:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 8 candidate(s) with evolutionary search
[23:15:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 8 candidates(s) for measurement
[23:15:38] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 8 sample(s) to builder
[23:15:38] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 8 sample(s) to runner
[23:15:47] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #4: "fused_nn_pad_1"
[23:15:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[23:15:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[23:16:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[23:16:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[23:16:26] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[23:16:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[23:16:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[23:17:19] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[23:17:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 8 candidates:
[1 : 8]:	0.8153  0.5919  0.5658  0.4627  0.3653  0.2519  0.1162  0.0022
[23:17:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 8 candidate(s) with evolutionary search
[23:17:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 8 candidates(s) for measurement
[23:17:21] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 8 sample(s) to builder
[23:17:32] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 8 sample(s) to runner
[23:17:52] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"
[23:17:52] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[23:17:52] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[23:18:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1954538)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17bc138)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17c5818)]: 0 failure(s)
[23:18:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[23:19:26] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1954538)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17bc138)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17c5818)]: 0 failure(s)
[23:20:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1954538)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17bc138)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17c5818)]: 0 failure(s)
[23:21:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1954538)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17bc138)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17c5818)]: 0 failure(s)
[23:22:28] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1954538)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17bc138)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17c5818)]: 0 failure(s)
[23:22:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 32 candidates:
[1 : 16]:	1.0000  0.9998  0.9998  0.9997  0.9996  0.9995  0.9995  0.9989  0.9988  0.9988  0.9987  0.9986  0.9986  0.9985  0.9984  0.9982
[17 : 32]:	0.9982  0.9979  0.9978  0.9977  0.9975  0.9973  0.9972  0.9972  0.9969  0.9968  0.9967  0.9967  0.9965  0.9963  0.9961  0.9960
[23:22:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 32 candidate(s) with evolutionary search
[23:22:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 32 candidates(s) for measurement
[23:23:01] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[23:23:36] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 32 sample(s) to runner
[23:24:09] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #6: "fused_nn_pad_2"
[23:24:09] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[23:24:09] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[23:24:11] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[23:24:11] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[23:24:18] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[23:24:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[23:24:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[23:24:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[23:24:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 8 candidates:
[1 : 8]:	0.7623  0.5259  0.4061  0.3044  0.2763  0.1761  0.1748  0.1004
[23:24:55] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 8 candidate(s) with evolutionary search
[23:24:55] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 8 candidates(s) for measurement
[23:24:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 8 sample(s) to builder
[23:25:26] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 8 sample(s) to runner
[23:25:31] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #7: "fused_nn_max_pool2d_1"
[23:25:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[23:25:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[23:25:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[23:25:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[23:25:46] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[23:26:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[23:26:19] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[23:26:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[23:26:48] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 8 candidates:
[1 : 8]:	0.9645  0.8059  0.7355  0.6440  0.5147  0.4307  0.2044  0.1817
[23:26:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 8 candidate(s) with evolutionary search
[23:26:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 8 candidates(s) for measurement
[23:26:50] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 8 sample(s) to builder
[23:26:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 8 sample(s) to runner
[23:26:59] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #8: "fused_nn_pad_3"
[23:26:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[23:26:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[23:27:25] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[23:27:25] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[23:27:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[23:28:08] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[23:28:37] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[23:28:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[23:29:01] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 8 candidates:
[1 : 8]:	0.9555  0.9293  0.8130  0.7304  0.6087  0.4055  0.1396  0.0897
[23:29:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 8 candidate(s) with evolutionary search
[23:29:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 8 candidates(s) for measurement
[23:29:03] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 8 sample(s) to builder
[23:29:21] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 8 sample(s) to runner
[23:29:26] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"
[23:29:26] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[23:29:26] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[23:30:01] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1949d98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17a6768)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17ecea8)]: 0 failure(s)
[23:30:01] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[23:31:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1949d98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17a6768)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17ecea8)]: 0 failure(s)
[23:32:26] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1949d98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17a6768)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17ecea8)]: 0 failure(s)
[23:33:36] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1949d98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17a6768)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17ecea8)]: 0 failure(s)
[23:34:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1949d98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17a6768)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17ecea8)]: 0 failure(s)
[23:35:13] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 32 candidates:
[1 : 16]:	0.9999  0.9999  0.9999  0.9998  0.9997  0.9996  0.9995  0.9995  0.9991  0.9988  0.9988  0.9986  0.9984  0.9984  0.9981  0.9981
[17 : 32]:	0.9981  0.9980  0.9979  0.9978  0.9977  0.9975  0.9975  0.9975  0.9974  0.9973  0.9971  0.9971  0.9965  0.9965  0.9964  0.9964
[23:35:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 32 candidate(s) with evolutionary search
[23:35:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 32 candidates(s) for measurement
[23:35:23] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[23:35:55] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 32 sample(s) to runner
[23:36:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #10: "fused_nn_pad_4"
[23:36:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[23:36:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[23:36:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[23:36:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[23:36:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[23:36:48] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[23:37:01] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[23:37:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[23:37:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 8 candidates:
[1 : 8]:	0.7270  0.6956  0.6924  0.6191  0.5272  0.4944  0.4421  0.0820
[23:37:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 8 candidate(s) with evolutionary search
[23:37:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 8 candidates(s) for measurement
[23:37:21] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 8 sample(s) to builder
[23:37:28] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 8 sample(s) to runner
[23:37:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #11: "fused_nn_max_pool2d_2"
[23:37:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[23:37:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[23:37:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[23:37:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[23:38:03] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[23:38:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[23:38:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[23:38:55] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[23:39:19] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 8 candidates:
[1 : 8]:	0.9940  0.8866  0.8245  0.7235  0.6982  0.6111  0.4409  0.3096
[23:39:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 8 candidate(s) with evolutionary search
[23:39:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 8 candidates(s) for measurement
[23:39:22] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 8 sample(s) to builder
[23:39:26] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 8 sample(s) to runner
[23:39:41] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #12: "fused_nn_pad_5"
[23:39:41] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[23:39:41] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[23:40:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[23:40:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[23:40:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[23:41:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[23:42:01] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[23:42:39] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[23:42:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 8 candidates:
[1 : 8]:	0.8686  0.7435  0.6353  0.5392  0.4622  0.3152  0.2852  0.2230
[23:42:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 8 candidate(s) with evolutionary search
[23:42:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 8 candidates(s) for measurement
[23:43:00] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 8 sample(s) to builder
[23:43:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 8 sample(s) to runner
[23:43:21] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"
[23:43:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[23:43:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[23:43:50] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1b42628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1eeb3a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1914ad8)]: 0 failure(s)
[23:43:50] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[23:44:36] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1b42628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1eeb3a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1914ad8)]: 0 failure(s)
[23:45:44] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1b42628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1eeb3a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1914ad8)]: 0 failure(s)
[23:46:46] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1b42628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1eeb3a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1914ad8)]: 0 failure(s)
[23:47:30] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1b42628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1eeb3a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1914ad8)]: 0 failure(s)
[23:48:18] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 32 candidates:
[1 : 16]:	1.0000  0.9993  0.9993  0.9992  0.9992  0.9990  0.9989  0.9988  0.9987  0.9987  0.9987  0.9987  0.9986  0.9985  0.9985  0.9983
[17 : 32]:	0.9979  0.9978  0.9978  0.9976  0.9974  0.9974  0.9971  0.9970  0.9969  0.9968  0.9965  0.9965  0.9964  0.9964  0.9962  0.9962
[23:48:26] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 32 candidate(s) with evolutionary search
[23:48:26] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 32 candidates(s) for measurement
[23:48:29] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[23:49:06] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 32 sample(s) to runner
[23:49:21] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #14: "fused_nn_pad_6"
[23:49:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[23:49:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[23:49:23] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[23:49:23] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[23:49:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[23:49:53] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[23:50:11] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[23:50:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[23:50:41] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 8 candidates:
[1 : 8]:	0.9259  0.7048  0.6291  0.5490  0.4924  0.4789  0.3809  0.1452
[23:50:42] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 8 candidate(s) with evolutionary search
[23:50:42] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 8 candidates(s) for measurement
[23:50:43] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 8 sample(s) to builder
[23:50:47] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 8 sample(s) to runner
[23:50:52] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #15: "fused_nn_max_pool2d_3"
[23:50:52] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[23:50:52] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[23:50:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[23:50:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[23:51:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[23:51:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[23:52:03] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[23:52:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[23:52:46] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 8 candidates:
[1 : 8]:	0.9642  0.6550  0.6526  0.5783  0.3790  0.2217  0.2208  0.0147
[23:52:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 8 candidate(s) with evolutionary search
[23:52:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 8 candidates(s) for measurement
[23:52:48] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 8 sample(s) to builder
[23:52:50] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 8 sample(s) to runner
[23:52:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #16: "fused_nn_pad_7"
[23:52:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[23:52:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[23:53:23] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[23:53:23] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[23:53:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[23:54:36] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[23:55:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[23:55:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[23:55:42] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 8 candidates:
[1 : 8]:	0.8003  0.6912  0.5225  0.3347  0.3276  0.1306  0.1225  0.0840
[23:55:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 8 candidate(s) with evolutionary search
[23:55:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 8 candidates(s) for measurement
[23:55:44] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 8 sample(s) to builder
[23:55:55] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 8 sample(s) to runner
[23:56:24] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"
[23:56:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[23:56:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[23:57:01] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a03f78)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc165f658)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a2aa8)]: 0 failure(s)
[23:57:01] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[23:57:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a03f78)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc165f658)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a2aa8)]: 0 failure(s)
[23:58:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a03f78)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc165f658)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a2aa8)]: 0 failure(s)
[00:00:01] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a03f78)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc165f658)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a2aa8)]: 0 failure(s)
[00:01:11] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a03f78)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc165f658)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a2aa8)]: 0 failure(s)
[00:01:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 32 candidates:
[1 : 16]:	1.0000  0.9999  0.9997  0.9997  0.9996  0.9996  0.9995  0.9994  0.9993  0.9993  0.9990  0.9989  0.9988  0.9987  0.9985  0.9985
[17 : 32]:	0.9984  0.9984  0.9984  0.9983  0.9982  0.9981  0.9981  0.9979  0.9977  0.9973  0.9973  0.9971  0.9968  0.9968  0.9968  0.9967
[00:02:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 32 candidate(s) with evolutionary search
[00:02:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 32 candidates(s) for measurement
[00:02:06] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[00:02:36] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 32 sample(s) to runner
[00:03:00] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #18: "fused_nn_pad_8"
[00:03:00] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[00:03:00] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[00:03:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[00:03:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[00:03:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[00:03:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[00:03:55] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[00:04:10] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[00:04:18] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 8 candidates:
[1 : 8]:	0.9914  0.6759  0.6230  0.5444  0.4648  0.3470  0.0913  0.0103
[00:04:18] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 8 candidate(s) with evolutionary search
[00:04:18] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 8 candidates(s) for measurement
[00:04:19] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 8 sample(s) to builder
[00:04:20] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 8 sample(s) to runner
[00:04:55] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #19: "fused_nn_max_pool2d_4"
[00:04:55] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[00:04:55] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[00:04:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[00:04:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[00:05:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[00:05:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[00:06:03] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[00:06:22] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[00:06:36] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 8 candidates:
[1 : 8]:	0.7322  0.7172  0.6354  0.5410  0.3245  0.3185  0.2506  0.2209
[00:06:36] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 8 candidate(s) with evolutionary search
[00:06:37] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 8 candidates(s) for measurement
[00:06:37] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 8 sample(s) to builder
[00:06:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 8 sample(s) to runner
[00:07:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #20: "fused_nn_pad_9"
[00:07:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[00:07:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[00:08:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[00:08:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[00:09:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[00:09:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[00:09:55] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[00:10:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[00:10:46] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 8 candidates:
[1 : 8]:	0.9621  0.9083  0.7577  0.6581  0.6217  0.4948  0.3638  0.3361
[00:10:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 8 candidate(s) with evolutionary search
[00:10:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 8 candidates(s) for measurement
[00:10:48] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 8 sample(s) to builder
[00:10:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 8 sample(s) to runner
[00:10:57] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"
[00:10:57] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[00:10:57] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[00:11:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19d0828)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a431e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1988e68)]: 0 failure(s)
[00:11:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[00:12:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19d0828)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a431e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1988e68)]: 0 failure(s)
[00:13:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19d0828)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a431e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1988e68)]: 0 failure(s)
[00:14:48] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19d0828)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a431e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1988e68)]: 0 failure(s)
[00:16:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19d0828)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a431e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1988e68)]: 0 failure(s)
[00:16:37] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 32 candidates:
[1 : 16]:	0.9999  0.9996  0.9995  0.9993  0.9992  0.9992  0.9992  0.9992  0.9991  0.9990  0.9989  0.9988  0.9988  0.9988  0.9987  0.9983
[17 : 32]:	0.9982  0.9980  0.9979  0.9977  0.9976  0.9976  0.9976  0.9975  0.9975  0.9975  0.9974  0.9971  0.9970  0.9970  0.9970  0.9968
[00:16:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 32 candidate(s) with evolutionary search
[00:16:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 32 candidates(s) for measurement
[00:16:46] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[00:17:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 32 sample(s) to runner
[00:18:05] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #22: "fused_nn_pad_10"
[00:18:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[00:18:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[00:18:22] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[00:18:22] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[00:18:41] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[00:19:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[00:19:23] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[00:19:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[00:19:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 8 candidates:
[1 : 8]:	0.8185  0.8022  0.6977  0.6321  0.5742  0.5590  0.4981  0.1603
[00:19:46] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 8 candidate(s) with evolutionary search
[00:19:46] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 8 candidates(s) for measurement
[00:19:49] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 8 sample(s) to builder
[00:19:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 8 sample(s) to runner
[00:20:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #23: "fused_nn_max_pool2d_5"
[00:20:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[00:20:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[00:20:19] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[00:20:19] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[00:20:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[00:20:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[00:21:09] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[00:21:25] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[00:21:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 8 candidates:
[1 : 8]:	0.8466  0.7078  0.4995  0.3806  0.2927  0.1155  0.0776  0.0367
[00:21:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 8 candidate(s) with evolutionary search
[00:21:52] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 8 candidates(s) for measurement
[00:21:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 8 sample(s) to builder
[00:22:19] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 8 sample(s) to runner
[00:22:23] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #24: "fused_nn_pad_11"
[00:22:23] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[00:22:23] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[00:22:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[00:22:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[00:23:13] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[00:23:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[00:24:18] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[00:24:48] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[00:24:53] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 8 candidates:
[1 : 8]:	0.9883  0.9634  0.8686  0.7112  0.6025  0.5805  0.5661  0.3227
[00:24:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 8 candidate(s) with evolutionary search
[00:24:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 8 candidates(s) for measurement
[00:24:55] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 8 sample(s) to builder
[00:24:58] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 8 sample(s) to runner
[00:25:02] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"
[00:25:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[00:25:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[00:25:26] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19143c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1afd9b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1977d28)]: 0 failure(s)
[00:25:26] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[00:26:25] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19143c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1afd9b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1977d28)]: 0 failure(s)
[00:27:30] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19143c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1afd9b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1977d28)]: 0 failure(s)
[00:28:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19143c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1afd9b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1977d28)]: 0 failure(s)
[00:29:37] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19143c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1afd9b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1977d28)]: 0 failure(s)
[00:30:11] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 32 candidates:
[1 : 16]:	0.9999  0.9999  0.9996  0.9992  0.9992  0.9988  0.9988  0.9988  0.9988  0.9987  0.9986  0.9986  0.9986  0.9984  0.9983  0.9982
[17 : 32]:	0.9981  0.9980  0.9980  0.9978  0.9977  0.9976  0.9975  0.9975  0.9975  0.9974  0.9973  0.9971  0.9971  0.9970  0.9970  0.9969
[00:30:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 32 candidate(s) with evolutionary search
[00:30:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 32 candidates(s) for measurement
[00:30:19] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[00:30:49] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 32 sample(s) to runner
[00:33:02] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #26: "fused_nn_pad_12"
[00:33:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[00:33:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[00:33:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[00:33:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[00:34:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[00:34:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[00:35:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[00:35:50] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[00:36:09] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 4 candidates:
[1 : 4]:	0.9468  0.7055  0.4316  0.2314
[00:36:10] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 4 candidate(s) with evolutionary search
[00:36:10] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 4 candidates(s) for measurement
[00:36:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 4 sample(s) to builder
[00:36:20] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 4 sample(s) to runner
[00:36:23] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"
[00:36:23] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[00:36:23] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[00:36:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f7508)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a56a98)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19f7788)]: 0 failure(s)
[00:36:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[00:37:48] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f7508)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a56a98)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19f7788)]: 0 failure(s)
[00:38:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f7508)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a56a98)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19f7788)]: 0 failure(s)
[00:39:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f7508)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a56a98)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19f7788)]: 0 failure(s)
[00:40:55] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f7508)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a56a98)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19f7788)]: 0 failure(s)
[00:41:36] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 32 candidates:
[1 : 16]:	0.9997  0.9991  0.9990  0.9988  0.9987  0.9983  0.9982  0.9981  0.9978  0.9977  0.9976  0.9976  0.9975  0.9973  0.9973  0.9973
[17 : 32]:	0.9972  0.9971  0.9971  0.9968  0.9966  0.9965  0.9964  0.9964  0.9964  0.9963  0.9962  0.9958  0.9955  0.9955  0.9952  0.9952
[00:41:42] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 32 candidate(s) with evolutionary search
[00:41:42] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 32 candidates(s) for measurement
[00:41:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[00:42:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 32 sample(s) to runner
[00:45:52] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #28: "fused_nn_pad_layout_transform"
[00:45:52] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[00:45:52] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[00:46:22] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[00:46:22] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[00:46:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[00:47:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[00:47:41] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[00:48:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[00:48:30] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 4 candidates:
[1 : 4]:	0.3285  0.3144  0.2716  0.2178
[00:48:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 4 candidate(s) with evolutionary search
[00:48:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 4 candidates(s) for measurement
[00:48:32] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 4 sample(s) to builder
[00:48:36] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 4 sample(s) to runner
[00:49:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #29: "fused_nn_contrib_conv2d_NCHWc_add"
[00:49:10] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[00:49:10] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[00:49:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a1078)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1b231e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1986c58)]: 0 failure(s)
[00:49:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[00:50:23] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a1078)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1b231e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1986c58)]: 0 failure(s)
[00:51:08] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a1078)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1b231e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1986c58)]: 0 failure(s)
[00:51:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a1078)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1b231e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1986c58)]: 0 failure(s)
[00:52:48] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a1078)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1b231e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1986c58)]: 0 failure(s)
[00:53:25] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 32 candidates:
[1 : 16]:	0.9997  0.9996  0.9996  0.9995  0.9992  0.9992  0.9989  0.9987  0.9984  0.9983  0.9982  0.9981  0.9981  0.9981  0.9979  0.9978
[17 : 32]:	0.9978  0.9978  0.9978  0.9977  0.9977  0.9976  0.9975  0.9971  0.9970  0.9969  0.9965  0.9960  0.9958  0.9957  0.9956  0.9956
[00:53:30] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 32 candidate(s) with evolutionary search
[00:53:30] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 32 candidates(s) for measurement
[00:53:32] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[00:54:05] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 32 sample(s) to runner
[00:54:18] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #30: "fused_layout_transform"
[00:54:18] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[00:54:18] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 0 candidate(s) from database
[00:54:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[00:54:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2048 candidate(s)
[00:54:30] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[00:54:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[00:55:01] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[00:55:22] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[00:55:37] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 8 candidates:
[1 : 8]:	0.9607  0.7798  0.7575  0.6583  0.6283  0.6017  0.5270  0.2678
[00:55:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 8 candidate(s) with evolutionary search
[00:55:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 8 candidates(s) for measurement
[00:55:39] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 8 sample(s) to builder
[00:55:39] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 8 sample(s) to runner
[00:56:49] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_multiply_add_nn_pad_layout_transform"] Trial #0: GFLOPs: 0.3579. Time: 2.9009 ms. Best GFLOPs: 0.3579
[00:56:49] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_multiply_add_nn_pad_layout_transform"] Trial #1: GFLOPs: 0.2520. Time: 4.1202 ms. Best GFLOPs: 0.3579
[00:56:49] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_multiply_add_nn_pad_layout_transform"] Trial #2: GFLOPs: 0.6564. Time: 1.5818 ms. Best GFLOPs: 0.6564
[00:56:49] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_multiply_add_nn_pad_layout_transform"] Trial #3: GFLOPs: 0.3536. Time: 2.9361 ms. Best GFLOPs: 0.6564
[00:56:49] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_multiply_add_nn_pad_layout_transform"] Trial #4: GFLOPs: 0.3894. Time: 2.6663 ms. Best GFLOPs: 0.6564
[00:56:49] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_multiply_add_nn_pad_layout_transform"] Trial #5: GFLOPs: 0.2397. Time: 4.3323 ms. Best GFLOPs: 0.6564
[00:56:49] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_multiply_add_nn_pad_layout_transform"] Trial #6: GFLOPs: 0.4447. Time: 2.3349 ms. Best GFLOPs: 0.6564
[00:56:49] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_multiply_add_nn_pad_layout_transform"] Trial #7: GFLOPs: 0.4780. Time: 2.1723 ms. Best GFLOPs: 0.6564
[00:56:49] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_multiply_add_nn_pad_layout_transform"] Trial #8: GFLOPs: 0.3441. Time: 3.0177 ms. Best GFLOPs: 0.6564
[00:56:49] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_multiply_add_nn_pad_layout_transform"] Trial #9: GFLOPs: 0.2573. Time: 4.0351 ms. Best GFLOPs: 0.6564
[00:56:49] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_multiply_add_nn_pad_layout_transform"] Trial #10: GFLOPs: 0.5382. Time: 1.9292 ms. Best GFLOPs: 0.6564
[00:56:49] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_multiply_add_nn_pad_layout_transform"] Trial #11: GFLOPs: 0.1947. Time: 5.3326 ms. Best GFLOPs: 0.6564
[00:56:49] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_multiply_add_nn_pad_layout_transform"] Trial #12: GFLOPs: 0.4212. Time: 2.4650 ms. Best GFLOPs: 0.6564
[00:56:49] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_multiply_add_nn_pad_layout_transform"] Trial #13: GFLOPs: 0.5437. Time: 1.9097 ms. Best GFLOPs: 0.6564
[00:56:49] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_multiply_add_nn_pad_layout_transform"] Trial #14: GFLOPs: 0.5673. Time: 1.8302 ms. Best GFLOPs: 0.6564
[00:56:49] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_multiply_add_nn_pad_layout_transform"] Trial #15: GFLOPs: 0.5060. Time: 2.0521 ms. Best GFLOPs: 0.6564
[00:56:49] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_multiply_add_nn_pad_layout_transform"] Trial #16: GFLOPs: 0.1712. Time: 6.0653 ms. Best GFLOPs: 0.6564
[00:56:49] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_multiply_add_nn_pad_layout_transform"] Trial #17: GFLOPs: 0.2500. Time: 4.1540 ms. Best GFLOPs: 0.6564
[00:56:49] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_multiply_add_nn_pad_layout_transform"] Trial #18: GFLOPs: 0.3475. Time: 2.9881 ms. Best GFLOPs: 0.6564
[00:56:49] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_multiply_add_nn_pad_layout_transform"] Trial #19: GFLOPs: 0.4204. Time: 2.4702 ms. Best GFLOPs: 0.6564
[00:56:49] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_multiply_add_nn_pad_layout_transform"] Trial #20: GFLOPs: 0.2242. Time: 4.6309 ms. Best GFLOPs: 0.6564
[00:56:49] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_multiply_add_nn_pad_layout_transform"] Trial #21: GFLOPs: 0.7769. Time: 1.3364 ms. Best GFLOPs: 0.7769
[00:56:49] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_multiply_add_nn_pad_layout_transform"] Trial #22: GFLOPs: 0.1647. Time: 6.3030 ms. Best GFLOPs: 0.7769
[00:56:49] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_multiply_add_nn_pad_layout_transform"] Trial #23: GFLOPs: 0.2469. Time: 4.2052 ms. Best GFLOPs: 0.7769
[00:57:11] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #0: "fused_multiply_add_nn_pad_layout_transform"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |            N/A |          N/A |                   N/A |      0 |            
  2 |                                      fused_nn_pad |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |            N/A |          N/A |                   N/A |      0 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 24
Total latency (us): 1336.44

[00:57:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #0: GFLOPs: 11.7910. Time: 13.1506 ms. Best GFLOPs: 11.7910
[00:57:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #1: GFLOPs: 7.2036. Time: 21.5252 ms. Best GFLOPs: 11.7910
[00:57:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #2: GFLOPs: 6.3879. Time: 24.2739 ms. Best GFLOPs: 11.7910
[00:57:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #3: GFLOPs: 11.9017. Time: 13.0282 ms. Best GFLOPs: 11.9017
[00:57:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #4: GFLOPs: 12.9218. Time: 11.9997 ms. Best GFLOPs: 12.9218
[00:57:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #5: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1, 418, 418, 3), "float32"], placeholder_1: T.Buffer[(4, 1, 3, 3, 3, 4), "float32"], placeholder_2: T.Buffer[(1, 4, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 4, 416, 416, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 4, 416, 416, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused in T.parallel(512, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i2_2_init, i3_2_init, i2_3_init in T.grid(13, 52, 8):
                with T.block("conv2d_NCHWc_init"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 256 * 2 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 64 // 32)
                    oh = T.axis.spatial(416, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 256 // 64 * 104 + i2_2_init * 8 + i2_3_init)
                    ow = T.axis.spatial(416, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 32 // 4 * 52 + i3_2_init)
                    oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 4)
                    T.reads()
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1, 418, 418, 3], "float32"], ["TENSOR", [4, 1, 3, 3, 3, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW3c", "NCHW4c", "float32"]})
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
            for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(3, 3, 1, 1, 1, 13, 52, 1, 1, 1, 3, 1, 1, 8, 1, 1):
                with T.block("conv2d_NCHWc_update"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 256 * 2 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 64 // 32)
                    oh = T.axis.spatial(416, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 256 // 64 * 104 + i2_2 * 8 + i2_3)
                    ow = T.axis.spatial(416, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 32 // 4 * 52 + i3_2)
                    oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 4)
                    ic, kh, kw = T.axis.remap("RRR", [i5_0, i6_0, i7_1])
                    T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 3, oh + kh, ow + kw, ic % 3], placeholder_1[oc_chunk, ic // 3, kh, kw, ic % 3, oc_block])
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1, 418, 418, 3], "float32"], ["TENSOR", [4, 1, 3, 3, 3, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW3c", "NCHW4c", "float32"]})
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 3, oh + kh, ow + kw, ic % 3] * placeholder_1[oc_chunk, ic // 3, kh, kw, ic % 3, oc_block]
        for i0_i1_i2_fused in T.parallel(1664, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3 in T.serial(416):
                for i4_fused in T.vectorized(4):
                    with T.block("T_leaky_relu"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(4, i0_i1_i2_fused // 416)
                        ax2 = T.axis.spatial(416, i0_i1_i2_fused % 416)
                        ax3, ax4 = T.axis.remap("SS", [i3, i4_fused])
                        T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                        T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[2, 2, 1, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 13, 8])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 52, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 4, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[3, 1])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
sch.enter_postproc()
b64 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.unroll_explicit")
b65, b66 = sch.get_child_blocks(b64)
l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b65)
l93 = sch.fuse(l67, l68, l69, l70, l71, l72, l73, l74, l75, l76)
sch.parallel(loop=l93)
sch.annotate(block_or_loop=l93, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l93, ann_key="pragma_unroll_explicit", ann_val=1)
l94, l95, l96, l97, l98 = sch.get_loops(block=b66)
l99 = sch.fuse(l94, l95, l96)
sch.parallel(loop=l99)
l100 = sch.fuse(l98)
sch.vectorize(loop=l100)
sch.annotate(block_or_loop=l99, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l99, ann_key="pragma_unroll_explicit", ann_val=1)
b101 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b101)
b119 = sch.decompose_reduction(block=b101, loop=l103)
[00:57:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #6: GFLOPs: 5.0356. Time: 30.7927 ms. Best GFLOPs: 12.9218
[00:57:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #7: GFLOPs: 8.5443. Time: 18.1475 ms. Best GFLOPs: 12.9218
[00:57:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #8: GFLOPs: 14.8176. Time: 10.4644 ms. Best GFLOPs: 14.8176
[00:57:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #9: GFLOPs: 11.2687. Time: 13.7600 ms. Best GFLOPs: 14.8176
[00:57:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #10: GFLOPs: 11.8383. Time: 13.0980 ms. Best GFLOPs: 14.8176
[00:57:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #11: GFLOPs: 4.2216. Time: 36.7297 ms. Best GFLOPs: 14.8176
[00:57:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #12: GFLOPs: 6.6764. Time: 23.2249 ms. Best GFLOPs: 14.8176
[00:57:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #13: GFLOPs: 7.9402. Time: 19.5282 ms. Best GFLOPs: 14.8176
[00:57:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #14: GFLOPs: 4.6328. Time: 33.4699 ms. Best GFLOPs: 14.8176
[00:57:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #15: GFLOPs: 7.5883. Time: 20.4339 ms. Best GFLOPs: 14.8176
[00:57:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #16: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1, 418, 418, 3), "float32"], placeholder_1: T.Buffer[(4, 1, 3, 3, 3, 4), "float32"], placeholder_2: T.Buffer[(1, 4, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 4, 416, 416, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 4, 416, 416, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused in T.parallel(832, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3_1, i4_1 in T.grid(16, 1):
                for i5_0, i6_0 in T.grid(1, 1):
                    for i4_2_init, i2_3_init, i3_3_init in T.grid(2, 4, 26):
                        with T.block("conv2d_NCHWc_init"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 104 // 26)
                            oh = T.axis.spatial(416, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused // 208 * 104 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 26 * 4 + i2_3_init)
                            ow = T.axis.spatial(416, i3_1 * 26 + i3_3_init)
                            oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 208 // 104 * 2 + i4_2_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1, 418, 418, 3], "float32"], ["TENSOR", [4, 1, 3, 3, 3, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW3c", "NCHW4c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                    for i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(3, 1, 1, 1, 1, 2, 3, 3, 1, 1, 1, 4, 26, 1):
                        with T.block("conv2d_NCHWc_update"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 104 // 26)
                            oh = T.axis.spatial(416, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused // 208 * 104 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 26 * 4 + i2_3)
                            ow = T.axis.spatial(416, i3_1 * 26 + i3_3)
                            oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 208 // 104 * 2 + i4_2)
                            ic, kh, kw = T.axis.remap("RRR", [i5_1, i6_1, i7_0])
                            T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 3, oh + kh, ow + kw, ic % 3], placeholder_1[oc_chunk, ic // 3, kh, kw, ic % 3, oc_block])
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1, 418, 418, 3], "float32"], ["TENSOR", [4, 1, 3, 3, 3, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW3c", "NCHW4c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 3, oh + kh, ow + kw, ic % 3] * placeholder_1[oc_chunk, ic // 3, kh, kw, ic % 3, oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(1, 1, 4, 26):
                    for ax4_fused in T.vectorized(2):
                        with T.block("T_leaky_relu"):
                            ax0_1 = T.axis.spatial(1, 0)
                            ax1_1 = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 104 // 26)
                            ax2_1 = T.axis.spatial(416, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused // 208 * 104 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 26 * 4 + ax2)
                            ax3_1 = T.axis.spatial(416, i3_1 * 26 + ax3)
                            ax4 = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 208 // 104 * 2 + ax4_fused)
                            T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                            T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4])
                            T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 4, 1, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 26, 1, 4])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 16, 1, 26])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 2, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 3])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, l73, l74, l75)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b67)
l103 = sch.fuse(l102)
sch.vectorize(loop=l103)
sch.annotate(block_or_loop=l95, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l95, ann_key="pragma_unroll_explicit", ann_val=1)
b104 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123 = sch.get_loops(block=b104)
b124 = sch.decompose_reduction(block=b104, loop=l110)
[00:57:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #17: GFLOPs: 4.3865. Time: 35.3492 ms. Best GFLOPs: 14.8176
[00:57:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #18: GFLOPs: 4.0486. Time: 38.2995 ms. Best GFLOPs: 14.8176
[00:57:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #19: GFLOPs: 11.2544. Time: 13.7776 ms. Best GFLOPs: 14.8176
[00:57:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #20: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1, 418, 418, 3), "float32"], placeholder_1: T.Buffer[(4, 1, 3, 3, 3, 4), "float32"], placeholder_2: T.Buffer[(1, 4, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 4, 416, 416, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 4, 416, 416, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused in T.parallel(128, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i2_2_init, i3_2_init, i4_2_init, i3_3_init in T.grid(208, 4, 2, 13):
                with T.block("conv2d_NCHWc_init"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 32)
                    oh = T.axis.spatial(416, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 32 // 16 * 208 + i2_2_init)
                    ow = T.axis.spatial(416, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 16 // 8 * 208 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 4 * 52 + i3_2_init * 13 + i3_3_init)
                    oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 8 // 4 * 2 + i4_2_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1, 418, 418, 3], "float32"], ["TENSOR", [4, 1, 3, 3, 3, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW3c", "NCHW4c", "float32"]})
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
            for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(3, 1, 1, 1, 1, 208, 4, 2, 1, 3, 3, 1, 1, 1, 13, 1):
                with T.block("conv2d_NCHWc_update"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 32)
                    oh = T.axis.spatial(416, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 32 // 16 * 208 + i2_2)
                    ow = T.axis.spatial(416, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 16 // 8 * 208 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 4 * 52 + i3_2 * 13 + i3_3)
                    oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 8 // 4 * 2 + i4_2)
                    ic, kh, kw = T.axis.remap("RRR", [i5_0, i6_1, i7_1])
                    T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 3, oh + kh, ow + kw, ic % 3], placeholder_1[oc_chunk, ic // 3, kh, kw, ic % 3, oc_block])
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1, 418, 418, 3], "float32"], ["TENSOR", [4, 1, 3, 3, 3, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW3c", "NCHW4c", "float32"]})
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 3, oh + kh, ow + kw, ic % 3] * placeholder_1[oc_chunk, ic // 3, kh, kw, ic % 3, oc_block]
        for i0_i1_i2_fused in T.parallel(1664, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3 in T.serial(416):
                for i4_fused in T.vectorized(4):
                    with T.block("T_leaky_relu"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(4, i0_i1_i2_fused // 416)
                        ax2 = T.axis.spatial(416, i0_i1_i2_fused % 416)
                        ax3, ax4 = T.axis.remap("SS", [i3, i4_fused])
                        T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                        T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[4, 1, 1, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 208, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 4, 4, 13])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 2, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[3, 1])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
sch.enter_postproc()
b64 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.unroll_explicit")
b65, b66 = sch.get_child_blocks(b64)
l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b65)
l93 = sch.fuse(l67, l68, l69, l70, l71, l72, l73, l74, l75, l76)
sch.parallel(loop=l93)
sch.annotate(block_or_loop=l93, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l93, ann_key="pragma_unroll_explicit", ann_val=1)
l94, l95, l96, l97, l98 = sch.get_loops(block=b66)
l99 = sch.fuse(l94, l95, l96)
sch.parallel(loop=l99)
l100 = sch.fuse(l98)
sch.vectorize(loop=l100)
sch.annotate(block_or_loop=l99, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l99, ann_key="pragma_unroll_explicit", ann_val=1)
b101 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b101)
b119 = sch.decompose_reduction(block=b101, loop=l103)
[00:57:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #21: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1, 418, 418, 3), "float32"], placeholder_1: T.Buffer[(4, 1, 3, 3, 3, 4), "float32"], placeholder_2: T.Buffer[(1, 4, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 4, 416, 416, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 4, 416, 416, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_fused in T.parallel(32, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1, i1_1, i2_1, i3_1, i4_1, i5_0 in T.grid(1, 1, 1, 26, 2, 1):
                for i2_2_init, i3_2_init, i1_3_init, i2_3_init, i3_3_init in T.grid(13, 2, 4, 2, 8):
                    with T.block("conv2d_NCHWc_init"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(4, i1_3_init)
                        oh = T.axis.spatial(416, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 2 * 26 + i2_2_init * 2 + i2_3_init)
                        ow = T.axis.spatial(416, i3_1 * 16 + i3_2_init * 8 + i3_3_init)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 2 * 2 + i4_1)
                        T.reads()
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1, 418, 418, 3], "float32"], ["TENSOR", [4, 1, 3, 3, 3, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW3c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(3, 3, 1, 1, 13, 2, 1, 3, 1, 1, 1, 4, 2, 8, 1):
                    with T.block("conv2d_NCHWc_update"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(4, i1_3)
                        oh = T.axis.spatial(416, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 2 * 26 + i2_2 * 2 + i2_3)
                        ow = T.axis.spatial(416, i3_1 * 16 + i3_2 * 8 + i3_3)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 2 * 2 + i4_1)
                        ic, kh, kw = T.axis.remap("RRR", [i5_1, i6_0, i7_0])
                        T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 3, oh + kh, ow + kw, ic % 3], placeholder_1[oc_chunk, ic // 3, kh, kw, ic % 3, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1, 418, 418, 3], "float32"], ["TENSOR", [4, 1, 3, 3, 3, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW3c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 3, oh + kh, ow + kw, ic % 3] * placeholder_1[oc_chunk, ic // 3, kh, kw, ic % 3, oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(1, 4, 26, 416):
                for ax4_fused in T.vectorized(2):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1 = T.axis.spatial(4, ax1)
                        ax2_1 = T.axis.spatial(416, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 2 * 26 + ax2)
                        ax3_1 = T.axis.spatial(416, ax3)
                        ax4 = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 2 * 2 + ax4_fused)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 1, 13, 2])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 26, 2, 8])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 2, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 3])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b67)
l101 = sch.fuse(l100)
sch.vectorize(loop=l101)
sch.annotate(block_or_loop=l95, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l95, ann_key="pragma_unroll_explicit", ann_val=1)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b102)
b125 = sch.decompose_reduction(block=b102, loop=l110)
[00:57:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #22: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1, 418, 418, 3), "float32"], placeholder_1: T.Buffer[(4, 1, 3, 3, 3, 4), "float32"], placeholder_2: T.Buffer[(1, 4, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 4, 416, 416, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 4, 416, 416, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_fused in T.parallel(416, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i4_0, i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(2, 1, 1, 2, 1, 1):
                for i1_2_init, i2_2_init, i3_3_init in T.grid(4, 16, 13):
                    for i4_3_fused_init in T.vectorized(2):
                        with T.block("conv2d_NCHWc_init"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(4, i1_2_init)
                            oh = T.axis.spatial(416, i0_0_i1_0_i2_0_i3_0_fused // 32 * 32 + i2_1 * 16 + i2_2_init)
                            ow = T.axis.spatial(416, i0_0_i1_0_i2_0_i3_0_fused % 32 * 13 + i3_3_init)
                            oc_block = T.axis.spatial(4, i4_0 * 2 + i4_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1, 418, 418, 3], "float32"], ["TENSOR", [4, 1, 3, 3, 3, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW3c", "NCHW4c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3 in T.grid(3, 3, 1, 1, 4, 16, 1, 1, 1, 1, 3, 1, 1, 1, 13):
                    for i4_3_fused in T.vectorized(2):
                        with T.block("conv2d_NCHWc_update"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(4, i1_2)
                            oh = T.axis.spatial(416, i0_0_i1_0_i2_0_i3_0_fused // 32 * 32 + i2_1 * 16 + i2_2)
                            ow = T.axis.spatial(416, i0_0_i1_0_i2_0_i3_0_fused % 32 * 13 + i3_3)
                            oc_block = T.axis.spatial(4, i4_0 * 2 + i4_3_fused)
                            ic, kh, kw = T.axis.remap("RRR", [i5_0, i6_0, i7_1])
                            T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 3, oh + kh, ow + kw, ic % 3], placeholder_1[oc_chunk, ic // 3, kh, kw, ic % 3, oc_block])
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1, 418, 418, 3], "float32"], ["TENSOR", [4, 1, 3, 3, 3, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW3c", "NCHW4c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 3, oh + kh, ow + kw, ic % 3] * placeholder_1[oc_chunk, ic // 3, kh, kw, ic % 3, oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(1, 4, 16, 13):
                    for ax4_fused in T.vectorized(2):
                        with T.block("T_leaky_relu"):
                            ax0_1 = T.axis.spatial(1, 0)
                            ax1_1 = T.axis.spatial(4, ax1)
                            ax2_1 = T.axis.spatial(416, i0_0_i1_0_i2_0_i3_0_fused // 32 * 32 + i2_1 * 16 + ax2)
                            ax3_1 = T.axis.spatial(416, i0_0_i1_0_i2_0_i3_0_fused % 32 * 13 + ax3)
                            ax4 = T.axis.spatial(4, i4_0 * 2 + ax4_fused)
                            T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                            T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4])
                            T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 4, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[13, 2, 16, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[32, 1, 1, 13])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[3, 1])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71)
sch.parallel(loop=l94)
l95 = sch.fuse(l93)
sch.vectorize(loop=l95)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b67)
l108 = sch.fuse(l107)
sch.vectorize(loop=l108)
sch.annotate(block_or_loop=l96, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l96, ann_key="pragma_unroll_explicit", ann_val=1)
b109 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b109)
b133 = sch.decompose_reduction(block=b109, loop=l117)
[00:57:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #23: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1, 418, 418, 3), "float32"], placeholder_1: T.Buffer[(4, 1, 3, 3, 3, 4), "float32"], placeholder_2: T.Buffer[(1, 4, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 4, 416, 416, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 4, 416, 416, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_fused in T.parallel(208, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 2, 32, 1, 2):
                for i5_0 in T.serial(1):
                    for i1_2_init, i3_2_init, i2_3_init, i3_3_init in T.grid(2, 2, 13, 2):
                        with T.block("conv2d_NCHWc_init"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(4, i1_1 * 2 + i1_2_init)
                            oh = T.axis.spatial(416, i2_1 * 13 + i2_3_init)
                            ow = T.axis.spatial(416, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 2 * 4 + i3_2_init * 2 + i3_3_init)
                            oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 2 * 2 + i4_1)
                            T.reads()
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1, 418, 418, 3], "float32"], ["TENSOR", [4, 1, 3, 3, 3, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW3c", "NCHW4c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                    for i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(3, 1, 1, 2, 1, 2, 1, 3, 1, 3, 1, 1, 13, 2, 1):
                        with T.block("conv2d_NCHWc_update"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(4, i1_1 * 2 + i1_2)
                            oh = T.axis.spatial(416, i2_1 * 13 + i2_3)
                            ow = T.axis.spatial(416, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 2 * 4 + i3_2 * 2 + i3_3)
                            oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 2 * 2 + i4_1)
                            ic, kh, kw = T.axis.remap("RRR", [i5_1, i6_0, i7_1])
                            T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 3, oh + kh, ow + kw, ic % 3], placeholder_1[oc_chunk, ic // 3, kh, kw, ic % 3, oc_block])
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1, 418, 418, 3], "float32"], ["TENSOR", [4, 1, 3, 3, 3, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW3c", "NCHW4c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 3, oh + kh, ow + kw, ic % 3] * placeholder_1[oc_chunk, ic // 3, kh, kw, ic % 3, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 2, 13, 4, 1):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1 = T.axis.spatial(4, i1_1 * 2 + ax1)
                        ax2_1 = T.axis.spatial(416, i2_1 * 13 + ax2)
                        ax3_1 = T.axis.spatial(416, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 2 * 4 + ax3)
                        ax4_1 = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 2 * 2 + i4_1)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 2, 2, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 32, 1, 13])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[104, 1, 2, 2])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 2, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 3])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b67)
sch.annotate(block_or_loop=l95, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l95, ann_key="pragma_unroll_explicit", ann_val=1)
b106 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128 = sch.get_loops(block=b106)
b129 = sch.decompose_reduction(block=b106, loop=l114)
[00:57:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #24: GFLOPs: 10.7382. Time: 14.4399 ms. Best GFLOPs: 14.8176
[00:57:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #25: GFLOPs: 4.3124. Time: 35.9567 ms. Best GFLOPs: 14.8176
[00:57:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #26: GFLOPs: 4.1508. Time: 37.3563 ms. Best GFLOPs: 14.8176
[00:57:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #27: GFLOPs: 27.1369. Time: 5.7139 ms. Best GFLOPs: 27.1369
[00:57:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #28: GFLOPs: 9.2062. Time: 16.8428 ms. Best GFLOPs: 27.1369
[00:57:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #29: GFLOPs: 8.0465. Time: 19.2703 ms. Best GFLOPs: 27.1369
[00:57:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #30: GFLOPs: 8.3483. Time: 18.5737 ms. Best GFLOPs: 27.1369
[00:57:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"] Trial #31: GFLOPs: 17.2174. Time: 9.0059 ms. Best GFLOPs: 27.1369
[00:57:43] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |            N/A |          N/A |                   N/A |      0 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 56
Total latency (us): 7050.36

[00:57:44] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #2: "fused_nn_pad"] Trial #0: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4, 416, 416, 4), "float32"], T_pad: T.Buffer[(1, 4, 416, 416, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        for i0_i1_i2_fused in T.parallel(1664, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3 in T.serial(416):
                for i4_fused in T.vectorized(4):
                    with T.block("T_pad"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(4, i0_i1_i2_fused // 416)
                        ax2 = T.axis.spatial(416, i0_i1_i2_fused % 416)
                        ax3, ax4 = T.axis.remap("SS", [i3, i4_fused])
                        T.reads(placeholder[ax0, ax1, ax2, ax3, ax4])
                        T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                        T_pad[ax0, ax1, ax2, ax3, ax4] = placeholder[ax0, ax1, ax2, ax3, ax4]
    

b0 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.vectorize", ann_val=64)
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
sch.enter_postproc()
b2 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit")
b3, = sch.get_child_blocks(b2)
l4, l5, l6, l7, l8 = sch.get_loops(block=b3)
l9 = sch.fuse(l4, l5, l6)
sch.parallel(loop=l9)
l10 = sch.fuse(l8)
sch.vectorize(loop=l10)
sch.annotate(block_or_loop=l9, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l9, ann_key="pragma_unroll_explicit", ann_val=1)
[00:57:44] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_nn_pad"] Trial #1: GFLOPs: 0.0000. Time: 1.8932 ms. Best GFLOPs: 0.0000
[00:57:44] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_nn_pad"] Trial #2: GFLOPs: 0.0000. Time: 2.8267 ms. Best GFLOPs: 0.0000
[00:57:44] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_nn_pad"] Trial #3: GFLOPs: 0.0000. Time: 0.2786 ms. Best GFLOPs: 0.0000
[00:57:44] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_nn_pad"] Trial #4: GFLOPs: 0.0000. Time: 0.4682 ms. Best GFLOPs: 0.0000
[00:57:44] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_nn_pad"] Trial #5: GFLOPs: 0.0000. Time: 0.2110 ms. Best GFLOPs: 0.0000
[00:57:44] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_nn_pad"] Trial #6: GFLOPs: 0.0000. Time: 1.1217 ms. Best GFLOPs: 0.0000
[00:57:44] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #2: "fused_nn_pad"] Trial #7: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4, 416, 416, 4), "float32"], T_pad: T.Buffer[(1, 4, 416, 416, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        for i0_i1_fused in T.parallel(4, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i2, i3 in T.grid(416, 416):
                for i4_fused in T.vectorized(4):
                    with T.block("T_pad"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1, ax2, ax3, ax4 = T.axis.remap("SSSS", [i0_i1_fused, i2, i3, i4_fused])
                        T.reads(placeholder[ax0, ax1, ax2, ax3, ax4])
                        T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                        T_pad[ax0, ax1, ax2, ax3, ax4] = placeholder[ax0, ax1, ax2, ax3, ax4]
    

b0 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.parallel", ann_val=1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.vectorize", ann_val=64)
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
sch.enter_postproc()
b2 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit")
b3, = sch.get_child_blocks(b2)
l4, l5, l6, l7, l8 = sch.get_loops(block=b3)
l9 = sch.fuse(l4, l5)
sch.parallel(loop=l9)
l10 = sch.fuse(l8)
sch.vectorize(loop=l10)
sch.annotate(block_or_loop=l9, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l9, ann_key="pragma_unroll_explicit", ann_val=1)
[00:57:57] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #2: "fused_nn_pad"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |            N/A |          N/A |                   N/A |      0 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 64
Total latency (us): 7261.39

[00:57:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_max_pool2d"] Trial #0: GFLOPs: 0.5141. Time: 5.3856 ms. Best GFLOPs: 0.5141
[00:57:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_max_pool2d"] Trial #1: GFLOPs: 0.6126. Time: 4.5202 ms. Best GFLOPs: 0.6126
[00:57:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_max_pool2d"] Trial #2: GFLOPs: 0.4697. Time: 5.8947 ms. Best GFLOPs: 0.6126
[00:57:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_max_pool2d"] Trial #3: GFLOPs: 0.5012. Time: 5.5250 ms. Best GFLOPs: 0.6126
[00:57:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_max_pool2d"] Trial #4: GFLOPs: 0.6153. Time: 4.4997 ms. Best GFLOPs: 0.6153
[00:57:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_max_pool2d"] Trial #5: GFLOPs: 9.5558. Time: 0.2898 ms. Best GFLOPs: 9.5558
[00:57:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_max_pool2d"] Trial #6: GFLOPs: 5.6507. Time: 0.4900 ms. Best GFLOPs: 9.5558
[00:57:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_max_pool2d"] Trial #7: GFLOPs: 5.8300. Time: 0.4749 ms. Best GFLOPs: 9.5558
[00:58:27] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #3: "fused_nn_max_pool2d"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 72
Total latency (us): 7551.15

[00:58:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_pad_1"] Trial #0: GFLOPs: 0.0000. Time: 3.0964 ms. Best GFLOPs: 0.0000
[00:58:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_pad_1"] Trial #1: GFLOPs: 0.0000. Time: 3.0039 ms. Best GFLOPs: 0.0000
[00:58:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_pad_1"] Trial #2: GFLOPs: 0.0000. Time: 1.4207 ms. Best GFLOPs: 0.0000
[00:58:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_pad_1"] Trial #3: GFLOPs: 0.0000. Time: 3.5992 ms. Best GFLOPs: 0.0000
[00:58:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_pad_1"] Trial #4: GFLOPs: 0.0000. Time: 3.3593 ms. Best GFLOPs: 0.0000
[00:58:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_pad_1"] Trial #5: GFLOPs: 0.0000. Time: 3.8509 ms. Best GFLOPs: 0.0000
[00:58:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_pad_1"] Trial #6: GFLOPs: 0.0000. Time: 3.5269 ms. Best GFLOPs: 0.0000
[00:58:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_pad_1"] Trial #7: GFLOPs: 0.0000. Time: 4.2976 ms. Best GFLOPs: 0.0000
[00:58:57] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #4: "fused_nn_pad_1"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 80
Total latency (us): 8971.84

[00:58:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #0: GFLOPs: 7.3847. Time: 54.3681 ms. Best GFLOPs: 7.3847
[00:58:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #1: GFLOPs: 13.0435. Time: 30.7808 ms. Best GFLOPs: 13.0435
[00:58:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #2: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4, 210, 210, 4), "float32"], placeholder_1: T.Buffer[(8, 4, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 8, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 8, 208, 208, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 8, 208, 208, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused in T.parallel(416, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3_1, i4_1 in T.grid(2, 1):
                for i1_2_init, i3_2_init, i2_3_init in T.grid(4, 26, 8):
                    for i3_3_i4_3_fused_init in T.vectorized(2):
                        with T.block("conv2d_NCHWc_init"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(8, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 52 // 26 * 4 + i1_2_init)
                            oh = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 26 * 8 + i2_3_init)
                            ow = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused // 104 * 52 + i3_1 * 26 + i3_2_init)
                            oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 104 // 52 * 2 + i3_3_i4_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 4, 210, 210, 4], "float32"], ["TENSOR", [8, 4, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3 in T.grid(16, 3, 3, 1, 4, 1, 26, 1, 1, 1, 1, 1, 1, 8):
                    for i3_3_i4_3_fused in T.vectorized(2):
                        with T.block("conv2d_NCHWc_update"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(8, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 52 // 26 * 4 + i1_2)
                            oh = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 26 * 8 + i2_3)
                            ow = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused // 104 * 52 + i3_1 * 26 + i3_2)
                            oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 104 // 52 * 2 + i3_3_i4_3_fused)
                            ic, kh, kw = T.axis.remap("RRR", [i5_0, i6_0, i7_0])
                            T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 4, 210, 210, 4], "float32"], ["TENSOR", [8, 4, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
        for i0_i1_i2_fused in T.parallel(1664, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3 in T.serial(208):
                for i4_fused in T.vectorized(4):
                    with T.block("T_leaky_relu"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(8, i0_i1_i2_fused // 208)
                        ax2 = T.axis.spatial(208, i0_i1_i2_fused % 208)
                        ax3, ax4 = T.axis.remap("SS", [i3, i4_fused])
                        T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                        T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 2, 4, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 26, 1, 8])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 2, 26, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[16, 1])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
sch.enter_postproc()
b64 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.unroll_explicit")
b65, b66 = sch.get_child_blocks(b64)
l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b65)
l93 = sch.fuse(l67, l68, l69, l70, l71, l72, l73, l74)
sch.parallel(loop=l93)
l94 = sch.fuse(l91, l92)
sch.vectorize(loop=l94)
sch.annotate(block_or_loop=l93, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l93, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99 = sch.get_loops(block=b66)
l100 = sch.fuse(l95, l96, l97)
sch.parallel(loop=l100)
l101 = sch.fuse(l99)
sch.vectorize(loop=l101)
sch.annotate(block_or_loop=l100, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l100, ann_key="pragma_unroll_explicit", ann_val=1)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b102)
b121 = sch.decompose_reduction(block=b102, loop=l106)
[00:58:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #3: GFLOPs: 5.0361. Time: 79.7231 ms. Best GFLOPs: 13.0435
[00:58:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #4: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4, 210, 210, 4), "float32"], placeholder_1: T.Buffer[(8, 4, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 8, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 8, 208, 208, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 8, 208, 208, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused in T.parallel(128, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i2_2_init, i4_2_init, i1_3_init, i3_3_init in T.grid(104, 2, 2, 13):
                for i4_3_fused_init in T.vectorized(2):
                    with T.block("conv2d_NCHWc_init"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(8, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 32 * 2 + i1_3_init)
                        oh = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 32 // 16 * 104 + i2_2_init)
                        ow = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 16 * 13 + i3_3_init)
                        oc_block = T.axis.spatial(4, i4_2_init * 2 + i4_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 4, 210, 210, 4], "float32"], ["TENSOR", [8, 4, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
            for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3 in T.grid(4, 3, 1, 1, 1, 104, 1, 2, 4, 1, 3, 1, 2, 1, 13):
                for i4_3_fused in T.vectorized(2):
                    with T.block("conv2d_NCHWc_update"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(8, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 32 * 2 + i1_3)
                        oh = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 32 // 16 * 104 + i2_2)
                        ow = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 16 * 13 + i3_3)
                        oc_block = T.axis.spatial(4, i4_2 * 2 + i4_3_fused)
                        ic = T.axis.reduce(16, i5_0 * 4 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_0, i7_1])
                        T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 4, 210, 210, 4], "float32"], ["TENSOR", [8, 4, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
            for ax0, ax1, ax2 in T.grid(1, 2, 104):
                for ax3_ax4_fused in T.vectorized(52):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1 = T.axis.spatial(8, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 32 * 2 + ax1)
                        ax2_1 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 32 // 16 * 104 + ax2)
                        ax3 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 16 * 13 + ax3_ax4_fused // 4)
                        ax4 = T.axis.spatial(4, ax3_ax4_fused % 4)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3, ax4])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[4, 1, 1, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 104, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 16, 1, 13])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 2, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[4, 4])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, l73, l74, l75, l76, l77)
sch.parallel(loop=l94)
l95 = sch.fuse(l93)
sch.vectorize(loop=l95)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b67)
l102 = sch.fuse(l100, l101)
sch.vectorize(loop=l102)
sch.annotate(block_or_loop=l96, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l96, ann_key="pragma_unroll_explicit", ann_val=1)
b103 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b103)
b121 = sch.decompose_reduction(block=b103, loop=l105)
[00:58:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #5: GFLOPs: 5.6344. Time: 71.2570 ms. Best GFLOPs: 13.0435
[00:58:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #6: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4, 210, 210, 4), "float32"], placeholder_1: T.Buffer[(8, 4, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 8, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 8, 208, 208, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 8, 208, 208, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused in T.parallel(416, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i2_1, i3_1, i4_1 in T.grid(2, 1, 1):
                for i2_2_init, i3_2_init, i4_2_init, i1_3_init, i2_3_init, i3_3_init in T.grid(2, 2, 2, 2, 2, 52):
                    with T.block("conv2d_NCHWc_init"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(8, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused % 4 * 2 + i1_3_init)
                        oh = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused // 16 * 8 + i2_1 * 4 + i2_2_init * 2 + i2_3_init)
                        ow = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused % 16 // 8 * 104 + i3_2_init * 52 + i3_3_init)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused % 8 // 4 * 2 + i4_2_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 4, 210, 210, 4], "float32"], ["TENSOR", [8, 4, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(16, 1, 1, 1, 1, 2, 2, 2, 1, 3, 3, 1, 2, 2, 52, 1):
                    with T.block("conv2d_NCHWc_update"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(8, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused % 4 * 2 + i1_3)
                        oh = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused // 16 * 8 + i2_1 * 4 + i2_2 * 2 + i2_3)
                        ow = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused % 16 // 8 * 104 + i3_2 * 52 + i3_3)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused % 8 // 4 * 2 + i4_2)
                        ic, kh, kw = T.axis.remap("RRR", [i5_0, i6_1, i7_1])
                        T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 4, 210, 210, 4], "float32"], ["TENSOR", [8, 4, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
        for i0_i1_i2_fused in T.parallel(1664, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3 in T.serial(208):
                for i4_fused in T.vectorized(4):
                    with T.block("T_leaky_relu"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(8, i0_i1_i2_fused // 208)
                        ax2 = T.axis.spatial(208, i0_i1_i2_fused % 208)
                        ax3, ax4 = T.axis.remap("SS", [i3, i4_fused])
                        T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                        T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 4, 1, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[26, 2, 2, 2])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 2, 52])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 2, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[16, 1])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
sch.enter_postproc()
b64 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.unroll_explicit")
b65, b66 = sch.get_child_blocks(b64)
l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b65)
l93 = sch.fuse(l67, l68, l69, l70, l71, l72, l73)
sch.parallel(loop=l93)
sch.annotate(block_or_loop=l93, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l93, ann_key="pragma_unroll_explicit", ann_val=1)
l94, l95, l96, l97, l98 = sch.get_loops(block=b66)
l99 = sch.fuse(l94, l95, l96)
sch.parallel(loop=l99)
l100 = sch.fuse(l98)
sch.vectorize(loop=l100)
sch.annotate(block_or_loop=l99, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l99, ann_key="pragma_unroll_explicit", ann_val=1)
b101 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121 = sch.get_loops(block=b101)
b122 = sch.decompose_reduction(block=b101, loop=l106)
[00:59:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #7: GFLOPs: 12.8602. Time: 31.2196 ms. Best GFLOPs: 13.0435
[00:59:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #8: GFLOPs: 6.8829. Time: 58.3317 ms. Best GFLOPs: 13.0435
[00:59:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #9: GFLOPs: 3.8506. Time: 104.2665 ms. Best GFLOPs: 13.0435
[00:59:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #10: GFLOPs: 2.8417. Time: 141.2870 ms. Best GFLOPs: 13.0435
[00:59:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #11: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4, 210, 210, 4), "float32"], placeholder_1: T.Buffer[(8, 4, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 8, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 8, 208, 208, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 8, 208, 208, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_fused in T.parallel(52, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 2, 1, 2, 2):
                for i2_2_init, i3_2_init, i1_3_init, i2_3_init in T.grid(8, 52, 4, 2):
                    with T.block("conv2d_NCHWc_init"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(8, i1_1 * 4 + i1_3_init)
                        oh = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 4 * 16 + i2_2_init * 2 + i2_3_init)
                        ow = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 4 // 2 * 104 + i3_1 * 52 + i3_2_init)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 2 * 2 + i4_1)
                        T.reads()
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 4, 210, 210, 4], "float32"], ["TENSOR", [8, 4, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(2, 3, 3, 1, 1, 8, 52, 1, 8, 1, 1, 1, 4, 2, 1, 1):
                    with T.block("conv2d_NCHWc_update"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(8, i1_1 * 4 + i1_3)
                        oh = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 4 * 16 + i2_2 * 2 + i2_3)
                        ow = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 4 // 2 * 104 + i3_1 * 52 + i3_2)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 2 * 2 + i4_1)
                        ic = T.axis.reduce(16, i5_0 * 8 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_0, i7_0])
                        T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 4, 210, 210, 4], "float32"], ["TENSOR", [8, 4, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(1, 8, 16, 104):
                for ax4_fused in T.vectorized(2):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1 = T.axis.spatial(8, ax1)
                        ax2_1 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 4 * 16 + ax2)
                        ax3_1 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 4 // 2 * 104 + ax3)
                        ax4 = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 2 * 2 + ax4_fused)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 2, 1, 4])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[13, 1, 8, 2])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 52, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 2, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[2, 8])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b67)
l101 = sch.fuse(l100)
sch.vectorize(loop=l101)
sch.annotate(block_or_loop=l95, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l95, ann_key="pragma_unroll_explicit", ann_val=1)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b102)
b125 = sch.decompose_reduction(block=b102, loop=l109)
[00:59:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #12: GFLOPs: 5.1176. Time: 78.4531 ms. Best GFLOPs: 13.0435
[00:59:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #13: GFLOPs: 2.8964. Time: 138.6145 ms. Best GFLOPs: 13.0435
[00:59:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #14: GFLOPs: 5.3443. Time: 75.1243 ms. Best GFLOPs: 13.0435
[00:59:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #15: GFLOPs: 8.7977. Time: 45.6356 ms. Best GFLOPs: 13.0435
[00:59:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #16: GFLOPs: 6.0667. Time: 66.1798 ms. Best GFLOPs: 13.0435
[00:59:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #17: GFLOPs: 1.6446. Time: 244.1313 ms. Best GFLOPs: 13.0435
[00:59:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #18: GFLOPs: 4.6397. Time: 86.5342 ms. Best GFLOPs: 13.0435
[00:59:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #19: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4, 210, 210, 4), "float32"], placeholder_1: T.Buffer[(8, 4, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 8, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 8, 208, 208, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 8, 208, 208, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_fused in T.parallel(13, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 1, 16, 2, 1):
                for i1_2_init, i2_2_init, i3_2_init, i1_3_init in T.grid(2, 13, 8, 4):
                    for i2_3_i3_3_i4_3_fused_init in T.vectorized(4):
                        with T.block("conv2d_NCHWc_init"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(8, i1_2_init * 4 + i1_3_init)
                            oh = T.axis.spatial(208, i2_1 * 13 + i2_2_init)
                            ow = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_fused * 16 + i3_1 * 8 + i3_2_init)
                            oc_block = T.axis.spatial(4, i2_3_i3_3_i4_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 4, 210, 210, 4], "float32"], ["TENSOR", [8, 4, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3 in T.grid(4, 1, 3, 1, 2, 13, 8, 1, 4, 3, 1, 1, 4):
                    for i2_3_i3_3_i4_3_fused in T.vectorized(4):
                        with T.block("conv2d_NCHWc_update"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(8, i1_2 * 4 + i1_3)
                            oh = T.axis.spatial(208, i2_1 * 13 + i2_2)
                            ow = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_fused * 16 + i3_1 * 8 + i3_2)
                            oc_block = T.axis.spatial(4, i2_3_i3_3_i4_3_fused)
                            ic = T.axis.reduce(16, i5_0 * 4 + i5_1)
                            kh, kw = T.axis.remap("RR", [i6_1, i7_0])
                            T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 4, 210, 210, 4], "float32"], ["TENSOR", [8, 4, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
            for ax0, ax1, ax2 in T.grid(1, 8, 208):
                for ax3_ax4_fused in T.vectorized(64):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1, ax2_1 = T.axis.remap("SS", [ax1, ax2])
                        ax3 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_fused * 16 + ax3_ax4_fused // 4)
                        ax4 = T.axis.spatial(4, ax3_ax4_fused % 4)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3, ax4])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 2, 4])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 16, 13, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[13, 2, 8, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[4, 4])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72)
sch.parallel(loop=l94)
l95 = sch.fuse(l91, l92, l93)
sch.vectorize(loop=l95)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b67)
l102 = sch.fuse(l100, l101)
sch.vectorize(loop=l102)
sch.annotate(block_or_loop=l96, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l96, ann_key="pragma_unroll_explicit", ann_val=1)
b103 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123 = sch.get_loops(block=b103)
b124 = sch.decompose_reduction(block=b103, loop=l110)
[00:59:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #20: GFLOPs: 3.7291. Time: 107.6654 ms. Best GFLOPs: 13.0435
[00:59:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #21: GFLOPs: 5.7693. Time: 69.5910 ms. Best GFLOPs: 13.0435
[00:59:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #22: GFLOPs: 2.6637. Time: 150.7292 ms. Best GFLOPs: 13.0435
[00:59:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #23: GFLOPs: 4.2064. Time: 95.4479 ms. Best GFLOPs: 13.0435
[00:59:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #24: GFLOPs: 2.6649. Time: 150.6560 ms. Best GFLOPs: 13.0435
[00:59:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #25: GFLOPs: 3.5892. Time: 111.8593 ms. Best GFLOPs: 13.0435
[00:59:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #26: GFLOPs: 3.2037. Time: 125.3215 ms. Best GFLOPs: 13.0435
[00:59:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #27: GFLOPs: 4.8305. Time: 83.1162 ms. Best GFLOPs: 13.0435
[00:59:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #28: GFLOPs: 4.5303. Time: 88.6231 ms. Best GFLOPs: 13.0435
[00:59:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #29: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4, 210, 210, 4), "float32"], placeholder_1: T.Buffer[(8, 4, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 8, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 8, 208, 208, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 8, 208, 208, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused in T.parallel(416, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3_1, i4_1 in T.grid(1, 1):
                for i2_2_init, i3_2_init, i4_2_init, i1_3_init, i3_3_init in T.grid(26, 4, 2, 8, 2):
                    with T.block("conv2d_NCHWc_init"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(8, i1_3_init)
                        oh = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused // 208 * 104 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 4 * 26 + i2_2_init)
                        ow = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 208 // 8 * 8 + i3_2_init * 2 + i3_3_init)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 8 // 4 * 2 + i4_2_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 4, 210, 210, 4], "float32"], ["TENSOR", [8, 4, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(16, 3, 3, 1, 1, 26, 4, 2, 1, 1, 1, 1, 8, 1, 2, 1):
                    with T.block("conv2d_NCHWc_update"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(8, i1_3)
                        oh = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused // 208 * 104 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 4 * 26 + i2_2)
                        ow = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 208 // 8 * 8 + i3_2 * 2 + i3_3)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 8 // 4 * 2 + i4_2)
                        ic, kh, kw = T.axis.remap("RRR", [i5_0, i6_0, i7_0])
                        T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 4, 210, 210, 4], "float32"], ["TENSOR", [8, 4, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(1, 8, 26, 8):
                    for ax4_fused in T.vectorized(2):
                        with T.block("T_leaky_relu"):
                            ax0_1 = T.axis.spatial(1, 0)
                            ax1_1 = T.axis.spatial(8, ax1)
                            ax2_1 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused // 208 * 104 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 4 * 26 + ax2)
                            ax3_1 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 208 // 8 * 8 + ax3)
                            ax4 = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 8 // 4 * 2 + ax4_fused)
                            T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                            T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4])
                            T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 8])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 4, 26, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[26, 1, 4, 2])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 2, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[16, 1])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, l73, l74, l75)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b67)
l103 = sch.fuse(l102)
sch.vectorize(loop=l103)
sch.annotate(block_or_loop=l95, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l95, ann_key="pragma_unroll_explicit", ann_val=1)
b104 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123 = sch.get_loops(block=b104)
b124 = sch.decompose_reduction(block=b104, loop=l108)
[00:59:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #30: GFLOPs: 6.1464. Time: 65.3209 ms. Best GFLOPs: 13.0435
[00:59:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"] Trial #31: GFLOPs: 4.3875. Time: 91.5066 ms. Best GFLOPs: 13.0435
[00:59:18] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 112
Total latency (us): 39752.6

[00:59:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_pad_2"] Trial #0: GFLOPs: 0.0000. Time: 5.2312 ms. Best GFLOPs: 0.0000
[00:59:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_pad_2"] Trial #1: GFLOPs: 0.0000. Time: 8.0001 ms. Best GFLOPs: 0.0000
[00:59:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #6: "fused_nn_pad_2"] Trial #2: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 8, 208, 208, 4), "float32"], T_pad: T.Buffer[(1, 8, 208, 208, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        for i0_i1_i2_fused in T.parallel(1664, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3 in T.serial(208):
                for i4_fused in T.vectorized(4):
                    with T.block("T_pad"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(8, i0_i1_i2_fused // 208)
                        ax2 = T.axis.spatial(208, i0_i1_i2_fused % 208)
                        ax3, ax4 = T.axis.remap("SS", [i3, i4_fused])
                        T.reads(placeholder[ax0, ax1, ax2, ax3, ax4])
                        T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                        T_pad[ax0, ax1, ax2, ax3, ax4] = placeholder[ax0, ax1, ax2, ax3, ax4]
    

b0 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.vectorize", ann_val=64)
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
sch.enter_postproc()
b2 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit")
b3, = sch.get_child_blocks(b2)
l4, l5, l6, l7, l8 = sch.get_loops(block=b3)
l9 = sch.fuse(l4, l5, l6)
sch.parallel(loop=l9)
l10 = sch.fuse(l8)
sch.vectorize(loop=l10)
sch.annotate(block_or_loop=l9, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l9, ann_key="pragma_unroll_explicit", ann_val=1)
[00:59:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_pad_2"] Trial #3: GFLOPs: 0.0000. Time: 6.2924 ms. Best GFLOPs: 0.0000
[00:59:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_pad_2"] Trial #4: GFLOPs: 0.0000. Time: 8.4686 ms. Best GFLOPs: 0.0000
[00:59:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #6: "fused_nn_pad_2"] Trial #5: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 8, 208, 208, 4), "float32"], T_pad: T.Buffer[(1, 8, 208, 208, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        for i0_i1_fused in T.parallel(8, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i2, i3 in T.grid(208, 208):
                for i4_fused in T.vectorized(4):
                    with T.block("T_pad"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1, ax2, ax3, ax4 = T.axis.remap("SSSS", [i0_i1_fused, i2, i3, i4_fused])
                        T.reads(placeholder[ax0, ax1, ax2, ax3, ax4])
                        T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                        T_pad[ax0, ax1, ax2, ax3, ax4] = placeholder[ax0, ax1, ax2, ax3, ax4]
    

b0 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.parallel", ann_val=1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.vectorize", ann_val=64)
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
sch.enter_postproc()
b2 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit")
b3, = sch.get_child_blocks(b2)
l4, l5, l6, l7, l8 = sch.get_loops(block=b3)
l9 = sch.fuse(l4, l5)
sch.parallel(loop=l9)
l10 = sch.fuse(l8)
sch.vectorize(loop=l10)
sch.annotate(block_or_loop=l9, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l9, ann_key="pragma_unroll_explicit", ann_val=1)
[00:59:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_pad_2"] Trial #6: GFLOPs: 0.0000. Time: 6.1982 ms. Best GFLOPs: 0.0000
[00:59:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_pad_2"] Trial #7: GFLOPs: 0.0000. Time: 5.1187 ms. Best GFLOPs: 0.0000
[00:59:54] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #6: "fused_nn_pad_2"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 120
Total latency (us): 44871.3

[00:59:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #0: GFLOPs: 0.1531. Time: 9.0407 ms. Best GFLOPs: 0.1531
[00:59:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #1: GFLOPs: 0.2984. Time: 4.6394 ms. Best GFLOPs: 0.2984
[00:59:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #2: GFLOPs: 0.2335. Time: 5.9296 ms. Best GFLOPs: 0.2984
[00:59:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #3: GFLOPs: 0.1236. Time: 11.1992 ms. Best GFLOPs: 0.2984
[00:59:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #4: GFLOPs: 0.2681. Time: 5.1648 ms. Best GFLOPs: 0.2984
[00:59:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #5: GFLOPs: 0.1882. Time: 7.3578 ms. Best GFLOPs: 0.2984
[00:59:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #6: GFLOPs: 0.2886. Time: 4.7969 ms. Best GFLOPs: 0.2984
[00:59:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #7: GFLOPs: 0.1239. Time: 11.1728 ms. Best GFLOPs: 0.2984
[01:00:18] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #7: "fused_nn_max_pool2d_1"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 128
Total latency (us): 49510.7

[01:00:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_nn_pad_3"] Trial #0: GFLOPs: 0.0000. Time: 4.1540 ms. Best GFLOPs: 0.0000
[01:00:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_nn_pad_3"] Trial #1: GFLOPs: 0.0000. Time: 4.4776 ms. Best GFLOPs: 0.0000
[01:00:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_nn_pad_3"] Trial #2: GFLOPs: 0.0000. Time: 9.2498 ms. Best GFLOPs: 0.0000
[01:00:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_nn_pad_3"] Trial #3: GFLOPs: 0.0000. Time: 3.9955 ms. Best GFLOPs: 0.0000
[01:00:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_nn_pad_3"] Trial #4: GFLOPs: 0.0000. Time: 7.8875 ms. Best GFLOPs: 0.0000
[01:00:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_nn_pad_3"] Trial #5: GFLOPs: 0.0000. Time: 38.6539 ms. Best GFLOPs: 0.0000
[01:00:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_nn_pad_3"] Trial #6: GFLOPs: 0.0000. Time: 11.4985 ms. Best GFLOPs: 0.0000
[01:00:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_nn_pad_3"] Trial #7: GFLOPs: 0.0000. Time: 5.8940 ms. Best GFLOPs: 0.0000
[01:00:48] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #8: "fused_nn_pad_3"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 136
Total latency (us): 53506.2

[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #0: GFLOPs: 11.4790. Time: 34.8554 ms. Best GFLOPs: 11.4790
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #1: GFLOPs: 4.2882. Time: 93.3044 ms. Best GFLOPs: 11.4790
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #2: GFLOPs: 4.3108. Time: 92.8157 ms. Best GFLOPs: 11.4790
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #3: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 8, 106, 106, 4), "float32"], placeholder_1: T.Buffer[(16, 8, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 16, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 16, 104, 104, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 16, 104, 104, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused in T.parallel(416, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3_1, i4_1 in T.grid(8, 1):
                for i1_2_init, i3_2_init, i2_3_init in T.grid(2, 13, 2):
                    for i3_3_i4_3_fused_init in T.vectorized(4):
                        with T.block("conv2d_NCHWc_init"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused // 208 * 8 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 208 // 52 * 2 + i1_2_init)
                            oh = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 52 * 2 + i2_3_init)
                            ow = T.axis.spatial(104, i3_1 * 13 + i3_2_init)
                            oc_block = T.axis.spatial(4, i3_3_i4_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 106, 106, 4], "float32"], ["TENSOR", [16, 8, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3 in T.grid(32, 1, 3, 1, 2, 1, 13, 1, 1, 3, 1, 1, 1, 2):
                    for i3_3_i4_3_fused in T.vectorized(4):
                        with T.block("conv2d_NCHWc_update"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused // 208 * 8 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 208 // 52 * 2 + i1_2)
                            oh = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 52 * 2 + i2_3)
                            ow = T.axis.spatial(104, i3_1 * 13 + i3_2)
                            oc_block, ic, kh, kw = T.axis.remap("SRRR", [i3_3_i4_3_fused, i5_0, i6_1, i7_0])
                            T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 106, 106, 4], "float32"], ["TENSOR", [16, 8, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
        for i0_i1_i2_fused in T.parallel(1664, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3 in T.serial(104):
                for i4_fused in T.vectorized(4):
                    with T.block("T_leaky_relu"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(16, i0_i1_i2_fused // 104)
                        ax2 = T.axis.spatial(104, i0_i1_i2_fused % 104)
                        ax3, ax4 = T.axis.remap("SS", [i3, i4_fused])
                        T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                        T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[2, 4, 2, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 52, 1, 2])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 13, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[32, 1])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
sch.enter_postproc()
b64 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.unroll_explicit")
b65, b66 = sch.get_child_blocks(b64)
l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b65)
l93 = sch.fuse(l67, l68, l69, l70, l71, l72, l73, l74)
sch.parallel(loop=l93)
l94 = sch.fuse(l91, l92)
sch.vectorize(loop=l94)
sch.annotate(block_or_loop=l93, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l93, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99 = sch.get_loops(block=b66)
l100 = sch.fuse(l95, l96, l97)
sch.parallel(loop=l100)
l101 = sch.fuse(l99)
sch.vectorize(loop=l101)
sch.annotate(block_or_loop=l100, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l100, ann_key="pragma_unroll_explicit", ann_val=1)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b102)
b121 = sch.decompose_reduction(block=b102, loop=l106)
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #4: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 8, 106, 106, 4), "float32"], placeholder_1: T.Buffer[(16, 8, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 16, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 16, 104, 104, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 16, 104, 104, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_fused in T.parallel(8, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 2, 2, 1, 1):
                for i1_2_init, i2_2_init, i3_2_init, i4_2_init, i2_3_init, i3_3_init in T.grid(2, 4, 13, 2, 13, 8):
                    with T.block("conv2d_NCHWc_init"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 2 * 4 + i1_1 * 2 + i1_2_init)
                        oh = T.axis.spatial(104, i2_1 * 52 + i2_2_init * 13 + i2_3_init)
                        ow = T.axis.spatial(104, i3_2_init * 8 + i3_3_init)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 2 * 2 + i4_2_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 106, 106, 4], "float32"], ["TENSOR", [16, 8, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(8, 1, 1, 1, 2, 4, 13, 2, 4, 3, 3, 1, 1, 13, 8, 1):
                    with T.block("conv2d_NCHWc_update"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 2 * 4 + i1_1 * 2 + i1_2)
                        oh = T.axis.spatial(104, i2_1 * 52 + i2_2 * 13 + i2_3)
                        ow = T.axis.spatial(104, i3_2 * 8 + i3_3)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 2 * 2 + i4_2)
                        ic = T.axis.reduce(32, i5_0 * 4 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_1, i7_1])
                        T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 106, 106, 4], "float32"], ["TENSOR", [16, 8, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(1, 4, 104, 104):
                for ax4_fused in T.vectorized(2):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1 = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 2 * 4 + ax1)
                        ax2_1, ax3_1 = T.axis.remap("SS", [ax2, ax3])
                        ax4 = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 2 * 2 + ax4_fused)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[4, 2, 2, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 4, 13])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 8])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 2, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[8, 4])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b67)
l101 = sch.fuse(l100)
sch.vectorize(loop=l101)
sch.annotate(block_or_loop=l95, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l95, ann_key="pragma_unroll_explicit", ann_val=1)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b102)
b125 = sch.decompose_reduction(block=b102, loop=l109)
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #5: GFLOPs: 1.0863. Time: 368.3316 ms. Best GFLOPs: 11.4790
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #6: GFLOPs: 8.3470. Time: 47.9340 ms. Best GFLOPs: 11.4790
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #7: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 8, 106, 106, 4), "float32"], placeholder_1: T.Buffer[(16, 8, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 16, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 16, 104, 104, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 16, 104, 104, 4], dtype="float32")
        for i0_0 in T.serial(1, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i1_0, i2_0, i3_0, i4_0 in T.grid(1, 1, 1, 1):
                for i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 1, 52, 4, 1):
                    for i1_2_init, i4_2_init, i2_3_init, i3_3_init in T.grid(16, 4, 2, 26):
                        with T.block("conv2d_NCHWc_init"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(16, i1_2_init)
                            oh = T.axis.spatial(104, i2_1 * 2 + i2_3_init)
                            ow = T.axis.spatial(104, i3_1 * 26 + i3_3_init)
                            oc_block = T.axis.spatial(4, i4_2_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 106, 106, 4], "float32"], ["TENSOR", [16, 8, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                    for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(8, 1, 3, 1, 16, 1, 1, 4, 4, 3, 1, 1, 1, 2, 26, 1):
                        with T.block("conv2d_NCHWc_update"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(16, i1_2)
                            oh = T.axis.spatial(104, i2_1 * 2 + i2_3)
                            ow = T.axis.spatial(104, i3_1 * 26 + i3_3)
                            oc_block = T.axis.spatial(4, i4_2)
                            ic = T.axis.reduce(32, i5_0 * 4 + i5_1)
                            kh, kw = T.axis.remap("RR", [i6_1, i7_0])
                            T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 106, 106, 4], "float32"], ["TENSOR", [16, 8, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(1, 16, 104, 104):
                    for ax4_fused in T.vectorized(4):
                        with T.block("T_leaky_relu"):
                            ax0_1 = T.axis.spatial(1, 0)
                            ax1_1, ax2_1, ax3_1, ax4 = T.axis.remap("SSSS", [ax1, ax2, ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                            T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4])
                            T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 52, 1, 2])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 1, 26])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 4, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[8, 4])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
sch.annotate(block_or_loop=l68, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l68, ann_key="pragma_unroll_explicit", ann_val=1)
l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b67)
l104 = sch.fuse(l103)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
b105 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b105)
b132 = sch.decompose_reduction(block=b105, loop=l116)
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #8: GFLOPs: 4.2870. Time: 93.3290 ms. Best GFLOPs: 11.4790
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #9: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 8, 106, 106, 4), "float32"], placeholder_1: T.Buffer[(16, 8, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 16, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 16, 104, 104, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 16, 104, 104, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused in T.parallel(256, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i4_1 in T.serial(1):
                for i3_2_init, i1_3_init, i2_3_init in T.grid(13, 2, 52):
                    for i3_3_i4_3_fused_init in T.vectorized(2):
                        with T.block("conv2d_NCHWc_init"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 128 // 16 * 2 + i1_3_init)
                            oh = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 16 // 8 * 52 + i2_3_init)
                            ow = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 8 * 13 + i3_2_init)
                            oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused // 128 * 2 + i3_3_i4_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 106, 106, 4], "float32"], ["TENSOR", [16, 8, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3 in T.grid(2, 3, 3, 1, 1, 1, 13, 1, 16, 1, 1, 1, 2, 52):
                    for i3_3_i4_3_fused in T.vectorized(2):
                        with T.block("conv2d_NCHWc_update"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 128 // 16 * 2 + i1_3)
                            oh = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 16 // 8 * 52 + i2_3)
                            ow = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 8 * 13 + i3_2)
                            oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused // 128 * 2 + i3_3_i4_3_fused)
                            ic = T.axis.reduce(32, i5_0 * 16 + i5_1)
                            kh, kw = T.axis.remap("RR", [i6_0, i7_0])
                            T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 106, 106, 4], "float32"], ["TENSOR", [16, 8, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
        for i0_i1_i2_fused in T.parallel(1664, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3 in T.serial(104):
                for i4_fused in T.vectorized(4):
                    with T.block("T_leaky_relu"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(16, i0_i1_i2_fused // 104)
                        ax2 = T.axis.spatial(104, i0_i1_i2_fused % 104)
                        ax3, ax4 = T.axis.remap("SS", [i3, i4_fused])
                        T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                        T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 8, 1, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 52])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 13, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[2, 16])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
sch.enter_postproc()
b64 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.unroll_explicit")
b65, b66 = sch.get_child_blocks(b64)
l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b65)
l93 = sch.fuse(l67, l68, l69, l70, l71, l72, l73, l74, l75)
sch.parallel(loop=l93)
l94 = sch.fuse(l91, l92)
sch.vectorize(loop=l94)
sch.annotate(block_or_loop=l93, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l93, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99 = sch.get_loops(block=b66)
l100 = sch.fuse(l95, l96, l97)
sch.parallel(loop=l100)
l101 = sch.fuse(l99)
sch.vectorize(loop=l101)
sch.annotate(block_or_loop=l100, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l100, ann_key="pragma_unroll_explicit", ann_val=1)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b102)
b120 = sch.decompose_reduction(block=b102, loop=l105)
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #10: GFLOPs: 3.0342. Time: 131.8634 ms. Best GFLOPs: 11.4790
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #11: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 8, 106, 106, 4), "float32"], placeholder_1: T.Buffer[(16, 8, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 16, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 16, 104, 104, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 16, 104, 104, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_fused in T.parallel(8, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 2, 13, 1, 2):
                for i1_2_init, i2_2_init, i2_3_init, i3_3_init in T.grid(8, 2, 4, 26):
                    with T.block("conv2d_NCHWc_init"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(16, i1_1 * 8 + i1_2_init)
                        oh = T.axis.spatial(104, i2_1 * 8 + i2_2_init * 4 + i2_3_init)
                        ow = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 2 * 26 + i3_3_init)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 2 * 2 + i4_1)
                        T.reads()
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 106, 106, 4], "float32"], ["TENSOR", [16, 8, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(16, 1, 1, 1, 8, 2, 1, 1, 2, 3, 3, 1, 1, 4, 26, 1):
                    with T.block("conv2d_NCHWc_update"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(16, i1_1 * 8 + i1_2)
                        oh = T.axis.spatial(104, i2_1 * 8 + i2_2 * 4 + i2_3)
                        ow = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 2 * 26 + i3_3)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 2 * 2 + i4_1)
                        ic = T.axis.reduce(32, i5_0 * 2 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_1, i7_1])
                        T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 106, 106, 4], "float32"], ["TENSOR", [16, 8, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(1, 16, 104, 26):
                for ax4_fused in T.vectorized(2):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1, ax2_1 = T.axis.remap("SS", [ax1, ax2])
                        ax3_1 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 2 * 26 + ax3)
                        ax4 = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 2 * 2 + ax4_fused)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 2, 8, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 13, 2, 4])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 1, 26])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 2, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[16, 2])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b67)
l101 = sch.fuse(l100)
sch.vectorize(loop=l101)
sch.annotate(block_or_loop=l95, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l95, ann_key="pragma_unroll_explicit", ann_val=1)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b102)
b125 = sch.decompose_reduction(block=b102, loop=l109)
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #12: GFLOPs: 1.7349. Time: 230.6207 ms. Best GFLOPs: 11.4790
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #13: GFLOPs: 5.7625. Time: 69.4326 ms. Best GFLOPs: 11.4790
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #14: GFLOPs: 3.4385. Time: 116.3620 ms. Best GFLOPs: 11.4790
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #15: GFLOPs: 8.8282. Time: 45.3214 ms. Best GFLOPs: 11.4790
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #16: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 8, 106, 106, 4), "float32"], placeholder_1: T.Buffer[(16, 8, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 16, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 16, 104, 104, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 16, 104, 104, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_fused in T.parallel(208, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1, i1_1, i2_1, i3_1, i4_1, i5_0, i6_0 in T.grid(1, 4, 1, 26, 1, 1, 1):
                for i1_2_init, i3_2_init, i4_2_init, i2_3_init in T.grid(4, 2, 2, 2):
                    with T.block("conv2d_NCHWc_init"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(16, i1_1 * 4 + i1_2_init)
                        oh = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 4 * 2 + i2_3_init)
                        ow = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 4 // 2 * 52 + i3_1 * 2 + i3_2_init)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 2 * 2 + i4_2_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 106, 106, 4], "float32"], ["TENSOR", [16, 8, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(3, 1, 4, 1, 2, 2, 32, 3, 1, 1, 1, 2, 1, 1):
                    with T.block("conv2d_NCHWc_update"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(16, i1_1 * 4 + i1_2)
                        oh = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 4 * 2 + i2_3)
                        ow = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 4 // 2 * 52 + i3_1 * 2 + i3_2)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 2 * 2 + i4_2)
                        ic, kh, kw = T.axis.remap("RRR", [i5_1, i6_1, i7_0])
                        T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 106, 106, 4], "float32"], ["TENSOR", [16, 8, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
        for i0_i1_i2_fused in T.parallel(1664, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3 in T.serial(104):
                for i4_fused in T.vectorized(4):
                    with T.block("T_leaky_relu"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(16, i0_i1_i2_fused // 104)
                        ax2 = T.axis.spatial(104, i0_i1_i2_fused % 104)
                        ax3, ax4 = T.axis.remap("SS", [i3, i4_fused])
                        T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                        T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 4, 4, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[52, 1, 1, 2])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 26, 2, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 2, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 32])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
sch.enter_postproc()
b64 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.unroll_explicit")
b65, b66 = sch.get_child_blocks(b64)
l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b65)
l93 = sch.fuse(l67, l68, l69, l70, l71)
sch.parallel(loop=l93)
sch.annotate(block_or_loop=l93, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l93, ann_key="pragma_unroll_explicit", ann_val=1)
l94, l95, l96, l97, l98 = sch.get_loops(block=b66)
l99 = sch.fuse(l94, l95, l96)
sch.parallel(loop=l99)
l100 = sch.fuse(l98)
sch.vectorize(loop=l100)
sch.annotate(block_or_loop=l99, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l99, ann_key="pragma_unroll_explicit", ann_val=1)
b101 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123 = sch.get_loops(block=b101)
b124 = sch.decompose_reduction(block=b101, loop=l110)
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #17: GFLOPs: 10.7219. Time: 37.3166 ms. Best GFLOPs: 11.4790
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #18: GFLOPs: 2.7283. Time: 146.6489 ms. Best GFLOPs: 11.4790
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #19: GFLOPs: 7.8994. Time: 50.6501 ms. Best GFLOPs: 11.4790
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #20: GFLOPs: 7.6652. Time: 52.1974 ms. Best GFLOPs: 11.4790
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #21: GFLOPs: 6.0026. Time: 66.6553 ms. Best GFLOPs: 11.4790
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #22: GFLOPs: 5.1690. Time: 77.4048 ms. Best GFLOPs: 11.4790
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #23: GFLOPs: 7.8000. Time: 51.2956 ms. Best GFLOPs: 11.4790
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #24: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 8, 106, 106, 4), "float32"], placeholder_1: T.Buffer[(16, 8, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 16, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 16, 104, 104, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 16, 104, 104, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused in T.parallel(208, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i1_2_init, i2_2_init, i3_2_init, i1_3_init, i3_3_init in T.grid(8, 4, 2, 2, 26):
                with T.block("conv2d_NCHWc_init"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(16, i1_2_init * 2 + i1_3_init)
                    oh = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 8 * 4 + i2_2_init)
                    ow = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 8 // 4 * 52 + i3_2_init * 26 + i3_3_init)
                    oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 4 // 2 * 2 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 2)
                    T.reads()
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 106, 106, 4], "float32"], ["TENSOR", [16, 8, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
            for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(2, 3, 3, 1, 8, 4, 2, 1, 16, 1, 1, 1, 2, 1, 26, 1):
                with T.block("conv2d_NCHWc_update"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(16, i1_2 * 2 + i1_3)
                    oh = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 8 * 4 + i2_2)
                    ow = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 8 // 4 * 52 + i3_2 * 26 + i3_3)
                    oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 4 // 2 * 2 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 2)
                    ic = T.axis.reduce(32, i5_0 * 16 + i5_1)
                    kh, kw = T.axis.remap("RR", [i6_0, i7_0])
                    T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 106, 106, 4], "float32"], ["TENSOR", [16, 8, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 16, 4, 52, 1):
                with T.block("T_leaky_relu"):
                    ax0_1 = T.axis.spatial(1, 0)
                    ax1_1 = T.axis.spatial(16, ax1)
                    ax2_1 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 8 * 4 + ax2)
                    ax3_1 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 8 // 4 * 52 + ax3)
                    ax4_1 = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 4 // 2 * 2 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 2)
                    T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1])
                    T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                    T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 8, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[26, 1, 4, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 2, 26])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 2, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[2, 16])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, l73, l74, l75, l76, l77)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b67)
sch.annotate(block_or_loop=l95, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l95, ann_key="pragma_unroll_explicit", ann_val=1)
b101 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b101)
b119 = sch.decompose_reduction(block=b101, loop=l103)
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #25: GFLOPs: 4.8589. Time: 82.3450 ms. Best GFLOPs: 11.4790
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #26: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 8, 106, 106, 4), "float32"], placeholder_1: T.Buffer[(16, 8, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 16, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 16, 104, 104, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 16, 104, 104, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused in T.parallel(104, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i1_2_init, i3_2_init, i4_2_init, i2_3_init, i3_3_init in T.grid(16, 2, 4, 26, 2):
                with T.block("conv2d_NCHWc_init"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(16, i1_2_init)
                    oh = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 26 * 26 + i2_3_init)
                    ow = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 26 // 13 * 52 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 13 * 4 + i3_2_init * 2 + i3_3_init)
                    oc_block = T.axis.spatial(4, i4_2_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 106, 106, 4], "float32"], ["TENSOR", [16, 8, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
            for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(32, 1, 1, 1, 16, 1, 2, 4, 1, 3, 3, 1, 1, 26, 2, 1):
                with T.block("conv2d_NCHWc_update"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(16, i1_2)
                    oh = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 26 * 26 + i2_3)
                    ow = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 26 // 13 * 52 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 13 * 4 + i3_2 * 2 + i3_3)
                    oc_block, ic, kh, kw = T.axis.remap("SRRR", [i4_2, i5_0, i6_1, i7_1])
                    T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 106, 106, 4], "float32"], ["TENSOR", [16, 8, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
        for i0_i1_i2_fused in T.parallel(1664, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3 in T.serial(104):
                for i4_fused in T.vectorized(4):
                    with T.block("T_leaky_relu"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(16, i0_i1_i2_fused // 104)
                        ax2 = T.axis.spatial(104, i0_i1_i2_fused % 104)
                        ax3, ax4 = T.axis.remap("SS", [i3, i4_fused])
                        T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                        T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 1, 26])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 13, 2, 2])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 4, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[32, 1])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
sch.enter_postproc()
b64 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.unroll_explicit")
b65, b66 = sch.get_child_blocks(b64)
l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b65)
l93 = sch.fuse(l67, l68, l69, l70, l71, l72, l73, l74, l75, l76)
sch.parallel(loop=l93)
sch.annotate(block_or_loop=l93, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l93, ann_key="pragma_unroll_explicit", ann_val=1)
l94, l95, l96, l97, l98 = sch.get_loops(block=b66)
l99 = sch.fuse(l94, l95, l96)
sch.parallel(loop=l99)
l100 = sch.fuse(l98)
sch.vectorize(loop=l100)
sch.annotate(block_or_loop=l99, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l99, ann_key="pragma_unroll_explicit", ann_val=1)
b101 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b101)
b119 = sch.decompose_reduction(block=b101, loop=l103)
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #27: GFLOPs: 3.6598. Time: 109.3239 ms. Best GFLOPs: 11.4790
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #28: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 8, 106, 106, 4), "float32"], placeholder_1: T.Buffer[(16, 8, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 16, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 16, 104, 104, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 16, 104, 104, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused in T.parallel(104, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i1_2_init, i2_2_init, i3_3_init in T.grid(16, 52, 4):
                for i4_3_fused_init in T.vectorized(2):
                    with T.block("conv2d_NCHWc_init"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(16, i1_2_init)
                        oh = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 52 * 52 + i2_2_init)
                        ow = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 52 // 26 * 52 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 13 * 4 + i3_3_init)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 26 // 13 * 2 + i4_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 106, 106, 4], "float32"], ["TENSOR", [16, 8, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
            for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3 in T.grid(8, 1, 3, 1, 16, 52, 1, 1, 4, 3, 1, 1, 1, 1, 4):
                for i4_3_fused in T.vectorized(2):
                    with T.block("conv2d_NCHWc_update"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(16, i1_2)
                        oh = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 52 * 52 + i2_2)
                        ow = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 52 // 26 * 52 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 13 * 4 + i3_3)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 26 // 13 * 2 + i4_3_fused)
                        ic = T.axis.reduce(32, i5_0 * 4 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_1, i7_0])
                        T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 106, 106, 4], "float32"], ["TENSOR", [16, 8, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(1, 16, 52, 4):
                for ax4_fused in T.vectorized(2):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1 = T.axis.spatial(16, ax1)
                        ax2_1 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 52 * 52 + ax2)
                        ax3_1 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 52 // 26 * 52 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 13 * 4 + ax3)
                        ax4 = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 26 // 13 * 2 + ax4_fused)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 52, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 13, 1, 4])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[8, 4])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, l73, l74, l75, l76, l77)
sch.parallel(loop=l94)
l95 = sch.fuse(l93)
sch.vectorize(loop=l95)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b67)
l102 = sch.fuse(l101)
sch.vectorize(loop=l102)
sch.annotate(block_or_loop=l96, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l96, ann_key="pragma_unroll_explicit", ann_val=1)
b103 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b103)
b121 = sch.decompose_reduction(block=b103, loop=l105)
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #29: GFLOPs: 4.4132. Time: 90.6611 ms. Best GFLOPs: 11.4790
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #30: GFLOPs: 5.7568. Time: 69.5019 ms. Best GFLOPs: 11.4790
[01:00:51] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"] Trial #31: GFLOPs: 3.8611. Time: 103.6243 ms. Best GFLOPs: 11.4790
[01:01:13] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 168
Total latency (us): 88361.6

[01:01:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_pad_4"] Trial #0: GFLOPs: 0.0000. Time: 8.6127 ms. Best GFLOPs: 0.0000
[01:01:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_pad_4"] Trial #1: GFLOPs: 0.0000. Time: 8.9224 ms. Best GFLOPs: 0.0000
[01:01:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_pad_4"] Trial #2: GFLOPs: 0.0000. Time: 5.0421 ms. Best GFLOPs: 0.0000
[01:01:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_pad_4"] Trial #3: GFLOPs: 0.0000. Time: 4.1570 ms. Best GFLOPs: 0.0000
[01:01:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_pad_4"] Trial #4: GFLOPs: 0.0000. Time: 7.1587 ms. Best GFLOPs: 0.0000
[01:01:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_pad_4"] Trial #5: GFLOPs: 0.0000. Time: 5.5381 ms. Best GFLOPs: 0.0000
[01:01:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_pad_4"] Trial #6: GFLOPs: 0.0000. Time: 8.4602 ms. Best GFLOPs: 0.0000
[01:01:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_pad_4"] Trial #7: GFLOPs: 0.0000. Time: 5.4471 ms. Best GFLOPs: 0.0000
[01:01:43] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #10: "fused_nn_pad_4"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 176
Total latency (us): 92518.5

[01:01:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_max_pool2d_2"] Trial #0: GFLOPs: 0.1150. Time: 6.0199 ms. Best GFLOPs: 0.1150
[01:01:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_max_pool2d_2"] Trial #1: GFLOPs: 0.0980. Time: 7.0664 ms. Best GFLOPs: 0.1150
[01:01:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_max_pool2d_2"] Trial #2: GFLOPs: 0.1263. Time: 5.4803 ms. Best GFLOPs: 0.1263
[01:01:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_max_pool2d_2"] Trial #3: GFLOPs: 0.0815. Time: 8.4956 ms. Best GFLOPs: 0.1263
[01:01:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_max_pool2d_2"] Trial #4: GFLOPs: 0.2097. Time: 3.3011 ms. Best GFLOPs: 0.2097
[01:01:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_max_pool2d_2"] Trial #5: GFLOPs: 0.3323. Time: 2.0834 ms. Best GFLOPs: 0.3323
[01:01:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_max_pool2d_2"] Trial #6: GFLOPs: 0.0956. Time: 7.2371 ms. Best GFLOPs: 0.3323
[01:01:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_max_pool2d_2"] Trial #7: GFLOPs: 0.0989. Time: 6.9986 ms. Best GFLOPs: 0.3323
[01:02:13] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #11: "fused_nn_max_pool2d_2"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 184
Total latency (us): 94601.9

[01:02:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_pad_5"] Trial #0: GFLOPs: 0.0000. Time: 20.0090 ms. Best GFLOPs: 0.0000
[01:02:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_pad_5"] Trial #1: GFLOPs: 0.0000. Time: 19.0094 ms. Best GFLOPs: 0.0000
[01:02:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_pad_5"] Trial #2: GFLOPs: 0.0000. Time: 14.4771 ms. Best GFLOPs: 0.0000
[01:02:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_pad_5"] Trial #3: GFLOPs: 0.0000. Time: 45.3302 ms. Best GFLOPs: 0.0000
[01:02:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_pad_5"] Trial #4: GFLOPs: 0.0000. Time: 19.1089 ms. Best GFLOPs: 0.0000
[01:02:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_pad_5"] Trial #5: GFLOPs: 0.0000. Time: 19.9945 ms. Best GFLOPs: 0.0000
[01:02:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_pad_5"] Trial #6: GFLOPs: 0.0000. Time: 23.3829 ms. Best GFLOPs: 0.0000
[01:02:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_pad_5"] Trial #7: GFLOPs: 0.0000. Time: 17.8160 ms. Best GFLOPs: 0.0000
[01:02:53] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #12: "fused_nn_pad_5"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 192
Total latency (us): 109079

[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #0: GFLOPs: 3.7512. Time: 106.4767 ms. Best GFLOPs: 3.7512
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #1: GFLOPs: 4.7555. Time: 83.9897 ms. Best GFLOPs: 4.7555
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #2: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 54, 54, 4), "float32"], placeholder_1: T.Buffer[(32, 16, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 32, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 32, 52, 52, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 32, 52, 52, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused in T.parallel(256, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i2_1, i3_1, i4_1 in T.grid(26, 2, 1):
                for i3_2_init, i3_3_init in T.grid(13, 2):
                    with T.block("conv2d_NCHWc_init"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(32, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused // 16 * 2 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused % 2)
                        oh = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused % 16 // 8 * 26 + i2_1)
                        ow = T.axis.spatial(52, i3_1 * 26 + i3_2_init * 2 + i3_3_init)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused % 8 // 2)
                        T.reads()
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 16, 54, 54, 4], "float32"], ["TENSOR", [32, 16, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(4, 1, 3, 1, 1, 1, 13, 1, 16, 3, 1, 1, 1, 1, 2, 1):
                    with T.block("conv2d_NCHWc_update"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(32, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused // 16 * 2 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused % 2)
                        oh = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused % 16 // 8 * 26 + i2_1)
                        ow = T.axis.spatial(52, i3_1 * 26 + i3_2 * 2 + i3_3)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused % 8 // 2)
                        ic = T.axis.reduce(64, i5_0 * 16 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_1, i7_0])
                        T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 16, 54, 54, 4], "float32"], ["TENSOR", [32, 16, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
        for i0_i1_i2_fused in T.parallel(1664, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3 in T.serial(52):
                for i4_fused in T.vectorized(4):
                    with T.block("T_leaky_relu"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(32, i0_i1_i2_fused // 52)
                        ax2 = T.axis.spatial(52, i0_i1_i2_fused % 52)
                        ax3, ax4 = T.axis.remap("SS", [i3, i4_fused])
                        T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                        T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[16, 2, 1, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 26, 1, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 13, 2])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[4, 16])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
sch.enter_postproc()
b64 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.unroll_explicit")
b65, b66 = sch.get_child_blocks(b64)
l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b65)
l93 = sch.fuse(l67, l68, l69, l70, l71, l72, l73)
sch.parallel(loop=l93)
sch.annotate(block_or_loop=l93, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l93, ann_key="pragma_unroll_explicit", ann_val=1)
l94, l95, l96, l97, l98 = sch.get_loops(block=b66)
l99 = sch.fuse(l94, l95, l96)
sch.parallel(loop=l99)
l100 = sch.fuse(l98)
sch.vectorize(loop=l100)
sch.annotate(block_or_loop=l99, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l99, ann_key="pragma_unroll_explicit", ann_val=1)
b101 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121 = sch.get_loops(block=b101)
b122 = sch.decompose_reduction(block=b101, loop=l106)
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #3: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 54, 54, 4), "float32"], placeholder_1: T.Buffer[(32, 16, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 32, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 32, 52, 52, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 32, 52, 52, 4], dtype="float32")
        for i0_0_i1_0_i2_0_fused in T.parallel(208, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3_0, i4_0, i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 1, 1, 1, 1, 1, 2):
                for i1_2_init, i2_2_init, i3_2_init, i4_2_init, i1_3_init, i3_3_init in T.grid(2, 2, 2, 2, 2, 26):
                    with T.block("conv2d_NCHWc_init"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(32, i0_0_i1_0_i2_0_fused // 26 * 4 + i1_2_init * 2 + i1_3_init)
                        oh = T.axis.spatial(52, i0_0_i1_0_i2_0_fused % 26 * 2 + i2_2_init)
                        ow = T.axis.spatial(52, i3_2_init * 26 + i3_3_init)
                        oc_block = T.axis.spatial(4, i4_1 * 2 + i4_2_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 16, 54, 54, 4], "float32"], ["TENSOR", [32, 16, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(16, 1, 3, 1, 2, 2, 2, 2, 4, 3, 1, 1, 2, 1, 26, 1):
                    with T.block("conv2d_NCHWc_update"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(32, i0_0_i1_0_i2_0_fused // 26 * 4 + i1_2 * 2 + i1_3)
                        oh = T.axis.spatial(52, i0_0_i1_0_i2_0_fused % 26 * 2 + i2_2)
                        ow = T.axis.spatial(52, i3_2 * 26 + i3_3)
                        oc_block = T.axis.spatial(4, i4_1 * 2 + i4_2)
                        ic = T.axis.reduce(64, i5_0 * 4 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_1, i7_0])
                        T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 16, 54, 54, 4], "float32"], ["TENSOR", [32, 16, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
        for i0_i1_i2_fused in T.parallel(1664, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3 in T.serial(52):
                for i4_fused in T.vectorized(4):
                    with T.block("T_leaky_relu"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(32, i0_i1_i2_fused // 52)
                        ax2 = T.axis.spatial(52, i0_i1_i2_fused % 52)
                        ax3, ax4 = T.axis.remap("SS", [i3, i4_fused])
                        T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                        T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[8, 1, 2, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[26, 1, 2, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 26])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 2, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[16, 4])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
sch.enter_postproc()
b64 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.unroll_explicit")
b65, b66 = sch.get_child_blocks(b64)
l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b65)
l93 = sch.fuse(l67, l68, l69)
sch.parallel(loop=l93)
sch.annotate(block_or_loop=l93, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l93, ann_key="pragma_unroll_explicit", ann_val=1)
l94, l95, l96, l97, l98 = sch.get_loops(block=b66)
l99 = sch.fuse(l94, l95, l96)
sch.parallel(loop=l99)
l100 = sch.fuse(l98)
sch.vectorize(loop=l100)
sch.annotate(block_or_loop=l99, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l99, ann_key="pragma_unroll_explicit", ann_val=1)
b101 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b101)
b126 = sch.decompose_reduction(block=b101, loop=l110)
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #4: GFLOPs: 2.1097. Time: 189.3233 ms. Best GFLOPs: 4.7555
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #5: GFLOPs: 4.3416. Time: 91.9971 ms. Best GFLOPs: 4.7555
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #6: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 54, 54, 4), "float32"], placeholder_1: T.Buffer[(32, 16, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 32, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 32, 52, 52, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 32, 52, 52, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused in T.parallel(832, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i4_1 in T.serial(1):
                for i1_2_init, i2_2_init, i3_2_init, i1_3_init, i2_3_init in T.grid(2, 13, 2, 4, 2):
                    with T.block("conv2d_NCHWc_init"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(32, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 52 // 13 * 8 + i1_2_init * 4 + i1_3_init)
                        oh = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused // 416 * 26 + i2_2_init * 2 + i2_3_init)
                        ow = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 416 // 208 * 26 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 13 * 2 + i3_2_init)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 208 // 52)
                        T.reads()
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 16, 54, 54, 4], "float32"], ["TENSOR", [32, 16, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(16, 3, 3, 1, 2, 13, 2, 1, 4, 1, 1, 1, 4, 2, 1, 1):
                    with T.block("conv2d_NCHWc_update"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(32, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 52 // 13 * 8 + i1_2 * 4 + i1_3)
                        oh = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused // 416 * 26 + i2_2 * 2 + i2_3)
                        ow = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 416 // 208 * 26 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 13 * 2 + i3_2)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 208 // 52)
                        ic = T.axis.reduce(64, i5_0 * 4 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_0, i7_0])
                        T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 16, 54, 54, 4], "float32"], ["TENSOR", [32, 16, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 8, 26, 2, 1):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1 = T.axis.spatial(32, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 52 // 13 * 8 + ax1)
                        ax2_1 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused // 416 * 26 + ax2)
                        ax3_1 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 416 // 208 * 26 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 13 * 2 + ax3)
                        ax4_1 = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 208 // 52)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 4, 2, 4])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 13, 2])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 13, 2, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[16, 4])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, l73, l74, l75, l76)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b67)
sch.annotate(block_or_loop=l95, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l95, ann_key="pragma_unroll_explicit", ann_val=1)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b102)
b121 = sch.decompose_reduction(block=b102, loop=l105)
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #7: GFLOPs: 5.4409. Time: 73.4090 ms. Best GFLOPs: 5.4409
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #8: GFLOPs: 3.6576. Time: 109.2012 ms. Best GFLOPs: 5.4409
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #9: GFLOPs: 3.5634. Time: 112.0890 ms. Best GFLOPs: 5.4409
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #10: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 54, 54, 4), "float32"], placeholder_1: T.Buffer[(32, 16, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 32, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 32, 52, 52, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 32, 52, 52, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_fused in T.parallel(338, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i4_0, i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(2, 1, 2, 2, 1, 1):
                for i5_0 in T.serial(1):
                    for i1_2_init, i2_2_init, i4_2_init, i3_3_init in T.grid(16, 2, 2, 2):
                        with T.block("conv2d_NCHWc_init"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(32, i1_1 * 16 + i1_2_init)
                            oh = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused // 26 * 4 + i2_1 * 2 + i2_2_init)
                            ow = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 26 * 2 + i3_3_init)
                            oc_block = T.axis.spatial(4, i4_0 * 2 + i4_2_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 16, 54, 54, 4], "float32"], ["TENSOR", [32, 16, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                    for i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(3, 1, 1, 16, 2, 1, 2, 64, 1, 3, 1, 1, 1, 2, 1):
                        with T.block("conv2d_NCHWc_update"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(32, i1_1 * 16 + i1_2)
                            oh = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused // 26 * 4 + i2_1 * 2 + i2_2)
                            ow = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 26 * 2 + i3_3)
                            oc_block = T.axis.spatial(4, i4_0 * 2 + i4_2)
                            ic, kh, kw = T.axis.remap("RRR", [i5_1, i6_0, i7_1])
                            T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 16, 54, 54, 4], "float32"], ["TENSOR", [32, 16, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(1, 16, 2, 2):
                    for ax4_fused in T.vectorized(2):
                        with T.block("T_leaky_relu"):
                            ax0_1 = T.axis.spatial(1, 0)
                            ax1_1 = T.axis.spatial(32, i1_1 * 16 + ax1)
                            ax2_1 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused // 26 * 4 + i2_1 * 2 + ax2)
                            ax3_1 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 26 * 2 + ax3)
                            ax4 = T.axis.spatial(4, i4_0 * 2 + ax4_fused)
                            T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                            T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4])
                            T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 2, 16, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[13, 2, 2, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[26, 1, 1, 2])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 2, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 64])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b67)
l107 = sch.fuse(l106)
sch.vectorize(loop=l107)
sch.annotate(block_or_loop=l95, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l95, ann_key="pragma_unroll_explicit", ann_val=1)
b108 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b108)
b132 = sch.decompose_reduction(block=b108, loop=l117)
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #11: GFLOPs: 5.4228. Time: 73.6541 ms. Best GFLOPs: 5.4409
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #12: GFLOPs: 3.6915. Time: 108.1985 ms. Best GFLOPs: 5.4409
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #13: GFLOPs: 7.9555. Time: 50.2059 ms. Best GFLOPs: 7.9555
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #14: GFLOPs: 6.6581. Time: 59.9888 ms. Best GFLOPs: 7.9555
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #15: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 54, 54, 4), "float32"], placeholder_1: T.Buffer[(32, 16, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 32, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 32, 52, 52, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 32, 52, 52, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused in T.parallel(64, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i1_2_init, i2_2_init, i3_2_init, i2_3_init, i3_3_init in T.grid(4, 2, 4, 13, 13):
                with T.block("conv2d_NCHWc_init"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(32, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 32 * 16 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 8 // 2 * 4 + i1_2_init)
                    oh = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 32 // 16 * 26 + i2_2_init * 13 + i2_3_init)
                    ow = T.axis.spatial(52, i3_2_init * 13 + i3_3_init)
                    oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 16 // 8 * 2 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 2)
                    T.reads()
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 16, 54, 54, 4], "float32"], ["TENSOR", [32, 16, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
            for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(64, 3, 3, 1, 4, 2, 4, 1, 1, 1, 1, 1, 1, 13, 13, 1):
                with T.block("conv2d_NCHWc_update"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(32, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 32 * 16 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 8 // 2 * 4 + i1_2)
                    oh = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 32 // 16 * 26 + i2_2 * 13 + i2_3)
                    ow = T.axis.spatial(52, i3_2 * 13 + i3_3)
                    oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 16 // 8 * 2 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 2)
                    ic, kh, kw = T.axis.remap("RRR", [i5_0, i6_0, i7_0])
                    T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 16, 54, 54, 4], "float32"], ["TENSOR", [32, 16, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
        for i0_i1_i2_fused in T.parallel(1664, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3 in T.serial(52):
                for i4_fused in T.vectorized(4):
                    with T.block("T_leaky_relu"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(32, i0_i1_i2_fused // 52)
                        ax2 = T.axis.spatial(52, i0_i1_i2_fused % 52)
                        ax3, ax4 = T.axis.remap("SS", [i3, i4_fused])
                        T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                        T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[2, 4, 4, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 2, 13])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 4, 13])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 2, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[64, 1])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
sch.enter_postproc()
b64 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.unroll_explicit")
b65, b66 = sch.get_child_blocks(b64)
l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b65)
l93 = sch.fuse(l67, l68, l69, l70, l71, l72, l73, l74, l75, l76)
sch.parallel(loop=l93)
sch.annotate(block_or_loop=l93, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l93, ann_key="pragma_unroll_explicit", ann_val=1)
l94, l95, l96, l97, l98 = sch.get_loops(block=b66)
l99 = sch.fuse(l94, l95, l96)
sch.parallel(loop=l99)
l100 = sch.fuse(l98)
sch.vectorize(loop=l100)
sch.annotate(block_or_loop=l99, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l99, ann_key="pragma_unroll_explicit", ann_val=1)
b101 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b101)
b119 = sch.decompose_reduction(block=b101, loop=l103)
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #16: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 54, 54, 4), "float32"], placeholder_1: T.Buffer[(32, 16, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 32, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 32, 52, 52, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 32, 52, 52, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_fused in T.parallel(52, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 16, 1, 4, 1):
                for i2_2_init, i4_2_init, i1_3_init in T.grid(13, 4, 2):
                    with T.block("conv2d_NCHWc_init"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(32, i1_1 * 2 + i1_3_init)
                        oh = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 13 * 13 + i2_2_init)
                        ow = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 13 * 4 + i3_1)
                        oc_block = T.axis.spatial(4, i4_2_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 16, 54, 54, 4], "float32"], ["TENSOR", [32, 16, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(4, 1, 1, 1, 1, 13, 1, 4, 16, 3, 3, 1, 2, 1, 1, 1):
                    with T.block("conv2d_NCHWc_update"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(32, i1_1 * 2 + i1_3)
                        oh = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 13 * 13 + i2_2)
                        ow = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 13 * 4 + i3_1)
                        oc_block = T.axis.spatial(4, i4_2)
                        ic = T.axis.reduce(64, i5_0 * 16 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_1, i7_1])
                        T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 16, 54, 54, 4], "float32"], ["TENSOR", [32, 16, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
            for ax0, ax1, ax2 in T.grid(1, 32, 13):
                for ax3_ax4_fused in T.vectorized(16):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1 = T.axis.spatial(32, ax1)
                        ax2_1 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 13 * 13 + ax2)
                        ax3 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 13 * 4 + ax3_ax4_fused // 4)
                        ax4 = T.axis.spatial(4, ax3_ax4_fused % 4)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3, ax4])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 16, 1, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 13, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[13, 4, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 4, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[4, 16])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b67)
l101 = sch.fuse(l99, l100)
sch.vectorize(loop=l101)
sch.annotate(block_or_loop=l95, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l95, ann_key="pragma_unroll_explicit", ann_val=1)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b102)
b125 = sch.decompose_reduction(block=b102, loop=l109)
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #17: GFLOPs: 8.5605. Time: 46.6578 ms. Best GFLOPs: 8.5605
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #18: GFLOPs: 12.1061. Time: 32.9926 ms. Best GFLOPs: 12.1061
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #19: GFLOPs: 11.3538. Time: 35.1787 ms. Best GFLOPs: 12.1061
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #20: GFLOPs: 1.6069. Time: 248.5689 ms. Best GFLOPs: 12.1061
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #21: GFLOPs: 3.0343. Time: 131.6334 ms. Best GFLOPs: 12.1061
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #22: GFLOPs: 12.4840. Time: 31.9939 ms. Best GFLOPs: 12.4840
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #23: GFLOPs: 4.1023. Time: 97.3637 ms. Best GFLOPs: 12.4840
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #24: GFLOPs: 7.2871. Time: 54.8112 ms. Best GFLOPs: 12.4840
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #25: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 54, 54, 4), "float32"], placeholder_1: T.Buffer[(32, 16, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 32, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 32, 52, 52, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 32, 52, 52, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused in T.parallel(26, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i1_2_init, i2_2_init, i1_3_init, i3_3_init in T.grid(8, 4, 4, 26):
                for i4_3_fused_init in T.vectorized(4):
                    with T.block("conv2d_NCHWc_init"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(32, i1_2_init * 4 + i1_3_init)
                        oh = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 13 * 4 + i2_2_init)
                        ow = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 13 * 26 + i3_3_init)
                        oc_block = T.axis.spatial(4, i4_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 16, 54, 54, 4], "float32"], ["TENSOR", [32, 16, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
            for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3 in T.grid(2, 1, 3, 1, 8, 4, 1, 1, 32, 3, 1, 1, 4, 1, 26):
                for i4_3_fused in T.vectorized(4):
                    with T.block("conv2d_NCHWc_update"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(32, i1_2 * 4 + i1_3)
                        oh = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 13 * 4 + i2_2)
                        ow = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 13 * 26 + i3_3)
                        oc_block = T.axis.spatial(4, i4_3_fused)
                        ic = T.axis.reduce(64, i5_0 * 32 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_1, i7_0])
                        T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 16, 54, 54, 4], "float32"], ["TENSOR", [32, 16, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(1, 32, 4, 26):
                for ax4_fused in T.vectorized(4):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1 = T.axis.spatial(32, ax1)
                        ax2_1 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 13 * 4 + ax2)
                        ax3_1 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 13 * 26 + ax3)
                        ax4 = T.axis.spatial(4, ax4_fused)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 8, 4])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 13, 4, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 1, 26])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[2, 32])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, l73, l74, l75, l76, l77)
sch.parallel(loop=l94)
l95 = sch.fuse(l93)
sch.vectorize(loop=l95)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b67)
l102 = sch.fuse(l101)
sch.vectorize(loop=l102)
sch.annotate(block_or_loop=l96, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l96, ann_key="pragma_unroll_explicit", ann_val=1)
b103 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b103)
b121 = sch.decompose_reduction(block=b103, loop=l105)
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #26: GFLOPs: 14.6660. Time: 27.2340 ms. Best GFLOPs: 14.6660
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #27: GFLOPs: 10.3326. Time: 38.6555 ms. Best GFLOPs: 14.6660
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #28: GFLOPs: 6.9505. Time: 57.4657 ms. Best GFLOPs: 14.6660
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #29: GFLOPs: 4.6048. Time: 86.7382 ms. Best GFLOPs: 14.6660
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #30: GFLOPs: 6.3552. Time: 62.8483 ms. Best GFLOPs: 14.6660
[01:02:59] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"] Trial #31: GFLOPs: 2.3589. Time: 169.3205 ms. Best GFLOPs: 14.6660
[01:03:28] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 224
Total latency (us): 136313

[01:03:28] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_nn_pad_6"] Trial #0: GFLOPs: 0.0000. Time: 9.6665 ms. Best GFLOPs: 0.0000
[01:03:28] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_nn_pad_6"] Trial #1: GFLOPs: 0.0000. Time: 5.5982 ms. Best GFLOPs: 0.0000
[01:03:28] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_nn_pad_6"] Trial #2: GFLOPs: 0.0000. Time: 4.8488 ms. Best GFLOPs: 0.0000
[01:03:28] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_nn_pad_6"] Trial #3: GFLOPs: 0.0000. Time: 3.8660 ms. Best GFLOPs: 0.0000
[01:03:28] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_nn_pad_6"] Trial #4: GFLOPs: 0.0000. Time: 8.5388 ms. Best GFLOPs: 0.0000
[01:03:28] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_nn_pad_6"] Trial #5: GFLOPs: 0.0000. Time: 3.8606 ms. Best GFLOPs: 0.0000
[01:03:28] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_nn_pad_6"] Trial #6: GFLOPs: 0.0000. Time: 5.1233 ms. Best GFLOPs: 0.0000
[01:03:28] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_nn_pad_6"] Trial #7: GFLOPs: 0.0000. Time: 4.7686 ms. Best GFLOPs: 0.0000
[01:04:15] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #14: "fused_nn_pad_6"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 232
Total latency (us): 140174

[01:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_max_pool2d_3"] Trial #0: GFLOPs: 0.0460. Time: 7.5267 ms. Best GFLOPs: 0.0460
[01:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_max_pool2d_3"] Trial #1: GFLOPs: 0.0734. Time: 4.7141 ms. Best GFLOPs: 0.0734
[01:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_max_pool2d_3"] Trial #2: GFLOPs: 0.0643. Time: 5.3844 ms. Best GFLOPs: 0.0734
[01:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_max_pool2d_3"] Trial #3: GFLOPs: 0.0096. Time: 35.9408 ms. Best GFLOPs: 0.0734
[01:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_max_pool2d_3"] Trial #4: GFLOPs: 0.0474. Time: 7.2943 ms. Best GFLOPs: 0.0734
[01:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_max_pool2d_3"] Trial #5: GFLOPs: 0.0087. Time: 39.9944 ms. Best GFLOPs: 0.0734
[01:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_max_pool2d_3"] Trial #6: GFLOPs: 0.0640. Time: 5.4105 ms. Best GFLOPs: 0.0734
[01:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_max_pool2d_3"] Trial #7: GFLOPs: 0.0892. Time: 3.8781 ms. Best GFLOPs: 0.0892
[01:04:56] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #15: "fused_nn_max_pool2d_3"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 240
Total latency (us): 144052

[01:04:56] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_pad_7"] Trial #0: GFLOPs: 0.0000. Time: 5.1284 ms. Best GFLOPs: 0.0000
[01:04:56] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_pad_7"] Trial #1: GFLOPs: 0.0000. Time: 5.6844 ms. Best GFLOPs: 0.0000
[01:04:56] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_pad_7"] Trial #2: GFLOPs: 0.0000. Time: 3.8611 ms. Best GFLOPs: 0.0000
[01:04:56] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_pad_7"] Trial #3: GFLOPs: 0.0000. Time: 4.1544 ms. Best GFLOPs: 0.0000
[01:04:56] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_pad_7"] Trial #4: GFLOPs: 0.0000. Time: 9.3328 ms. Best GFLOPs: 0.0000
[01:04:56] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_pad_7"] Trial #5: GFLOPs: 0.0000. Time: 4.9515 ms. Best GFLOPs: 0.0000
[01:04:56] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_pad_7"] Trial #6: GFLOPs: 0.0000. Time: 6.1575 ms. Best GFLOPs: 0.0000
[01:04:56] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_pad_7"] Trial #7: GFLOPs: 0.0000. Time: 4.3988 ms. Best GFLOPs: 0.0000
[01:05:30] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #16: "fused_nn_pad_7"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 248
Total latency (us): 147913

[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #0: GFLOPs: 6.8027. Time: 58.6632 ms. Best GFLOPs: 6.8027
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #1: GFLOPs: 4.2753. Time: 93.3421 ms. Best GFLOPs: 6.8027
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #2: GFLOPs: 4.3552. Time: 91.6291 ms. Best GFLOPs: 6.8027
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #3: GFLOPs: 3.7167. Time: 107.3704 ms. Best GFLOPs: 6.8027
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #4: GFLOPs: 9.2445. Time: 43.1682 ms. Best GFLOPs: 9.2445
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #5: GFLOPs: 1.5508. Time: 257.3234 ms. Best GFLOPs: 9.2445
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #6: GFLOPs: 1.0153. Time: 393.0684 ms. Best GFLOPs: 9.2445
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #7: GFLOPs: 14.6035. Time: 27.3268 ms. Best GFLOPs: 14.6035
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #8: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 32, 28, 28, 4), "float32"], placeholder_1: T.Buffer[(64, 32, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 64, 26, 26, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 64, 26, 26, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_fused in T.parallel(208, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i4_0, i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 1, 2, 1, 13, 1):
                for i1_2_init, i2_2_init, i4_2_init in T.grid(4, 2, 2):
                    for i0_3_i1_3_i2_3_i3_3_i4_3_fused_init in T.vectorized(2):
                        with T.block("conv2d_NCHWc_init"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused // 26 * 8 + i1_1 * 4 + i1_2_init)
                            oh = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused % 26 // 2 * 2 + i2_2_init)
                            ow = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused % 2 * 13 + i3_1)
                            oc_block = T.axis.spatial(4, i4_2_init * 2 + i0_3_i1_3_i2_3_i3_3_i4_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 32, 28, 28, 4], "float32"], ["TENSOR", [64, 32, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1 in T.grid(64, 3, 1, 1, 4, 2, 1, 2, 2, 1, 3):
                    for i0_3_i1_3_i2_3_i3_3_i4_3_fused in T.vectorized(2):
                        with T.block("conv2d_NCHWc_update"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused // 26 * 8 + i1_1 * 4 + i1_2)
                            oh = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused % 26 // 2 * 2 + i2_2)
                            ow = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused % 2 * 13 + i3_1)
                            oc_block = T.axis.spatial(4, i4_2 * 2 + i0_3_i1_3_i2_3_i3_3_i4_3_fused)
                            ic = T.axis.reduce(128, i5_0 * 2 + i5_1)
                            kh, kw = T.axis.remap("RR", [i6_0, i7_1])
                            T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 32, 28, 28, 4], "float32"], ["TENSOR", [64, 32, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
        for i0_i1_i2_fused in T.parallel(1664, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3 in T.serial(26):
                for i4_fused in T.vectorized(4):
                    with T.block("T_leaky_relu"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(64, i0_i1_i2_fused // 26)
                        ax2 = T.axis.spatial(26, i0_i1_i2_fused % 26)
                        ax3, ax4 = T.axis.remap("SS", [i3, i4_fused])
                        T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                        T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[8, 2, 4, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[13, 1, 2, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 13, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 2, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[64, 2])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
sch.enter_postproc()
b64 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.unroll_explicit")
b65, b66 = sch.get_child_blocks(b64)
l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b65)
l93 = sch.fuse(l67, l68, l69, l70)
sch.parallel(loop=l93)
l94 = sch.fuse(l88, l89, l90, l91, l92)
sch.vectorize(loop=l94)
sch.annotate(block_or_loop=l93, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l93, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99 = sch.get_loops(block=b66)
l100 = sch.fuse(l95, l96, l97)
sch.parallel(loop=l100)
l101 = sch.fuse(l99)
sch.vectorize(loop=l101)
sch.annotate(block_or_loop=l100, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l100, ann_key="pragma_unroll_explicit", ann_val=1)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121 = sch.get_loops(block=b102)
b122 = sch.decompose_reduction(block=b102, loop=l110)
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #9: GFLOPs: 5.0914. Time: 78.3800 ms. Best GFLOPs: 14.6035
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #10: GFLOPs: 2.7838. Time: 143.3556 ms. Best GFLOPs: 14.6035
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #11: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 32, 28, 28, 4), "float32"], placeholder_1: T.Buffer[(64, 32, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 64, 26, 26, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 64, 26, 26, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused in T.parallel(104, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i2_2_init, i1_3_init, i2_3_init, i3_3_init in T.grid(2, 16, 13, 2):
                for i4_3_fused_init in T.vectorized(2):
                    with T.block("conv2d_NCHWc_init"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 26 * 16 + i1_3_init)
                        oh = T.axis.spatial(26, i2_2_init * 13 + i2_3_init)
                        ow = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 26 // 2 * 2 + i3_3_init)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 2 * 2 + i4_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 32, 28, 28, 4], "float32"], ["TENSOR", [64, 32, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
            for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3 in T.grid(32, 3, 1, 1, 1, 2, 1, 1, 4, 1, 3, 1, 16, 13, 2):
                for i4_3_fused in T.vectorized(2):
                    with T.block("conv2d_NCHWc_update"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 26 * 16 + i1_3)
                        oh = T.axis.spatial(26, i2_2 * 13 + i2_3)
                        ow = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 26 // 2 * 2 + i3_3)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 2 * 2 + i4_3_fused)
                        ic = T.axis.reduce(128, i5_0 * 4 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_0, i7_1])
                        T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 32, 28, 28, 4], "float32"], ["TENSOR", [64, 32, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
        for i0_i1_i2_fused in T.parallel(1664, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3 in T.serial(26):
                for i4_fused in T.vectorized(4):
                    with T.block("T_leaky_relu"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(64, i0_i1_i2_fused // 26)
                        ax2 = T.axis.spatial(26, i0_i1_i2_fused % 26)
                        ax3, ax4 = T.axis.remap("SS", [i3, i4_fused])
                        T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                        T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[4, 1, 1, 16])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 2, 13])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[13, 1, 1, 2])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[32, 4])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
sch.enter_postproc()
b64 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.unroll_explicit")
b65, b66 = sch.get_child_blocks(b64)
l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b65)
l93 = sch.fuse(l67, l68, l69, l70, l71, l72, l73, l74, l75, l76)
sch.parallel(loop=l93)
l94 = sch.fuse(l92)
sch.vectorize(loop=l94)
sch.annotate(block_or_loop=l93, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l93, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99 = sch.get_loops(block=b66)
l100 = sch.fuse(l95, l96, l97)
sch.parallel(loop=l100)
l101 = sch.fuse(l99)
sch.vectorize(loop=l101)
sch.annotate(block_or_loop=l100, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l100, ann_key="pragma_unroll_explicit", ann_val=1)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b102)
b120 = sch.decompose_reduction(block=b102, loop=l104)
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #12: GFLOPs: 2.6692. Time: 149.5090 ms. Best GFLOPs: 14.6035
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #13: GFLOPs: 2.9936. Time: 133.3071 ms. Best GFLOPs: 14.6035
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #14: GFLOPs: 9.6642. Time: 41.2935 ms. Best GFLOPs: 14.6035
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #15: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 32, 28, 28, 4), "float32"], placeholder_1: T.Buffer[(64, 32, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 64, 26, 26, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 64, 26, 26, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_fused in T.parallel(4, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 2, 2, 2, 1):
                for i1_2_init, i3_2_init, i1_3_init, i2_3_init in T.grid(2, 13, 4, 13):
                    for i3_3_i4_3_fused_init in T.vectorized(4):
                        with T.block("conv2d_NCHWc_init"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_i4_0_fused * 16 + i1_1 * 8 + i1_2_init * 4 + i1_3_init)
                            oh = T.axis.spatial(26, i2_1 * 13 + i2_3_init)
                            ow = T.axis.spatial(26, i3_1 * 13 + i3_2_init)
                            oc_block = T.axis.spatial(4, i3_3_i4_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 32, 28, 28, 4], "float32"], ["TENSOR", [64, 32, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3 in T.grid(64, 3, 1, 1, 2, 1, 13, 1, 2, 1, 3, 1, 4, 13):
                    for i3_3_i4_3_fused in T.vectorized(4):
                        with T.block("conv2d_NCHWc_update"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_i4_0_fused * 16 + i1_1 * 8 + i1_2 * 4 + i1_3)
                            oh = T.axis.spatial(26, i2_1 * 13 + i2_3)
                            ow = T.axis.spatial(26, i3_1 * 13 + i3_2)
                            oc_block = T.axis.spatial(4, i3_3_i4_3_fused)
                            ic = T.axis.reduce(128, i5_0 * 2 + i5_1)
                            kh, kw = T.axis.remap("RR", [i6_0, i7_1])
                            T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 32, 28, 28, 4], "float32"], ["TENSOR", [64, 32, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(1, 16, 26, 26):
                for ax4_fused in T.vectorized(4):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1 = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_i4_0_fused * 16 + ax1)
                        ax2_1, ax3_1, ax4 = T.axis.remap("SSS", [ax2, ax3, ax4_fused])
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[4, 2, 2, 4])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 13])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 13, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[64, 2])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72)
sch.parallel(loop=l94)
l95 = sch.fuse(l92, l93)
sch.vectorize(loop=l95)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b67)
l102 = sch.fuse(l101)
sch.vectorize(loop=l102)
sch.annotate(block_or_loop=l96, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l96, ann_key="pragma_unroll_explicit", ann_val=1)
b103 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b103)
b125 = sch.decompose_reduction(block=b103, loop=l110)
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #16: GFLOPs: 2.7789. Time: 143.6066 ms. Best GFLOPs: 14.6035
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #17: GFLOPs: 3.8945. Time: 102.4699 ms. Best GFLOPs: 14.6035
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #18: GFLOPs: 2.8736. Time: 138.8713 ms. Best GFLOPs: 14.6035
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #19: GFLOPs: 5.9713. Time: 66.8308 ms. Best GFLOPs: 14.6035
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #20: GFLOPs: 3.7656. Time: 105.9780 ms. Best GFLOPs: 14.6035
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #21: GFLOPs: 2.4455. Time: 163.1814 ms. Best GFLOPs: 14.6035
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #22: GFLOPs: 7.6830. Time: 51.9419 ms. Best GFLOPs: 14.6035
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #23: GFLOPs: 9.9808. Time: 39.9833 ms. Best GFLOPs: 14.6035
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #24: GFLOPs: 2.7424. Time: 145.5174 ms. Best GFLOPs: 14.6035
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #25: GFLOPs: 2.7069. Time: 147.4272 ms. Best GFLOPs: 14.6035
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #26: GFLOPs: 8.2697. Time: 48.2567 ms. Best GFLOPs: 14.6035
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #27: GFLOPs: 11.9825. Time: 33.3042 ms. Best GFLOPs: 14.6035
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #28: GFLOPs: 4.4095. Time: 90.5025 ms. Best GFLOPs: 14.6035
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #29: GFLOPs: 4.2374. Time: 94.1773 ms. Best GFLOPs: 14.6035
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #30: GFLOPs: 2.2895. Time: 174.3053 ms. Best GFLOPs: 14.6035
[01:05:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"] Trial #31: GFLOPs: 3.9102. Time: 102.0584 ms. Best GFLOPs: 14.6035
[01:06:20] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 280
Total latency (us): 175240

[01:06:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_pad_8"] Trial #0: GFLOPs: 0.0000. Time: 3.6984 ms. Best GFLOPs: 0.0000
[01:06:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_pad_8"] Trial #1: GFLOPs: 0.0000. Time: 5.3840 ms. Best GFLOPs: 0.0000
[01:06:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_pad_8"] Trial #2: GFLOPs: 0.0000. Time: 6.6642 ms. Best GFLOPs: 0.0000
[01:06:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_pad_8"] Trial #3: GFLOPs: 0.0000. Time: 3.8816 ms. Best GFLOPs: 0.0000
[01:06:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_pad_8"] Trial #4: GFLOPs: 0.0000. Time: 4.5551 ms. Best GFLOPs: 0.0000
[01:06:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #18: "fused_nn_pad_8"] Trial #5: Error in building: LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 26, 26, 4), "float32"], T_pad: T.Buffer[(1, 64, 26, 26, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        for i0_i1_fused in T.parallel(64, annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for i2, i3 in T.grid(26, 26):
                for i4_fused in T.vectorized(4):
                    with T.block("T_pad"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1, ax2, ax3, ax4 = T.axis.remap("SSSS", [i0_i1_fused, i2, i3, i4_fused])
                        T.reads(placeholder[ax0, ax1, ax2, ax3, ax4])
                        T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                        T_pad[ax0, ax1, ax2, ax3, ax4] = placeholder[ax0, ax1, ax2, ax3, ax4]
    

b0 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.parallel", ann_val=1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.vectorize", ann_val=64)
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
sch.enter_postproc()
b2 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit")
b3, = sch.get_child_blocks(b2)
l4, l5, l6, l7, l8 = sch.get_loops(block=b3)
l9 = sch.fuse(l4, l5)
sch.parallel(loop=l9)
l10 = sch.fuse(l8)
sch.vectorize(loop=l10)
sch.annotate(block_or_loop=l9, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l9, ann_key="pragma_unroll_explicit", ann_val=1)
[01:06:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_pad_8"] Trial #6: GFLOPs: 0.0000. Time: 3.2943 ms. Best GFLOPs: 0.0000
[01:06:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_pad_8"] Trial #7: GFLOPs: 0.0000. Time: 9.5265 ms. Best GFLOPs: 0.0000
[01:07:10] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #18: "fused_nn_pad_8"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 288
Total latency (us): 178534

[01:07:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_max_pool2d_4"] Trial #0: GFLOPs: 0.0499. Time: 3.4687 ms. Best GFLOPs: 0.0499
[01:07:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_max_pool2d_4"] Trial #1: GFLOPs: 0.0493. Time: 3.5077 ms. Best GFLOPs: 0.0499
[01:07:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_max_pool2d_4"] Trial #2: GFLOPs: 0.0780. Time: 2.2185 ms. Best GFLOPs: 0.0780
[01:07:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_max_pool2d_4"] Trial #3: GFLOPs: 0.0182. Time: 9.4989 ms. Best GFLOPs: 0.0780
[01:07:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_max_pool2d_4"] Trial #4: GFLOPs: 0.0852. Time: 2.0310 ms. Best GFLOPs: 0.0852
[01:07:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #19: "fused_nn_max_pool2d_4"] Trial #5: Error in building: LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 26, 26, 4), "float32"], tensor: T.Buffer[(1, 64, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        for i0_i1_i2_fused in T.parallel(832, annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for i3, i4 in T.grid(13, 4):
                with T.block("tensor_init"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(64, i0_i1_i2_fused // 13)
                    ax2 = T.axis.spatial(13, i0_i1_i2_fused % 13)
                    ax3, ax4 = T.axis.remap("SS", [i3, i4])
                    T.reads()
                    T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                    tensor[ax0, ax1, ax2, ax3, ax4] = T.float32(-3.4028234663852886e+38)
                for i5, i6 in T.grid(2, 2):
                    with T.block("tensor_update"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(64, i0_i1_i2_fused // 13)
                        ax2 = T.axis.spatial(13, i0_i1_i2_fused % 13)
                        ax3, ax4, rv0, rv1 = T.axis.remap("SSRR", [i3, i4, i5, i6])
                        T.reads(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
                        T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                        tensor[ax0, ax1, ax2, ax3, ax4] = T.max(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
    

b0 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.vectorize", ann_val=64)
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
sch.enter_postproc()
b2 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit")
b3, = sch.get_child_blocks(b2)
l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b3)
l11 = sch.fuse(l4, l5, l6)
sch.parallel(loop=l11)
sch.annotate(block_or_loop=l11, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l11, ann_key="pragma_unroll_explicit", ann_val=1)
b12 = sch.get_block(name="tensor", func_name="main")
l13, l14, l15, l16, l17 = sch.get_loops(block=b12)
b18 = sch.decompose_reduction(block=b12, loop=l16)
[01:07:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_max_pool2d_4"] Trial #6: GFLOPs: 0.0045. Time: 38.5965 ms. Best GFLOPs: 0.0852
[01:07:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_max_pool2d_4"] Trial #7: GFLOPs: 0.0274. Time: 6.3137 ms. Best GFLOPs: 0.0852
[01:07:35] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #19: "fused_nn_max_pool2d_4"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 296
Total latency (us): 180565

[01:07:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_nn_pad_9"] Trial #0: GFLOPs: 0.0000. Time: 4.7274 ms. Best GFLOPs: 0.0000
[01:07:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_nn_pad_9"] Trial #1: GFLOPs: 0.0000. Time: 5.4982 ms. Best GFLOPs: 0.0000
[01:07:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_nn_pad_9"] Trial #2: GFLOPs: 0.0000. Time: 5.5813 ms. Best GFLOPs: 0.0000
[01:07:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_nn_pad_9"] Trial #3: GFLOPs: 0.0000. Time: 7.7327 ms. Best GFLOPs: 0.0000
[01:07:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_nn_pad_9"] Trial #4: GFLOPs: 0.0000. Time: 5.7764 ms. Best GFLOPs: 0.0000
[01:07:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_nn_pad_9"] Trial #5: GFLOPs: 0.0000. Time: 3.9999 ms. Best GFLOPs: 0.0000
[01:07:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_nn_pad_9"] Trial #6: GFLOPs: 0.0000. Time: 7.9941 ms. Best GFLOPs: 0.0000
[01:07:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_nn_pad_9"] Trial #7: GFLOPs: 0.0000. Time: 9.7498 ms. Best GFLOPs: 0.0000
[01:08:15] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #20: "fused_nn_pad_9"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 304
Total latency (us): 184565

[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #0: GFLOPs: 3.0530. Time: 130.6548 ms. Best GFLOPs: 3.0530
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #1: GFLOPs: 5.8672. Time: 67.9866 ms. Best GFLOPs: 5.8672
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #2: GFLOPs: 2.8585. Time: 139.5485 ms. Best GFLOPs: 5.8672
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #3: GFLOPs: 4.5525. Time: 87.6209 ms. Best GFLOPs: 5.8672
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #4: GFLOPs: 4.5621. Time: 87.4358 ms. Best GFLOPs: 5.8672
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #5: GFLOPs: 1.5074. Time: 264.6253 ms. Best GFLOPs: 5.8672
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #6: GFLOPs: 4.4030. Time: 90.5961 ms. Best GFLOPs: 5.8672
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #7: GFLOPs: 2.1079. Time: 189.2384 ms. Best GFLOPs: 5.8672
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #8: GFLOPs: 1.6999. Time: 234.6570 ms. Best GFLOPs: 5.8672
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #9: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 15, 15, 4), "float32"], placeholder_1: T.Buffer[(128, 64, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 128, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 128, 13, 13, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused in T.parallel(832, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i4_1 in T.serial(1):
                for i1_2_init, i2_2_init, i4_2_init, i1_3_init in T.grid(2, 13, 2, 2):
                    with T.block("conv2d_NCHWc_init"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused // 52 * 8 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 26 // 13 * 4 + i1_2_init * 2 + i1_3_init)
                        oh = T.axis.spatial(13, i2_2_init)
                        ow = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 13)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 52 // 26 * 2 + i4_2_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 64, 15, 15, 4], "float32"], ["TENSOR", [128, 64, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(64, 3, 3, 1, 2, 13, 1, 2, 4, 1, 1, 1, 2, 1, 1, 1):
                    with T.block("conv2d_NCHWc_update"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused // 52 * 8 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 26 // 13 * 4 + i1_2 * 2 + i1_3)
                        oh = T.axis.spatial(13, i2_2)
                        ow = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 13)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 52 // 26 * 2 + i4_2)
                        ic = T.axis.reduce(256, i5_0 * 4 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_0, i7_0])
                        T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 64, 15, 15, 4], "float32"], ["TENSOR", [128, 64, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
        for i0_i1_i2_fused in T.parallel(1664, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3_i4_fused in T.vectorized(52):
                with T.block("T_leaky_relu"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(128, i0_i1_i2_fused // 13)
                    ax2 = T.axis.spatial(13, i0_i1_i2_fused % 13)
                    ax3 = T.axis.spatial(13, i3_i4_fused // 4)
                    ax4 = T.axis.spatial(4, i3_i4_fused % 4)
                    T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                    T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                    T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[16, 2, 2, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 13, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 2, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[64, 4])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
sch.enter_postproc()
b64 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.unroll_explicit")
b65, b66 = sch.get_child_blocks(b64)
l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b65)
l93 = sch.fuse(l67, l68, l69, l70, l71, l72, l73, l74, l75)
sch.parallel(loop=l93)
sch.annotate(block_or_loop=l93, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l93, ann_key="pragma_unroll_explicit", ann_val=1)
l94, l95, l96, l97, l98 = sch.get_loops(block=b66)
l99 = sch.fuse(l94, l95, l96)
sch.parallel(loop=l99)
l100 = sch.fuse(l97, l98)
sch.vectorize(loop=l100)
sch.annotate(block_or_loop=l99, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l99, ann_key="pragma_unroll_explicit", ann_val=1)
b101 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b101)
b120 = sch.decompose_reduction(block=b101, loop=l104)
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #10: GFLOPs: 0.1709. Time: 2334.5680 ms. Best GFLOPs: 5.8672
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #11: GFLOPs: 2.8566. Time: 139.6388 ms. Best GFLOPs: 5.8672
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #12: GFLOPs: 3.0915. Time: 129.0283 ms. Best GFLOPs: 5.8672
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #13: GFLOPs: 4.7514. Time: 83.9531 ms. Best GFLOPs: 5.8672
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #14: GFLOPs: 2.6357. Time: 151.3455 ms. Best GFLOPs: 5.8672
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #15: GFLOPs: 2.5398. Time: 157.0550 ms. Best GFLOPs: 5.8672
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #16: GFLOPs: 6.1957. Time: 64.3822 ms. Best GFLOPs: 6.1957
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #17: GFLOPs: 7.3769. Time: 54.0731 ms. Best GFLOPs: 7.3769
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #18: GFLOPs: 0.6680. Time: 597.1114 ms. Best GFLOPs: 7.3769
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #19: GFLOPs: 2.4899. Time: 160.2078 ms. Best GFLOPs: 7.3769
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #20: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 15, 15, 4), "float32"], placeholder_1: T.Buffer[(128, 64, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 128, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 128, 13, 13, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_fused in T.parallel(52, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 2, 1, 1, 1):
                for i1_2_init, i1_3_init, i2_3_init in T.grid(16, 4, 13):
                    with T.block("conv2d_NCHWc_init"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(128, i1_1 * 64 + i1_2_init * 4 + i1_3_init)
                        oh = T.axis.spatial(13, i2_3_init)
                        ow = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 4)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 4)
                        T.reads()
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 64, 15, 15, 4], "float32"], ["TENSOR", [128, 64, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(128, 1, 3, 1, 16, 1, 1, 1, 2, 3, 1, 1, 4, 13, 1, 1):
                    with T.block("conv2d_NCHWc_update"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(128, i1_1 * 64 + i1_2 * 4 + i1_3)
                        oh = T.axis.spatial(13, i2_3)
                        ow = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 4)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 4)
                        ic = T.axis.reduce(256, i5_0 * 2 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_1, i7_0])
                        T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 64, 15, 15, 4], "float32"], ["TENSOR", [128, 64, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 128, 13, 1, 1):
                with T.block("T_leaky_relu"):
                    ax0_1 = T.axis.spatial(1, 0)
                    ax1_1, ax2_1 = T.axis.remap("SS", [ax1, ax2])
                    ax3_1 = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 4)
                    ax4_1 = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 4)
                    T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1])
                    T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                    T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 2, 16, 4])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[13, 1, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[128, 2])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b67)
sch.annotate(block_or_loop=l95, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l95, ann_key="pragma_unroll_explicit", ann_val=1)
b101 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123 = sch.get_loops(block=b101)
b124 = sch.decompose_reduction(block=b101, loop=l108)
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #21: GFLOPs: 1.3181. Time: 302.6228 ms. Best GFLOPs: 7.3769
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #22: GFLOPs: 1.2218. Time: 326.4681 ms. Best GFLOPs: 7.3769
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #23: GFLOPs: 1.5502. Time: 257.3223 ms. Best GFLOPs: 7.3769
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #24: GFLOPs: 3.2788. Time: 121.6577 ms. Best GFLOPs: 7.3769
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #25: GFLOPs: 5.7211. Time: 69.7233 ms. Best GFLOPs: 7.3769
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #26: GFLOPs: 0.8524. Time: 467.9898 ms. Best GFLOPs: 7.3769
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #27: GFLOPs: 2.5817. Time: 154.5078 ms. Best GFLOPs: 7.3769
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #28: GFLOPs: 2.2162. Time: 179.9877 ms. Best GFLOPs: 7.3769
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #29: GFLOPs: 2.1680. Time: 183.9889 ms. Best GFLOPs: 7.3769
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #30: GFLOPs: 1.0801. Time: 369.3187 ms. Best GFLOPs: 7.3769
[01:08:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"] Trial #31: GFLOPs: 1.0723. Time: 371.9893 ms. Best GFLOPs: 7.3769
[01:09:15] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 336
Total latency (us): 238638

[01:09:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_pad_10"] Trial #0: GFLOPs: 0.0000. Time: 5.5194 ms. Best GFLOPs: 0.0000
[01:09:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_pad_10"] Trial #1: GFLOPs: 0.0000. Time: 3.9996 ms. Best GFLOPs: 0.0000
[01:09:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_pad_10"] Trial #2: GFLOPs: 0.0000. Time: 6.3065 ms. Best GFLOPs: 0.0000
[01:09:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_pad_10"] Trial #3: GFLOPs: 0.0000. Time: 7.2311 ms. Best GFLOPs: 0.0000
[01:09:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_pad_10"] Trial #4: GFLOPs: 0.0000. Time: 5.7260 ms. Best GFLOPs: 0.0000
[01:09:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_pad_10"] Trial #5: GFLOPs: 0.0000. Time: 5.4388 ms. Best GFLOPs: 0.0000
[01:09:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_pad_10"] Trial #6: GFLOPs: 0.0000. Time: 5.3677 ms. Best GFLOPs: 0.0000
[01:09:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_pad_10"] Trial #7: GFLOPs: 0.0000. Time: 4.7691 ms. Best GFLOPs: 0.0000
[01:09:56] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #22: "fused_nn_pad_10"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 344
Total latency (us): 242637

[01:09:56] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_max_pool2d_5"] Trial #0: GFLOPs: 0.0401. Time: 8.6313 ms. Best GFLOPs: 0.0401
[01:09:56] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_max_pool2d_5"] Trial #1: GFLOPs: 0.0656. Time: 5.2721 ms. Best GFLOPs: 0.0656
[01:09:56] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_max_pool2d_5"] Trial #2: GFLOPs: 0.0632. Time: 5.4729 ms. Best GFLOPs: 0.0656
[01:09:56] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_max_pool2d_5"] Trial #3: GFLOPs: 0.0615. Time: 5.6260 ms. Best GFLOPs: 0.0656
[01:09:56] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_max_pool2d_5"] Trial #4: GFLOPs: 0.0651. Time: 5.3143 ms. Best GFLOPs: 0.0656
[01:09:56] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_max_pool2d_5"] Trial #5: GFLOPs: 0.0523. Time: 6.6188 ms. Best GFLOPs: 0.0656
[01:09:56] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_max_pool2d_5"] Trial #6: GFLOPs: 0.1000. Time: 3.4616 ms. Best GFLOPs: 0.1000
[01:09:56] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_max_pool2d_5"] Trial #7: GFLOPs: 0.0411. Time: 8.4202 ms. Best GFLOPs: 0.1000
[01:10:22] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #23: "fused_nn_max_pool2d_5"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 352
Total latency (us): 246099

[01:10:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_pad_11"] Trial #0: GFLOPs: 0.0000. Time: 4.6498 ms. Best GFLOPs: 0.0000
[01:10:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_pad_11"] Trial #1: GFLOPs: 0.0000. Time: 5.6455 ms. Best GFLOPs: 0.0000
[01:10:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_pad_11"] Trial #2: GFLOPs: 0.0000. Time: 6.1531 ms. Best GFLOPs: 0.0000
[01:10:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_pad_11"] Trial #3: GFLOPs: 0.0000. Time: 4.8469 ms. Best GFLOPs: 0.0000
[01:10:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_pad_11"] Trial #4: GFLOPs: 0.0000. Time: 4.3093 ms. Best GFLOPs: 0.0000
[01:10:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_pad_11"] Trial #5: GFLOPs: 0.0000. Time: 2.9986 ms. Best GFLOPs: 0.0000
[01:10:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_pad_11"] Trial #6: GFLOPs: 0.0000. Time: 2.6842 ms. Best GFLOPs: 0.0000
[01:10:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_pad_11"] Trial #7: GFLOPs: 0.0000. Time: 7.1572 ms. Best GFLOPs: 0.0000
[01:10:59] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #24: "fused_nn_pad_11"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 360
Total latency (us): 248783

[01:11:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #0: GFLOPs: 6.2033. Time: 257.1591 ms. Best GFLOPs: 6.2033
[01:11:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #1: GFLOPs: 1.9195. Time: 831.0748 ms. Best GFLOPs: 6.2033
[01:11:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #2: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 15, 15, 4), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 256, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 256, 13, 13, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused in T.parallel(169, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i4_1 in T.serial(4):
                for i1_2_init, i1_3_init in T.grid(8, 32):
                    with T.block("conv2d_NCHWc_init"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(256, i1_2_init * 32 + i1_3_init)
                        oh = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused // 13)
                        ow = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 13)
                        oc_block = T.axis.spatial(4, i4_1)
                        T.reads()
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 128, 15, 15, 4], "float32"], ["TENSOR", [256, 128, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(8, 1, 1, 1, 8, 1, 1, 1, 64, 3, 3, 1, 32, 1, 1, 1):
                    with T.block("conv2d_NCHWc_update"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(256, i1_2 * 32 + i1_3)
                        oh = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused // 13)
                        ow = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 13)
                        oc_block = T.axis.spatial(4, i4_1)
                        ic = T.axis.reduce(512, i5_0 * 64 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_1, i7_1])
                        T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 128, 15, 15, 4], "float32"], ["TENSOR", [256, 128, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
        for i0_i1_fused in T.parallel(256, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i2 in T.serial(13):
                for i3_i4_fused in T.vectorized(52):
                    with T.block("T_leaky_relu"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1, ax2 = T.axis.remap("SS", [i0_i1_fused, i2])
                        ax3 = T.axis.spatial(13, i3_i4_fused // 4)
                        ax4 = T.axis.spatial(4, i3_i4_fused % 4)
                        T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                        T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 8, 32])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 13, 1, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 13, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 4, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[8, 64])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
sch.enter_postproc()
b64 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.unroll_explicit")
b65, b66 = sch.get_child_blocks(b64)
l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b65)
l93 = sch.fuse(l67, l68, l69, l70, l71, l72, l73, l74, l75)
sch.parallel(loop=l93)
sch.annotate(block_or_loop=l93, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l93, ann_key="pragma_unroll_explicit", ann_val=1)
l94, l95, l96, l97, l98 = sch.get_loops(block=b66)
l99 = sch.fuse(l94, l95)
sch.parallel(loop=l99)
l100 = sch.fuse(l97, l98)
sch.vectorize(loop=l100)
sch.annotate(block_or_loop=l99, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l99, ann_key="pragma_unroll_explicit", ann_val=1)
b101 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b101)
b120 = sch.decompose_reduction(block=b101, loop=l104)
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #3: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 15, 15, 4), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 256, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 256, 13, 13, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused in T.parallel(208, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i1_2_init, i1_3_init, i3_3_init in T.grid(8, 4, 13):
                for i4_3_fused_init in T.vectorized(2):
                    with T.block("conv2d_NCHWc_init"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 16 // 2 * 32 + i1_2_init * 4 + i1_3_init)
                        oh = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 16)
                        ow = T.axis.spatial(13, i3_3_init)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 2 * 2 + i4_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 128, 15, 15, 4], "float32"], ["TENSOR", [256, 128, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
            for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3 in T.grid(256, 1, 1, 1, 8, 1, 1, 1, 2, 3, 3, 1, 4, 1, 13):
                for i4_3_fused in T.vectorized(2):
                    with T.block("conv2d_NCHWc_update"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 16 // 2 * 32 + i1_2 * 4 + i1_3)
                        oh = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 16)
                        ow = T.axis.spatial(13, i3_3)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 2 * 2 + i4_3_fused)
                        ic = T.axis.reduce(512, i5_0 * 2 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_1, i7_1])
                        T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 128, 15, 15, 4], "float32"], ["TENSOR", [256, 128, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
        for i0_i1_fused in T.parallel(256, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i2 in T.serial(13):
                for i3_i4_fused in T.vectorized(52):
                    with T.block("T_leaky_relu"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1, ax2 = T.axis.remap("SS", [i0_i1_fused, i2])
                        ax3 = T.axis.spatial(13, i3_i4_fused // 4)
                        ax4 = T.axis.spatial(4, i3_i4_fused % 4)
                        T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                        T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 8, 8, 4])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[13, 1, 1, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[256, 2])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
sch.enter_postproc()
b64 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.unroll_explicit")
b65, b66 = sch.get_child_blocks(b64)
l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b65)
l93 = sch.fuse(l67, l68, l69, l70, l71, l72, l73, l74, l75, l76)
sch.parallel(loop=l93)
l94 = sch.fuse(l92)
sch.vectorize(loop=l94)
sch.annotate(block_or_loop=l93, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l93, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99 = sch.get_loops(block=b66)
l100 = sch.fuse(l95, l96)
sch.parallel(loop=l100)
l101 = sch.fuse(l98, l99)
sch.vectorize(loop=l101)
sch.annotate(block_or_loop=l100, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l100, ann_key="pragma_unroll_explicit", ann_val=1)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b102)
b120 = sch.decompose_reduction(block=b102, loop=l104)
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #4: GFLOPs: 4.7660. Time: 334.7077 ms. Best GFLOPs: 6.2033
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #5: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 15, 15, 4), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 256, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 256, 13, 13, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_fused in T.parallel(4, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 16, 1, 1, 1):
                for i1_2_init, i3_2_init, i4_2_init, i2_3_init in T.grid(8, 13, 2, 13):
                    with T.block("conv2d_NCHWc_init"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 2 * 128 + i1_1 * 8 + i1_2_init)
                        oh, ow = T.axis.remap("SS", [i2_3_init, i3_2_init])
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 2 * 2 + i4_2_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 128, 15, 15, 4], "float32"], ["TENSOR", [256, 128, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(8, 1, 1, 1, 8, 1, 13, 2, 64, 3, 3, 1, 1, 13, 1, 1):
                    with T.block("conv2d_NCHWc_update"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 2 * 128 + i1_1 * 8 + i1_2)
                        oh, ow = T.axis.remap("SS", [i2_3, i3_2])
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 2 * 2 + i4_2)
                        ic = T.axis.reduce(512, i5_0 * 64 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_1, i7_1])
                        T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 128, 15, 15, 4], "float32"], ["TENSOR", [256, 128, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(1, 128, 13, 13):
                for ax4_fused in T.vectorized(2):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 2 * 128 + ax1)
                        ax2_1, ax3_1 = T.axis.remap("SS", [ax2, ax3])
                        ax4 = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 2 * 2 + ax4_fused)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[2, 16, 8, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 2, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[8, 64])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b67)
l101 = sch.fuse(l100)
sch.vectorize(loop=l101)
sch.annotate(block_or_loop=l95, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l95, ann_key="pragma_unroll_explicit", ann_val=1)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b102)
b125 = sch.decompose_reduction(block=b102, loop=l109)
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #6: GFLOPs: 1.7241. Time: 925.2564 ms. Best GFLOPs: 6.2033
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #7: GFLOPs: 0.8727. Time: 1827.9937 ms. Best GFLOPs: 6.2033
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #8: GFLOPs: 22.1010. Time: 72.1791 ms. Best GFLOPs: 22.1010
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #9: GFLOPs: 12.1756. Time: 131.0187 ms. Best GFLOPs: 22.1010
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #10: GFLOPs: 11.8201. Time: 134.9590 ms. Best GFLOPs: 22.1010
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #11: GFLOPs: 20.4763. Time: 77.9062 ms. Best GFLOPs: 22.1010
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #12: GFLOPs: 1.3230. Time: 1205.7236 ms. Best GFLOPs: 22.1010
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #13: GFLOPs: 4.5018. Time: 354.3549 ms. Best GFLOPs: 22.1010
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #14: GFLOPs: 9.8074. Time: 162.6551 ms. Best GFLOPs: 22.1010
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #15: GFLOPs: 1.0500. Time: 1519.2541 ms. Best GFLOPs: 22.1010
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #16: GFLOPs: 3.3750. Time: 472.6606 ms. Best GFLOPs: 22.1010
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #17: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 15, 15, 4), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 256, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 256, 13, 13, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused in T.parallel(256, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i2_1, i3_1, i4_1 in T.grid(1, 1, 1):
                for i1_2_init, i2_3_init, i3_3_init in T.grid(2, 13, 13):
                    for i4_3_fused_init in T.vectorized(2):
                        with T.block("conv2d_NCHWc_init"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused % 128 * 2 + i1_2_init)
                            oh, ow = T.axis.remap("SS", [i2_3_init, i3_3_init])
                            oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused // 128 * 2 + i4_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 128, 15, 15, 4], "float32"], ["TENSOR", [256, 128, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3 in T.grid(8, 3, 3, 1, 2, 1, 1, 1, 64, 1, 1, 1, 1, 13, 13):
                    for i4_3_fused in T.vectorized(2):
                        with T.block("conv2d_NCHWc_update"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused % 128 * 2 + i1_2)
                            oh, ow = T.axis.remap("SS", [i2_3, i3_3])
                            oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused // 128 * 2 + i4_3_fused)
                            ic = T.axis.reduce(512, i5_0 * 64 + i5_1)
                            kh, kw = T.axis.remap("RR", [i6_0, i7_0])
                            T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 128, 15, 15, 4], "float32"], ["TENSOR", [256, 128, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(1, 2, 13, 13):
                    for ax4_fused in T.vectorized(2):
                        with T.block("T_leaky_relu"):
                            ax0_1 = T.axis.spatial(1, 0)
                            ax1_1 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused % 128 * 2 + ax1)
                            ax2_1, ax3_1 = T.axis.remap("SS", [ax2, ax3])
                            ax4 = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused // 128 * 2 + ax4_fused)
                            T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                            T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4])
                            T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 128, 2, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[8, 64])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, l73, l74)
sch.parallel(loop=l94)
l95 = sch.fuse(l93)
sch.vectorize(loop=l95)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b67)
l105 = sch.fuse(l104)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l96, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l96, ann_key="pragma_unroll_explicit", ann_val=1)
b106 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b106)
b127 = sch.decompose_reduction(block=b106, loop=l111)
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #18: GFLOPs: 2.4682. Time: 646.3109 ms. Best GFLOPs: 22.1010
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #19: GFLOPs: 15.9407. Time: 100.0729 ms. Best GFLOPs: 22.1010
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #20: GFLOPs: 2.7425. Time: 581.6784 ms. Best GFLOPs: 22.1010
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #21: GFLOPs: 4.9146. Time: 324.5897 ms. Best GFLOPs: 22.1010
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #22: GFLOPs: 3.8762. Time: 411.5471 ms. Best GFLOPs: 22.1010
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #23: GFLOPs: 12.7432. Time: 125.1825 ms. Best GFLOPs: 22.1010
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #24: GFLOPs: 2.3718. Time: 672.5925 ms. Best GFLOPs: 22.1010
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #25: GFLOPs: 2.8775. Time: 554.3746 ms. Best GFLOPs: 22.1010
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #26: GFLOPs: 3.5107. Time: 454.3866 ms. Best GFLOPs: 22.1010
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #27: Error in building: LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 15, 15, 4), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 256, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 256, 13, 13, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_fused in T.parallel(4, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 2, 1, 1, 2):
                for i2_2_init, i3_2_init, i4_2_init, i1_3_init in T.grid(13, 13, 2, 32):
                    with T.block("conv2d_NCHWc_init"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i4_0_fused * 64 + i1_1 * 32 + i1_3_init)
                        oh, ow = T.axis.remap("SS", [i2_2_init, i3_2_init])
                        oc_block = T.axis.spatial(4, i4_1 * 2 + i4_2_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 128, 15, 15, 4], "float32"], ["TENSOR", [256, 128, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(128, 1, 3, 1, 1, 13, 13, 2, 4, 3, 1, 1, 32, 1, 1, 1):
                    with T.block("conv2d_NCHWc_update"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i4_0_fused * 64 + i1_1 * 32 + i1_3)
                        oh, ow = T.axis.remap("SS", [i2_2, i3_2])
                        oc_block = T.axis.spatial(4, i4_1 * 2 + i4_2)
                        ic = T.axis.reduce(512, i5_0 * 4 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_1, i7_0])
                        T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 128, 15, 15, 4], "float32"], ["TENSOR", [256, 128, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
            for ax0, ax1, ax2 in T.grid(1, 64, 13):
                for ax3_ax4_fused in T.vectorized(52):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i4_0_fused * 64 + ax1)
                        ax2_1 = T.axis.spatial(13, ax2)
                        ax3 = T.axis.spatial(13, ax3_ax4_fused // 4)
                        ax4 = T.axis.spatial(4, ax3_ax4_fused % 4)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3, ax4])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[4, 2, 1, 32])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 2, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[128, 4])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b67)
l101 = sch.fuse(l99, l100)
sch.vectorize(loop=l101)
sch.annotate(block_or_loop=l95, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l95, ann_key="pragma_unroll_explicit", ann_val=1)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b102)
b125 = sch.decompose_reduction(block=b102, loop=l109)
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #28: GFLOPs: 9.8939. Time: 161.2339 ms. Best GFLOPs: 22.1010
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #29: GFLOPs: 8.1538. Time: 195.6434 ms. Best GFLOPs: 22.1010
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #30: GFLOPs: 6.9170. Time: 230.6253 ms. Best GFLOPs: 22.1010
[01:11:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"] Trial #31: GFLOPs: 2.2512. Time: 708.6055 ms. Best GFLOPs: 22.1010
[01:11:29] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 392
Total latency (us): 320962

[01:11:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_nn_pad_12"] Trial #0: GFLOPs: 0.0000. Time: 6.7526 ms. Best GFLOPs: 0.0000
[01:11:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_nn_pad_12"] Trial #1: GFLOPs: 0.0000. Time: 8.6331 ms. Best GFLOPs: 0.0000
[01:11:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_nn_pad_12"] Trial #2: GFLOPs: 0.0000. Time: 4.7326 ms. Best GFLOPs: 0.0000
[01:11:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_nn_pad_12"] Trial #3: GFLOPs: 0.0000. Time: 6.9326 ms. Best GFLOPs: 0.0000
[01:12:16] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #26: "fused_nn_pad_12"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 396
Total latency (us): 325695

[01:12:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #0: GFLOPs: 8.9855. Time: 355.0285 ms. Best GFLOPs: 8.9855
[01:12:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #1: GFLOPs: 3.7006. Time: 862.0494 ms. Best GFLOPs: 8.9855
[01:12:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #2: GFLOPs: 18.9900. Time: 167.9890 ms. Best GFLOPs: 18.9900
[01:12:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #3: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 15, 15, 4), "float32"], placeholder_1: T.Buffer[(256, 256, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 256, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 256, 13, 13, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_fused in T.parallel(676, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i4_0, i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 1, 4, 1, 1, 4):
                for i1_2_init in T.serial(16):
                    with T.block("conv2d_NCHWc_init"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 169 * 64 + i1_1 * 16 + i1_2_init)
                        oh = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_fused % 169 // 13)
                        ow = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_fused % 13)
                        oc_block = T.axis.spatial(4, i4_1)
                        T.reads()
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 256, 15, 15, 4], "float32"], ["TENSOR", [256, 256, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(16, 3, 3, 1, 16, 1, 1, 1, 64, 1, 1, 1, 1, 1, 1, 1):
                    with T.block("conv2d_NCHWc_update"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 169 * 64 + i1_1 * 16 + i1_2)
                        oh = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_fused % 169 // 13)
                        ow = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_fused % 13)
                        oc_block = T.axis.spatial(4, i4_1)
                        ic = T.axis.reduce(1024, i5_0 * 64 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_0, i7_0])
                        T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 256, 15, 15, 4], "float32"], ["TENSOR", [256, 256, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
        for i0_i1_fused in T.parallel(256, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i2 in T.serial(13):
                for i3_i4_fused in T.vectorized(52):
                    with T.block("T_leaky_relu"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1, ax2 = T.axis.remap("SS", [i0_i1_fused, i2])
                        ax3 = T.axis.spatial(13, i3_i4_fused // 4)
                        ax4 = T.axis.spatial(4, i3_i4_fused % 4)
                        T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                        T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[4, 4, 16, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[13, 1, 1, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[13, 1, 1, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 4, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[16, 64])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
sch.enter_postproc()
b64 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.unroll_explicit")
b65, b66 = sch.get_child_blocks(b64)
l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b65)
l93 = sch.fuse(l67, l68, l69, l70)
sch.parallel(loop=l93)
sch.annotate(block_or_loop=l93, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l93, ann_key="pragma_unroll_explicit", ann_val=1)
l94, l95, l96, l97, l98 = sch.get_loops(block=b66)
l99 = sch.fuse(l94, l95)
sch.parallel(loop=l99)
l100 = sch.fuse(l97, l98)
sch.vectorize(loop=l100)
sch.annotate(block_or_loop=l99, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l99, ann_key="pragma_unroll_explicit", ann_val=1)
b101 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b101)
b125 = sch.decompose_reduction(block=b101, loop=l109)
[01:12:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #4: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 15, 15, 4), "float32"], placeholder_1: T.Buffer[(256, 256, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 256, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 256, 13, 13, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused in T.parallel(32, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i1_3_init, i2_3_init, i3_3_init in T.grid(32, 13, 13):
                with T.block("conv2d_NCHWc_init"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 4 * 32 + i1_3_init)
                    oh, ow = T.axis.remap("SS", [i2_3_init, i3_3_init])
                    oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 4)
                    T.reads()
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 256, 15, 15, 4], "float32"], ["TENSOR", [256, 256, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
            for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(64, 3, 1, 1, 1, 1, 1, 1, 16, 1, 3, 1, 32, 13, 13, 1):
                with T.block("conv2d_NCHWc_update"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 4 * 32 + i1_3)
                    oh, ow = T.axis.remap("SS", [i2_3, i3_3])
                    oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 4)
                    ic = T.axis.reduce(1024, i5_0 * 16 + i5_1)
                    kh, kw = T.axis.remap("RR", [i6_0, i7_1])
                    T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 256, 15, 15, 4], "float32"], ["TENSOR", [256, 256, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 32, 13, 13, 1):
                with T.block("T_leaky_relu"):
                    ax0_1 = T.axis.spatial(1, 0)
                    ax1_1 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 4 * 32 + ax1)
                    ax2_1, ax3_1 = T.axis.remap("SS", [ax2, ax3])
                    ax4_1 = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 4)
                    T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1])
                    T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                    T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[8, 1, 1, 32])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 4, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[64, 16])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, l73, l74, l75, l76, l77)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b67)
sch.annotate(block_or_loop=l95, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l95, ann_key="pragma_unroll_explicit", ann_val=1)
b101 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b101)
b119 = sch.decompose_reduction(block=b101, loop=l103)
[01:12:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #5: GFLOPs: 41.6171. Time: 76.6540 ms. Best GFLOPs: 41.6171
[01:12:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #6: GFLOPs: 12.1768. Time: 261.9836 ms. Best GFLOPs: 41.6171
[01:12:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #7: GFLOPs: 2.7282. Time: 1169.3195 ms. Best GFLOPs: 41.6171
[01:12:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #8: GFLOPs: 3.0697. Time: 1039.2327 ms. Best GFLOPs: 41.6171
[01:12:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #9: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 15, 15, 4), "float32"], placeholder_1: T.Buffer[(256, 256, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 256, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 256, 13, 13, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused in T.parallel(416, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3_1, i4_1 in T.grid(1, 1):
                for i1_2_init, i3_2_init in T.grid(32, 13):
                    with T.block("conv2d_NCHWc_init"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 104 // 13 * 32 + i1_2_init)
                        oh = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 13)
                        ow = T.axis.spatial(13, i3_2_init)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused // 104)
                        T.reads()
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 256, 15, 15, 4], "float32"], ["TENSOR", [256, 256, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(32, 1, 1, 1, 32, 1, 13, 1, 32, 3, 3, 1, 1, 1, 1, 1):
                    with T.block("conv2d_NCHWc_update"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 104 // 13 * 32 + i1_2)
                        oh = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 13)
                        ow = T.axis.spatial(13, i3_2)
                        oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused // 104)
                        ic = T.axis.reduce(1024, i5_0 * 32 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_1, i7_1])
                        T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 256, 15, 15, 4], "float32"], ["TENSOR", [256, 256, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 32, 1, 13, 1):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 104 // 13 * 32 + ax1)
                        ax2_1 = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused % 13)
                        ax3_1 = T.axis.spatial(13, ax3)
                        ax4_1 = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_fused // 104)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1], placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4_1]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 8, 32, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 13, 1, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[32, 32])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, l73, l74, l75)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b67)
sch.annotate(block_or_loop=l95, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l95, ann_key="pragma_unroll_explicit", ann_val=1)
b103 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122 = sch.get_loops(block=b103)
b123 = sch.decompose_reduction(block=b103, loop=l107)
[01:12:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #10: GFLOPs: 0.9920. Time: 3215.9882 ms. Best GFLOPs: 41.6171
[01:12:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #11: GFLOPs: 4.7192. Time: 675.9921 ms. Best GFLOPs: 41.6171
[01:12:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #12: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 15, 15, 4), "float32"], placeholder_1: T.Buffer[(256, 256, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 256, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 256, 13, 13, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused in T.parallel(128, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i1_2_init, i2_3_init, i3_3_init in T.grid(8, 13, 13):
                with T.block("conv2d_NCHWc_init"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 32 * 8 + i1_2_init)
                    oh, ow = T.axis.remap("SS", [i2_3_init, i3_3_init])
                    oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 32)
                    T.reads()
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 256, 15, 15, 4], "float32"], ["TENSOR", [256, 256, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
            for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(64, 1, 3, 1, 8, 1, 1, 1, 16, 3, 1, 1, 1, 13, 13, 1):
                with T.block("conv2d_NCHWc_update"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 32 * 8 + i1_2)
                    oh, ow = T.axis.remap("SS", [i2_3, i3_3])
                    oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 32)
                    ic = T.axis.reduce(1024, i5_0 * 16 + i5_1)
                    kh, kw = T.axis.remap("RR", [i6_1, i7_0])
                    T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 256, 15, 15, 4], "float32"], ["TENSOR", [256, 256, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
        for i0_i1_fused in T.parallel(256, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i2 in T.serial(13):
                for i3_i4_fused in T.vectorized(52):
                    with T.block("T_leaky_relu"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1, ax2 = T.axis.remap("SS", [i0_i1_fused, i2])
                        ax3 = T.axis.spatial(13, i3_i4_fused // 4)
                        ax4 = T.axis.spatial(4, i3_i4_fused % 4)
                        T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                        T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 32, 8, 1])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 1, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[64, 16])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
sch.enter_postproc()
b64 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.unroll_explicit")
b65, b66 = sch.get_child_blocks(b64)
l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b65)
l93 = sch.fuse(l67, l68, l69, l70, l71, l72, l73, l74, l75, l76)
sch.parallel(loop=l93)
sch.annotate(block_or_loop=l93, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l93, ann_key="pragma_unroll_explicit", ann_val=1)
l94, l95, l96, l97, l98 = sch.get_loops(block=b66)
l99 = sch.fuse(l94, l95)
sch.parallel(loop=l99)
l100 = sch.fuse(l97, l98)
sch.vectorize(loop=l100)
sch.annotate(block_or_loop=l99, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l99, ann_key="pragma_unroll_explicit", ann_val=1)
b101 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b101)
b119 = sch.decompose_reduction(block=b101, loop=l103)
[01:12:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #13: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 15, 15, 4), "float32"], placeholder_1: T.Buffer[(256, 256, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 256, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 256, 13, 13, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused in T.parallel(4, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i1_2_init, i2_2_init, i3_2_init, i4_2_init, i1_3_init in T.grid(32, 13, 13, 4, 2):
                with T.block("conv2d_NCHWc_init"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 2 * 128 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 2 * 64 + i1_2_init * 2 + i1_3_init)
                    oh, ow, oc_block = T.axis.remap("SSS", [i2_2_init, i3_2_init, i4_2_init])
                    T.reads()
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 256, 15, 15, 4], "float32"], ["TENSOR", [256, 256, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
            for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(32, 1, 3, 1, 32, 13, 13, 4, 32, 3, 1, 1, 2, 1, 1, 1):
                with T.block("conv2d_NCHWc_update"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 2 * 128 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 2 * 64 + i1_2 * 2 + i1_3)
                    oh, ow, oc_block = T.axis.remap("SSS", [i2_2, i3_2, i4_2])
                    ic = T.axis.reduce(1024, i5_0 * 32 + i5_1)
                    kh, kw = T.axis.remap("RR", [i6_1, i7_0])
                    T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 256, 15, 15, 4], "float32"], ["TENSOR", [256, 256, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
        for i0_i1_fused in T.parallel(256, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i2 in T.serial(13):
                for i3_i4_fused in T.vectorized(52):
                    with T.block("T_leaky_relu"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1, ax2 = T.axis.remap("SS", [i0_i1_fused, i2])
                        ax3 = T.axis.spatial(13, i3_i4_fused // 4)
                        ax4 = T.axis.spatial(4, i3_i4_fused % 4)
                        T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0, ax1, ax2, ax3, ax4])
                        T_leaky_relu[ax0, ax1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4], (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[2, 2, 32, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 4, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[32, 32])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
sch.enter_postproc()
b64 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.unroll_explicit")
b65, b66 = sch.get_child_blocks(b64)
l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b65)
l93 = sch.fuse(l67, l68, l69, l70, l71, l72, l73, l74, l75, l76)
sch.parallel(loop=l93)
sch.annotate(block_or_loop=l93, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l93, ann_key="pragma_unroll_explicit", ann_val=1)
l94, l95, l96, l97, l98 = sch.get_loops(block=b66)
l99 = sch.fuse(l94, l95)
sch.parallel(loop=l99)
l100 = sch.fuse(l97, l98)
sch.vectorize(loop=l100)
sch.annotate(block_or_loop=l99, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l99, ann_key="pragma_unroll_explicit", ann_val=1)
b101 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b101)
b119 = sch.decompose_reduction(block=b101, loop=l103)
[01:12:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #14: GFLOPs: 7.6197. Time: 418.6664 ms. Best GFLOPs: 41.6171
[01:12:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #15: GFLOPs: 5.0076. Time: 637.0514 ms. Best GFLOPs: 41.6171
[01:12:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #16: GFLOPs: 4.7290. Time: 674.5827 ms. Best GFLOPs: 41.6171
[01:12:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #17: GFLOPs: 3.0034. Time: 1062.1825 ms. Best GFLOPs: 41.6171
[01:12:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #18: GFLOPs: 1.3070. Time: 2440.8296 ms. Best GFLOPs: 41.6171
[01:12:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #19: GFLOPs: 4.4869. Time: 710.9847 ms. Best GFLOPs: 41.6171
[01:12:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #20: Error in building: LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 15, 15, 4), "float32"], placeholder_1: T.Buffer[(256, 256, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 256, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 256, 13, 13, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused in T.parallel(8, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i1_2_init, i2_2_init, i3_2_init, i4_2_init, i1_3_init in T.grid(2, 13, 13, 2, 32):
                with T.block("conv2d_NCHWc_init"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 2 * 64 + i1_2_init * 32 + i1_3_init)
                    oh, ow = T.axis.remap("SS", [i2_2_init, i3_2_init])
                    oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 2 * 2 + i4_2_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 256, 15, 15, 4], "float32"], ["TENSOR", [256, 256, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
            for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(512, 3, 3, 1, 2, 13, 13, 2, 2, 1, 1, 1, 32, 1, 1, 1):
                with T.block("conv2d_NCHWc_update"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 2 * 64 + i1_2 * 32 + i1_3)
                    oh, ow = T.axis.remap("SS", [i2_2, i3_2])
                    oc_block = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 2 * 2 + i4_2)
                    ic = T.axis.reduce(1024, i5_0 * 2 + i5_1)
                    kh, kw = T.axis.remap("RR", [i6_0, i7_0])
                    T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 256, 15, 15, 4], "float32"], ["TENSOR", [256, 256, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(1, 64, 13, 13):
                for ax4_fused in T.vectorized(2):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 2 * 64 + ax1)
                        ax2_1, ax3_1 = T.axis.remap("SS", [ax2, ax3])
                        ax4 = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 2 * 2 + ax4_fused)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4])
                        T_leaky_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], (conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[4, 1, 2, 32])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 2, 1])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[512, 2])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, l73, l74, l75, l76, l77)
sch.parallel(loop=l94)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b67)
l101 = sch.fuse(l100)
sch.vectorize(loop=l101)
sch.annotate(block_or_loop=l95, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l95, ann_key="pragma_unroll_explicit", ann_val=1)
b102 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b102)
b120 = sch.decompose_reduction(block=b102, loop=l104)
[01:12:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #21: GFLOPs: 2.9108. Time: 1095.9701 ms. Best GFLOPs: 41.6171
[01:12:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #22: GFLOPs: 3.4297. Time: 930.1332 ms. Best GFLOPs: 41.6171
[01:12:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #23: GFLOPs: 2.2551. Time: 1414.6533 ms. Best GFLOPs: 41.6171
[01:12:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #24: GFLOPs: 2.5159. Time: 1267.9924 ms. Best GFLOPs: 41.6171
[01:12:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #25: GFLOPs: 3.1254. Time: 1020.6898 ms. Best GFLOPs: 41.6171
[01:12:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #26: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 15, 15, 4), "float32"], placeholder_1: T.Buffer[(256, 256, 3, 3, 4, 4), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1, 4), "float32"], T_leaky_relu: T.Buffer[(1, 256, 13, 13, 4), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 256, 13, 13, 4], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused in T.parallel(52, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i1_2_init, i3_2_init, i4_2_init, i1_3_init in T.grid(32, 13, 2, 2):
                for i2_3_i3_3_i4_3_fused_init in T.vectorized(2):
                    with T.block("conv2d_NCHWc_init"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 26 * 128 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 26 // 13 * 64 + i1_2_init * 2 + i1_3_init)
                        oh = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 13)
                        ow = T.axis.spatial(13, i3_2_init)
                        oc_block = T.axis.spatial(4, i4_2_init * 2 + i2_3_i3_3_i4_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 256, 15, 15, 4], "float32"], ["TENSOR", [256, 256, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
            for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3 in T.grid(128, 3, 3, 1, 32, 1, 13, 2, 8, 1, 1, 1, 2):
                for i2_3_i3_3_i4_3_fused in T.vectorized(2):
                    with T.block("conv2d_NCHWc_update"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 26 * 128 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 26 // 13 * 64 + i1_2 * 2 + i1_3)
                        oh = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 13)
                        ow = T.axis.spatial(13, i3_2)
                        oc_block = T.axis.spatial(4, i4_2 * 2 + i2_3_i3_3_i4_3_fused)
                        ic = T.axis.reduce(1024, i5_0 * 8 + i5_1)
                        kh, kw = T.axis.remap("RR", [i6_0, i7_0])
                        T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4], placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 256, 15, 15, 4], "float32"], ["TENSOR", [256, 256, 3, 3, 4, 4], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW4c", "NCHW4c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 4, oh + kh, ow + kw, ic % 4] * placeholder_1[oc_chunk, ic // 4, kh, kw, ic % 4, oc_block]
            for ax0, ax1 in T.grid(1, 64):
                for ax2_ax3_ax4_fused in T.vectorized(52):
                    with T.block("T_leaky_relu"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 26 * 128 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 26 // 13 * 64 + ax1)
                        ax2 = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 13)
                        ax3 = T.axis.spatial(13, ax2_ax3_ax4_fused // 4)
                        ax4 = T.axis.spatial(4, ax2_ax3_ax4_fused % 4)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2, ax3, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                        T.writes(T_leaky_relu[ax0_1, ax1_1, ax2, ax3, ax4])
                        T_leaky_relu[ax0_1, ax1_1, ax2, ax3, ax4] = T.Select(T.float32(0) < conv2d_NCHWc[ax0_1, ax1_1, ax2, ax3, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], conv2d_NCHWc[ax0_1, ax1_1, ax2, ax3, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], (conv2d_NCHWc[ax0_1, ax1_1, ax2, ax3, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)
v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])
v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[2, 2, 32, 2])
l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])
v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 13, 1, 1])
l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])
v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])
v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 2, 2])
l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])
v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[128, 8])
l53, l54 = sch.split(loop=l8, factors=[v51, v52])
v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l57, l58 = sch.split(loop=l9, factors=[v55, v56])
v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l61, l62 = sch.split(loop=l10, factors=[v59, v60])
sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)
b63, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
sch.enter_postproc()
b65 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b65, ann_key="meta_schedule.unroll_explicit")
b66, b67 = sch.get_child_blocks(b65)
l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)
l94 = sch.fuse(l68, l69, l70, l71, l72, l73, l74, l75, l76, l77)
sch.parallel(loop=l94)
l95 = sch.fuse(l91, l92, l93)
sch.vectorize(loop=l95)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b67)
l102 = sch.fuse(l99, l100, l101)
sch.vectorize(loop=l102)
sch.annotate(block_or_loop=l96, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l96, ann_key="pragma_unroll_explicit", ann_val=1)
b103 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b103)
b119 = sch.decompose_reduction(block=b103, loop=l105)
[01:12:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #27: GFLOPs: 2.1325. Time: 1495.9660 ms. Best GFLOPs: 41.6171
[01:12:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #28: GFLOPs: 24.6663. Time: 129.3311 ms. Best GFLOPs: 41.6171
[01:12:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #29: GFLOPs: 3.8034. Time: 838.7563 ms. Best GFLOPs: 41.6171
[01:12:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #30: GFLOPs: 6.6113. Time: 482.5249 ms. Best GFLOPs: 41.6171
[01:12:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"] Trial #31: GFLOPs: 4.7831. Time: 666.9589 ms. Best GFLOPs: 41.6171
[01:12:46] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 428
Total latency (us): 402349

[01:12:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_pad_layout_transform"] Trial #0: GFLOPs: 0.0000. Time: 6.7263 ms. Best GFLOPs: 0.0000
[01:12:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #28: "fused_nn_pad_layout_transform"] Trial #1: Error in building: LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 13, 13, 4), "float32"], T_layout_trans: T.Buffer[(1, 1024, 13, 13, 1), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        for i0_i1_fused in T.parallel(1024, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i2, i3, i4 in T.grid(13, 13, 1):
                with T.block("T_layout_trans"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1, ax2, ax3 = T.axis.remap("SSS", [i0_i1_fused, i2, i3])
                    ax4 = T.axis.spatial(1, 0)
                    T.reads(placeholder[ax0, (ax1 + ax4) // 4, ax2, ax3, (ax1 + ax4) % 4])
                    T.writes(T_layout_trans[ax0, ax1, ax2, ax3, ax4])
                    T_layout_trans[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(ax0 < 1 and ax1 + ax4 < 1024 and ax2 < 13 and ax3 < 13, placeholder[ax0, (ax1 + ax4) // 4, ax2, ax3, (ax1 + ax4) % 4], T.float32(0), dtype="float32")
    

b0 = sch.get_block(name="T_pad", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b0)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v2 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v2)
sch.enter_postproc()
b3 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b3, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b3, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit")
b4, = sch.get_child_blocks(b3)
l5, l6, l7, l8, l9 = sch.get_loops(block=b4)
l10 = sch.fuse(l5, l6)
sch.parallel(loop=l10)
sch.annotate(block_or_loop=l10, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l10, ann_key="pragma_unroll_explicit", ann_val=1)
[01:12:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_pad_layout_transform"] Trial #2: GFLOPs: 0.0000. Time: 6.0939 ms. Best GFLOPs: 0.0000
[01:12:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_pad_layout_transform"] Trial #3: GFLOPs: 0.0000. Time: 6.2808 ms. Best GFLOPs: 0.0000
[01:13:05] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #28: "fused_nn_pad_layout_transform"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |            N/A |          N/A |                   N/A |      0 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 432
Total latency (us): 408443

[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #0: GFLOPs: 1.9048. Time: 22.7246 ms. Best GFLOPs: 1.9048
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #1: GFLOPs: 1.1596. Time: 37.3266 ms. Best GFLOPs: 1.9048
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #2: GFLOPs: 2.9858. Time: 14.4971 ms. Best GFLOPs: 2.9858
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #3: GFLOPs: 3.8403. Time: 11.2713 ms. Best GFLOPs: 3.8403
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #4: GFLOPs: 1.8038. Time: 23.9961 ms. Best GFLOPs: 3.8403
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #5: GFLOPs: 1.4431. Time: 29.9948 ms. Best GFLOPs: 3.8403
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #6: GFLOPs: 0.4326. Time: 100.0507 ms. Best GFLOPs: 3.8403
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #7: GFLOPs: 2.4793. Time: 17.4585 ms. Best GFLOPs: 3.8403
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #8: GFLOPs: 1.3528. Time: 31.9976 ms. Best GFLOPs: 3.8403
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #9: GFLOPs: 0.6538. Time: 66.2022 ms. Best GFLOPs: 3.8403
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #10: GFLOPs: 4.2520. Time: 10.1800 ms. Best GFLOPs: 4.2520
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #11: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1024, 13, 13, 1), "float32"], placeholder_1: T.Buffer[(125, 1024, 1, 1, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 125, 1, 1, 1), "float32"], T_add: T.Buffer[(1, 125, 13, 13, 1), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 125, 13, 13, 1], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused in T.parallel(25, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i1_2_init, i2_2_init, i3_2_init in T.grid(5, 13, 13):
                with T.block("conv2d_NCHWc_init"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(125, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 5 * 25 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 5 * 5 + i1_2_init)
                    oh, ow = T.axis.remap("SS", [i2_2_init, i3_2_init])
                    oc_block = T.axis.spatial(1, 0)
                    T.reads()
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1024, 13, 13, 1], "float32"], ["TENSOR", [125, 1024, 1, 1, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW1c", "NCHW1c", "float32"]})
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
            for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(512, 1, 1, 1, 5, 13, 13, 1, 2, 1, 1, 1, 1, 1, 1, 1):
                with T.block("conv2d_NCHWc_update"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(125, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 5 * 25 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 5 * 5 + i1_2)
                    oh, ow = T.axis.remap("SS", [i2_2, i3_2])
                    oc_block = T.axis.spatial(1, 0)
                    ic = T.axis.reduce(1024, i5_0 * 2 + i5_1)
                    kh = T.axis.reduce(1, 0)
                    kw = T.axis.reduce(1, 0)
                    T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic, oh + kh, ow + kw, 0], placeholder_1[oc_chunk, ic, kh, kw, 0, oc_block])
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1024, 13, 13, 1], "float32"], ["TENSOR", [125, 1024, 1, 1, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW1c", "NCHW1c", "float32"]})
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic, oh + kh, ow + kw, 0] * placeholder_1[oc_chunk, ic, kh, kw, 0, oc_block]
        for i0_i1_i2_fused in T.parallel(1625, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3_i4_fused in T.vectorized(13):
                with T.block("T_add"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(125, i0_i1_i2_fused // 13)
                    ax2 = T.axis.spatial(13, i0_i1_i2_fused % 13)
                    ax3 = T.axis.spatial(13, i3_i4_fused)
                    ax4 = T.axis.spatial(1, 0)
                    T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                    T.writes(T_add[ax0, ax1, ax2, ax3, ax4])
                    T_add[ax0, ax1, ax2, ax3, ax4] = conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b0)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l2, factors=[v10, v11, v12, v13])
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[5, 5, 5, 1])
l22, l23, l24, l25 = sch.split(loop=l3, factors=[v18, v19, v20, v21])
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l30, l31, l32, l33 = sch.split(loop=l4, factors=[v26, v27, v28, v29])
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l38, l39, l40, l41 = sch.split(loop=l5, factors=[v34, v35, v36, v37])
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l46, l47, l48, l49 = sch.split(loop=l6, factors=[v42, v43, v44, v45])
v50, v51 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[512, 2])
l52, l53 = sch.split(loop=l7, factors=[v50, v51])
v54, v55 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])
l56, l57 = sch.split(loop=l8, factors=[v54, v55])
v58, v59 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l60, l61 = sch.split(loop=l9, factors=[v58, v59])
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l60, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v62 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v62)
sch.enter_postproc()
b63 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b63, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b63, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b63, ann_key="meta_schedule.unroll_explicit")
b64, b65 = sch.get_child_blocks(b63)
l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91 = sch.get_loops(block=b64)
l92 = sch.fuse(l66, l67, l68, l69, l70, l71, l72, l73, l74, l75)
sch.parallel(loop=l92)
sch.annotate(block_or_loop=l92, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l92, ann_key="pragma_unroll_explicit", ann_val=1)
l93, l94, l95, l96, l97 = sch.get_loops(block=b65)
l98 = sch.fuse(l93, l94, l95)
sch.parallel(loop=l98)
l99 = sch.fuse(l96, l97)
sch.vectorize(loop=l99)
sch.annotate(block_or_loop=l98, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l98, ann_key="pragma_unroll_explicit", ann_val=1)
b100 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b100)
b118 = sch.decompose_reduction(block=b100, loop=l102)
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #12: GFLOPs: 2.0949. Time: 20.6618 ms. Best GFLOPs: 4.2520
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #13: GFLOPs: 0.2517. Time: 171.9905 ms. Best GFLOPs: 4.2520
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #14: GFLOPs: 3.7888. Time: 11.4245 ms. Best GFLOPs: 4.2520
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #15: GFLOPs: 0.8325. Time: 51.9936 ms. Best GFLOPs: 4.2520
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #16: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1024, 13, 13, 1), "float32"], placeholder_1: T.Buffer[(125, 1024, 1, 1, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 125, 1, 1, 1), "float32"], T_add: T.Buffer[(1, 125, 13, 13, 1), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 125, 13, 13, 1], dtype="float32")
        for i0_0 in T.serial(1, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i1_0, i2_0, i3_0, i4_0, i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 1, 1, 1, 1, 1, 1, 1, 1):
                for i1_2_init, i1_3_init, i2_3_init in T.grid(5, 25, 13):
                    for i3_3_i4_3_fused_init in T.vectorized(13):
                        with T.block("conv2d_NCHWc_init"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(125, i1_2_init * 25 + i1_3_init)
                            oh, ow = T.axis.remap("SS", [i2_3_init, i3_3_i4_3_fused_init])
                            oc_block = T.axis.spatial(1, 0)
                            T.reads()
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1024, 13, 13, 1], "float32"], ["TENSOR", [125, 1024, 1, 1, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW1c", "NCHW1c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3 in T.grid(512, 1, 1, 1, 5, 1, 1, 1, 2, 1, 1, 1, 25, 13):
                    for i3_3_i4_3_fused in T.vectorized(13):
                        with T.block("conv2d_NCHWc_update"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(125, i1_2 * 25 + i1_3)
                            oh, ow = T.axis.remap("SS", [i2_3, i3_3_i4_3_fused])
                            oc_block = T.axis.spatial(1, 0)
                            ic = T.axis.reduce(1024, i5_0 * 2 + i5_1)
                            kh = T.axis.reduce(1, 0)
                            kw = T.axis.reduce(1, 0)
                            T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic, oh + kh, ow + kw, 0], placeholder_1[oc_chunk, ic, kh, kw, 0, oc_block])
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1024, 13, 13, 1], "float32"], ["TENSOR", [125, 1024, 1, 1, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW1c", "NCHW1c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic, oh + kh, ow + kw, 0] * placeholder_1[oc_chunk, ic, kh, kw, 0, oc_block]
        for i0_i1_i2_fused in T.parallel(1625, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3_i4_fused in T.vectorized(13):
                with T.block("T_add"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(125, i0_i1_i2_fused // 13)
                    ax2 = T.axis.spatial(13, i0_i1_i2_fused % 13)
                    ax3 = T.axis.spatial(13, i3_i4_fused)
                    ax4 = T.axis.spatial(1, 0)
                    T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                    T.writes(T_add[ax0, ax1, ax2, ax3, ax4])
                    T_add[ax0, ax1, ax2, ax3, ax4] = conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b0)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l2, factors=[v10, v11, v12, v13])
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 5, 25])
l22, l23, l24, l25 = sch.split(loop=l3, factors=[v18, v19, v20, v21])
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l30, l31, l32, l33 = sch.split(loop=l4, factors=[v26, v27, v28, v29])
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l38, l39, l40, l41 = sch.split(loop=l5, factors=[v34, v35, v36, v37])
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l46, l47, l48, l49 = sch.split(loop=l6, factors=[v42, v43, v44, v45])
v50, v51 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[512, 2])
l52, l53 = sch.split(loop=l7, factors=[v50, v51])
v54, v55 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])
l56, l57 = sch.split(loop=l8, factors=[v54, v55])
v58, v59 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l60, l61 = sch.split(loop=l9, factors=[v58, v59])
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l60, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v62 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v62)
sch.enter_postproc()
b63 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b63, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b63, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b63, ann_key="meta_schedule.unroll_explicit")
b64, b65 = sch.get_child_blocks(b63)
l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91 = sch.get_loops(block=b64)
l92 = sch.fuse(l90, l91)
sch.vectorize(loop=l92)
sch.annotate(block_or_loop=l66, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l66, ann_key="pragma_unroll_explicit", ann_val=1)
l93, l94, l95, l96, l97 = sch.get_loops(block=b65)
l98 = sch.fuse(l93, l94, l95)
sch.parallel(loop=l98)
l99 = sch.fuse(l96, l97)
sch.vectorize(loop=l99)
sch.annotate(block_or_loop=l98, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l98, ann_key="pragma_unroll_explicit", ann_val=1)
b100 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b100)
b126 = sch.decompose_reduction(block=b100, loop=l111)
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #17: GFLOPs: 3.9384. Time: 10.9905 ms. Best GFLOPs: 4.2520
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #18: GFLOPs: 2.3689. Time: 18.2722 ms. Best GFLOPs: 4.2520
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #19: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1024, 13, 13, 1), "float32"], placeholder_1: T.Buffer[(125, 1024, 1, 1, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 125, 1, 1, 1), "float32"], T_add: T.Buffer[(1, 125, 13, 13, 1), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 125, 13, 13, 1], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused in T.parallel(65, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i1_2_init, i3_2_init in T.grid(25, 13):
                with T.block("conv2d_NCHWc_init"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(125, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 13 * 25 + i1_2_init)
                    oh = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 13)
                    ow = T.axis.spatial(13, i3_2_init)
                    oc_block = T.axis.spatial(1, 0)
                    T.reads()
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1024, 13, 13, 1], "float32"], ["TENSOR", [125, 1024, 1, 1, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW1c", "NCHW1c", "float32"]})
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
            for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(32, 1, 1, 1, 25, 1, 13, 1, 32, 1, 1, 1, 1, 1, 1, 1):
                with T.block("conv2d_NCHWc_update"):
                    n = T.axis.spatial(1, 0)
                    oc_chunk = T.axis.spatial(125, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 13 * 25 + i1_2)
                    oh = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 13)
                    ow = T.axis.spatial(13, i3_2)
                    oc_block = T.axis.spatial(1, 0)
                    ic = T.axis.reduce(1024, i5_0 * 32 + i5_1)
                    kh = T.axis.reduce(1, 0)
                    kw = T.axis.reduce(1, 0)
                    T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic, oh + kh, ow + kw, 0], placeholder_1[oc_chunk, ic, kh, kw, 0, oc_block])
                    T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1024, 13, 13, 1], "float32"], ["TENSOR", [125, 1024, 1, 1, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW1c", "NCHW1c", "float32"]})
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic, oh + kh, ow + kw, 0] * placeholder_1[oc_chunk, ic, kh, kw, 0, oc_block]
            for ax0, ax1 in T.grid(1, 25):
                for ax2_ax3_ax4_fused in T.vectorized(13):
                    with T.block("T_add"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1 = T.axis.spatial(125, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 13 * 25 + ax1)
                        ax2 = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 13)
                        ax3 = T.axis.spatial(13, ax2_ax3_ax4_fused)
                        ax4 = T.axis.spatial(1, 0)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2, ax3, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                        T.writes(T_add[ax0_1, ax1_1, ax2, ax3, ax4])
                        T_add[ax0_1, ax1_1, ax2, ax3, ax4] = conv2d_NCHWc[ax0_1, ax1_1, ax2, ax3, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4]
    

b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b0)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l2, factors=[v10, v11, v12, v13])
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[5, 1, 25, 1])
l22, l23, l24, l25 = sch.split(loop=l3, factors=[v18, v19, v20, v21])
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 13, 1, 1])
l30, l31, l32, l33 = sch.split(loop=l4, factors=[v26, v27, v28, v29])
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l38, l39, l40, l41 = sch.split(loop=l5, factors=[v34, v35, v36, v37])
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l46, l47, l48, l49 = sch.split(loop=l6, factors=[v42, v43, v44, v45])
v50, v51 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[32, 32])
l52, l53 = sch.split(loop=l7, factors=[v50, v51])
v54, v55 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])
l56, l57 = sch.split(loop=l8, factors=[v54, v55])
v58, v59 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l60, l61 = sch.split(loop=l9, factors=[v58, v59])
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l60, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49)
b62, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b62, loop=l47, preserve_unit_loops=True)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
sch.enter_postproc()
b64 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b64, ann_key="meta_schedule.unroll_explicit")
b65, b66 = sch.get_child_blocks(b64)
l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b65)
l93 = sch.fuse(l67, l68, l69, l70, l71, l72, l73, l74, l75, l76)
sch.parallel(loop=l93)
sch.annotate(block_or_loop=l93, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l93, ann_key="pragma_unroll_explicit", ann_val=1)
l94, l95, l96, l97, l98, l99 = sch.get_loops(block=b66)
l100 = sch.fuse(l97, l98, l99)
sch.vectorize(loop=l100)
sch.annotate(block_or_loop=l94, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l94, ann_key="pragma_unroll_explicit", ann_val=1)
b101 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b101)
b119 = sch.decompose_reduction(block=b101, loop=l103)
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #20: GFLOPs: 1.8823. Time: 22.9961 ms. Best GFLOPs: 4.2520
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #21: GFLOPs: 4.9077. Time: 8.8199 ms. Best GFLOPs: 4.9077
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #22: GFLOPs: 1.5151. Time: 28.5695 ms. Best GFLOPs: 4.9077
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #23: GFLOPs: 4.7883. Time: 9.0398 ms. Best GFLOPs: 4.9077
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #24: GFLOPs: 4.4091. Time: 9.8173 ms. Best GFLOPs: 4.9077
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #25: GFLOPs: 3.9673. Time: 10.9104 ms. Best GFLOPs: 4.9077
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #26: GFLOPs: 0.7916. Time: 54.6810 ms. Best GFLOPs: 4.9077
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #27: GFLOPs: 1.6399. Time: 26.3954 ms. Best GFLOPs: 4.9077
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #28: GFLOPs: 4.2522. Time: 10.1796 ms. Best GFLOPs: 4.9077
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #29: GFLOPs: 2.4053. Time: 17.9960 ms. Best GFLOPs: 4.9077
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #30: GFLOPs: 4.0623. Time: 10.6554 ms. Best GFLOPs: 4.9077
[01:13:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_contrib_conv2d_NCHWc_add"] Trial #31: GFLOPs: 3.5017. Time: 12.3611 ms. Best GFLOPs: 4.9077
[01:13:41] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #29: "fused_nn_contrib_conv2d_NCHWc_add"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |            
 30 |                            fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 464
Total latency (us): 417263

[01:13:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #30: "fused_layout_transform"] Trial #0: Error in building: LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 125, 13, 13, 1), "float32"], T_layout_trans: T.Buffer[(1, 125, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        for i0_i1_fused in T.parallel(125, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i2 in T.serial(13):
                for i3_fused in T.vectorized(13):
                    with T.block("T_layout_trans"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1, ax2, ax3 = T.axis.remap("SSS", [i0_i1_fused, i2, i3_fused])
                        T.reads(placeholder[ax0, ax1, ax2, ax3, 0])
                        T.writes(T_layout_trans[ax0, ax1, ax2, ax3])
                        T_layout_trans[ax0, ax1, ax2, ax3] = T.if_then_else(ax0 < 1 and ax1 < 125 and ax2 < 13 and ax3 < 13, placeholder[ax0, ax1, ax2, ax3, 0], T.float32(0), dtype="float32")
    

b0 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.parallel", ann_val=1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.vectorize", ann_val=64)
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
sch.enter_postproc()
b2 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit")
b3, = sch.get_child_blocks(b2)
l4, l5, l6, l7 = sch.get_loops(block=b3)
l8 = sch.fuse(l4, l5)
sch.parallel(loop=l8)
l9 = sch.fuse(l7)
sch.vectorize(loop=l9)
sch.annotate(block_or_loop=l8, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l8, ann_key="pragma_unroll_explicit", ann_val=1)
[01:13:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_layout_transform"] Trial #1: GFLOPs: 0.0000. Time: 6.4355 ms. Best GFLOPs: 0.0000
[01:13:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_layout_transform"] Trial #2: GFLOPs: 0.0000. Time: 1.5576 ms. Best GFLOPs: 0.0000
[01:13:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_layout_transform"] Trial #3: GFLOPs: 0.0000. Time: 3.1124 ms. Best GFLOPs: 0.0000
[01:13:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_layout_transform"] Trial #4: GFLOPs: 0.0000. Time: 1.9622 ms. Best GFLOPs: 0.0000
[01:13:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_layout_transform"] Trial #5: GFLOPs: 0.0000. Time: 2.3337 ms. Best GFLOPs: 0.0000
[01:13:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_layout_transform"] Trial #6: GFLOPs: 0.0000. Time: 1.4797 ms. Best GFLOPs: 0.0000
[01:13:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #30: "fused_layout_transform"] Trial #7: Error in building: LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 125, 13, 13, 1), "float32"], T_layout_trans: T.Buffer[(1, 125, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        for i0_i1_i2_fused in T.parallel(1625):
            for i3_fused in T.vectorized(13):
                with T.block("T_layout_trans"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(125, i0_i1_i2_fused // 13)
                    ax2 = T.axis.spatial(13, i0_i1_i2_fused % 13)
                    ax3 = T.axis.spatial(13, i3_fused)
                    T.reads(placeholder[ax0, ax1, ax2, ax3, 0])
                    T.writes(T_layout_trans[ax0, ax1, ax2, ax3])
                    T_layout_trans[ax0, ax1, ax2, ax3] = T.if_then_else(ax0 < 1 and ax1 < 125 and ax2 < 13 and ax3 < 13, placeholder[ax0, ax1, ax2, ax3, 0], T.float32(0), dtype="float32")
    

b0 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.vectorize", ann_val=64)
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
sch.enter_postproc()
b2 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit")
b3, = sch.get_child_blocks(b2)
l4, l5, l6, l7 = sch.get_loops(block=b3)
l8 = sch.fuse(l4, l5, l6)
sch.parallel(loop=l8)
l9 = sch.fuse(l7)
sch.vectorize(loop=l9)
[01:14:23] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #30: "fused_layout_transform"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |            
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |            
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |            
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |            
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |            
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |            
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |            
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |            
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[01:14:23] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #27: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7"
[01:14:23] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #27 has finished. Remaining task(s): 30
[01:14:23] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #25: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6"
[01:14:23] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #25 has finished. Remaining task(s): 29
[01:14:23] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #21: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5"
[01:14:23] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #21 has finished. Remaining task(s): 28
[01:14:23] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2"
[01:14:23] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #9 has finished. Remaining task(s): 27
[01:14:23] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1"
[01:14:23] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #5 has finished. Remaining task(s): 26
[01:14:23] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #17: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4"
[01:14:23] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #17 has finished. Remaining task(s): 25
[01:14:23] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3"
[01:14:23] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #13 has finished. Remaining task(s): 24
[01:14:23] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #12: "fused_nn_pad_5"
[01:14:23] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[01:14:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[01:14:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[01:14:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[01:15:37] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[01:16:41] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[01:17:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[01:18:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[01:19:13] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[01:19:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[01:19:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[01:19:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[01:19:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[01:19:15] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #12: "fused_nn_pad_5"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |            
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[01:19:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #29: "fused_nn_contrib_conv2d_NCHWc_add"
[01:19:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #29 has finished. Remaining task(s): 23
[01:19:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #12: "fused_nn_pad_5"
[01:19:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[01:19:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[01:19:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[01:19:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[01:20:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[01:21:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[01:23:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[01:24:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[01:24:39] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[01:24:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[01:24:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[01:24:41] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[01:24:41] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[01:24:41] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #12: "fused_nn_pad_5"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[01:24:41] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #28: "fused_nn_pad_layout_transform"
[01:24:41] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[01:24:41] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 4 candidate(s) from database
[01:24:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[01:24:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2044 candidate(s)
[01:25:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[01:26:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[01:27:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[01:27:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[01:28:09] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[01:28:10] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[01:28:10] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[01:28:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[01:28:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[01:28:11] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #28: "fused_nn_pad_layout_transform"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |            
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[01:28:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu"
[01:28:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #1 has finished. Remaining task(s): 22
[01:28:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #6: "fused_nn_pad_2"
[01:28:11] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[01:28:11] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[01:28:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[01:28:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[01:28:23] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[01:28:37] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[01:28:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[01:29:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[01:29:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[01:29:36] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[01:29:36] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[01:29:37] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[01:29:37] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[01:29:37] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #6: "fused_nn_pad_2"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[01:29:37] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #12: "fused_nn_pad_5"
[01:29:37] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[01:29:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[01:30:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[01:30:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[01:31:22] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[01:32:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[01:33:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[01:34:41] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[01:35:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[01:35:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[01:35:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[01:35:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[01:35:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[01:35:34] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #12: "fused_nn_pad_5"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[01:35:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #26: "fused_nn_pad_12"
[01:35:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[01:35:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 4 candidate(s) from database
[01:35:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[01:35:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2044 candidate(s)
[01:36:53] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[01:37:46] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[01:38:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[01:39:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[01:40:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[01:40:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[01:40:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[01:40:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[01:40:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[01:40:15] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #26: "fused_nn_pad_12"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[01:40:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #7: "fused_nn_max_pool2d_1"
[01:40:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[01:40:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[01:40:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[01:40:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[01:40:53] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[01:41:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[01:41:30] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[01:41:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[01:42:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[01:42:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[01:42:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[01:42:25] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[01:42:25] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[01:42:25] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #7: "fused_nn_max_pool2d_1"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[01:42:25] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #10: "fused_nn_pad_4"
[01:42:25] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[01:42:26] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[01:42:30] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[01:42:30] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[01:42:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[01:43:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[01:43:26] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[01:43:46] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[01:44:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[01:44:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[01:44:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[01:44:05] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[01:44:05] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[01:44:05] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #10: "fused_nn_pad_4"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[01:44:05] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #20: "fused_nn_pad_9"
[01:44:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[01:44:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[01:44:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[01:44:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[01:45:41] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[01:46:44] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[01:47:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[01:48:50] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[01:49:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[01:49:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[01:49:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[01:49:32] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[01:49:32] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[01:49:32] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #20: "fused_nn_pad_9"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[01:49:32] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #22: "fused_nn_pad_10"
[01:49:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[01:49:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[01:49:39] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[01:49:39] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[01:50:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[01:50:52] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[01:51:18] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[01:51:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[01:51:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[01:51:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[01:51:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[01:52:00] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[01:52:00] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[01:52:00] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #22: "fused_nn_pad_10"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[01:52:00] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #8: "fused_nn_pad_3"
[01:52:00] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[01:52:01] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[01:52:30] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[01:52:30] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[01:53:48] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[01:55:00] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[01:56:09] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[01:57:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[01:58:11] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[01:58:11] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[01:58:11] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[01:58:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[01:58:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[01:58:12] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #8: "fused_nn_pad_3"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[01:58:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #15: "fused_nn_max_pool2d_3"
[01:58:12] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[01:58:12] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[01:58:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[01:58:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[01:58:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[01:59:23] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[01:59:57] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[02:00:18] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[02:00:55] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[02:00:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[02:00:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[02:00:58] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[02:00:58] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[02:00:58] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #15: "fused_nn_max_pool2d_3"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[02:00:58] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #16: "fused_nn_pad_7"
[02:00:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[02:00:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[02:01:41] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[02:01:41] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[02:02:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[02:03:48] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[02:04:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[02:05:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[02:06:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[02:06:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[02:06:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[02:06:33] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[02:06:33] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[02:06:33] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #16: "fused_nn_pad_7"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[02:06:33] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #14: "fused_nn_pad_6"
[02:06:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[02:06:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[02:06:37] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[02:06:37] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[02:06:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[02:07:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[02:07:42] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[02:07:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[02:08:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[02:08:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[02:08:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[02:08:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[02:08:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[02:08:15] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #14: "fused_nn_pad_6"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[02:08:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #12: "fused_nn_pad_5"
[02:08:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[02:08:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[02:08:48] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[02:08:48] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[02:09:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[02:10:44] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[02:11:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[02:12:07] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[02:12:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[02:12:50] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[02:12:50] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[02:12:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[02:12:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[02:12:51] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #12: "fused_nn_pad_5"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[02:12:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #23: "fused_nn_max_pool2d_5"
[02:12:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[02:12:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[02:12:53] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[02:12:53] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[02:13:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[02:13:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[02:14:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[02:15:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[02:15:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[02:15:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[02:15:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[02:15:36] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[02:15:36] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[02:15:36] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #23: "fused_nn_max_pool2d_5"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[02:15:36] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #18: "fused_nn_pad_8"
[02:15:36] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[02:15:36] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[02:15:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[02:15:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[02:15:55] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[02:16:12] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[02:16:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[02:16:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[02:17:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[02:17:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[02:17:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[02:17:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[02:17:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[02:17:17] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #18: "fused_nn_pad_8"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[02:17:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #28: "fused_nn_pad_layout_transform"
[02:17:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[02:17:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 4 candidate(s) from database
[02:17:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[02:17:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2044 candidate(s)
[02:18:19] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[02:19:03] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[02:19:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[02:20:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[02:20:44] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[02:20:44] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[02:20:44] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[02:20:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[02:20:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[02:20:45] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #28: "fused_nn_pad_layout_transform"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[02:20:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #12: "fused_nn_pad_5"
[02:20:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[02:20:46] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[02:21:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[02:21:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[02:22:07] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[02:23:22] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[02:24:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[02:24:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1aa4ac8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac43b8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1930488)]: 0 failure(s)
[02:25:28] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[02:25:28] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[02:25:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[02:25:29] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #12 has finished. Remaining task(s): 21
[02:25:29] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #24: "fused_nn_pad_11"
[02:25:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[02:25:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[02:25:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[02:25:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[02:26:57] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[02:28:12] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[02:28:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[02:29:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[02:30:28] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[02:30:28] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[02:30:28] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[02:30:29] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[02:30:29] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[02:30:29] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #24: "fused_nn_pad_11"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[02:30:29] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #6: "fused_nn_pad_2"
[02:30:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[02:30:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[02:30:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[02:30:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[02:30:52] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[02:31:09] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[02:31:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[02:31:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[02:31:39] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[02:31:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[02:31:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[02:31:40] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[02:31:40] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[02:31:40] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #6: "fused_nn_pad_2"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[02:31:40] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #26: "fused_nn_pad_12"
[02:31:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[02:31:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 4 candidate(s) from database
[02:32:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[02:32:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2044 candidate(s)
[02:32:50] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[02:33:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[02:34:26] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[02:35:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[02:36:08] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[02:36:08] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[02:36:08] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[02:36:08] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[02:36:08] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[02:36:08] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #26: "fused_nn_pad_12"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[02:36:08] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #7: "fused_nn_max_pool2d_1"
[02:36:08] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[02:36:08] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[02:36:11] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[02:36:11] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[02:36:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[02:37:12] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[02:37:36] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[02:38:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[02:38:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[02:38:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[02:38:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[02:38:28] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[02:38:28] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[02:38:28] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #7: "fused_nn_max_pool2d_1"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[02:38:28] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #11: "fused_nn_max_pool2d_2"
[02:38:28] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[02:38:28] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[02:38:30] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[02:38:30] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[02:39:03] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[02:39:23] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[02:39:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[02:40:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[02:40:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[02:40:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[02:40:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[02:40:52] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[02:40:52] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[02:40:52] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #11: "fused_nn_max_pool2d_2"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[02:40:52] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #10: "fused_nn_pad_4"
[02:40:52] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[02:40:52] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[02:40:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[02:40:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[02:41:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[02:41:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[02:41:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[02:42:11] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[02:42:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[02:42:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[02:42:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[02:42:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[02:42:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[02:42:35] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #10: "fused_nn_pad_4"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[02:42:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #28: "fused_nn_pad_layout_transform"
[02:42:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[02:42:36] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 4 candidate(s) from database
[02:42:57] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[02:42:57] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2044 candidate(s)
[02:43:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[02:43:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[02:44:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[02:44:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[02:45:13] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[02:45:13] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[02:45:13] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[02:45:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[02:45:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[02:45:14] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #28: "fused_nn_pad_layout_transform"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[02:45:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #19: "fused_nn_max_pool2d_4"
[02:45:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[02:45:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[02:45:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[02:45:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[02:45:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[02:46:07] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[02:46:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[02:46:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[02:47:19] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[02:47:19] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[02:47:19] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[02:47:19] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[02:47:19] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[02:47:19] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #19: "fused_nn_max_pool2d_4"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[02:47:19] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #20: "fused_nn_pad_9"
[02:47:19] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[02:47:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[02:47:48] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[02:47:48] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[02:48:39] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[02:49:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[02:50:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[02:51:30] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[02:52:07] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[02:52:07] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[02:52:07] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[02:52:08] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[02:52:08] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[02:52:08] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #20: "fused_nn_pad_9"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[02:52:08] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #22: "fused_nn_pad_10"
[02:52:08] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[02:52:08] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[02:52:19] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[02:52:19] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[02:52:50] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[02:53:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[02:53:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[02:54:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[02:54:30] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[02:54:30] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[02:54:30] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[02:54:30] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[02:54:30] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[02:54:30] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #22: "fused_nn_pad_10"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[02:54:30] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #8: "fused_nn_pad_3"
[02:54:30] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[02:54:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[02:54:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[02:54:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[02:55:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[02:56:37] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[02:57:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[02:58:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[02:59:18] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[02:59:18] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[02:59:19] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[02:59:20] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[02:59:20] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[02:59:20] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #8: "fused_nn_pad_3"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[02:59:20] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #15: "fused_nn_max_pool2d_3"
[02:59:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[02:59:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[02:59:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[02:59:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[02:59:52] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[03:00:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[03:00:50] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[03:01:12] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[03:01:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:01:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:01:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:01:32] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[03:01:32] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[03:01:32] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #15: "fused_nn_max_pool2d_3"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[03:01:32] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #16: "fused_nn_pad_7"
[03:01:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:01:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[03:01:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[03:01:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[03:02:26] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[03:03:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[03:03:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[03:04:50] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[03:05:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:05:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:05:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:05:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[03:05:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[03:05:15] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #16: "fused_nn_pad_7"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[03:05:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #14: "fused_nn_pad_6"
[03:05:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:05:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[03:05:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[03:05:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[03:05:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[03:05:44] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[03:05:52] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[03:06:00] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[03:06:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:06:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:06:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:06:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[03:06:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[03:06:17] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #14: "fused_nn_pad_6"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[03:06:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #23: "fused_nn_max_pool2d_5"
[03:06:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:06:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[03:06:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[03:06:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[03:06:44] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[03:07:13] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[03:07:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[03:08:01] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[03:08:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:08:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:08:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:08:27] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[03:08:27] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[03:08:27] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #23: "fused_nn_max_pool2d_5"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[03:08:27] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #6: "fused_nn_pad_2"
[03:08:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:08:28] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[03:08:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[03:08:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[03:08:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[03:08:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[03:09:23] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[03:09:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[03:09:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:09:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:09:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:09:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[03:09:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[03:09:54] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #6: "fused_nn_pad_2"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[03:09:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #18: "fused_nn_pad_8"
[03:09:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:09:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[03:09:55] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[03:09:55] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[03:10:12] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[03:10:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[03:10:48] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[03:10:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[03:11:04] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:11:04] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:11:04] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:11:05] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[03:11:05] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[03:11:05] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #18: "fused_nn_pad_8"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[03:11:05] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #26: "fused_nn_pad_12"
[03:11:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:11:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 4 candidate(s) from database
[03:11:30] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[03:11:30] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2044 candidate(s)
[03:12:07] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[03:12:48] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[03:13:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[03:14:18] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[03:14:55] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:14:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:14:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:14:57] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[03:14:57] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[03:14:57] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #26: "fused_nn_pad_12"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[03:14:57] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #7: "fused_nn_max_pool2d_1"
[03:14:57] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:14:57] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[03:15:00] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[03:15:00] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[03:15:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[03:15:48] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[03:16:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[03:16:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[03:16:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:16:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:16:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:16:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[03:16:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[03:16:35] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #7: "fused_nn_max_pool2d_1"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[03:16:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #28: "fused_nn_pad_layout_transform"
[03:16:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:16:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 4 candidate(s) from database
[03:16:52] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[03:16:52] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2044 candidate(s)
[03:17:23] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[03:17:52] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[03:18:18] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[03:18:46] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[03:19:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:19:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:19:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:19:02] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[03:19:02] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[03:19:02] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #28: "fused_nn_pad_layout_transform"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[03:19:02] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #30: "fused_layout_transform"
[03:19:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:19:03] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[03:19:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[03:19:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[03:19:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[03:19:42] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[03:20:03] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[03:20:10] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[03:20:18] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:20:18] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:20:18] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:20:19] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[03:20:19] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[03:20:19] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #30: "fused_layout_transform"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[03:20:19] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #4: "fused_nn_pad_1"
[03:20:19] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:20:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[03:20:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[03:20:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[03:21:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[03:22:09] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[03:22:48] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[03:23:26] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[03:23:57] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:23:57] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:23:57] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:23:58] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[03:23:58] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[03:23:58] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #4: "fused_nn_pad_1"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[03:23:58] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #10: "fused_nn_pad_4"
[03:23:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:23:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[03:24:01] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[03:24:01] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[03:24:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[03:24:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[03:24:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[03:24:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[03:24:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:24:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:24:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:25:00] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[03:25:00] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[03:25:00] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #10: "fused_nn_pad_4"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[03:25:00] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #24: "fused_nn_pad_11"
[03:25:00] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:25:00] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[03:25:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[03:25:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[03:25:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[03:26:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[03:27:19] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[03:27:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[03:28:25] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:28:25] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:28:25] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:28:25] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[03:28:25] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[03:28:25] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #24: "fused_nn_pad_11"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[03:28:25] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #0: "fused_multiply_add_nn_pad_layout_transform"
[03:28:25] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:28:28] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 24 candidate(s) from database
[03:29:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[03:29:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2024 candidate(s)
[03:31:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[03:32:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[03:34:04] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[03:35:18] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[03:35:53] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:35:53] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:35:53] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:35:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[03:35:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[03:35:53] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #0: "fused_multiply_add_nn_pad_layout_transform"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[03:35:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #20: "fused_nn_pad_9"
[03:35:53] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:35:53] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[03:36:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[03:36:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[03:36:52] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[03:37:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[03:38:01] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[03:38:28] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[03:38:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:38:50] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:38:50] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:38:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[03:38:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[03:38:51] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #20: "fused_nn_pad_9"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[03:38:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #22: "fused_nn_pad_10"
[03:38:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:38:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[03:38:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[03:38:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[03:39:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[03:39:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[03:39:55] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[03:40:13] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[03:40:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:40:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:40:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:40:24] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[03:40:24] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[03:40:24] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #22: "fused_nn_pad_10"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[03:40:24] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #8: "fused_nn_pad_3"
[03:40:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:40:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[03:40:41] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[03:40:41] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[03:41:09] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[03:41:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[03:42:07] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[03:42:50] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[03:43:04] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:43:04] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:43:04] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:43:05] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[03:43:05] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[03:43:05] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #8: "fused_nn_pad_3"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[03:43:05] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #15: "fused_nn_max_pool2d_3"
[03:43:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:43:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[03:43:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[03:43:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[03:43:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[03:43:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[03:43:55] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[03:44:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[03:44:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:44:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:44:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:44:31] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[03:44:31] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[03:44:31] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #15: "fused_nn_max_pool2d_3"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[03:44:31] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #16: "fused_nn_pad_7"
[03:44:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:44:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[03:44:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[03:44:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[03:45:30] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[03:46:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[03:46:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[03:47:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[03:47:42] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:47:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:47:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:47:44] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[03:47:44] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[03:47:44] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #16: "fused_nn_pad_7"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[03:47:44] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #14: "fused_nn_pad_6"
[03:47:44] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:47:44] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[03:47:46] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[03:47:46] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[03:47:57] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[03:48:09] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[03:48:22] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[03:48:30] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[03:48:36] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:48:36] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:48:37] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:48:37] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[03:48:37] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[03:48:37] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #14: "fused_nn_pad_6"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[03:48:37] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #6: "fused_nn_pad_2"
[03:48:37] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:48:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[03:48:41] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[03:48:41] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[03:48:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[03:49:07] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[03:49:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[03:49:28] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[03:49:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:49:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:49:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:49:40] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[03:49:40] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[03:49:40] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #6: "fused_nn_pad_2"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |            
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[03:49:40] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #28: "fused_nn_pad_layout_transform"
[03:49:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:49:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 4 candidate(s) from database
[03:49:55] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[03:49:55] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2044 candidate(s)
[03:50:11] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[03:50:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[03:50:44] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[03:51:04] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc0127e38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19f4778)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18dbfd8)]: 0 failure(s)
[03:51:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:51:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:51:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:51:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #28 has finished. Remaining task(s): 20
[03:51:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #26: "fused_nn_pad_12"
[03:51:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:51:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 4 candidate(s) from database
[03:51:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[03:51:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2044 candidate(s)
[03:52:04] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[03:52:36] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[03:53:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[03:53:37] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[03:54:03] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:54:03] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:54:03] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:54:04] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[03:54:04] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[03:54:04] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #26: "fused_nn_pad_12"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[03:54:04] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #7: "fused_nn_max_pool2d_1"
[03:54:04] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:54:04] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[03:54:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[03:54:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[03:54:18] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[03:54:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[03:54:39] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[03:54:53] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[03:55:01] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:55:01] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:55:01] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:55:01] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[03:55:01] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[03:55:01] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #7: "fused_nn_max_pool2d_1"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[03:55:01] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #23: "fused_nn_max_pool2d_5"
[03:55:01] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:55:01] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[03:55:03] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[03:55:03] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[03:55:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[03:55:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[03:55:46] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[03:56:00] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[03:56:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:56:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:56:18] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:56:19] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[03:56:19] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[03:56:19] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #23: "fused_nn_max_pool2d_5"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[03:56:19] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #18: "fused_nn_pad_8"
[03:56:19] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:56:19] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[03:56:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[03:56:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[03:56:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[03:56:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[03:56:46] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[03:56:57] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[03:57:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:57:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:57:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:57:06] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[03:57:06] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[03:57:06] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #18: "fused_nn_pad_8"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[03:57:06] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #11: "fused_nn_max_pool2d_2"
[03:57:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:57:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[03:57:07] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[03:57:07] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[03:57:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[03:57:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[03:57:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[03:58:12] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[03:58:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:58:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:58:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:58:21] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[03:58:21] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[03:58:21] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #11: "fused_nn_max_pool2d_2"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[03:58:21] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #10: "fused_nn_pad_4"
[03:58:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:58:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[03:58:23] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[03:58:23] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[03:58:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[03:58:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[03:58:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[03:58:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[03:58:57] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:58:57] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:58:57] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:58:57] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[03:58:57] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[03:58:57] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #10: "fused_nn_pad_4"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |            
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[03:58:57] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #6: "fused_nn_pad_2"
[03:58:57] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:58:57] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[03:58:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[03:58:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[03:59:08] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[03:59:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[03:59:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[03:59:28] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18fdfd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1856718)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18bb4f8)]: 0 failure(s)
[03:59:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[03:59:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[03:59:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[03:59:33] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #6 has finished. Remaining task(s): 19
[03:59:33] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #19: "fused_nn_max_pool2d_4"
[03:59:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[03:59:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[03:59:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[03:59:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[03:59:44] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[03:59:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[04:00:08] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[04:00:22] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[04:00:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:00:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:00:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:00:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:00:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:00:35] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #19: "fused_nn_max_pool2d_4"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:00:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #20: "fused_nn_pad_9"
[04:00:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:00:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:00:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[04:00:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:01:10] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[04:01:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[04:01:53] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[04:02:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[04:02:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:02:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:02:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:02:32] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:02:32] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:02:32] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #20: "fused_nn_pad_9"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:02:32] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #22: "fused_nn_pad_10"
[04:02:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:02:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:02:37] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[04:02:37] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:02:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[04:02:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[04:03:13] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[04:03:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[04:03:36] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:03:36] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:03:36] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:03:37] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:03:37] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:03:37] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #22: "fused_nn_pad_10"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:03:37] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #8: "fused_nn_pad_3"
[04:03:37] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:03:37] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:03:53] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[04:03:53] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:04:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[04:04:50] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[04:05:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[04:05:39] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[04:05:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:05:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:05:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:05:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:05:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:05:56] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #8: "fused_nn_pad_3"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:05:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #15: "fused_nn_max_pool2d_3"
[04:05:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:05:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:05:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[04:05:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:06:11] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[04:06:23] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[04:06:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[04:06:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[04:06:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:06:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:06:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:06:49] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:06:49] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:06:49] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #15: "fused_nn_max_pool2d_3"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:06:49] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #16: "fused_nn_pad_7"
[04:06:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:06:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:07:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[04:07:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:07:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[04:07:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[04:08:07] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[04:08:22] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[04:08:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:08:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:08:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:08:33] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:08:33] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:08:33] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #16: "fused_nn_pad_7"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:08:33] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #14: "fused_nn_pad_6"
[04:08:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:08:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:08:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[04:08:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:08:37] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[04:08:39] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[04:08:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[04:08:46] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[04:08:48] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:08:48] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:08:48] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:08:48] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:08:48] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:08:48] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #14: "fused_nn_pad_6"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |            
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |            
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:08:48] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #26: "fused_nn_pad_12"
[04:08:48] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:08:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 4 candidate(s) from database
[04:08:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[04:08:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2044 candidate(s)
[04:09:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[04:09:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[04:09:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[04:09:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc167fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a49598)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dadb8)]: 0 failure(s)
[04:10:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:10:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:10:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:10:06] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #26 has finished. Remaining task(s): 18
[04:10:06] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #7: "fused_nn_max_pool2d_1"
[04:10:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:10:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:10:08] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[04:10:08] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:10:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[04:10:19] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[04:10:25] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[04:10:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18f27c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1809008)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1a34908)]: 0 failure(s)
[04:10:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:10:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:10:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:10:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #7 has finished. Remaining task(s): 17
[04:10:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #24: "fused_nn_pad_11"
[04:10:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:10:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:10:44] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[04:10:44] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:10:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[04:11:09] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[04:11:19] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[04:11:28] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[04:11:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:11:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:11:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:11:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:11:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:11:35] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #24: "fused_nn_pad_11"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |          Y 
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |          Y 
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:11:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #23: "fused_nn_max_pool2d_5"
[04:11:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:11:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:11:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[04:11:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:11:39] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[04:11:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[04:11:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[04:11:52] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[04:11:55] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:11:55] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:11:55] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:11:55] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:11:55] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:11:55] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #23: "fused_nn_max_pool2d_5"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |          Y 
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |            
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |          Y 
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:11:55] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #10: "fused_nn_pad_4"
[04:11:55] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:11:55] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:11:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[04:11:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:11:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[04:12:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[04:12:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[04:12:10] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1807498)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1951368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1952658)]: 0 failure(s)
[04:12:13] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:12:13] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:12:13] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:12:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #10 has finished. Remaining task(s): 16
[04:12:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #18: "fused_nn_pad_8"
[04:12:13] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:12:13] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:12:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[04:12:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:12:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[04:12:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[04:12:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[04:12:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[04:12:30] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:12:30] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:12:30] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:12:30] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:12:30] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:12:30] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #18: "fused_nn_pad_8"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |          Y 
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |          Y 
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |            
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |            
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |            
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |            
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |            
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |          Y 
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:12:30] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #20: "fused_nn_pad_9"
[04:12:30] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:12:30] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:12:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[04:12:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:12:53] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[04:13:10] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[04:13:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[04:13:37] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a364f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1743a38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19dde98)]: 0 failure(s)
[04:13:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:13:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:13:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:13:47] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #20 has finished. Remaining task(s): 15
[04:13:47] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #22: "fused_nn_pad_10"
[04:13:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:13:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:13:50] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[04:13:50] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:13:57] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[04:14:04] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[04:14:11] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[04:14:18] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dd628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a55518)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc180f918)]: 0 failure(s)
[04:14:25] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:14:25] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:14:25] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:14:25] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #22 has finished. Remaining task(s): 14
[04:14:25] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #8: "fused_nn_pad_3"
[04:14:25] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:14:25] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:14:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[04:14:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:14:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[04:15:03] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[04:15:19] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[04:15:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17a5b68)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc17cc4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc193d178)]: 0 failure(s)
[04:15:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:15:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:15:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:15:47] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #8 has finished. Remaining task(s): 13
[04:15:47] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #15: "fused_nn_max_pool2d_3"
[04:15:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:15:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:15:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[04:15:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:15:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[04:15:57] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[04:16:04] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[04:16:10] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a69408)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a188d8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d1b8)]: 0 failure(s)
[04:16:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:16:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:16:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:16:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #15 has finished. Remaining task(s): 12
[04:16:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #16: "fused_nn_pad_7"
[04:16:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:16:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:16:22] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[04:16:22] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:16:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[04:16:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[04:17:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[04:17:23] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1887008)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a36ee8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1f678)]: 0 failure(s)
[04:17:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:17:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:17:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:17:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #16 has finished. Remaining task(s): 11
[04:17:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #14: "fused_nn_pad_6"
[04:17:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:17:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:17:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[04:17:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:17:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[04:17:41] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[04:17:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[04:17:48] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a4a6b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a82a48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1b1d118)]: 0 failure(s)
[04:17:50] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:17:50] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:17:50] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:17:50] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #14 has finished. Remaining task(s): 10
[04:17:50] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #30: "fused_layout_transform"
[04:17:50] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:17:50] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:17:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[04:17:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:17:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[04:17:57] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[04:18:01] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[04:18:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[04:18:07] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:18:07] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:18:07] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:18:07] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:18:07] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:18:07] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #30: "fused_layout_transform"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |          Y 
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |          Y 
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |          Y 
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |          Y 
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |          Y 
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |          Y 
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |          Y 
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |          Y 
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |          Y 
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:18:07] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #4: "fused_nn_pad_1"
[04:18:07] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:18:07] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:18:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[04:18:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:18:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[04:18:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[04:18:52] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[04:19:04] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[04:19:10] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:19:10] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:19:10] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:19:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:19:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:19:10] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #4: "fused_nn_pad_1"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |          Y 
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |          Y 
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |          Y 
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |          Y 
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |          Y 
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |          Y 
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |          Y 
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |          Y 
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |          Y 
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:19:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #11: "fused_nn_max_pool2d_2"
[04:19:10] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:19:10] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:19:11] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[04:19:11] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:19:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[04:19:19] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[04:19:23] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[04:19:28] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[04:19:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:19:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:19:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:19:32] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:19:32] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:19:32] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #11: "fused_nn_max_pool2d_2"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |          Y 
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |          Y 
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |          Y 
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |          Y 
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |          Y 
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |          Y 
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |          Y 
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |          Y 
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |            
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |          Y 
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:19:32] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #23: "fused_nn_max_pool2d_5"
[04:19:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:19:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:19:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[04:19:33] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:19:37] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[04:19:41] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[04:19:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[04:19:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173a308)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a694e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1811348)]: 0 failure(s)
[04:19:53] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:19:53] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:19:53] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:19:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #23 has finished. Remaining task(s): 9
[04:19:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #19: "fused_nn_max_pool2d_4"
[04:19:53] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:19:53] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:19:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[04:19:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:19:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[04:20:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[04:20:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[04:20:09] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[04:20:13] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:20:13] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:20:13] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:20:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:20:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:20:13] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #19: "fused_nn_max_pool2d_4"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |          Y 
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |          Y 
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |          Y 
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |          Y 
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |          Y 
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |          Y 
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |          Y 
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |          Y 
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |          Y 
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |          Y 
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:20:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #24: "fused_nn_pad_11"
[04:20:13] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:20:13] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:20:18] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[04:20:18] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:20:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[04:20:36] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[04:20:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[04:20:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[04:21:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:21:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:21:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:21:02] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:21:02] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:21:02] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #24: "fused_nn_pad_11"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |          Y 
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |          Y 
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |          Y 
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |          Y 
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |          Y 
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |          Y 
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |          Y 
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |          Y 
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |          Y 
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |          Y 
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:21:02] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #0: "fused_multiply_add_nn_pad_layout_transform"
[04:21:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:21:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 24 candidate(s) from database
[04:21:25] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[04:21:25] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2024 candidate(s)
[04:21:52] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[04:22:18] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[04:22:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[04:22:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[04:23:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:23:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:23:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:23:05] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:23:05] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:23:05] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #0: "fused_multiply_add_nn_pad_layout_transform"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |          Y 
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |          Y 
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |          Y 
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |          Y 
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |          Y 
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |          Y 
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |            
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |          Y 
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |          Y 
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |          Y 
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |            
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |          Y 
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:23:05] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #18: "fused_nn_pad_8"
[04:23:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:23:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:23:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[04:23:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:23:07] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[04:23:10] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[04:23:12] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[04:23:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19dcd08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19cb758)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19bc2b8)]: 0 failure(s)
[04:23:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:23:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:23:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:23:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #18 has finished. Remaining task(s): 8
[04:23:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #24: "fused_nn_pad_11"
[04:23:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:23:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:23:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[04:23:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:23:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[04:23:37] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[04:23:46] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[04:23:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f2bd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18cede8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18ce1c8)]: 0 failure(s)
[04:23:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:23:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:23:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:24:00] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #24 has finished. Remaining task(s): 7
[04:24:00] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #11: "fused_nn_max_pool2d_2"
[04:24:00] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:24:00] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:24:00] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[04:24:00] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:24:03] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[04:24:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[04:24:10] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[04:24:13] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[04:24:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:24:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:24:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:24:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:24:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:24:16] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #11: "fused_nn_max_pool2d_2"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |          Y 
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |          Y 
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |          Y 
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |          Y 
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |          Y 
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |          Y 
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |          Y 
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |          Y 
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |          Y 
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |          Y 
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |          Y 
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |          Y 
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:24:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #19: "fused_nn_max_pool2d_4"
[04:24:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:24:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:24:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[04:24:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:24:19] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[04:24:22] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[04:24:25] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[04:24:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[04:24:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:24:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:24:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:24:31] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:24:31] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:24:31] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #19: "fused_nn_max_pool2d_4"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |          Y 
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |          Y 
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |          Y 
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |          Y 
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |          Y 
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |          Y 
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |          Y 
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |          Y 
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |          Y 
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |          Y 
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |          Y 
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |          Y 
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:24:31] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #30: "fused_layout_transform"
[04:24:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:24:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:24:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[04:24:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:24:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[04:24:36] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[04:24:39] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[04:24:41] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[04:24:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:24:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:24:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:24:43] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:24:43] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:24:43] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #30: "fused_layout_transform"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |          Y 
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |          Y 
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |          Y 
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |          Y 
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |          Y 
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |          Y 
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |          Y 
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |          Y 
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |          Y 
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |          Y 
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |          Y 
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |          Y 
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:24:43] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #4: "fused_nn_pad_1"
[04:24:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:24:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:24:48] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[04:24:48] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:24:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[04:25:04] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[04:25:13] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[04:25:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[04:25:26] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:25:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:25:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:25:27] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:25:27] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:25:27] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #4: "fused_nn_pad_1"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |          Y 
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |          Y 
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |          Y 
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |          Y 
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |          Y 
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |          Y 
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |          Y 
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |          Y 
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |          Y 
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |          Y 
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |          Y 
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |          Y 
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:25:27] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #0: "fused_multiply_add_nn_pad_layout_transform"
[04:25:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:25:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 24 candidate(s) from database
[04:25:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[04:25:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2024 candidate(s)
[04:26:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[04:26:22] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[04:26:41] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[04:27:01] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[04:27:08] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:27:08] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:27:08] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:27:08] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:27:08] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:27:08] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #0: "fused_multiply_add_nn_pad_layout_transform"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |          Y 
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |          Y 
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |          Y 
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |            
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |          Y 
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |          Y 
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |          Y 
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |          Y 
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |            
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |          Y 
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |          Y 
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |          Y 
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |          Y 
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |          Y 
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:27:08] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #11: "fused_nn_max_pool2d_2"
[04:27:08] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:27:08] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:27:09] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[04:27:09] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:27:12] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[04:27:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[04:27:18] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[04:27:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc17cb1c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc191e6e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1885fd8)]: 0 failure(s)
[04:27:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:27:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:27:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:27:24] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #11 has finished. Remaining task(s): 6
[04:27:24] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #19: "fused_nn_max_pool2d_4"
[04:27:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:27:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:27:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[04:27:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:27:28] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[04:27:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[04:27:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[04:27:37] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1ac1c58)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1392e38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1897d08)]: 0 failure(s)
[04:27:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:27:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:27:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:27:40] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #19 has finished. Remaining task(s): 5
[04:27:40] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #30: "fused_layout_transform"
[04:27:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:27:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:27:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[04:27:40] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:27:42] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[04:27:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[04:27:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[04:27:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[04:27:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:27:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:27:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:27:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:27:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:27:51] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #30: "fused_layout_transform"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |          Y 
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |          Y 
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |          Y 
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |          Y 
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |          Y 
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |          Y 
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |          Y 
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |          Y 
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |          Y 
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |          Y 
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |          Y 
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |          Y 
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |          Y 
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |          Y 
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:27:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #4: "fused_nn_pad_1"
[04:27:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:27:51] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:27:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[04:27:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:28:04] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[04:28:12] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[04:28:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[04:28:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[04:28:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:28:34] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:28:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:28:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:28:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:28:35] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #4: "fused_nn_pad_1"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |          Y 
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |          Y 
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |          Y 
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |          Y 
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |          Y 
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |          Y 
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |          Y 
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |          Y 
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |          Y 
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |          Y 
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |          Y 
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |          Y 
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |          Y 
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |          Y 
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:28:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #0: "fused_multiply_add_nn_pad_layout_transform"
[04:28:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:28:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 24 candidate(s) from database
[04:28:52] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[04:28:52] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2024 candidate(s)
[04:29:11] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[04:29:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[04:29:50] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[04:30:10] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[04:30:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:30:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:30:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:30:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:30:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:30:17] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #0: "fused_multiply_add_nn_pad_layout_transform"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |          Y 
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |          Y 
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |          Y 
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |          Y 
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |          Y 
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |          Y 
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |          Y 
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |          Y 
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |          Y 
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |          Y 
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |          Y 
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |          Y 
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |          Y 
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |          Y 
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |            
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:30:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #30: "fused_layout_transform"
[04:30:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:30:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:30:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[04:30:17] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:30:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[04:30:22] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[04:30:24] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[04:30:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc19f3b08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1a210e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1916168)]: 0 failure(s)
[04:30:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:30:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:30:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:30:29] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #30 has finished. Remaining task(s): 4
[04:30:29] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #3: "fused_nn_max_pool2d"
[04:30:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:30:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:30:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[04:30:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:30:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[04:30:36] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[04:30:39] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[04:30:42] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[04:30:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:30:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:30:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:30:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:30:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:30:45] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #3: "fused_nn_max_pool2d"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |          Y 
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |          Y 
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |          Y 
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |          Y 
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |          Y 
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |          Y 
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |          Y 
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |          Y 
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |          Y 
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |          Y 
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |          Y 
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |          Y 
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |          Y 
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |          Y 
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |          Y 
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:30:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #4: "fused_nn_pad_1"
[04:30:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:30:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:30:50] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[04:30:50] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:30:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[04:31:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[04:31:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[04:31:23] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc18b6dd8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18428c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc1684098)]: 0 failure(s)
[04:31:28] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:31:28] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:31:28] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:31:28] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #4 has finished. Remaining task(s): 3
[04:31:28] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #0: "fused_multiply_add_nn_pad_layout_transform"
[04:31:28] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:31:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 24 candidate(s) from database
[04:31:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[04:31:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2024 candidate(s)
[04:32:06] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[04:32:25] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[04:32:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[04:33:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc173fb38)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc19b4ea8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc19c9838)]: 0 failure(s)
[04:33:12] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:33:12] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:33:12] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:33:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #0 has finished. Remaining task(s): 2
[04:33:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #2: "fused_nn_pad"
[04:33:12] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:33:12] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:33:12] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[04:33:12] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:33:14] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[04:33:16] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[04:33:19] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[04:33:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[04:33:22] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:33:22] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:33:22] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:33:22] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:33:22] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:33:22] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #2: "fused_nn_pad"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |          Y 
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |          Y 
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |          Y 
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |          Y 
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |          Y 
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |          Y 
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |          Y 
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |          Y 
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |          Y 
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |          Y 
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |          Y 
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |          Y 
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |          Y 
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |          Y 
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |          Y 
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |          Y 
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |          Y 
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:33:22] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #3: "fused_nn_max_pool2d"
[04:33:22] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:33:22] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:33:23] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[04:33:23] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:33:26] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[04:33:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[04:33:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[04:33:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[04:33:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:33:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:33:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:33:38] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:33:38] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:33:38] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #3: "fused_nn_max_pool2d"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |          Y 
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |          Y 
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |          Y 
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |          Y 
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |          Y 
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |          Y 
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |          Y 
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |          Y 
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |          Y 
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |          Y 
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |          Y 
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |          Y 
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |          Y 
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |          Y 
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |          Y 
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |          Y 
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |          Y 
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:33:38] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #2: "fused_nn_pad"
[04:33:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:33:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:33:39] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[04:33:39] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:33:41] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[04:33:43] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[04:33:45] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[04:33:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[04:33:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:33:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:33:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:33:49] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:33:49] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:33:49] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #2: "fused_nn_pad"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |          Y 
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |          Y 
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |          Y 
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |          Y 
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |          Y 
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |          Y 
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |          Y 
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |          Y 
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |          Y 
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |          Y 
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |          Y 
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |          Y 
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |          Y 
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |          Y 
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |          Y 
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |          Y 
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |          Y 
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:33:49] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #3: "fused_nn_max_pool2d"
[04:33:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:33:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:33:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[04:33:49] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:33:52] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[04:33:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[04:33:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[04:34:02] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[04:34:04] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:34:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:34:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:34:05] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:34:05] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:34:05] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #3: "fused_nn_max_pool2d"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |          Y 
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |          Y 
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |          Y 
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |          Y 
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |          Y 
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |          Y 
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |          Y 
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |          Y 
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |          Y 
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |          Y 
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |          Y 
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |          Y 
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |          Y 
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |          Y 
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |          Y 
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |          Y 
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |          Y 
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:34:05] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #3: "fused_nn_max_pool2d"
[04:34:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:34:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:34:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[04:34:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:34:08] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[04:34:12] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[04:34:15] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[04:34:18] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[04:34:20] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:34:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:34:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:34:21] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:34:21] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:34:21] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #3: "fused_nn_max_pool2d"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |          Y 
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |          Y 
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |          Y 
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |          Y 
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |          Y 
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |          Y 
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |          Y 
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |          Y 
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |          Y 
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |          Y 
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |          Y 
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |          Y 
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |          Y 
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |          Y 
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |          Y 
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |          Y 
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |          Y 
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:34:21] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #2: "fused_nn_pad"
[04:34:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:34:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:34:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[04:34:21] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:34:23] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[04:34:25] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[04:34:27] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[04:34:29] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[04:34:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:34:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:34:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:34:31] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:34:31] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:34:31] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #2: "fused_nn_pad"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |          Y 
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |            
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |          Y 
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |          Y 
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |          Y 
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |          Y 
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |          Y 
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |          Y 
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |          Y 
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |          Y 
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |          Y 
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |          Y 
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |          Y 
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |          Y 
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |          Y 
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |          Y 
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |          Y 
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |          Y 
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:34:31] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #3: "fused_nn_max_pool2d"
[04:34:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:34:31] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:34:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[04:34:32] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:34:35] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[04:34:38] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[04:34:41] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[04:34:44] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc1a844f8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc18abe28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc17dd4f8)]: 0 failure(s)
[04:34:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:34:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:34:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:34:47] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #3 has finished. Remaining task(s): 1
[04:34:47] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #2: "fused_nn_pad"
[04:34:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:34:47] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:34:48] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[04:34:48] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:34:50] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[04:34:52] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[04:34:54] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[04:34:56] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[04:34:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:34:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:34:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:34:58] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 0 sample(s) to builder
[04:34:58] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:54: Sending 0 sample(s) to runner
[04:34:58] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #2: "fused_nn_pad"
 ID |                                              Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |        fused_multiply_add_nn_pad_layout_transform |    1038336 |      1 |         0.7769 |    1336.4399 |             1336.4399 |     24 |          Y 
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu |  155058176 |      1 |        27.1369 |    5713.9182 |             5713.9182 |     32 |          Y 
  2 |                                      fused_nn_pad |          1 |      1 |         0.0000 |     211.0292 |              211.0292 |      8 |            
  3 |                               fused_nn_max_pool2d |    2768896 |      1 |         9.5558 |     289.7608 |              289.7608 |      8 |          Y 
  4 |                                    fused_nn_pad_1 |          1 |      1 |         0.0000 |    1420.6900 |             1420.6900 |      8 |          Y 
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_1 |  401489920 |      1 |        13.0435 |   30780.7947 |            30780.7947 |     32 |          Y 
  6 |                                    fused_nn_pad_2 |          1 |      1 |         0.0000 |    5118.6583 |             5118.6583 |      8 |          Y 
  7 |                             fused_nn_max_pool2d_1 |    1384448 |      1 |         0.2984 |    4639.4268 |             4639.4268 |      8 |          Y 
  8 |                                    fused_nn_pad_3 |          1 |      1 |         0.0000 |    3995.4646 |             3995.4646 |      8 |          Y 
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_2 |  400105472 |      1 |        11.4790 |   34855.3796 |            34855.3796 |     32 |          Y 
 10 |                                    fused_nn_pad_4 |          1 |      1 |         0.0000 |    4156.9862 |             4156.9862 |      8 |          Y 
 11 |                             fused_nn_max_pool2d_2 |     692224 |      1 |         0.3323 |    2083.3556 |             2083.3556 |      8 |          Y 
 12 |                                    fused_nn_pad_5 |          1 |      1 |         0.0000 |   14477.1190 |            14477.1190 |      8 |          Y 
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_3 |  399413248 |      1 |        14.6660 |   27233.9942 |            27233.9942 |     32 |          Y 
 14 |                                    fused_nn_pad_6 |          1 |      1 |         0.0000 |    3860.5717 |             3860.5717 |      8 |          Y 
 15 |                             fused_nn_max_pool2d_3 |     346112 |      1 |         0.0892 |    3878.0850 |             3878.0850 |      8 |          Y 
 16 |                                    fused_nn_pad_7 |          1 |      1 |         0.0000 |    3861.0727 |             3861.0727 |      8 |          Y 
 17 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_4 |  399067136 |      1 |        14.6035 |   27326.7758 |            27326.7758 |     32 |          Y 
 18 |                                    fused_nn_pad_8 |          1 |      1 |         0.0000 |    3294.3312 |             3294.3312 |      8 |          Y 
 19 |                             fused_nn_max_pool2d_4 |     173056 |      1 |         0.0852 |    2030.9977 |             2030.9977 |      8 |          Y 
 20 |                                    fused_nn_pad_9 |          1 |      1 |         0.0000 |    3999.8538 |             3999.8538 |      8 |          Y 
 21 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_5 |  398894080 |      1 |         7.3769 |   54073.1500 |            54073.1500 |     32 |          Y 
 22 |                                   fused_nn_pad_10 |          1 |      1 |         0.0000 |    3999.6355 |             3999.6355 |      8 |          Y 
 23 |                             fused_nn_max_pool2d_5 |     346112 |      1 |         0.1000 |    3461.6042 |             3461.6042 |      8 |          Y 
 24 |                                   fused_nn_pad_11 |          1 |      1 |         0.0000 |    2684.2049 |             2684.2049 |      8 |          Y 
 25 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_6 | 1595230208 |      1 |        22.1010 |   72179.0977 |            72179.0977 |     32 |          Y 
 26 |                                   fused_nn_pad_12 |          1 |      1 |         0.0000 |    4732.6500 |             4732.6500 |      4 |          Y 
 27 | fused_nn_contrib_conv2d_NCHWc_add_nn_leaky_relu_7 | 3190114304 |      1 |        41.6171 |   76653.9907 |            76653.9907 |     32 |          Y 
 28 |                     fused_nn_pad_layout_transform |          1 |      1 |         0.0000 |    6093.8647 |             6093.8647 |      4 |          Y 
 29 |                 fused_nn_contrib_conv2d_NCHWc_add |   43285125 |      1 |         4.9077 |    8819.9126 |             8819.9126 |     32 |          Y 
 30 |                            fused_layout_transform |          1 |      1 |         0.0000 |    1479.6781 |             1479.6781 |      8 |          Y 
------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 472
Total latency (us): 418742

[04:34:58] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:126: Scheduler picks Task #2: "fused_nn_pad"
[04:34:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:656: Generating candidates......
[04:34:58] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:658: Picked top 8 candidate(s) from database
[04:34:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:494: Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[04:34:59] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:660: Sampled 2040 candidate(s)
[04:35:01] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[04:35:03] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[04:35:05] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[04:35:07] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:571: Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55bdc170d548)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x55bdc1ac19f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x55bdc18a6698)]: 0 failure(s)
[04:35:09] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:595: Scores of the best 0 candidates:
[04:35:09] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:664: Got 0 candidate(s) with evolutionary search
[04:35:09] /home/yj/tvm/src/meta_schedule/search_strategy/evolutionary_search.cc:666: Sending 0 candidates(s) for measurement
[04:35:09] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:139: Task #2 has finished. Remaining task(s): 0
Starting to build with relay.
/home/yj/anaconda3/lib/python3.7/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html
  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)
One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.
The result is correct!
