nohup: ignoring input
Starting to build with relay.
One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.
[13:32:50] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #0: "fused_nn_conv2d_add_nn_leaky_relu"
[13:32:50] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 26, 26), "float32"], placeholder_1: T.Buffer[(512, 256, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 512, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 256, 27, 27], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        T_add = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 27, 27):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = T.if_then_else(1 <= i2_1 and i2_1 < 27 and 1 <= i3_1 and i3_1 < 27, placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 512, 13, 13, 256, 3, 3):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 26, 26], "float32"], ["TENSOR", [512, 256, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
            with T.block("T_leaky_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_leaky_relu[ax0, ax1, ax2, ax3])
                T_leaky_relu[ax0, ax1, ax2, ax3] = T.Select(T.float32(0) < T_add[ax0, ax1, ax2, ax3], T_add[ax0, ax1, ax2, ax3], T_add[ax0, ax1, ax2, ax3] * T.float32(0.10000000149011612))
    

[13:32:50] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:32:50] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 26, 26), "float32"], placeholder_1: T.Buffer[(512, 256, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 512, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":1024})
            conv2d_nchw_local = T.alloc_buffer([1, 512, 13, 13], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 256, 27, 27], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([512, 256, 3, 3], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(104, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(104, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(1, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(128, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(162):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(256, i4_0 * 2 + ax0_ax1_ax2_ax3_fused % 162 // 81)
                                    v2 = T.axis.spatial(27, i0_0_i1_0_i2_0_i3_0_fused % 13 * 2 + ax0_ax1_ax2_ax3_fused % 81 // 27)
                                    v3 = T.axis.spatial(27, ax0_ax1_ax2_ax3_fused % 27)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":1})
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 27 and 1 <= v3 and v3 < 27, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                            for ax0_ax1_ax2_ax3_fused in T.serial(1152):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused // 13 * 64 + ax0_ax1_ax2_ax3_fused // 18)
                                    v1 = T.axis.spatial(256, i4_0 * 2 + ax0_ax1_ax2_ax3_fused % 18 // 9)
                                    v2 = T.axis.spatial(3, ax0_ax1_ax2_ax3_fused % 9 // 3)
                                    v3 = T.axis.spatial(3, ax0_ax1_ax2_ax3_fused % 3)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":1})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 3, 1, 4, 1, 1, 2, 3, 1, 1, 2, 1, 1):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused // 13 * 64 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 8 + i1_3 * 2 + i1_4)
                                    yy = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_fused % 13)
                                    xx = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 13)
                                    rc = T.axis.reduce(256, i4_0 * 2 + i4_2)
                                    ry, rx = T.axis.remap("RR", [i5_2, i6_1])
                                    T.reads(pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 26, 26], "float32"], ["TENSOR", [512, 256, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 8, 1, 1):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused // 13 * 64 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 8 + ax1)
                                v2 = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_fused % 13 + ax2)
                                v3 = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 13 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                                T.writes(T_leaky_relu[v0, v1, v2, v3])
                                T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[8, 8, 1, 4, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[13, 1, 1, 1, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 13, 1, 1, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[128, 1, 2])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
[13:32:50] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #1: "fused_nn_conv2d_add"
[13:32:50] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1024, 13, 13), "float32"], placeholder_1: T.Buffer[(255, 1024, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 255, 1, 1), "float32"], T_add: T.Buffer[(1, 255, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 1024, 13, 13], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 255, 13, 13], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 1024, 13, 13):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[i0_1, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 255, 13, 13, 1024, 1, 1):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 1024, 13, 13], "float32"], ["TENSOR", [255, 1024, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 255, 13, 13):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
    

[13:32:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:32:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1024, 13, 13), "float32"], placeholder_1: T.Buffer[(255, 1024, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 255, 1, 1), "float32"], T_add: T.Buffer[(1, 255, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":64})
            conv2d_nchw_local = T.alloc_buffer([1, 255, 13, 13], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 1024, 13, 13], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([255, 1024, 1, 1], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(1, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(17, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(15, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(8, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(21632):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(1024, i4_0 * 128 + ax0_ax1_ax2_ax3_fused // 169)
                                    v2 = T.axis.spatial(13, ax0_ax1_ax2_ax3_fused % 169 // 13)
                                    v3 = T.axis.spatial(13, ax0_ax1_ax2_ax3_fused % 13)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":1})
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in T.serial(32640):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(255, ax0_ax1_ax2_ax3_fused // 128)
                                    v1 = T.axis.spatial(1024, i4_0 * 128 + ax0_ax1_ax2_ax3_fused % 128)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":2})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(8, 1, 1, 1, 1, 13, 13, 16, 1, 1, 1, 1, 1, 1):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(255, i0_1_i1_1_i2_1_i3_1_fused * 15 + i0_2_i1_2_i2_2_i3_2_fused)
                                    yy, xx = T.axis.remap("SS", [i2_3, i3_3])
                                    rc = T.axis.reduce(1024, i4_0 * 128 + i4_1 * 16 + i4_2)
                                    ry = T.axis.reduce(1, 0)
                                    rx = T.axis.reduce(1, 0)
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 1024, 13, 13], "float32"], ["TENSOR", [255, 1024, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 1, 13, 13):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(255, i0_1_i1_1_i2_1_i3_1_fused * 15 + i0_2_i1_2_i2_2_i3_2_fused + ax1)
                                v2, v3 = T.axis.remap("SS", [ax2, ax3])
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                                T.writes(T_add[v0, v1, v2, v3])
                                T_add[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b1)
v11, v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l16, l17, l18, l19, l20 = sch.split(loop=l4, factors=[v11, v12, v13, v14, v15])
v21, v22, v23, v24, v25 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 17, 15, 1, 1])
l26, l27, l28, l29, l30 = sch.split(loop=l5, factors=[v21, v22, v23, v24, v25])
v31, v32, v33, v34, v35 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 1, 1, 13, 1])
l36, l37, l38, l39, l40 = sch.split(loop=l6, factors=[v31, v32, v33, v34, v35])
v41, v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 1, 1, 13, 1])
l46, l47, l48, l49, l50 = sch.split(loop=l7, factors=[v41, v42, v43, v44, v45])
v51, v52, v53 = sch.sample_perfect_tile(loop=l8, n=3, max_innermost_factor=64, decision=[8, 8, 16])
l54, l55, l56 = sch.split(loop=l8, factors=[v51, v52, v53])
v57, v58, v59 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l60, l61, l62 = sch.split(loop=l9, factors=[v57, v58, v59])
v63, v64, v65 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l66, l67, l68 = sch.split(loop=l10, factors=[v63, v64, v65])
sch.reorder(l16, l26, l36, l46, l17, l27, l37, l47, l18, l28, l38, l48, l54, l60, l66, l55, l61, l67, l19, l29, l39, l49, l56, l62, l68, l20, l30, l40, l50)
l69 = sch.fuse(l16, l26, l36, l46)
sch.bind(loop=l69, thread_axis="blockIdx.x")
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="vthread.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b72 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b72, loop=l71, preserve_unit_loops=True)
b73 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b73, loop=l66, preserve_unit_loops=True)
l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b73)
l84 = sch.fuse(l80, l81, l82, l83)
v85 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b73, ann_key="meta_schedule.cooperative_fetch", ann_val=v85)
b86 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b86, loop=l66, preserve_unit_loops=True)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96 = sch.get_loops(block=b86)
l97 = sch.fuse(l93, l94, l95, l96)
v98 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b86, ann_key="meta_schedule.cooperative_fetch", ann_val=v98)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v99 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v99)
[13:32:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"
[13:32:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 255, 13, 13), "float32"], T_concat: T.Buffer[(1, 13, 13, 3, 85), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        T_transpose = T.alloc_buffer([1, 13, 13, 255], dtype="float32")
        T_reshape = T.alloc_buffer([1, 13, 13, 3, 85], dtype="float32")
        T_split = T.alloc_buffer([1, 13, 13, 3, 80], dtype="float32")
        T_sigmoid = T.alloc_buffer([1, 13, 13, 3, 80], dtype="float32")
        T_split_1 = T.alloc_buffer([1, 13, 13, 3, 1], dtype="float32")
        T_sigmoid_1 = T.alloc_buffer([1, 13, 13, 3, 1], dtype="float32")
        T_split_2 = T.alloc_buffer([1, 13, 13, 3, 4], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 13, 13, 255):
            with T.block("T_transpose"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[ax0, ax3, ax1, ax2])
                T.writes(T_transpose[ax0, ax1, ax2, ax3])
                T_transpose[ax0, ax1, ax2, ax3] = placeholder[ax0, ax3, ax1, ax2]
        for i0, i1, i2, i3, i4 in T.grid(1, 13, 13, 3, 85):
            with T.block("T_reshape"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_transpose[0, ((ax2 * 255 + ax3 * 85 + ax4) // 3315 + ax1) % 13, ((ax3 * 85 + ax4) // 255 + ax2) % 13, (ax3 * 85 + ax4) % 255])
                T.writes(T_reshape[ax0, ax1, ax2, ax3, ax4])
                T_reshape[ax0, ax1, ax2, ax3, ax4] = T_transpose[0, ((ax2 * 255 + ax3 * 85 + ax4) // 3315 + ax1) % 13, ((ax3 * 85 + ax4) // 255 + ax2) % 13, (ax3 * 85 + ax4) % 255]
        for i0, i1, i2, i3, i4 in T.grid(1, 13, 13, 3, 80):
            with T.block("T_split"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_reshape[ax0, ax1, ax2, ax3, ax4 + 5])
                T.writes(T_split[ax0, ax1, ax2, ax3, ax4])
                T_split[ax0, ax1, ax2, ax3, ax4] = T_reshape[ax0, ax1, ax2, ax3, ax4 + 5]
        for i0, i1, i2, i3, i4 in T.grid(1, 13, 13, 3, 80):
            with T.block("T_sigmoid"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_split[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_sigmoid[ax0, ax1, ax2, ax3, ax4])
                T_sigmoid[ax0, ax1, ax2, ax3, ax4] = T.sigmoid(T_split[ax0, ax1, ax2, ax3, ax4], dtype="float32")
        for i0, i1, i2, i3, i4 in T.grid(1, 13, 13, 3, 1):
            with T.block("T_split_1"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_reshape[ax0, ax1, ax2, ax3, ax4 + 4])
                T.writes(T_split_1[ax0, ax1, ax2, ax3, ax4])
                T_split_1[ax0, ax1, ax2, ax3, ax4] = T_reshape[ax0, ax1, ax2, ax3, ax4 + 4]
        for i0, i1, i2, i3, i4 in T.grid(1, 13, 13, 3, 1):
            with T.block("T_sigmoid_1"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_split_1[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_sigmoid_1[ax0, ax1, ax2, ax3, ax4])
                T_sigmoid_1[ax0, ax1, ax2, ax3, ax4] = T.sigmoid(T_split_1[ax0, ax1, ax2, ax3, ax4], dtype="float32")
        for i0, i1, i2, i3, i4 in T.grid(1, 13, 13, 3, 4):
            with T.block("T_split_2"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_reshape[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_split_2[ax0, ax1, ax2, ax3, ax4])
                T_split_2[ax0, ax1, ax2, ax3, ax4] = T_reshape[ax0, ax1, ax2, ax3, ax4]
        for i0, i1, i2, i3, i4 in T.grid(1, 13, 13, 3, 85):
            with T.block("T_concat"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_sigmoid[ax0, ax1, ax2, ax3, ax4 - 5], T_sigmoid_1[ax0, ax1, ax2, ax3, ax4 - 4], T_split_2[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_concat[ax0, ax1, ax2, ax3, ax4])
                T_concat[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(5 <= ax4, T_sigmoid[ax0, ax1, ax2, ax3, ax4 - 5], T.if_then_else(4 <= ax4, T_sigmoid_1[ax0, ax1, ax2, ax3, ax4 - 4], T_split_2[ax0, ax1, ax2, ax3, ax4], dtype="float32"), dtype="float32")
    

[13:32:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:32:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 255, 13, 13), "float32"], T_concat: T.Buffer[(1, 13, 13, 3, 85), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":512})
            for i0, i1, i2, i3, i4 in T.grid(1, 13, 13, 3, 85):
                with T.block("T_concat"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(placeholder[0, (ax3 * 85 + ax4) % 255, ((ax2 * 255 + ax3 * 85 + ax4) // 3315 + ax1) % 13, ((ax3 * 85 + ax4) // 255 + ax2) % 13])
                    T.writes(T_concat[ax0, ax1, ax2, ax3, ax4])
                    T_concat[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(5 <= ax4, T.sigmoid(placeholder[0, (ax3 * 85 + (ax4 - 5 + 5)) % 255, ((ax2 * 255 + ax3 * 85 + (ax4 - 5 + 5)) // 3315 + ax1) % 13, ((ax3 * 85 + (ax4 - 5 + 5)) // 255 + ax2) % 13], dtype="float32"), T.if_then_else(4 <= ax4, T.sigmoid(placeholder[0, (ax3 * 85 + (ax4 - 4 + 4)) % 255, ((ax2 * 255 + ax3 * 85 + (ax4 - 4 + 4)) // 3315 + ax1) % 13, ((ax3 * 85 + (ax4 - 4 + 4)) // 255 + ax2) % 13], dtype="float32"), placeholder[0, (ax3 * 85 + ax4) % 255, ((ax2 * 255 + ax3 * 85 + ax4) // 3315 + ax1) % 13, ((ax3 * 85 + ax4) // 255 + ax2) % 13], dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="T_transpose", func_name="main")
b1 = sch.get_block(name="T_reshape", func_name="main")
b2 = sch.get_block(name="T_split", func_name="main")
b3 = sch.get_block(name="T_sigmoid", func_name="main")
b4 = sch.get_block(name="T_split_1", func_name="main")
b5 = sch.get_block(name="T_sigmoid_1", func_name="main")
b6 = sch.get_block(name="T_split_2", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
v8 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v8)
[13:32:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"
[13:32:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 52, 52), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 256, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 128, 53, 53], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
        T_add = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 128, 53, 53):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = T.if_then_else(1 <= i2_1 and i2_1 < 53 and 1 <= i3_1 and i3_1 < 53, placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 256, 26, 26, 128, 3, 3):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
            with T.block("T_leaky_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_leaky_relu[ax0, ax1, ax2, ax3])
                T_leaky_relu[ax0, ax1, ax2, ax3] = T.Select(T.float32(0) < T_add[ax0, ax1, ax2, ax3], T_add[ax0, ax1, ax2, ax3], T_add[ax0, ax1, ax2, ax3] * T.float32(0.10000000149011612))
    

[13:32:52] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:32:52] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 52, 52), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 256, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":512})
            conv2d_nchw_local = T.alloc_buffer([1, 256, 26, 26], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 128, 53, 53], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([256, 128, 3, 3], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(16, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(26, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(1, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(64, 3, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(2754):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(128, i4_0 * 2 + ax0_ax1_ax2_ax3_fused % 2754 // 1377)
                                    v2 = T.axis.spatial(53, i5_0 + ax0_ax1_ax2_ax3_fused % 1377 // 27)
                                    v3 = T.axis.spatial(53, i0_0_i1_0_i2_0_i3_0_fused % 2 * 26 + ax0_ax1_ax2_ax3_fused % 27)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":2})
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 53 and 1 <= v3 and v3 < 53, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                            for ax0_ax1_ax2_ax3_fused in T.serial(192):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 2 * 32 + ax0_ax1_ax2_ax3_fused // 6)
                                    v1 = T.axis.spatial(128, i4_0 * 2 + ax0_ax1_ax2_ax3_fused % 6 // 3)
                                    v2 = T.axis.spatial(3, i5_0)
                                    v3 = T.axis.spatial(3, ax0_ax1_ax2_ax3_fused % 3)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":4})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(2, 1, 3, 1, 4, 13, 1, 1, 1, 1, 1, 4, 2, 1):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 2 * 32 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 16 + i1_3 * 4 + i1_4)
                                    yy = T.axis.spatial(26, i2_3 * 2 + i2_4)
                                    xx = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused % 2 * 13 + i0_1_i1_1_i2_1_i3_1_fused % 13)
                                    rc = T.axis.reduce(128, i4_0 * 2 + i4_1)
                                    ry, rx = T.axis.remap("RR", [i5_0, i6_1])
                                    T.reads(pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 16, 26, 1):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 2 * 32 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 16 + ax1)
                                v2 = T.axis.spatial(26, ax2)
                                v3 = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused % 2 * 13 + i0_1_i1_1_i2_1_i3_1_fused % 13 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                                T.writes(T_leaky_relu[v0, v1, v2, v3])
                                T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[8, 2, 1, 4, 4])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 1, 1, 13, 2])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[2, 13, 1, 1, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[64, 2, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
[13:32:52] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #4: "fused_nn_conv2d_add_1"
[13:32:52] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 26, 26), "float32"], placeholder_1: T.Buffer[(255, 512, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 255, 1, 1), "float32"], T_add: T.Buffer[(1, 255, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 512, 26, 26], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 255, 26, 26], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 26, 26):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[i0_1, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 255, 26, 26, 512, 1, 1):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 26, 26], "float32"], ["TENSOR", [255, 512, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 255, 26, 26):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
    

[13:32:52] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:32:52] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 26, 26), "float32"], placeholder_1: T.Buffer[(255, 512, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 255, 1, 1), "float32"], T_add: T.Buffer[(1, 255, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":16})
            conv2d_nchw_local = T.alloc_buffer([1, 255, 26, 26], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 512, 26, 26], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([255, 512, 1, 1], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(663, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(2, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(130, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(8, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(3328):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(512, i4_0 * 64 + ax0_ax1_ax2_ax3_fused // 52)
                                    v2 = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused % 13 * 2 + ax0_ax1_ax2_ax3_fused % 52 // 26)
                                    v3 = T.axis.spatial(26, ax0_ax1_ax2_ax3_fused % 26)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":1})
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in T.serial(320):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(255, i0_0_i1_0_i2_0_i3_0_fused // 13 * 5 + ax0_ax1_ax2_ax3_fused // 64)
                                    v1 = T.axis.spatial(512, i4_0 * 64 + ax0_ax1_ax2_ax3_fused % 64)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":3})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(255, i0_0_i1_0_i2_0_i3_0_fused // 13 * 5 + i0_2_i1_2_i2_2_i3_2_fused // 26)
                                    yy = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused % 13 * 2 + i0_2_i1_2_i2_2_i3_2_fused % 26 // 13)
                                    xx = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused * 13 + i0_2_i1_2_i2_2_i3_2_fused % 13)
                                    rc = T.axis.reduce(512, i4_0 * 64 + i4_1)
                                    ry = T.axis.reduce(1, 0)
                                    rx = T.axis.reduce(1, 0)
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 26, 26], "float32"], ["TENSOR", [255, 512, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 1, 1, 1):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(255, i0_0_i1_0_i2_0_i3_0_fused // 13 * 5 + i0_2_i1_2_i2_2_i3_2_fused // 26 + ax1)
                                v2 = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused % 13 * 2 + i0_2_i1_2_i2_2_i3_2_fused % 26 // 13 + ax2)
                                v3 = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused * 13 + i0_2_i1_2_i2_2_i3_2_fused % 13 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                                T.writes(T_add[v0, v1, v2, v3])
                                T_add[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b1)
v11, v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l16, l17, l18, l19, l20 = sch.split(loop=l4, factors=[v11, v12, v13, v14, v15])
v21, v22, v23, v24, v25 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[51, 1, 5, 1, 1])
l26, l27, l28, l29, l30 = sch.split(loop=l5, factors=[v21, v22, v23, v24, v25])
v31, v32, v33, v34, v35 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[13, 1, 2, 1, 1])
l36, l37, l38, l39, l40 = sch.split(loop=l6, factors=[v31, v32, v33, v34, v35])
v41, v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 2, 13, 1, 1])
l46, l47, l48, l49, l50 = sch.split(loop=l7, factors=[v41, v42, v43, v44, v45])
v51, v52, v53 = sch.sample_perfect_tile(loop=l8, n=3, max_innermost_factor=64, decision=[8, 64, 1])
l54, l55, l56 = sch.split(loop=l8, factors=[v51, v52, v53])
v57, v58, v59 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l60, l61, l62 = sch.split(loop=l9, factors=[v57, v58, v59])
v63, v64, v65 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l66, l67, l68 = sch.split(loop=l10, factors=[v63, v64, v65])
sch.reorder(l16, l26, l36, l46, l17, l27, l37, l47, l18, l28, l38, l48, l54, l60, l66, l55, l61, l67, l19, l29, l39, l49, l56, l62, l68, l20, l30, l40, l50)
l69 = sch.fuse(l16, l26, l36, l46)
sch.bind(loop=l69, thread_axis="blockIdx.x")
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="vthread.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b72 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b72, loop=l71, preserve_unit_loops=True)
b73 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b73, loop=l66, preserve_unit_loops=True)
l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b73)
l84 = sch.fuse(l80, l81, l82, l83)
v85 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b73, ann_key="meta_schedule.cooperative_fetch", ann_val=v85)
b86 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b86, loop=l66, preserve_unit_loops=True)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96 = sch.get_loops(block=b86)
l97 = sch.fuse(l93, l94, l95, l96)
v98 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b86, ann_key="meta_schedule.cooperative_fetch", ann_val=v98)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v99 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v99)
[13:32:52] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"
[13:32:52] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 255, 26, 26), "float32"], T_concat: T.Buffer[(1, 26, 26, 3, 85), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        T_transpose = T.alloc_buffer([1, 26, 26, 255], dtype="float32")
        T_reshape = T.alloc_buffer([1, 26, 26, 3, 85], dtype="float32")
        T_split = T.alloc_buffer([1, 26, 26, 3, 80], dtype="float32")
        T_sigmoid = T.alloc_buffer([1, 26, 26, 3, 80], dtype="float32")
        T_split_1 = T.alloc_buffer([1, 26, 26, 3, 1], dtype="float32")
        T_sigmoid_1 = T.alloc_buffer([1, 26, 26, 3, 1], dtype="float32")
        T_split_2 = T.alloc_buffer([1, 26, 26, 3, 4], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 26, 26, 255):
            with T.block("T_transpose"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[ax0, ax3, ax1, ax2])
                T.writes(T_transpose[ax0, ax1, ax2, ax3])
                T_transpose[ax0, ax1, ax2, ax3] = placeholder[ax0, ax3, ax1, ax2]
        for i0, i1, i2, i3, i4 in T.grid(1, 26, 26, 3, 85):
            with T.block("T_reshape"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_transpose[0, ((ax2 * 255 + ax3 * 85 + ax4) // 6630 + ax1) % 26, ((ax3 * 85 + ax4) // 255 + ax2) % 26, (ax3 * 85 + ax4) % 255])
                T.writes(T_reshape[ax0, ax1, ax2, ax3, ax4])
                T_reshape[ax0, ax1, ax2, ax3, ax4] = T_transpose[0, ((ax2 * 255 + ax3 * 85 + ax4) // 6630 + ax1) % 26, ((ax3 * 85 + ax4) // 255 + ax2) % 26, (ax3 * 85 + ax4) % 255]
        for i0, i1, i2, i3, i4 in T.grid(1, 26, 26, 3, 80):
            with T.block("T_split"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_reshape[ax0, ax1, ax2, ax3, ax4 + 5])
                T.writes(T_split[ax0, ax1, ax2, ax3, ax4])
                T_split[ax0, ax1, ax2, ax3, ax4] = T_reshape[ax0, ax1, ax2, ax3, ax4 + 5]
        for i0, i1, i2, i3, i4 in T.grid(1, 26, 26, 3, 80):
            with T.block("T_sigmoid"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_split[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_sigmoid[ax0, ax1, ax2, ax3, ax4])
                T_sigmoid[ax0, ax1, ax2, ax3, ax4] = T.sigmoid(T_split[ax0, ax1, ax2, ax3, ax4], dtype="float32")
        for i0, i1, i2, i3, i4 in T.grid(1, 26, 26, 3, 1):
            with T.block("T_split_1"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_reshape[ax0, ax1, ax2, ax3, ax4 + 4])
                T.writes(T_split_1[ax0, ax1, ax2, ax3, ax4])
                T_split_1[ax0, ax1, ax2, ax3, ax4] = T_reshape[ax0, ax1, ax2, ax3, ax4 + 4]
        for i0, i1, i2, i3, i4 in T.grid(1, 26, 26, 3, 1):
            with T.block("T_sigmoid_1"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_split_1[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_sigmoid_1[ax0, ax1, ax2, ax3, ax4])
                T_sigmoid_1[ax0, ax1, ax2, ax3, ax4] = T.sigmoid(T_split_1[ax0, ax1, ax2, ax3, ax4], dtype="float32")
        for i0, i1, i2, i3, i4 in T.grid(1, 26, 26, 3, 4):
            with T.block("T_split_2"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_reshape[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_split_2[ax0, ax1, ax2, ax3, ax4])
                T_split_2[ax0, ax1, ax2, ax3, ax4] = T_reshape[ax0, ax1, ax2, ax3, ax4]
        for i0, i1, i2, i3, i4 in T.grid(1, 26, 26, 3, 85):
            with T.block("T_concat"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_sigmoid[ax0, ax1, ax2, ax3, ax4 - 5], T_sigmoid_1[ax0, ax1, ax2, ax3, ax4 - 4], T_split_2[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_concat[ax0, ax1, ax2, ax3, ax4])
                T_concat[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(5 <= ax4, T_sigmoid[ax0, ax1, ax2, ax3, ax4 - 5], T.if_then_else(4 <= ax4, T_sigmoid_1[ax0, ax1, ax2, ax3, ax4 - 4], T_split_2[ax0, ax1, ax2, ax3, ax4], dtype="float32"), dtype="float32")
    

[13:32:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:32:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 255, 26, 26), "float32"], T_concat: T.Buffer[(1, 26, 26, 3, 85), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":512})
            for i0, i1, i2, i3, i4 in T.grid(1, 26, 26, 3, 85):
                with T.block("T_concat"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(placeholder[0, (ax3 * 85 + ax4) % 255, ((ax2 * 255 + ax3 * 85 + ax4) // 6630 + ax1) % 26, ((ax3 * 85 + ax4) // 255 + ax2) % 26])
                    T.writes(T_concat[ax0, ax1, ax2, ax3, ax4])
                    T_concat[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(5 <= ax4, T.sigmoid(placeholder[0, (ax3 * 85 + (ax4 - 5 + 5)) % 255, ((ax2 * 255 + ax3 * 85 + (ax4 - 5 + 5)) // 6630 + ax1) % 26, ((ax3 * 85 + (ax4 - 5 + 5)) // 255 + ax2) % 26], dtype="float32"), T.if_then_else(4 <= ax4, T.sigmoid(placeholder[0, (ax3 * 85 + (ax4 - 4 + 4)) % 255, ((ax2 * 255 + ax3 * 85 + (ax4 - 4 + 4)) // 6630 + ax1) % 26, ((ax3 * 85 + (ax4 - 4 + 4)) // 255 + ax2) % 26], dtype="float32"), placeholder[0, (ax3 * 85 + ax4) % 255, ((ax2 * 255 + ax3 * 85 + ax4) // 6630 + ax1) % 26, ((ax3 * 85 + ax4) // 255 + ax2) % 26], dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="T_transpose", func_name="main")
b1 = sch.get_block(name="T_reshape", func_name="main")
b2 = sch.get_block(name="T_split", func_name="main")
b3 = sch.get_block(name="T_sigmoid", func_name="main")
b4 = sch.get_block(name="T_split_1", func_name="main")
b5 = sch.get_block(name="T_sigmoid_1", func_name="main")
b6 = sch.get_block(name="T_split_2", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
v8 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v8)
[13:32:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #6: "fused_nn_max_pool2d"
[13:32:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 13, 13), "float32"], tensor: T.Buffer[(1, 512, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 512, 17, 17], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 17, 17):
            with T.block("pad_temp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[ax0, ax1, ax2 - 2, ax3 - 2])
                T.writes(pad_temp[ax0, ax1, ax2, ax3])
                pad_temp[ax0, ax1, ax2, ax3] = T.if_then_else(2 <= ax2 and ax2 < 15 and 2 <= ax3 and ax3 < 15, placeholder[ax0, ax1, ax2 - 2, ax3 - 2], T.float32(-3.4028234663852886e+38), dtype="float32")
        for i0, i1, i2, i3, i4, i5 in T.grid(1, 512, 13, 13, 5, 5):
            with T.block("tensor"):
                ax0, ax1, ax2, ax3, rv0, rv1 = T.axis.remap("SSSSRR", [i0, i1, i2, i3, i4, i5])
                T.reads(pad_temp[ax0, ax1, ax2 + rv0, ax3 + rv1])
                T.writes(tensor[ax0, ax1, ax2, ax3])
                with T.init():
                    tensor[ax0, ax1, ax2, ax3] = T.float32(-3.4028234663852886e+38)
                tensor[ax0, ax1, ax2, ax3] = T.max(tensor[ax0, ax1, ax2, ax3], pad_temp[ax0, ax1, ax2 + rv0, ax3 + rv1])
    

[13:32:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:32:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 13, 13), "float32"], tensor: T.Buffer[(1, 512, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":0})
            for i0, i1, i2, i3, i4, i5 in T.grid(1, 512, 13, 13, 5, 5):
                with T.block("tensor"):
                    ax0, ax1, ax2, ax3, rv0, rv1 = T.axis.remap("SSSSRR", [i0, i1, i2, i3, i4, i5])
                    T.reads(placeholder[ax0, ax1, ax2 + rv0 - 2, ax3 + rv1 - 2])
                    T.writes(tensor[ax0, ax1, ax2, ax3])
                    with T.init():
                        tensor[ax0, ax1, ax2, ax3] = T.float32(-3.4028234663852886e+38)
                    tensor[ax0, ax1, ax2, ax3] = T.max(tensor[ax0, ax1, ax2, ax3], T.if_then_else(2 <= ax2 + rv0 and ax2 + rv0 < 15 and 2 <= ax3 + rv1 and ax3 + rv1 < 15, placeholder[ax0, ax1, ax2 + rv0 - 2, ax3 + rv1 - 2], T.float32(-3.4028234663852886e+38), dtype="float32"))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b0)
v2 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v2)
[13:32:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #7: "fused_nn_max_pool2d_1"
[13:32:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 13, 13), "float32"], tensor: T.Buffer[(1, 512, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 512, 21, 21], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 21, 21):
            with T.block("pad_temp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[ax0, ax1, ax2 - 4, ax3 - 4])
                T.writes(pad_temp[ax0, ax1, ax2, ax3])
                pad_temp[ax0, ax1, ax2, ax3] = T.if_then_else(4 <= ax2 and ax2 < 17 and 4 <= ax3 and ax3 < 17, placeholder[ax0, ax1, ax2 - 4, ax3 - 4], T.float32(-3.4028234663852886e+38), dtype="float32")
        for i0, i1, i2, i3, i4, i5 in T.grid(1, 512, 13, 13, 9, 9):
            with T.block("tensor"):
                ax0, ax1, ax2, ax3, rv0, rv1 = T.axis.remap("SSSSRR", [i0, i1, i2, i3, i4, i5])
                T.reads(pad_temp[ax0, ax1, ax2 + rv0, ax3 + rv1])
                T.writes(tensor[ax0, ax1, ax2, ax3])
                with T.init():
                    tensor[ax0, ax1, ax2, ax3] = T.float32(-3.4028234663852886e+38)
                tensor[ax0, ax1, ax2, ax3] = T.max(tensor[ax0, ax1, ax2, ax3], pad_temp[ax0, ax1, ax2 + rv0, ax3 + rv1])
    

[13:32:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 2 design space(s) generated
[13:32:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 13, 13), "float32"], tensor: T.Buffer[(1, 512, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":64})
            for i0, i1, i2, i3, i4_i5_fused_0 in T.grid(1, 512, 13, 13, 21):
                for i4_i5_fused_1 in T.thread_binding(4, thread="threadIdx.x"):
                    with T.block("tensor"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1, ax2, ax3 = T.axis.remap("SSS", [i1, i2, i3])
                        rv0 = T.axis.reduce(9, (i4_i5_fused_0 * 4 + i4_i5_fused_1) // 9)
                        rv1 = T.axis.reduce(9, (i4_i5_fused_0 * 4 + i4_i5_fused_1) % 9)
                        T.where(i4_i5_fused_0 * 4 + i4_i5_fused_1 < 81)
                        T.reads(placeholder[ax0, ax1, ax2 + rv0 - 4, ax3 + rv1 - 4])
                        T.writes(tensor[ax0, ax1, ax2, ax3])
                        with T.init():
                            tensor[ax0, ax1, ax2, ax3] = T.float32(-3.4028234663852886e+38)
                        tensor[ax0, ax1, ax2, ax3] = T.max(tensor[ax0, ax1, ax2, ax3], T.if_then_else(4 <= ax2 + rv0 and ax2 + rv0 < 17 and 4 <= ax3 + rv1 and ax3 + rv1 < 17, placeholder[ax0, ax1, ax2 + rv0 - 4, ax3 + rv1 - 4], T.float32(-3.4028234663852886e+38), dtype="float32"))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="tensor", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b0)
v3 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=0)
l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b1)
l10 = sch.fuse(l8, l9)
l11, l12 = sch.split(loop=l10, factors=[None, v3])
sch.bind(loop=l12, thread_axis="threadIdx.x")
v13 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v13)
[13:32:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #1:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 13, 13), "float32"], tensor: T.Buffer[(1, 512, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":16})
            for i0, i1, i2, i3, i4, i5 in T.grid(1, 512, 13, 13, 9, 9):
                with T.block("tensor"):
                    ax0, ax1, ax2, ax3, rv0, rv1 = T.axis.remap("SSSSRR", [i0, i1, i2, i3, i4, i5])
                    T.reads(placeholder[ax0, ax1, ax2 + rv0 - 4, ax3 + rv1 - 4])
                    T.writes(tensor[ax0, ax1, ax2, ax3])
                    with T.init():
                        tensor[ax0, ax1, ax2, ax3] = T.float32(-3.4028234663852886e+38)
                    tensor[ax0, ax1, ax2, ax3] = T.max(tensor[ax0, ax1, ax2, ax3], T.if_then_else(4 <= ax2 + rv0 and ax2 + rv0 < 17 and 4 <= ax3 + rv1 and ax3 + rv1 < 17, placeholder[ax0, ax1, ax2 + rv0 - 4, ax3 + rv1 - 4], T.float32(-3.4028234663852886e+38), dtype="float32"))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b0)
v2 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v2)
[13:32:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #8: "fused_transpose"
[13:32:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 416, 416, 3), "float32"], T_transpose: T.Buffer[(1, 3, 416, 416), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3 in T.grid(1, 3, 416, 416):
            with T.block("T_transpose"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[ax0, ax2, ax3, ax1])
                T.writes(T_transpose[ax0, ax1, ax2, ax3])
                T_transpose[ax0, ax1, ax2, ax3] = placeholder[ax0, ax2, ax3, ax1]
    

[13:32:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:32:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 416, 416, 3), "float32"], T_transpose: T.Buffer[(1, 3, 416, 416), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":16})
            for i0, i1, i2, i3 in T.grid(1, 3, 416, 416):
                with T.block("T_transpose"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(placeholder[ax0, ax2, ax3, ax1])
                    T.writes(T_transpose[ax0, ax1, ax2, ax3])
                    T_transpose[ax0, ax1, ax2, ax3] = placeholder[ax0, ax2, ax3, ax1]
    

b0 = sch.get_block(name="root", func_name="main")
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
[13:32:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"
[13:32:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 3, 416, 416), "float32"], placeholder_1: T.Buffer[(32, 3, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 32, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 32, 416, 416), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 3, 418, 418], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 32, 416, 416], dtype="float32")
        T_add = T.alloc_buffer([1, 32, 416, 416], dtype="float32")
        T_exp = T.alloc_buffer([1, 32, 416, 416], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 32, 416, 416], dtype="float32")
        T_log = T.alloc_buffer([1, 32, 416, 416], dtype="float32")
        T_tanh = T.alloc_buffer([1, 32, 416, 416], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 3, 418, 418):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = T.if_then_else(1 <= i2_1 and i2_1 < 417 and 1 <= i3_1 and i3_1 < 417, placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 32, 416, 416, 3, 3, 3):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 3, 416, 416], "float32"], ["TENSOR", [32, 3, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 32, 416, 416):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 32, 416, 416):
            with T.block("T_exp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_exp[ax0, ax1, ax2, ax3])
                T_exp[ax0, ax1, ax2, ax3] = T.exp(T_add[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 32, 416, 416):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_3[ax0, 0, 0, 0], T_exp[ax0, ax1, ax2, ax3])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = placeholder_3[ax0, 0, 0, 0] + T_exp[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 32, 416, 416):
            with T.block("T_log"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3])
                T.writes(T_log[ax0, ax1, ax2, ax3])
                T_log[ax0, ax1, ax2, ax3] = T.log(T_add_1[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 32, 416, 416):
            with T.block("T_tanh"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_log[ax0, ax1, ax2, ax3])
                T.writes(T_tanh[ax0, ax1, ax2, ax3])
                T_tanh[ax0, ax1, ax2, ax3] = T.tanh(T_log[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 32, 416, 416):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3], T_tanh[ax0, ax1, ax2, ax3])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = T_add[ax0, ax1, ax2, ax3] * T_tanh[ax0, ax1, ax2, ax3]
    

[13:32:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:32:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 3, 416, 416), "float32"], placeholder_1: T.Buffer[(32, 3, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 32, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 32, 416, 416), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":1024})
            conv2d_nchw = T.alloc_buffer([1, 32, 416, 416], dtype="float32")
            conv2d_nchw_local = T.alloc_buffer([1, 32, 416, 416], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 3, 418, 418], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([32, 3, 3, 3], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(16, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(8, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(338, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(3, 3, 3):
                            for ax0_ax1_ax2_ax3_fused in T.serial(86528):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(3, i4_0 + 0)
                                    v2 = T.axis.spatial(418, i5_0 + ax0_ax1_ax2_ax3_fused % 86528 // 208)
                                    v3 = T.axis.spatial(418, i0_0_i1_0_i2_0_i3_0_fused % 2 * 208 + i6_0 + ax0_ax1_ax2_ax3_fused % 208)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":4})
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 417 and 1 <= v3 and v3 < 417, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                            for ax0_ax1_ax2_ax3_fused in T.serial(4):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(32, i0_0_i1_0_i2_0_i3_0_fused // 2 * 4 + ax0_ax1_ax2_ax3_fused)
                                    v1, v2, v3 = T.axis.remap("SSS", [i4_0, i5_0, i6_0])
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":1})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 8, 4):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(32, i0_0_i1_0_i2_0_i3_0_fused // 2 * 4 + i0_2_i1_2_i2_2_i3_2_fused // 169 * 2 + i1_4)
                                    yy = T.axis.spatial(416, i0_1_i1_1_i2_1_i3_1_fused // 4 * 208 + i0_2_i1_2_i2_2_i3_2_fused % 169 // 13 * 16 + i2_3 * 8 + i2_4)
                                    xx = T.axis.spatial(416, i0_0_i1_0_i2_0_i3_0_fused % 2 * 208 + i0_1_i1_1_i2_1_i3_1_fused % 4 * 52 + i0_2_i1_2_i2_2_i3_2_fused % 13 * 4 + i3_4)
                                    rc, ry, rx = T.axis.remap("RRR", [i4_0, i5_0, i6_0])
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 3, 416, 416], "float32"], ["TENSOR", [32, 3, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 2, 16, 4):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(32, i0_0_i1_0_i2_0_i3_0_fused // 2 * 4 + i0_2_i1_2_i2_2_i3_2_fused // 169 * 2 + ax1)
                                v2 = T.axis.spatial(416, i0_1_i1_1_i2_1_i3_1_fused // 4 * 208 + i0_2_i1_2_i2_2_i3_2_fused % 169 // 13 * 16 + ax2)
                                v3 = T.axis.spatial(416, i0_0_i1_0_i2_0_i3_0_fused % 2 * 208 + i0_1_i1_1_i2_1_i3_1_fused % 4 * 52 + i0_2_i1_2_i2_2_i3_2_fused % 13 * 4 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                                T.writes(conv2d_nchw[v0, v1, v2, v3])
                                conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
            for i0, i1, i2, i3 in T.grid(1, 32, 416, 416):
                with T.block("T_multiply"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_multiply[ax0, ax1, ax2, ax3])
                    T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[8, 1, 2, 1, 2])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 2, 13, 2, 8])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[2, 4, 13, 1, 4])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
[13:32:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"
[13:32:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 32, 416, 416), "float32"], placeholder_1: T.Buffer[(64, 32, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 64, 208, 208), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 32, 417, 417], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        T_add = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        T_exp = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        T_log = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        T_tanh = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 32, 417, 417):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = T.if_then_else(1 <= i2_1 and i2_1 < 417 and 1 <= i3_1 and i3_1 < 417, placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 64, 208, 208, 32, 3, 3):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 32, 416, 416], "float32"], ["TENSOR", [64, 32, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
            with T.block("T_exp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_exp[ax0, ax1, ax2, ax3])
                T_exp[ax0, ax1, ax2, ax3] = T.exp(T_add[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_3[ax0, 0, 0, 0], T_exp[ax0, ax1, ax2, ax3])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = placeholder_3[ax0, 0, 0, 0] + T_exp[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
            with T.block("T_log"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3])
                T.writes(T_log[ax0, ax1, ax2, ax3])
                T_log[ax0, ax1, ax2, ax3] = T.log(T_add_1[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
            with T.block("T_tanh"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_log[ax0, ax1, ax2, ax3])
                T.writes(T_tanh[ax0, ax1, ax2, ax3])
                T_tanh[ax0, ax1, ax2, ax3] = T.tanh(T_log[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3], T_tanh[ax0, ax1, ax2, ax3])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = T_add[ax0, ax1, ax2, ax3] * T_tanh[ax0, ax1, ax2, ax3]
    

[13:32:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:32:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 32, 416, 416), "float32"], placeholder_1: T.Buffer[(64, 32, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 64, 208, 208), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":16})
            conv2d_nchw = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
            conv2d_nchw_local = T.alloc_buffer([1, 64, 208, 208], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 32, 417, 417], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([64, 32, 3, 3], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(26, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(64, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(4, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(4, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(56712):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(32, i4_0 * 8 + ax0_ax1_ax2_ax3_fused % 56712 // 7089)
                                    v2 = T.axis.spatial(417, ax0_ax1_ax2_ax3_fused % 7089 // 17)
                                    v3 = T.axis.spatial(417, i0_0_i1_0_i2_0_i3_0_fused * 16 + ax0_ax1_ax2_ax3_fused % 17)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":3})
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 417 and 1 <= v3 and v3 < 417, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                            for ax0_ax1_ax2_ax3_fused in T.serial(4608):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(64, ax0_ax1_ax2_ax3_fused // 72)
                                    v1 = T.axis.spatial(32, i4_0 * 8 + ax0_ax1_ax2_ax3_fused % 72 // 9)
                                    v2 = T.axis.spatial(3, ax0_ax1_ax2_ax3_fused % 9 // 3)
                                    v3 = T.axis.spatial(3, ax0_ax1_ax2_ax3_fused % 3)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":4})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(8, 3, 3, 1, 1, 1, 2, 1, 1, 1, 1, 4, 13, 4):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(64, i0_1_i1_1_i2_1_i3_1_fused // 4 * 4 + i1_4)
                                    yy = T.axis.spatial(208, i0_1_i1_1_i2_1_i3_1_fused % 4 * 52 + i0_2_i1_2_i2_2_i3_2_fused * 13 + i2_4)
                                    xx = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused * 8 + i3_3 * 4 + i3_4)
                                    rc = T.axis.reduce(32, i4_0 * 8 + i4_1)
                                    ry, rx = T.axis.remap("RR", [i5_1, i6_1])
                                    T.reads(pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 32, 416, 416], "float32"], ["TENSOR", [64, 32, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 4, 13, 8):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(64, i0_1_i1_1_i2_1_i3_1_fused // 4 * 4 + ax1)
                                v2 = T.axis.spatial(208, i0_1_i1_1_i2_1_i3_1_fused % 4 * 52 + i0_2_i1_2_i2_2_i3_2_fused * 13 + ax2)
                                v3 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused * 8 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                                T.writes(conv2d_nchw[v0, v1, v2, v3])
                                conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
            for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
                with T.block("T_multiply"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_multiply[ax0, ax1, ax2, ax3])
                    T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 16, 1, 1, 4])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 4, 4, 1, 13])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[26, 1, 1, 2, 4])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[4, 8, 1])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
[13:32:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"
[13:32:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 208, 208), "float32"], placeholder_1: T.Buffer[(32, 64, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 32, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 32, 208, 208), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 32, 208, 208], dtype="float32")
        T_add = T.alloc_buffer([1, 32, 208, 208], dtype="float32")
        T_exp = T.alloc_buffer([1, 32, 208, 208], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 32, 208, 208], dtype="float32")
        T_log = T.alloc_buffer([1, 32, 208, 208], dtype="float32")
        T_tanh = T.alloc_buffer([1, 32, 208, 208], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[i0_1, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 32, 208, 208, 64, 1, 1):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 208, 208], "float32"], ["TENSOR", [32, 64, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 32, 208, 208):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 32, 208, 208):
            with T.block("T_exp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_exp[ax0, ax1, ax2, ax3])
                T_exp[ax0, ax1, ax2, ax3] = T.exp(T_add[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 32, 208, 208):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_3[ax0, 0, 0, 0], T_exp[ax0, ax1, ax2, ax3])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = placeholder_3[ax0, 0, 0, 0] + T_exp[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 32, 208, 208):
            with T.block("T_log"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3])
                T.writes(T_log[ax0, ax1, ax2, ax3])
                T_log[ax0, ax1, ax2, ax3] = T.log(T_add_1[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 32, 208, 208):
            with T.block("T_tanh"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_log[ax0, ax1, ax2, ax3])
                T.writes(T_tanh[ax0, ax1, ax2, ax3])
                T_tanh[ax0, ax1, ax2, ax3] = T.tanh(T_log[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 32, 208, 208):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3], T_tanh[ax0, ax1, ax2, ax3])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = T_add[ax0, ax1, ax2, ax3] * T_tanh[ax0, ax1, ax2, ax3]
    

[13:32:55] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:32:55] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 208, 208), "float32"], placeholder_1: T.Buffer[(32, 64, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 32, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 32, 208, 208), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":0})
            conv2d_nchw = T.alloc_buffer([1, 32, 208, 208], dtype="float32")
            conv2d_nchw_local = T.alloc_buffer([1, 32, 208, 208], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 64, 208, 208], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([32, 64, 1, 1], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(4, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(4, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(8, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(1, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(692224):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(64, ax0_ax1_ax2_ax3_fused // 10816)
                                    v2 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused // 2 * 104 + ax0_ax1_ax2_ax3_fused % 10816 // 104)
                                    v3 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 2 * 104 + ax0_ax1_ax2_ax3_fused % 104)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":1})
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in T.serial(2048):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(32, ax0_ax1_ax2_ax3_fused // 64)
                                    v1 = T.axis.spatial(64, ax0_ax1_ax2_ax3_fused % 64)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":1})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 1, 13, 52, 64, 1, 1, 1, 8, 1, 2):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(32, i0_1_i1_1_i2_1_i3_1_fused * 8 + i1_4)
                                    yy = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused // 2 * 104 + i0_2_i1_2_i2_2_i3_2_fused * 13 + i2_3)
                                    xx = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 2 * 104 + i3_3 * 2 + i3_4)
                                    rc = T.axis.reduce(64, i4_2)
                                    ry = T.axis.reduce(1, 0)
                                    rx = T.axis.reduce(1, 0)
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 208, 208], "float32"], ["TENSOR", [32, 64, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 8, 13, 104):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(32, i0_1_i1_1_i2_1_i3_1_fused * 8 + ax1)
                                v2 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused // 2 * 104 + i0_2_i1_2_i2_2_i3_2_fused * 13 + ax2)
                                v3 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 2 * 104 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                                T.writes(conv2d_nchw[v0, v1, v2, v3])
                                conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
            for i0, i1, i2, i3 in T.grid(1, 32, 208, 208):
                with T.block("T_multiply"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_multiply[ax0, ax1, ax2, ax3])
                    T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 4, 1, 1, 8])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[2, 1, 8, 13, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[2, 1, 1, 52, 2])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[1, 1, 64])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
[13:32:55] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"
[13:32:55] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 32, 208, 208), "float32"], placeholder_1: T.Buffer[(64, 32, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], placeholder_4: T.Buffer[(1, 64, 208, 208), "float32"], T_add: T.Buffer[(1, 64, 208, 208), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 32, 210, 210], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        T_exp = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        T_add_2 = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        T_log = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        T_tanh = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        T_multiply = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 32, 210, 210):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = T.if_then_else(1 <= i2_1 and i2_1 < 209 and 1 <= i3_1 and i3_1 < 209, placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 64, 208, 208, 32, 3, 3):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 32, 208, 208], "float32"], ["TENSOR", [64, 32, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
            with T.block("T_exp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3])
                T.writes(T_exp[ax0, ax1, ax2, ax3])
                T_exp[ax0, ax1, ax2, ax3] = T.exp(T_add_1[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_3[ax0, 0, 0, 0], T_exp[ax0, ax1, ax2, ax3])
                T.writes(T_add_2[ax0, ax1, ax2, ax3])
                T_add_2[ax0, ax1, ax2, ax3] = placeholder_3[ax0, 0, 0, 0] + T_exp[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
            with T.block("T_log"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_2[ax0, ax1, ax2, ax3])
                T.writes(T_log[ax0, ax1, ax2, ax3])
                T_log[ax0, ax1, ax2, ax3] = T.log(T_add_2[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
            with T.block("T_tanh"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_log[ax0, ax1, ax2, ax3])
                T.writes(T_tanh[ax0, ax1, ax2, ax3])
                T_tanh[ax0, ax1, ax2, ax3] = T.tanh(T_log[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3], T_tanh[ax0, ax1, ax2, ax3])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = T_add_1[ax0, ax1, ax2, ax3] * T_tanh[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
            with T.block("T_add_2"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_4[ax0, ax1, ax2, ax3], T_multiply[ax0, ax1, ax2, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = placeholder_4[ax0, ax1, ax2, ax3] + T_multiply[ax0, ax1, ax2, ax3]
    

[13:32:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:32:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 32, 208, 208), "float32"], placeholder_1: T.Buffer[(64, 32, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], placeholder_4: T.Buffer[(1, 64, 208, 208), "float32"], T_add: T.Buffer[(1, 64, 208, 208), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":1024})
            conv2d_nchw = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
            conv2d_nchw_local = T.alloc_buffer([1, 64, 208, 208], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 32, 210, 210], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([64, 32, 3, 3], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(16, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(208, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(8, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(2, 3, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(174720):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(32, i4_0 * 16 + ax0_ax1_ax2_ax3_fused % 174720 // 10920)
                                    v2 = T.axis.spatial(210, i0_0_i1_0_i2_0_i3_0_fused % 4 * 52 + i5_0 + ax0_ax1_ax2_ax3_fused % 10920 // 210)
                                    v3 = T.axis.spatial(210, ax0_ax1_ax2_ax3_fused % 210)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":1})
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 209 and 1 <= v3 and v3 < 209, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                            for ax0_ax1_ax2_ax3_fused in T.serial(768):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused // 4 * 16 + ax0_ax1_ax2_ax3_fused // 48)
                                    v1 = T.axis.spatial(32, i4_0 * 16 + ax0_ax1_ax2_ax3_fused % 48 // 3)
                                    v2 = T.axis.spatial(3, i5_0)
                                    v3 = T.axis.spatial(3, ax0_ax1_ax2_ax3_fused % 3)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":2})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 3, 1, 1, 26, 2, 16, 1, 1, 1, 1, 2, 1):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused // 4 * 16 + i0_1_i1_1_i2_1_i3_1_fused // 26 * 2 + i0_2_i1_2_i2_2_i3_2_fused // 4)
                                    yy = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 4 * 52 + i2_3 * 2 + i2_4)
                                    xx = T.axis.spatial(208, i0_1_i1_1_i2_1_i3_1_fused % 26 * 8 + i0_2_i1_2_i2_2_i3_2_fused % 4 * 2 + i3_3)
                                    rc = T.axis.reduce(32, i4_0 * 16 + i4_2)
                                    ry, rx = T.axis.remap("RR", [i5_0, i6_1])
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 32, 208, 208], "float32"], ["TENSOR", [64, 32, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 1, 52, 2):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused // 4 * 16 + i0_1_i1_1_i2_1_i3_1_fused // 26 * 2 + i0_2_i1_2_i2_2_i3_2_fused // 4 + ax1)
                                v2 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 4 * 52 + ax2)
                                v3 = T.axis.spatial(208, i0_1_i1_1_i2_1_i3_1_fused % 26 * 8 + i0_2_i1_2_i2_2_i3_2_fused % 4 * 2 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                                T.writes(conv2d_nchw[v0, v1, v2, v3])
                                conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
            for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
                with T.block("T_multiply"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(placeholder_4[ax0, ax1, ax2, ax3], conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_add[ax0, ax1, ax2, ax3])
                    T_add[ax0, ax1, ax2, ax3] = placeholder_4[ax0, ax1, ax2, ax3] + (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="T_add_2", func_name="main")
b8 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l9, l10, l11, l12, l13, l14, l15 = sch.get_loops(block=b1)
v16, v17, v18, v19, v20 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l21, l22, l23, l24, l25 = sch.split(loop=l9, factors=[v16, v17, v18, v19, v20])
v26, v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[4, 8, 2, 1, 1])
l31, l32, l33, l34, l35 = sch.split(loop=l10, factors=[v26, v27, v28, v29, v30])
v36, v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[4, 1, 1, 26, 2])
l41, l42, l43, l44, l45 = sch.split(loop=l11, factors=[v36, v37, v38, v39, v40])
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l12, n=5, max_innermost_factor=64, decision=[1, 26, 4, 2, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l12, factors=[v46, v47, v48, v49, v50])
v56, v57, v58 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[2, 1, 16])
l59, l60, l61 = sch.split(loop=l13, factors=[v56, v57, v58])
v62, v63, v64 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l65, l66, l67 = sch.split(loop=l14, factors=[v62, v63, v64])
v68, v69, v70 = sch.sample_perfect_tile(loop=l15, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l71, l72, l73 = sch.split(loop=l15, factors=[v68, v69, v70])
sch.reorder(l21, l31, l41, l51, l22, l32, l42, l52, l23, l33, l43, l53, l59, l65, l71, l60, l66, l72, l24, l34, l44, l54, l61, l67, l73, l25, l35, l45, l55)
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="blockIdx.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="vthread.x")
l76 = sch.fuse(l23, l33, l43, l53)
sch.bind(loop=l76, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b77 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b77, loop=l76, preserve_unit_loops=True)
b78 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b78, loop=l71, preserve_unit_loops=True)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b78)
l89 = sch.fuse(l85, l86, l87, l88)
v90 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b78, ann_key="meta_schedule.cooperative_fetch", ann_val=v90)
b91 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b91, loop=l71, preserve_unit_loops=True)
l92, l93, l94, l95, l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b91)
l102 = sch.fuse(l98, l99, l100, l101)
v103 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b91, ann_key="meta_schedule.cooperative_fetch", ann_val=v103)
sch.reverse_compute_inline(block=b7)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v104 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b8, ann_key="meta_schedule.unroll_explicit", ann_val=v104)
[13:32:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"
[13:32:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 208, 208), "float32"], placeholder_1: T.Buffer[(64, 64, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 64, 208, 208), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        T_add = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        T_exp = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        T_log = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        T_tanh = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[i0_1, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 64, 208, 208, 64, 1, 1):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 208, 208], "float32"], ["TENSOR", [64, 64, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
            with T.block("T_exp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_exp[ax0, ax1, ax2, ax3])
                T_exp[ax0, ax1, ax2, ax3] = T.exp(T_add[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_3[ax0, 0, 0, 0], T_exp[ax0, ax1, ax2, ax3])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = placeholder_3[ax0, 0, 0, 0] + T_exp[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
            with T.block("T_log"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3])
                T.writes(T_log[ax0, ax1, ax2, ax3])
                T_log[ax0, ax1, ax2, ax3] = T.log(T_add_1[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
            with T.block("T_tanh"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_log[ax0, ax1, ax2, ax3])
                T.writes(T_tanh[ax0, ax1, ax2, ax3])
                T_tanh[ax0, ax1, ax2, ax3] = T.tanh(T_log[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3], T_tanh[ax0, ax1, ax2, ax3])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = T_add[ax0, ax1, ax2, ax3] * T_tanh[ax0, ax1, ax2, ax3]
    

[13:32:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:32:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 208, 208), "float32"], placeholder_1: T.Buffer[(64, 64, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 64, 208, 208), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":512})
            conv2d_nchw = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
            conv2d_nchw_local = T.alloc_buffer([1, 64, 208, 208], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 64, 208, 208], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([64, 64, 1, 1], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(416, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(2, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(4, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(1, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(53248):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(64, ax0_ax1_ax2_ax3_fused // 832)
                                    v2 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 52 // 2 * 8 + ax0_ax1_ax2_ax3_fused % 832 // 104)
                                    v3 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 2 * 104 + ax0_ax1_ax2_ax3_fused % 104)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":3})
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in T.serial(512):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused // 52 * 8 + ax0_ax1_ax2_ax3_fused // 64)
                                    v1 = T.axis.spatial(64, ax0_ax1_ax2_ax3_fused % 64)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":2})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(8, 1, 1, 1, 2, 2, 52, 8, 1, 1, 1, 1, 2, 2):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused // 52 * 8 + i0_1_i1_1_i2_1_i3_1_fused * 4 + i0_2_i1_2_i2_2_i3_2_fused // 2 * 2 + i1_3)
                                    yy = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 52 // 2 * 8 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 4 + i2_3 * 2 + i2_4)
                                    xx = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 2 * 104 + i3_3 * 2 + i3_4)
                                    rc = T.axis.reduce(64, i4_1 * 8 + i4_2)
                                    ry = T.axis.reduce(1, 0)
                                    rx = T.axis.reduce(1, 0)
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 208, 208], "float32"], ["TENSOR", [64, 64, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 2, 4, 104):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused // 52 * 8 + i0_1_i1_1_i2_1_i3_1_fused * 4 + i0_2_i1_2_i2_2_i3_2_fused // 2 * 2 + ax1)
                                v2 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 52 // 2 * 8 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 4 + ax2)
                                v3 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 2 * 104 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                                T.writes(conv2d_nchw[v0, v1, v2, v3])
                                conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
            for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
                with T.block("T_multiply"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_multiply[ax0, ax1, ax2, ax3])
                    T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[8, 2, 2, 2, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[26, 1, 2, 2, 2])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[2, 1, 1, 52, 2])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[1, 8, 8])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
[13:32:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #14: "fused_concatenate"
[13:32:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 208, 208), "float32"], placeholder_1: T.Buffer[(1, 64, 208, 208), "float32"], T_concat: T.Buffer[(1, 128, 208, 208), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3 in T.grid(1, 128, 208, 208):
            with T.block("T_concat"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_1[ax0, ax1 - 64, ax2, ax3], placeholder[ax0, ax1, ax2, ax3])
                T.writes(T_concat[ax0, ax1, ax2, ax3])
                T_concat[ax0, ax1, ax2, ax3] = T.if_then_else(64 <= ax1, placeholder_1[ax0, ax1 - 64, ax2, ax3], placeholder[ax0, ax1, ax2, ax3], dtype="float32")
    

[13:32:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:32:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 208, 208), "float32"], placeholder_1: T.Buffer[(1, 64, 208, 208), "float32"], T_concat: T.Buffer[(1, 128, 208, 208), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":16})
            for i0, i1, i2, i3 in T.grid(1, 128, 208, 208):
                with T.block("T_concat"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(placeholder_1[ax0, ax1 - 64, ax2, ax3], placeholder[ax0, ax1, ax2, ax3])
                    T.writes(T_concat[ax0, ax1, ax2, ax3])
                    T_concat[ax0, ax1, ax2, ax3] = T.if_then_else(64 <= ax1, placeholder_1[ax0, ax1 - 64, ax2, ax3], placeholder[ax0, ax1, ax2, ax3], dtype="float32")
    

b0 = sch.get_block(name="root", func_name="main")
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
[13:32:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"
[13:32:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 208, 208), "float32"], placeholder_1: T.Buffer[(64, 128, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 64, 208, 208), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 128, 208, 208], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        T_add = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        T_exp = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        T_log = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        T_tanh = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 128, 208, 208):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[i0_1, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 64, 208, 208, 128, 1, 1):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 208, 208], "float32"], ["TENSOR", [64, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
            with T.block("T_exp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_exp[ax0, ax1, ax2, ax3])
                T_exp[ax0, ax1, ax2, ax3] = T.exp(T_add[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_3[ax0, 0, 0, 0], T_exp[ax0, ax1, ax2, ax3])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = placeholder_3[ax0, 0, 0, 0] + T_exp[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
            with T.block("T_log"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3])
                T.writes(T_log[ax0, ax1, ax2, ax3])
                T_log[ax0, ax1, ax2, ax3] = T.log(T_add_1[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
            with T.block("T_tanh"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_log[ax0, ax1, ax2, ax3])
                T.writes(T_tanh[ax0, ax1, ax2, ax3])
                T_tanh[ax0, ax1, ax2, ax3] = T.tanh(T_log[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3], T_tanh[ax0, ax1, ax2, ax3])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = T_add[ax0, ax1, ax2, ax3] * T_tanh[ax0, ax1, ax2, ax3]
    

[13:32:57] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:32:57] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 208, 208), "float32"], placeholder_1: T.Buffer[(64, 128, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 64, 208, 208), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":0})
            conv2d_nchw = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
            conv2d_nchw_local = T.alloc_buffer([1, 64, 208, 208], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 128, 208, 208], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([64, 128, 1, 1], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(52, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(2, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(8, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(128, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(832):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(128, i4_0)
                                    v2 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused * 4 + ax0_ax1_ax2_ax3_fused // 208)
                                    v3 = T.axis.spatial(208, ax0_ax1_ax2_ax3_fused % 208)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":3})
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in T.serial(64):
                                with T.block("placeholder_shared"):
                                    v0, v1 = T.axis.remap("SS", [ax0_ax1_ax2_ax3_fused, i4_0])
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":4})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 2, 2, 26, 1, 1, 1, 1, 32, 1, 1):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(64, i1_3 * 32 + i1_4)
                                    yy = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused * 4 + i0_2_i1_2_i2_2_i3_2_fused // 4 * 2 + i2_3)
                                    xx = T.axis.spatial(208, i0_1_i1_1_i2_1_i3_1_fused * 104 + i0_2_i1_2_i2_2_i3_2_fused % 4 * 26 + i3_3)
                                    rc = T.axis.reduce(128, i4_0)
                                    ry = T.axis.reduce(1, 0)
                                    rx = T.axis.reduce(1, 0)
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 208, 208], "float32"], ["TENSOR", [64, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 64, 2, 26):
                            with T.block("conv2d_nchw_local"):
                                v0, v1 = T.axis.remap("SS", [ax0, ax1])
                                v2 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused * 4 + i0_2_i1_2_i2_2_i3_2_fused // 4 * 2 + ax2)
                                v3 = T.axis.spatial(208, i0_1_i1_1_i2_1_i3_1_fused * 104 + i0_2_i1_2_i2_2_i3_2_fused % 4 * 26 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                                T.writes(conv2d_nchw[v0, v1, v2, v3])
                                conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
            for i0, i1, i2, i3 in T.grid(1, 64, 208, 208):
                with T.block("T_multiply"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_multiply[ax0, ax1, ax2, ax3])
                    T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 1, 1, 2, 32])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[52, 1, 2, 2, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 2, 4, 26, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[128, 1, 1])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
[13:32:57] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"
[13:32:57] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 208, 208), "float32"], placeholder_1: T.Buffer[(128, 64, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 128, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 64, 209, 209], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 128, 104, 104], dtype="float32")
        T_add = T.alloc_buffer([1, 128, 104, 104], dtype="float32")
        T_exp = T.alloc_buffer([1, 128, 104, 104], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 128, 104, 104], dtype="float32")
        T_log = T.alloc_buffer([1, 128, 104, 104], dtype="float32")
        T_tanh = T.alloc_buffer([1, 128, 104, 104], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 64, 209, 209):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = T.if_then_else(1 <= i2_1 and i2_1 < 209 and 1 <= i3_1 and i3_1 < 209, placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 128, 104, 104, 64, 3, 3):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 208, 208], "float32"], ["TENSOR", [128, 64, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 128, 104, 104):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 128, 104, 104):
            with T.block("T_exp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_exp[ax0, ax1, ax2, ax3])
                T_exp[ax0, ax1, ax2, ax3] = T.exp(T_add[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 128, 104, 104):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_3[ax0, 0, 0, 0], T_exp[ax0, ax1, ax2, ax3])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = placeholder_3[ax0, 0, 0, 0] + T_exp[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 128, 104, 104):
            with T.block("T_log"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3])
                T.writes(T_log[ax0, ax1, ax2, ax3])
                T_log[ax0, ax1, ax2, ax3] = T.log(T_add_1[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 128, 104, 104):
            with T.block("T_tanh"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_log[ax0, ax1, ax2, ax3])
                T.writes(T_tanh[ax0, ax1, ax2, ax3])
                T_tanh[ax0, ax1, ax2, ax3] = T.tanh(T_log[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 128, 104, 104):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3], T_tanh[ax0, ax1, ax2, ax3])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = T_add[ax0, ax1, ax2, ax3] * T_tanh[ax0, ax1, ax2, ax3]
    

[13:32:57] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:32:57] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 208, 208), "float32"], placeholder_1: T.Buffer[(128, 64, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 128, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":16})
            conv2d_nchw = T.alloc_buffer([1, 128, 104, 104], dtype="float32")
            conv2d_nchw_local = T.alloc_buffer([1, 128, 104, 104], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 64, 209, 209], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([128, 64, 3, 3], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(64, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(8, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(52, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(4, 3, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(173040):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(64, i4_0 * 16 + ax0_ax1_ax2_ax3_fused % 173040 // 10815)
                                    v2 = T.axis.spatial(209, i0_0_i1_0_i2_0_i3_0_fused % 4 // 2 * 104 + i5_0 + ax0_ax1_ax2_ax3_fused % 10815 // 105)
                                    v3 = T.axis.spatial(209, i0_0_i1_0_i2_0_i3_0_fused % 2 * 104 + ax0_ax1_ax2_ax3_fused % 105)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":1})
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 209 and 1 <= v3 and v3 < 209, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                            for ax0_ax1_ax2_ax3_fused in T.serial(384):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 4 * 8 + ax0_ax1_ax2_ax3_fused // 48)
                                    v1 = T.axis.spatial(64, i4_0 * 16 + ax0_ax1_ax2_ax3_fused % 48 // 3)
                                    v2 = T.axis.spatial(3, i5_0)
                                    v3 = T.axis.spatial(3, ax0_ax1_ax2_ax3_fused % 3)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":3})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(16, 1, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 13):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 4 * 8 + i0_1_i1_1_i2_1_i3_1_fused // 4 * 4 + i0_2_i1_2_i2_2_i3_2_fused // 26 * 2 + i1_3)
                                    yy = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 4 // 2 * 52 + i0_2_i1_2_i2_2_i3_2_fused % 26 * 2 + i2_4)
                                    xx = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 2 * 52 + i0_1_i1_1_i2_1_i3_1_fused % 4 * 13 + i3_4)
                                    rc = T.axis.reduce(64, i4_0 * 16 + i4_1)
                                    ry, rx = T.axis.remap("RR", [i5_0, i6_1])
                                    T.reads(pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 208, 208], "float32"], ["TENSOR", [128, 64, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 2, 2, 13):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 4 * 8 + i0_1_i1_1_i2_1_i3_1_fused // 4 * 4 + i0_2_i1_2_i2_2_i3_2_fused // 26 * 2 + ax1)
                                v2 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 4 // 2 * 52 + i0_2_i1_2_i2_2_i3_2_fused % 26 * 2 + ax2)
                                v3 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 2 * 52 + i0_1_i1_1_i2_1_i3_1_fused % 4 * 13 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                                T.writes(conv2d_nchw[v0, v1, v2, v3])
                                conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
            for i0, i1, i2, i3 in T.grid(1, 128, 104, 104):
                with T.block("T_multiply"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_multiply[ax0, ax1, ax2, ax3])
                    T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[16, 2, 2, 2, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[2, 1, 26, 1, 2])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[2, 4, 1, 1, 13])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[4, 16, 1])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
[13:32:57] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"
[13:32:57] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 104, 104), "float32"], placeholder_1: T.Buffer[(64, 128, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 64, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 128, 104, 104], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
        T_add = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
        T_exp = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
        T_log = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
        T_tanh = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 128, 104, 104):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[i0_1, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 64, 104, 104, 128, 1, 1):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [64, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 64, 104, 104):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 64, 104, 104):
            with T.block("T_exp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_exp[ax0, ax1, ax2, ax3])
                T_exp[ax0, ax1, ax2, ax3] = T.exp(T_add[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 64, 104, 104):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_3[ax0, 0, 0, 0], T_exp[ax0, ax1, ax2, ax3])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = placeholder_3[ax0, 0, 0, 0] + T_exp[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 64, 104, 104):
            with T.block("T_log"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3])
                T.writes(T_log[ax0, ax1, ax2, ax3])
                T_log[ax0, ax1, ax2, ax3] = T.log(T_add_1[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 64, 104, 104):
            with T.block("T_tanh"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_log[ax0, ax1, ax2, ax3])
                T.writes(T_tanh[ax0, ax1, ax2, ax3])
                T_tanh[ax0, ax1, ax2, ax3] = T.tanh(T_log[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 64, 104, 104):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3], T_tanh[ax0, ax1, ax2, ax3])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = T_add[ax0, ax1, ax2, ax3] * T_tanh[ax0, ax1, ax2, ax3]
    

[13:32:58] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:32:58] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 104, 104), "float32"], placeholder_1: T.Buffer[(64, 128, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 64, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":512})
            conv2d_nchw = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
            conv2d_nchw_local = T.alloc_buffer([1, 64, 104, 104], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 128, 104, 104], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([64, 128, 1, 1], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(8, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(52, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(2, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(4, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(346112):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(128, i4_0 * 32 + ax0_ax1_ax2_ax3_fused // 10816)
                                    v2 = T.axis.spatial(104, ax0_ax1_ax2_ax3_fused % 10816 // 104)
                                    v3 = T.axis.spatial(104, ax0_ax1_ax2_ax3_fused % 104)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":4})
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in T.serial(256):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused * 8 + ax0_ax1_ax2_ax3_fused // 32)
                                    v1 = T.axis.spatial(128, i4_0 * 32 + ax0_ax1_ax2_ax3_fused % 32)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":2})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(32, 1, 1, 1, 1, 104, 4, 1, 1, 1, 1, 2, 1, 1):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused * 8 + i0_1_i1_1_i2_1_i3_1_fused // 26 * 4 + i0_2_i1_2_i2_2_i3_2_fused * 2 + i1_4)
                                    yy = T.axis.spatial(104, i2_3)
                                    xx = T.axis.spatial(104, i0_1_i1_1_i2_1_i3_1_fused % 26 * 4 + i3_3)
                                    rc = T.axis.reduce(128, i4_0 * 32 + i4_1)
                                    ry = T.axis.reduce(1, 0)
                                    rx = T.axis.reduce(1, 0)
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [64, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 2, 104, 4):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused * 8 + i0_1_i1_1_i2_1_i3_1_fused // 26 * 4 + i0_2_i1_2_i2_2_i3_2_fused * 2 + ax1)
                                v2 = T.axis.spatial(104, ax2)
                                v3 = T.axis.spatial(104, i0_1_i1_1_i2_1_i3_1_fused % 26 * 4 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                                T.writes(conv2d_nchw[v0, v1, v2, v3])
                                conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
            for i0, i1, i2, i3 in T.grid(1, 64, 104, 104):
                with T.block("T_multiply"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_multiply[ax0, ax1, ax2, ax3])
                    T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[8, 2, 2, 1, 2])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 1, 1, 104, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 26, 1, 4, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[4, 32, 1])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
[13:32:58] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"
[13:32:58] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 104, 104), "float32"], placeholder_1: T.Buffer[(64, 64, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], placeholder_4: T.Buffer[(1, 64, 104, 104), "float32"], T_add: T.Buffer[(1, 64, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 64, 106, 106], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
        T_exp = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
        T_add_2 = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
        T_log = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
        T_tanh = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
        T_multiply = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 64, 106, 106):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = T.if_then_else(1 <= i2_1 and i2_1 < 105 and 1 <= i3_1 and i3_1 < 105, placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 64, 104, 104, 64, 3, 3):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 104, 104], "float32"], ["TENSOR", [64, 64, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 64, 104, 104):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 64, 104, 104):
            with T.block("T_exp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3])
                T.writes(T_exp[ax0, ax1, ax2, ax3])
                T_exp[ax0, ax1, ax2, ax3] = T.exp(T_add_1[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 64, 104, 104):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_3[ax0, 0, 0, 0], T_exp[ax0, ax1, ax2, ax3])
                T.writes(T_add_2[ax0, ax1, ax2, ax3])
                T_add_2[ax0, ax1, ax2, ax3] = placeholder_3[ax0, 0, 0, 0] + T_exp[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 64, 104, 104):
            with T.block("T_log"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_2[ax0, ax1, ax2, ax3])
                T.writes(T_log[ax0, ax1, ax2, ax3])
                T_log[ax0, ax1, ax2, ax3] = T.log(T_add_2[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 64, 104, 104):
            with T.block("T_tanh"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_log[ax0, ax1, ax2, ax3])
                T.writes(T_tanh[ax0, ax1, ax2, ax3])
                T_tanh[ax0, ax1, ax2, ax3] = T.tanh(T_log[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 64, 104, 104):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3], T_tanh[ax0, ax1, ax2, ax3])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = T_add_1[ax0, ax1, ax2, ax3] * T_tanh[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 64, 104, 104):
            with T.block("T_add_2"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_4[ax0, ax1, ax2, ax3], T_multiply[ax0, ax1, ax2, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = placeholder_4[ax0, ax1, ax2, ax3] + T_multiply[ax0, ax1, ax2, ax3]
    

[13:32:59] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:32:59] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 104, 104), "float32"], placeholder_1: T.Buffer[(64, 64, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], placeholder_4: T.Buffer[(1, 64, 104, 104), "float32"], T_add: T.Buffer[(1, 64, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":512})
            conv2d_nchw = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
            conv2d_nchw_local = T.alloc_buffer([1, 64, 104, 104], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 64, 106, 106], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([64, 64, 3, 3], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(32, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(2, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(2, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(4, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(24192):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(64, i4_0 * 16 + ax0_ax1_ax2_ax3_fused % 24192 // 1512)
                                    v2 = T.axis.spatial(106, i0_0_i1_0_i2_0_i3_0_fused % 8 // 2 * 26 + ax0_ax1_ax2_ax3_fused % 1512 // 54)
                                    v3 = T.axis.spatial(106, i0_0_i1_0_i2_0_i3_0_fused % 2 * 52 + ax0_ax1_ax2_ax3_fused % 54)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":4})
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 105 and 1 <= v3 and v3 < 105, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                            for ax0_ax1_ax2_ax3_fused in T.serial(2304):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused // 8 * 16 + ax0_ax1_ax2_ax3_fused // 144)
                                    v1 = T.axis.spatial(64, i4_0 * 16 + ax0_ax1_ax2_ax3_fused % 144 // 9)
                                    v2 = T.axis.spatial(3, ax0_ax1_ax2_ax3_fused % 9 // 3)
                                    v3 = T.axis.spatial(3, ax0_ax1_ax2_ax3_fused % 3)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":2})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(4, 1, 1, 1, 8, 13, 26, 4, 3, 3, 1, 1, 2, 1):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused // 8 * 16 + i0_1_i1_1_i2_1_i3_1_fused * 8 + i1_3)
                                    yy = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 8 // 2 * 26 + i2_3 * 2 + i2_4)
                                    xx = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 2 * 52 + i0_2_i1_2_i2_2_i3_2_fused * 26 + i3_3)
                                    rc = T.axis.reduce(64, i4_0 * 16 + i4_1 * 4 + i4_2)
                                    ry, rx = T.axis.remap("RR", [i5_2, i6_2])
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 104, 104], "float32"], ["TENSOR", [64, 64, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 8, 26, 26):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused // 8 * 16 + i0_1_i1_1_i2_1_i3_1_fused * 8 + ax1)
                                v2 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 8 // 2 * 26 + ax2)
                                v3 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 2 * 52 + i0_2_i1_2_i2_2_i3_2_fused * 26 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                                T.writes(conv2d_nchw[v0, v1, v2, v3])
                                conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
            for i0, i1, i2, i3 in T.grid(1, 64, 104, 104):
                with T.block("T_multiply"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(placeholder_4[ax0, ax1, ax2, ax3], conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_add[ax0, ax1, ax2, ax3])
                    T_add[ax0, ax1, ax2, ax3] = placeholder_4[ax0, ax1, ax2, ax3] + (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="T_add_2", func_name="main")
b8 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l9, l10, l11, l12, l13, l14, l15 = sch.get_loops(block=b1)
v16, v17, v18, v19, v20 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l21, l22, l23, l24, l25 = sch.split(loop=l9, factors=[v16, v17, v18, v19, v20])
v26, v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[4, 2, 1, 8, 1])
l31, l32, l33, l34, l35 = sch.split(loop=l10, factors=[v26, v27, v28, v29, v30])
v36, v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[4, 1, 1, 13, 2])
l41, l42, l43, l44, l45 = sch.split(loop=l11, factors=[v36, v37, v38, v39, v40])
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l12, n=5, max_innermost_factor=64, decision=[2, 1, 2, 26, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l12, factors=[v46, v47, v48, v49, v50])
v56, v57, v58 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[4, 4, 4])
l59, l60, l61 = sch.split(loop=l13, factors=[v56, v57, v58])
v62, v63, v64 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l65, l66, l67 = sch.split(loop=l14, factors=[v62, v63, v64])
v68, v69, v70 = sch.sample_perfect_tile(loop=l15, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l71, l72, l73 = sch.split(loop=l15, factors=[v68, v69, v70])
sch.reorder(l21, l31, l41, l51, l22, l32, l42, l52, l23, l33, l43, l53, l59, l65, l71, l60, l66, l72, l24, l34, l44, l54, l61, l67, l73, l25, l35, l45, l55)
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="blockIdx.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="vthread.x")
l76 = sch.fuse(l23, l33, l43, l53)
sch.bind(loop=l76, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b77 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b77, loop=l76, preserve_unit_loops=True)
b78 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b78, loop=l71, preserve_unit_loops=True)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b78)
l89 = sch.fuse(l85, l86, l87, l88)
v90 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b78, ann_key="meta_schedule.cooperative_fetch", ann_val=v90)
b91 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b91, loop=l71, preserve_unit_loops=True)
l92, l93, l94, l95, l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b91)
l102 = sch.fuse(l98, l99, l100, l101)
v103 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b91, ann_key="meta_schedule.cooperative_fetch", ann_val=v103)
sch.reverse_compute_inline(block=b7)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v104 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b8, ann_key="meta_schedule.unroll_explicit", ann_val=v104)
[13:32:59] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"
[13:32:59] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 104, 104), "float32"], placeholder_1: T.Buffer[(64, 64, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 64, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
        T_add = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
        T_exp = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
        T_log = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
        T_tanh = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 64, 104, 104):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[i0_1, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 64, 104, 104, 64, 1, 1):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 104, 104], "float32"], ["TENSOR", [64, 64, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 64, 104, 104):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 64, 104, 104):
            with T.block("T_exp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_exp[ax0, ax1, ax2, ax3])
                T_exp[ax0, ax1, ax2, ax3] = T.exp(T_add[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 64, 104, 104):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_3[ax0, 0, 0, 0], T_exp[ax0, ax1, ax2, ax3])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = placeholder_3[ax0, 0, 0, 0] + T_exp[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 64, 104, 104):
            with T.block("T_log"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3])
                T.writes(T_log[ax0, ax1, ax2, ax3])
                T_log[ax0, ax1, ax2, ax3] = T.log(T_add_1[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 64, 104, 104):
            with T.block("T_tanh"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_log[ax0, ax1, ax2, ax3])
                T.writes(T_tanh[ax0, ax1, ax2, ax3])
                T_tanh[ax0, ax1, ax2, ax3] = T.tanh(T_log[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 64, 104, 104):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3], T_tanh[ax0, ax1, ax2, ax3])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = T_add[ax0, ax1, ax2, ax3] * T_tanh[ax0, ax1, ax2, ax3]
    

[13:32:59] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:32:59] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 104, 104), "float32"], placeholder_1: T.Buffer[(64, 64, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 64, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":0})
            conv2d_nchw = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
            conv2d_nchw_local = T.alloc_buffer([1, 64, 104, 104], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 64, 104, 104], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([64, 64, 1, 1], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(26, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(52, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(8, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(2, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(13312):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(64, i4_0 * 32 + ax0_ax1_ax2_ax3_fused // 416)
                                    v2 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 4 + ax0_ax1_ax2_ax3_fused % 416 // 104)
                                    v3 = T.axis.spatial(104, ax0_ax1_ax2_ax3_fused % 104)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":3})
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in T.serial(2048):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(64, ax0_ax1_ax2_ax3_fused // 32)
                                    v1 = T.axis.spatial(64, i4_0 * 32 + ax0_ax1_ax2_ax3_fused % 32)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":1})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 2, 1, 2, 32, 1, 1, 1, 16, 1, 1):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(64, i0_1_i1_1_i2_1_i3_1_fused // 26 * 32 + i1_3 * 16 + i1_4)
                                    yy = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 4 + i0_2_i1_2_i2_2_i3_2_fused // 2)
                                    xx = T.axis.spatial(104, i0_1_i1_1_i2_1_i3_1_fused % 26 * 4 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 2 + i3_3)
                                    rc = T.axis.reduce(64, i4_0 * 32 + i4_2)
                                    ry = T.axis.reduce(1, 0)
                                    rx = T.axis.reduce(1, 0)
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 104, 104], "float32"], ["TENSOR", [64, 64, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 32, 1, 2):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(64, i0_1_i1_1_i2_1_i3_1_fused // 26 * 32 + ax1)
                                v2 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 4 + i0_2_i1_2_i2_2_i3_2_fused // 2 + ax2)
                                v3 = T.axis.spatial(104, i0_1_i1_1_i2_1_i3_1_fused % 26 * 4 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 2 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                                T.writes(conv2d_nchw[v0, v1, v2, v3])
                                conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
            for i0, i1, i2, i3 in T.grid(1, 64, 104, 104):
                with T.block("T_multiply"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_multiply[ax0, ax1, ax2, ax3])
                    T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 2, 1, 2, 16])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[26, 1, 4, 1, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 26, 2, 2, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[2, 1, 32])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
[13:32:59] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #20: "fused_concatenate_1"
[13:32:59] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 104, 104), "float32"], placeholder_1: T.Buffer[(1, 64, 104, 104), "float32"], T_concat: T.Buffer[(1, 128, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3 in T.grid(1, 128, 104, 104):
            with T.block("T_concat"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_1[ax0, ax1 - 64, ax2, ax3], placeholder[ax0, ax1, ax2, ax3])
                T.writes(T_concat[ax0, ax1, ax2, ax3])
                T_concat[ax0, ax1, ax2, ax3] = T.if_then_else(64 <= ax1, placeholder_1[ax0, ax1 - 64, ax2, ax3], placeholder[ax0, ax1, ax2, ax3], dtype="float32")
    

[13:32:59] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:32:59] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 104, 104), "float32"], placeholder_1: T.Buffer[(1, 64, 104, 104), "float32"], T_concat: T.Buffer[(1, 128, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":64})
            for i0, i1, i2, i3 in T.grid(1, 128, 104, 104):
                with T.block("T_concat"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(placeholder_1[ax0, ax1 - 64, ax2, ax3], placeholder[ax0, ax1, ax2, ax3])
                    T.writes(T_concat[ax0, ax1, ax2, ax3])
                    T_concat[ax0, ax1, ax2, ax3] = T.if_then_else(64 <= ax1, placeholder_1[ax0, ax1 - 64, ax2, ax3], placeholder[ax0, ax1, ax2, ax3], dtype="float32")
    

b0 = sch.get_block(name="root", func_name="main")
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
[13:32:59] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"
[13:32:59] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 104, 104), "float32"], placeholder_1: T.Buffer[(128, 128, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 128, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 128, 104, 104], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 128, 104, 104], dtype="float32")
        T_add = T.alloc_buffer([1, 128, 104, 104], dtype="float32")
        T_exp = T.alloc_buffer([1, 128, 104, 104], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 128, 104, 104], dtype="float32")
        T_log = T.alloc_buffer([1, 128, 104, 104], dtype="float32")
        T_tanh = T.alloc_buffer([1, 128, 104, 104], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 128, 104, 104):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[i0_1, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 128, 104, 104, 128, 1, 1):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [128, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 128, 104, 104):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 128, 104, 104):
            with T.block("T_exp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_exp[ax0, ax1, ax2, ax3])
                T_exp[ax0, ax1, ax2, ax3] = T.exp(T_add[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 128, 104, 104):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_3[ax0, 0, 0, 0], T_exp[ax0, ax1, ax2, ax3])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = placeholder_3[ax0, 0, 0, 0] + T_exp[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 128, 104, 104):
            with T.block("T_log"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3])
                T.writes(T_log[ax0, ax1, ax2, ax3])
                T_log[ax0, ax1, ax2, ax3] = T.log(T_add_1[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 128, 104, 104):
            with T.block("T_tanh"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_log[ax0, ax1, ax2, ax3])
                T.writes(T_tanh[ax0, ax1, ax2, ax3])
                T_tanh[ax0, ax1, ax2, ax3] = T.tanh(T_log[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 128, 104, 104):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3], T_tanh[ax0, ax1, ax2, ax3])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = T_add[ax0, ax1, ax2, ax3] * T_tanh[ax0, ax1, ax2, ax3]
    

[13:33:00] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:00] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 104, 104), "float32"], placeholder_1: T.Buffer[(128, 128, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 128, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":512})
            conv2d_nchw = T.alloc_buffer([1, 128, 104, 104], dtype="float32")
            conv2d_nchw_local = T.alloc_buffer([1, 128, 104, 104], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 128, 104, 104], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([128, 128, 1, 1], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(1, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(26, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(208, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(8, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(173056):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(128, i4_0 * 16 + ax0_ax1_ax2_ax3_fused // 10816)
                                    v2 = T.axis.spatial(104, ax0_ax1_ax2_ax3_fused % 10816 // 104)
                                    v3 = T.axis.spatial(104, ax0_ax1_ax2_ax3_fused % 104)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":3})
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in T.serial(2048):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(128, ax0_ax1_ax2_ax3_fused // 16)
                                    v1 = T.axis.spatial(128, i4_0 * 16 + ax0_ax1_ax2_ax3_fused % 16)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":3})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 2, 2, 2, 16, 1, 1, 1, 4, 2, 4):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 13 * 64 + i0_2_i1_2_i2_2_i3_2_fused // 26 * 8 + i1_3 * 4 + i1_4)
                                    yy = T.axis.spatial(104, i0_1_i1_1_i2_1_i3_1_fused % 13 * 8 + i0_2_i1_2_i2_2_i3_2_fused % 26 // 13 * 4 + i2_3 * 2 + i2_4)
                                    xx = T.axis.spatial(104, i0_2_i1_2_i2_2_i3_2_fused % 13 * 8 + i3_3 * 4 + i3_4)
                                    rc = T.axis.reduce(128, i4_0 * 16 + i4_2)
                                    ry = T.axis.reduce(1, 0)
                                    rx = T.axis.reduce(1, 0)
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [128, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 8, 4, 8):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 13 * 64 + i0_2_i1_2_i2_2_i3_2_fused // 26 * 8 + ax1)
                                v2 = T.axis.spatial(104, i0_1_i1_1_i2_1_i3_1_fused % 13 * 8 + i0_2_i1_2_i2_2_i3_2_fused % 26 // 13 * 4 + ax2)
                                v3 = T.axis.spatial(104, i0_2_i1_2_i2_2_i3_2_fused % 13 * 8 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                                T.writes(conv2d_nchw[v0, v1, v2, v3])
                                conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
            for i0, i1, i2, i3 in T.grid(1, 128, 104, 104):
                with T.block("T_multiply"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_multiply[ax0, ax1, ax2, ax3])
                    T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 2, 8, 2, 4])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 13, 2, 2, 2])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 1, 13, 2, 4])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[8, 1, 16])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
[13:33:00] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"
[13:33:00] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 104, 104), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 256, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 128, 105, 105], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 256, 52, 52], dtype="float32")
        T_add = T.alloc_buffer([1, 256, 52, 52], dtype="float32")
        T_exp = T.alloc_buffer([1, 256, 52, 52], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 256, 52, 52], dtype="float32")
        T_log = T.alloc_buffer([1, 256, 52, 52], dtype="float32")
        T_tanh = T.alloc_buffer([1, 256, 52, 52], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 128, 105, 105):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = T.if_then_else(1 <= i2_1 and i2_1 < 105 and 1 <= i3_1 and i3_1 < 105, placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 256, 52, 52, 128, 3, 3):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 256, 52, 52):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 256, 52, 52):
            with T.block("T_exp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_exp[ax0, ax1, ax2, ax3])
                T_exp[ax0, ax1, ax2, ax3] = T.exp(T_add[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 52, 52):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_3[ax0, 0, 0, 0], T_exp[ax0, ax1, ax2, ax3])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = placeholder_3[ax0, 0, 0, 0] + T_exp[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 256, 52, 52):
            with T.block("T_log"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3])
                T.writes(T_log[ax0, ax1, ax2, ax3])
                T_log[ax0, ax1, ax2, ax3] = T.log(T_add_1[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 52, 52):
            with T.block("T_tanh"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_log[ax0, ax1, ax2, ax3])
                T.writes(T_tanh[ax0, ax1, ax2, ax3])
                T_tanh[ax0, ax1, ax2, ax3] = T.tanh(T_log[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 52, 52):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3], T_tanh[ax0, ax1, ax2, ax3])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = T_add[ax0, ax1, ax2, ax3] * T_tanh[ax0, ax1, ax2, ax3]
    

[13:33:01] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:01] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 104, 104), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 256, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":0})
            conv2d_nchw = T.alloc_buffer([1, 256, 52, 52], dtype="float32")
            conv2d_nchw_local = T.alloc_buffer([1, 256, 52, 52], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 128, 105, 105], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([256, 128, 3, 3], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(208, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(52, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(4, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(8, 3, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(8240):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(128, i4_0 * 16 + ax0_ax1_ax2_ax3_fused % 8240 // 515)
                                    v2 = T.axis.spatial(105, i5_0 + ax0_ax1_ax2_ax3_fused % 515 // 5)
                                    v3 = T.axis.spatial(105, i0_0_i1_0_i2_0_i3_0_fused % 26 * 4 + ax0_ax1_ax2_ax3_fused % 5)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":1})
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 105 and 1 <= v3 and v3 < 105, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                            for ax0_ax1_ax2_ax3_fused in T.serial(1536):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 26 * 32 + ax0_ax1_ax2_ax3_fused // 48)
                                    v1 = T.axis.spatial(128, i4_0 * 16 + ax0_ax1_ax2_ax3_fused % 48 // 3)
                                    v2 = T.axis.spatial(3, i5_0)
                                    v3 = T.axis.spatial(3, ax0_ax1_ax2_ax3_fused % 3)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":1})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(2, 1, 3, 1, 1, 1, 2, 8, 1, 1, 1, 4, 2, 1):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 26 * 32 + i0_1_i1_1_i2_1_i3_1_fused // 26 * 16 + i0_2_i1_2_i2_2_i3_2_fused * 4 + i1_4)
                                    yy = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 26 * 2 + i2_4)
                                    xx = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 26 * 2 + i3_3)
                                    rc = T.axis.reduce(128, i4_0 * 16 + i4_1 * 8 + i4_2)
                                    ry, rx = T.axis.remap("RR", [i5_0, i6_1])
                                    T.reads(pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 4, 2, 2):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 26 * 32 + i0_1_i1_1_i2_1_i3_1_fused // 26 * 16 + i0_2_i1_2_i2_2_i3_2_fused * 4 + ax1)
                                v2 = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 26 * 2 + ax2)
                                v3 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 26 * 2 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                                T.writes(conv2d_nchw[v0, v1, v2, v3])
                                conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
            for i0, i1, i2, i3 in T.grid(1, 256, 52, 52):
                with T.block("T_multiply"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_multiply[ax0, ax1, ax2, ax3])
                    T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[8, 2, 4, 1, 4])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 26, 1, 1, 2])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[26, 1, 1, 2, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[8, 2, 8])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
[13:33:01] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"
[13:33:01] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 52, 52), "float32"], placeholder_1: T.Buffer[(128, 256, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 128, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 256, 52, 52], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        T_add = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        T_exp = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        T_log = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        T_tanh = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 52, 52):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[i0_1, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 128, 52, 52, 256, 1, 1):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [128, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 128, 52, 52):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 128, 52, 52):
            with T.block("T_exp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_exp[ax0, ax1, ax2, ax3])
                T_exp[ax0, ax1, ax2, ax3] = T.exp(T_add[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 128, 52, 52):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_3[ax0, 0, 0, 0], T_exp[ax0, ax1, ax2, ax3])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = placeholder_3[ax0, 0, 0, 0] + T_exp[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 128, 52, 52):
            with T.block("T_log"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3])
                T.writes(T_log[ax0, ax1, ax2, ax3])
                T_log[ax0, ax1, ax2, ax3] = T.log(T_add_1[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 128, 52, 52):
            with T.block("T_tanh"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_log[ax0, ax1, ax2, ax3])
                T.writes(T_tanh[ax0, ax1, ax2, ax3])
                T_tanh[ax0, ax1, ax2, ax3] = T.tanh(T_log[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 128, 52, 52):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3], T_tanh[ax0, ax1, ax2, ax3])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = T_add[ax0, ax1, ax2, ax3] * T_tanh[ax0, ax1, ax2, ax3]
    

[13:33:01] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:01] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 52, 52), "float32"], placeholder_1: T.Buffer[(128, 256, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 128, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":512})
            conv2d_nchw = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
            conv2d_nchw_local = T.alloc_buffer([1, 128, 52, 52], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 256, 52, 52], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([128, 256, 1, 1], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(8, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(26, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(2, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(4, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(43264):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(256, i4_0 * 64 + ax0_ax1_ax2_ax3_fused // 676)
                                    v2 = T.axis.spatial(52, ax0_ax1_ax2_ax3_fused % 676 // 13)
                                    v3 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 4 * 13 + ax0_ax1_ax2_ax3_fused % 13)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":4})
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in T.serial(4096):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 4 * 64 + ax0_ax1_ax2_ax3_fused // 64)
                                    v1 = T.axis.spatial(256, i4_0 * 64 + ax0_ax1_ax2_ax3_fused % 64)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":1})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 8, 2, 1, 64, 1, 1, 1, 2, 26, 1):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 4 * 64 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 32 + i0_2_i1_2_i2_2_i3_2_fused * 16 + i1_3 * 2 + i1_4)
                                    yy = T.axis.spatial(52, i2_3 * 26 + i2_4)
                                    xx = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 4 * 13 + i0_1_i1_1_i2_1_i3_1_fused % 13)
                                    rc = T.axis.reduce(256, i4_0 * 64 + i4_2)
                                    ry = T.axis.reduce(1, 0)
                                    rx = T.axis.reduce(1, 0)
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [128, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 16, 52, 1):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 4 * 64 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 32 + i0_2_i1_2_i2_2_i3_2_fused * 16 + ax1)
                                v2 = T.axis.spatial(52, ax2)
                                v3 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 4 * 13 + i0_1_i1_1_i2_1_i3_1_fused % 13 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                                T.writes(conv2d_nchw[v0, v1, v2, v3])
                                conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
            for i0, i1, i2, i3 in T.grid(1, 128, 52, 52):
                with T.block("T_multiply"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_multiply[ax0, ax1, ax2, ax3])
                    T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[2, 2, 2, 8, 2])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 1, 1, 2, 26])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[4, 13, 1, 1, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[4, 1, 64])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
[13:33:01] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"
[13:33:01] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 52, 52), "float32"], placeholder_1: T.Buffer[(128, 128, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], placeholder_4: T.Buffer[(1, 128, 52, 52), "float32"], T_add: T.Buffer[(1, 128, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 128, 54, 54], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        T_exp = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        T_add_2 = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        T_log = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        T_tanh = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        T_multiply = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 128, 54, 54):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = T.if_then_else(1 <= i2_1 and i2_1 < 53 and 1 <= i3_1 and i3_1 < 53, placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 128, 52, 52, 128, 3, 3):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [128, 128, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 128, 52, 52):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 128, 52, 52):
            with T.block("T_exp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3])
                T.writes(T_exp[ax0, ax1, ax2, ax3])
                T_exp[ax0, ax1, ax2, ax3] = T.exp(T_add_1[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 128, 52, 52):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_3[ax0, 0, 0, 0], T_exp[ax0, ax1, ax2, ax3])
                T.writes(T_add_2[ax0, ax1, ax2, ax3])
                T_add_2[ax0, ax1, ax2, ax3] = placeholder_3[ax0, 0, 0, 0] + T_exp[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 128, 52, 52):
            with T.block("T_log"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_2[ax0, ax1, ax2, ax3])
                T.writes(T_log[ax0, ax1, ax2, ax3])
                T_log[ax0, ax1, ax2, ax3] = T.log(T_add_2[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 128, 52, 52):
            with T.block("T_tanh"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_log[ax0, ax1, ax2, ax3])
                T.writes(T_tanh[ax0, ax1, ax2, ax3])
                T_tanh[ax0, ax1, ax2, ax3] = T.tanh(T_log[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 128, 52, 52):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3], T_tanh[ax0, ax1, ax2, ax3])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = T_add_1[ax0, ax1, ax2, ax3] * T_tanh[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 128, 52, 52):
            with T.block("T_add_2"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_4[ax0, ax1, ax2, ax3], T_multiply[ax0, ax1, ax2, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = placeholder_4[ax0, ax1, ax2, ax3] + T_multiply[ax0, ax1, ax2, ax3]
    

[13:33:02] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:02] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 52, 52), "float32"], placeholder_1: T.Buffer[(128, 128, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], placeholder_4: T.Buffer[(1, 128, 52, 52), "float32"], T_add: T.Buffer[(1, 128, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":64})
            conv2d_nchw = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
            conv2d_nchw_local = T.alloc_buffer([1, 128, 52, 52], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 128, 54, 54], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([128, 128, 3, 3], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(52, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(4, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(4, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(2, 3, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(13824):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(128, i4_0 * 64 + ax0_ax1_ax2_ax3_fused % 13824 // 216)
                                    v2 = T.axis.spatial(54, i0_0_i1_0_i2_0_i3_0_fused % 13 * 4 + i5_0 + ax0_ax1_ax2_ax3_fused % 216 // 54)
                                    v3 = T.axis.spatial(54, ax0_ax1_ax2_ax3_fused % 54)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":2})
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 53 and 1 <= v3 and v3 < 53, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                            for ax0_ax1_ax2_ax3_fused in T.serial(6144):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 13 * 32 + ax0_ax1_ax2_ax3_fused // 192)
                                    v1 = T.axis.spatial(128, i4_0 * 64 + ax0_ax1_ax2_ax3_fused % 192 // 3)
                                    v2 = T.axis.spatial(3, i5_0)
                                    v3 = T.axis.spatial(3, ax0_ax1_ax2_ax3_fused % 3)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":4})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(64, 1, 1, 1, 4, 1, 13, 1, 1, 3, 1, 2, 2, 2):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 13 * 32 + i0_1_i1_1_i2_1_i3_1_fused * 8 + i1_3 * 2 + i1_4)
                                    yy = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 13 * 4 + i0_2_i1_2_i2_2_i3_2_fused // 2 * 2 + i2_4)
                                    xx = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 2 * 26 + i3_3 * 2 + i3_4)
                                    rc = T.axis.reduce(128, i4_0 * 64 + i4_1)
                                    ry, rx = T.axis.remap("RR", [i5_0, i6_2])
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [128, 128, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 8, 2, 26):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 13 * 32 + i0_1_i1_1_i2_1_i3_1_fused * 8 + ax1)
                                v2 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 13 * 4 + i0_2_i1_2_i2_2_i3_2_fused // 2 * 2 + ax2)
                                v3 = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 2 * 26 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                                T.writes(conv2d_nchw[v0, v1, v2, v3])
                                conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
            for i0, i1, i2, i3 in T.grid(1, 128, 52, 52):
                with T.block("T_multiply"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(placeholder_4[ax0, ax1, ax2, ax3], conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_add[ax0, ax1, ax2, ax3])
                    T_add[ax0, ax1, ax2, ax3] = placeholder_4[ax0, ax1, ax2, ax3] + (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="T_add_2", func_name="main")
b8 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l9, l10, l11, l12, l13, l14, l15 = sch.get_loops(block=b1)
v16, v17, v18, v19, v20 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l21, l22, l23, l24, l25 = sch.split(loop=l9, factors=[v16, v17, v18, v19, v20])
v26, v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[4, 4, 1, 4, 2])
l31, l32, l33, l34, l35 = sch.split(loop=l10, factors=[v26, v27, v28, v29, v30])
v36, v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[13, 1, 2, 1, 2])
l41, l42, l43, l44, l45 = sch.split(loop=l11, factors=[v36, v37, v38, v39, v40])
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l12, n=5, max_innermost_factor=64, decision=[1, 1, 2, 13, 2])
l51, l52, l53, l54, l55 = sch.split(loop=l12, factors=[v46, v47, v48, v49, v50])
v56, v57, v58 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[2, 64, 1])
l59, l60, l61 = sch.split(loop=l13, factors=[v56, v57, v58])
v62, v63, v64 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l65, l66, l67 = sch.split(loop=l14, factors=[v62, v63, v64])
v68, v69, v70 = sch.sample_perfect_tile(loop=l15, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l71, l72, l73 = sch.split(loop=l15, factors=[v68, v69, v70])
sch.reorder(l21, l31, l41, l51, l22, l32, l42, l52, l23, l33, l43, l53, l59, l65, l71, l60, l66, l72, l24, l34, l44, l54, l61, l67, l73, l25, l35, l45, l55)
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="blockIdx.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="vthread.x")
l76 = sch.fuse(l23, l33, l43, l53)
sch.bind(loop=l76, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b77 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b77, loop=l76, preserve_unit_loops=True)
b78 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b78, loop=l71, preserve_unit_loops=True)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b78)
l89 = sch.fuse(l85, l86, l87, l88)
v90 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b78, ann_key="meta_schedule.cooperative_fetch", ann_val=v90)
b91 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b91, loop=l71, preserve_unit_loops=True)
l92, l93, l94, l95, l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b91)
l102 = sch.fuse(l98, l99, l100, l101)
v103 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b91, ann_key="meta_schedule.cooperative_fetch", ann_val=v103)
sch.reverse_compute_inline(block=b7)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v104 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b8, ann_key="meta_schedule.unroll_explicit", ann_val=v104)
[13:33:02] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"
[13:33:02] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 52, 52), "float32"], placeholder_1: T.Buffer[(128, 128, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 128, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        T_add = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        T_exp = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        T_log = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        T_tanh = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 128, 52, 52):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[i0_1, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 128, 52, 52, 128, 1, 1):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [128, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 128, 52, 52):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 128, 52, 52):
            with T.block("T_exp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_exp[ax0, ax1, ax2, ax3])
                T_exp[ax0, ax1, ax2, ax3] = T.exp(T_add[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 128, 52, 52):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_3[ax0, 0, 0, 0], T_exp[ax0, ax1, ax2, ax3])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = placeholder_3[ax0, 0, 0, 0] + T_exp[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 128, 52, 52):
            with T.block("T_log"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3])
                T.writes(T_log[ax0, ax1, ax2, ax3])
                T_log[ax0, ax1, ax2, ax3] = T.log(T_add_1[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 128, 52, 52):
            with T.block("T_tanh"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_log[ax0, ax1, ax2, ax3])
                T.writes(T_tanh[ax0, ax1, ax2, ax3])
                T_tanh[ax0, ax1, ax2, ax3] = T.tanh(T_log[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 128, 52, 52):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3], T_tanh[ax0, ax1, ax2, ax3])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = T_add[ax0, ax1, ax2, ax3] * T_tanh[ax0, ax1, ax2, ax3]
    

[13:33:02] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:02] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 52, 52), "float32"], placeholder_1: T.Buffer[(128, 128, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 128, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":16})
            conv2d_nchw = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
            conv2d_nchw_local = T.alloc_buffer([1, 128, 52, 52], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 128, 52, 52], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([128, 128, 1, 1], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(104, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(2, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(8, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(1, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(26624):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(128, ax0_ax1_ax2_ax3_fused // 208)
                                    v2 = T.axis.spatial(52, ax0_ax1_ax2_ax3_fused % 208 // 4)
                                    v3 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 13 * 4 + ax0_ax1_ax2_ax3_fused % 4)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":4})
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in T.serial(2048):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 13 * 16 + ax0_ax1_ax2_ax3_fused // 128)
                                    v1 = T.axis.spatial(128, ax0_ax1_ax2_ax3_fused % 128)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":2})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(128, 1, 1, 1, 2, 52, 1, 1, 1, 1, 1, 2, 1, 1):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 13 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 2 * 4 + i1_3 * 2 + i1_4)
                                    yy = T.axis.spatial(52, i2_3)
                                    xx = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 13 * 4 + i0_1_i1_1_i2_1_i3_1_fused * 2 + i0_2_i1_2_i2_2_i3_2_fused % 2)
                                    rc = T.axis.reduce(128, i4_1)
                                    ry = T.axis.reduce(1, 0)
                                    rx = T.axis.reduce(1, 0)
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [128, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 4, 52, 1):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 13 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 2 * 4 + ax1)
                                v2 = T.axis.spatial(52, ax2)
                                v3 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 13 * 4 + i0_1_i1_1_i2_1_i3_1_fused * 2 + i0_2_i1_2_i2_2_i3_2_fused % 2 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                                T.writes(conv2d_nchw[v0, v1, v2, v3])
                                conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
            for i0, i1, i2, i3 in T.grid(1, 128, 52, 52):
                with T.block("T_multiply"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_multiply[ax0, ax1, ax2, ax3])
                    T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[8, 1, 4, 2, 2])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 1, 1, 52, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[13, 2, 2, 1, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[1, 128, 1])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
[13:33:02] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #26: "fused_concatenate_2"
[13:33:02] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 52, 52), "float32"], placeholder_1: T.Buffer[(1, 128, 52, 52), "float32"], T_concat: T.Buffer[(1, 256, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3 in T.grid(1, 256, 52, 52):
            with T.block("T_concat"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_1[ax0, ax1 - 128, ax2, ax3], placeholder[ax0, ax1, ax2, ax3])
                T.writes(T_concat[ax0, ax1, ax2, ax3])
                T_concat[ax0, ax1, ax2, ax3] = T.if_then_else(128 <= ax1, placeholder_1[ax0, ax1 - 128, ax2, ax3], placeholder[ax0, ax1, ax2, ax3], dtype="float32")
    

[13:33:03] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:03] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 52, 52), "float32"], placeholder_1: T.Buffer[(1, 128, 52, 52), "float32"], T_concat: T.Buffer[(1, 256, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":512})
            for i0, i1, i2, i3 in T.grid(1, 256, 52, 52):
                with T.block("T_concat"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(placeholder_1[ax0, ax1 - 128, ax2, ax3], placeholder[ax0, ax1, ax2, ax3])
                    T.writes(T_concat[ax0, ax1, ax2, ax3])
                    T_concat[ax0, ax1, ax2, ax3] = T.if_then_else(128 <= ax1, placeholder_1[ax0, ax1 - 128, ax2, ax3], placeholder[ax0, ax1, ax2, ax3], dtype="float32")
    

b0 = sch.get_block(name="root", func_name="main")
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
[13:33:03] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"
[13:33:03] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 52, 52), "float32"], placeholder_1: T.Buffer[(256, 256, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 256, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 256, 52, 52], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 256, 52, 52], dtype="float32")
        T_add = T.alloc_buffer([1, 256, 52, 52], dtype="float32")
        T_exp = T.alloc_buffer([1, 256, 52, 52], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 256, 52, 52], dtype="float32")
        T_log = T.alloc_buffer([1, 256, 52, 52], dtype="float32")
        T_tanh = T.alloc_buffer([1, 256, 52, 52], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 52, 52):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[i0_1, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 256, 52, 52, 256, 1, 1):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [256, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 256, 52, 52):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 256, 52, 52):
            with T.block("T_exp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_exp[ax0, ax1, ax2, ax3])
                T_exp[ax0, ax1, ax2, ax3] = T.exp(T_add[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 52, 52):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_3[ax0, 0, 0, 0], T_exp[ax0, ax1, ax2, ax3])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = placeholder_3[ax0, 0, 0, 0] + T_exp[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 256, 52, 52):
            with T.block("T_log"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3])
                T.writes(T_log[ax0, ax1, ax2, ax3])
                T_log[ax0, ax1, ax2, ax3] = T.log(T_add_1[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 52, 52):
            with T.block("T_tanh"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_log[ax0, ax1, ax2, ax3])
                T.writes(T_tanh[ax0, ax1, ax2, ax3])
                T_tanh[ax0, ax1, ax2, ax3] = T.tanh(T_log[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 52, 52):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3], T_tanh[ax0, ax1, ax2, ax3])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = T_add[ax0, ax1, ax2, ax3] * T_tanh[ax0, ax1, ax2, ax3]
    

[13:33:03] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:03] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 52, 52), "float32"], placeholder_1: T.Buffer[(256, 256, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 256, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":1024})
            conv2d_nchw = T.alloc_buffer([1, 256, 52, 52], dtype="float32")
            conv2d_nchw_local = T.alloc_buffer([1, 256, 52, 52], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 256, 52, 52], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([256, 256, 1, 1], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(4, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(16, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(676, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(8, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(86528):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(256, i4_0 * 32 + ax0_ax1_ax2_ax3_fused // 2704)
                                    v2 = T.axis.spatial(52, ax0_ax1_ax2_ax3_fused % 2704 // 52)
                                    v3 = T.axis.spatial(52, ax0_ax1_ax2_ax3_fused % 52)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":2})
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in T.serial(2048):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused * 64 + ax0_ax1_ax2_ax3_fused // 32)
                                    v1 = T.axis.spatial(256, i4_0 * 32 + ax0_ax1_ax2_ax3_fused % 32)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":2})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(8, 1, 1, 1, 2, 2, 2, 4, 1, 1, 1, 1, 1, 2):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused * 64 + i0_1_i1_1_i2_1_i3_1_fused * 4 + i0_2_i1_2_i2_2_i3_2_fused // 338 * 2 + i1_3)
                                    yy = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 338 // 13 * 2 + i2_3)
                                    xx = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 13 * 4 + i3_3 * 2 + i3_4)
                                    rc = T.axis.reduce(256, i4_0 * 32 + i4_1 * 4 + i4_2)
                                    ry = T.axis.reduce(1, 0)
                                    rx = T.axis.reduce(1, 0)
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [256, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 2, 2, 4):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused * 64 + i0_1_i1_1_i2_1_i3_1_fused * 4 + i0_2_i1_2_i2_2_i3_2_fused // 338 * 2 + ax1)
                                v2 = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 338 // 13 * 2 + ax2)
                                v3 = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 13 * 4 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                                T.writes(conv2d_nchw[v0, v1, v2, v3])
                                conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
            for i0, i1, i2, i3 in T.grid(1, 256, 52, 52):
                with T.block("T_multiply"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_multiply[ax0, ax1, ax2, ax3])
                    T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[4, 16, 2, 2, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 1, 26, 2, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 1, 13, 2, 2])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[8, 8, 4])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
[13:33:03] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"
[13:33:03] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 52, 52), "float32"], placeholder_1: T.Buffer[(512, 256, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 512, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 256, 53, 53], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 512, 26, 26], dtype="float32")
        T_add = T.alloc_buffer([1, 512, 26, 26], dtype="float32")
        T_exp = T.alloc_buffer([1, 512, 26, 26], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 512, 26, 26], dtype="float32")
        T_log = T.alloc_buffer([1, 512, 26, 26], dtype="float32")
        T_tanh = T.alloc_buffer([1, 512, 26, 26], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 53, 53):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = T.if_then_else(1 <= i2_1 and i2_1 < 53 and 1 <= i3_1 and i3_1 < 53, placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 512, 26, 26, 256, 3, 3):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [512, 256, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 512, 26, 26):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 512, 26, 26):
            with T.block("T_exp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_exp[ax0, ax1, ax2, ax3])
                T_exp[ax0, ax1, ax2, ax3] = T.exp(T_add[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 26, 26):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_3[ax0, 0, 0, 0], T_exp[ax0, ax1, ax2, ax3])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = placeholder_3[ax0, 0, 0, 0] + T_exp[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 512, 26, 26):
            with T.block("T_log"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3])
                T.writes(T_log[ax0, ax1, ax2, ax3])
                T_log[ax0, ax1, ax2, ax3] = T.log(T_add_1[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 26, 26):
            with T.block("T_tanh"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_log[ax0, ax1, ax2, ax3])
                T.writes(T_tanh[ax0, ax1, ax2, ax3])
                T_tanh[ax0, ax1, ax2, ax3] = T.tanh(T_log[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 26, 26):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3], T_tanh[ax0, ax1, ax2, ax3])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = T_add[ax0, ax1, ax2, ax3] * T_tanh[ax0, ax1, ax2, ax3]
    

[13:33:04] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:04] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 52, 52), "float32"], placeholder_1: T.Buffer[(512, 256, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 512, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":512})
            conv2d_nchw = T.alloc_buffer([1, 512, 26, 26], dtype="float32")
            conv2d_nchw_local = T.alloc_buffer([1, 512, 26, 26], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 256, 53, 53], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([512, 256, 3, 3], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(1, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(26, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(8, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(2, 3, 3):
                            for ax0_ax1_ax2_ax3_fused in T.serial(332928):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(256, i4_0 * 128 + ax0_ax1_ax2_ax3_fused % 332928 // 2601)
                                    v2 = T.axis.spatial(53, i5_0 + ax0_ax1_ax2_ax3_fused % 2601 // 51)
                                    v3 = T.axis.spatial(53, i6_0 + ax0_ax1_ax2_ax3_fused % 51)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":2})
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 53 and 1 <= v3 and v3 < 53, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                            for ax0_ax1_ax2_ax3_fused in T.serial(65536):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(512, ax0_ax1_ax2_ax3_fused // 128)
                                    v1 = T.axis.spatial(256, i4_0 * 128 + ax0_ax1_ax2_ax3_fused % 128)
                                    v2, v3 = T.axis.remap("SS", [i5_0, i6_0])
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":3})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(16, 1, 1, 1, 4, 13, 1, 8, 1, 1, 1, 8, 2, 2):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(512, i0_1_i1_1_i2_1_i3_1_fused // 13 * 256 + i0_2_i1_2_i2_2_i3_2_fused * 32 + i1_3 * 8 + i1_4)
                                    yy = T.axis.spatial(26, i2_3 * 2 + i2_4)
                                    xx = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused % 13 * 2 + i3_4)
                                    rc = T.axis.reduce(256, i4_0 * 128 + i4_1 * 8 + i4_2)
                                    ry, rx = T.axis.remap("RR", [i5_0, i6_0])
                                    T.reads(pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [512, 256, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 32, 26, 2):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(512, i0_1_i1_1_i2_1_i3_1_fused // 13 * 256 + i0_2_i1_2_i2_2_i3_2_fused * 32 + ax1)
                                v2 = T.axis.spatial(26, ax2)
                                v3 = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused % 13 * 2 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                                T.writes(conv2d_nchw[v0, v1, v2, v3])
                                conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
            for i0, i1, i2, i3 in T.grid(1, 512, 26, 26):
                with T.block("T_multiply"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_multiply[ax0, ax1, ax2, ax3])
                    T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 2, 8, 4, 8])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 1, 1, 13, 2])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 13, 1, 1, 2])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[2, 16, 8])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
[13:33:04] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"
[13:33:04] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 26, 26), "float32"], placeholder_1: T.Buffer[(256, 512, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 256, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 512, 26, 26], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
        T_add = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
        T_exp = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
        T_log = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
        T_tanh = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 26, 26):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[i0_1, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 256, 26, 26, 512, 1, 1):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 26, 26], "float32"], ["TENSOR", [256, 512, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
            with T.block("T_exp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_exp[ax0, ax1, ax2, ax3])
                T_exp[ax0, ax1, ax2, ax3] = T.exp(T_add[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_3[ax0, 0, 0, 0], T_exp[ax0, ax1, ax2, ax3])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = placeholder_3[ax0, 0, 0, 0] + T_exp[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
            with T.block("T_log"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3])
                T.writes(T_log[ax0, ax1, ax2, ax3])
                T_log[ax0, ax1, ax2, ax3] = T.log(T_add_1[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
            with T.block("T_tanh"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_log[ax0, ax1, ax2, ax3])
                T.writes(T_tanh[ax0, ax1, ax2, ax3])
                T_tanh[ax0, ax1, ax2, ax3] = T.tanh(T_log[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3], T_tanh[ax0, ax1, ax2, ax3])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = T_add[ax0, ax1, ax2, ax3] * T_tanh[ax0, ax1, ax2, ax3]
    

[13:33:04] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:04] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 26, 26), "float32"], placeholder_1: T.Buffer[(256, 512, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 256, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":512})
            conv2d_nchw = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
            conv2d_nchw_local = T.alloc_buffer([1, 256, 26, 26], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 512, 26, 26], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([256, 512, 1, 1], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(16, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(13, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(2, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(8, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(43264):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(512, i4_0 * 64 + ax0_ax1_ax2_ax3_fused // 676)
                                    v2 = T.axis.spatial(26, ax0_ax1_ax2_ax3_fused % 676 // 26)
                                    v3 = T.axis.spatial(26, ax0_ax1_ax2_ax3_fused % 26)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":3})
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in T.serial(1024):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused * 16 + ax0_ax1_ax2_ax3_fused // 64)
                                    v1 = T.axis.spatial(512, i4_0 * 64 + ax0_ax1_ax2_ax3_fused % 64)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":1})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(2, 1, 1, 1, 4, 2, 2, 32, 1, 1, 1, 2, 13, 1):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused * 16 + i0_2_i1_2_i2_2_i3_2_fused * 8 + i1_3 * 2 + i1_4)
                                    yy = T.axis.spatial(26, i2_3 * 13 + i2_4)
                                    xx = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused * 2 + i3_3)
                                    rc = T.axis.reduce(512, i4_0 * 64 + i4_1 * 32 + i4_2)
                                    ry = T.axis.reduce(1, 0)
                                    rx = T.axis.reduce(1, 0)
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 26, 26], "float32"], ["TENSOR", [256, 512, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 8, 26, 2):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused * 16 + i0_2_i1_2_i2_2_i3_2_fused * 8 + ax1)
                                v2 = T.axis.spatial(26, ax2)
                                v3 = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused * 2 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                                T.writes(conv2d_nchw[v0, v1, v2, v3])
                                conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
            for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
                with T.block("T_multiply"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_multiply[ax0, ax1, ax2, ax3])
                    T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[16, 1, 2, 4, 2])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 1, 1, 2, 13])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 13, 1, 2, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[8, 2, 32])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
[13:33:04] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"
[13:33:04] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 26, 26), "float32"], placeholder_1: T.Buffer[(256, 256, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], placeholder_4: T.Buffer[(1, 256, 26, 26), "float32"], T_add: T.Buffer[(1, 256, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 256, 28, 28], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
        T_exp = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
        T_add_2 = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
        T_log = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
        T_tanh = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
        T_multiply = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 28, 28):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = T.if_then_else(1 <= i2_1 and i2_1 < 27 and 1 <= i3_1 and i3_1 < 27, placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 256, 26, 26, 256, 3, 3):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 26, 26], "float32"], ["TENSOR", [256, 256, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
            with T.block("T_exp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3])
                T.writes(T_exp[ax0, ax1, ax2, ax3])
                T_exp[ax0, ax1, ax2, ax3] = T.exp(T_add_1[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_3[ax0, 0, 0, 0], T_exp[ax0, ax1, ax2, ax3])
                T.writes(T_add_2[ax0, ax1, ax2, ax3])
                T_add_2[ax0, ax1, ax2, ax3] = placeholder_3[ax0, 0, 0, 0] + T_exp[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
            with T.block("T_log"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_2[ax0, ax1, ax2, ax3])
                T.writes(T_log[ax0, ax1, ax2, ax3])
                T_log[ax0, ax1, ax2, ax3] = T.log(T_add_2[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
            with T.block("T_tanh"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_log[ax0, ax1, ax2, ax3])
                T.writes(T_tanh[ax0, ax1, ax2, ax3])
                T_tanh[ax0, ax1, ax2, ax3] = T.tanh(T_log[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3], T_tanh[ax0, ax1, ax2, ax3])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = T_add_1[ax0, ax1, ax2, ax3] * T_tanh[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
            with T.block("T_add_2"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_4[ax0, ax1, ax2, ax3], T_multiply[ax0, ax1, ax2, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = placeholder_4[ax0, ax1, ax2, ax3] + T_multiply[ax0, ax1, ax2, ax3]
    

[13:33:05] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:05] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 26, 26), "float32"], placeholder_1: T.Buffer[(256, 256, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], placeholder_4: T.Buffer[(1, 256, 26, 26), "float32"], T_add: T.Buffer[(1, 256, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":512})
            conv2d_nchw = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
            conv2d_nchw_local = T.alloc_buffer([1, 256, 26, 26], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 256, 28, 28], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([256, 256, 3, 3], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(2, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(8, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(1, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(32, 3, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(2912):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(256, i4_0 * 8 + ax0_ax1_ax2_ax3_fused % 2912 // 364)
                                    v2 = T.axis.spatial(28, i0_0_i1_0_i2_0_i3_0_fused * 13 + i5_0 + ax0_ax1_ax2_ax3_fused % 364 // 28)
                                    v3 = T.axis.spatial(28, ax0_ax1_ax2_ax3_fused % 28)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":3})
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 27 and 1 <= v3 and v3 < 27, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                            for ax0_ax1_ax2_ax3_fused in T.serial(6144):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(256, ax0_ax1_ax2_ax3_fused // 24)
                                    v1 = T.axis.spatial(256, i4_0 * 8 + ax0_ax1_ax2_ax3_fused % 24 // 3)
                                    v2 = T.axis.spatial(3, i5_0)
                                    v3 = T.axis.spatial(3, ax0_ax1_ax2_ax3_fused % 3)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":4})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(4, 1, 3, 1, 8, 1, 26, 2, 1, 1, 1, 4, 13, 1):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(256, i0_1_i1_1_i2_1_i3_1_fused * 32 + i1_3 * 4 + i1_4)
                                    yy = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused * 13 + i2_4)
                                    xx = T.axis.spatial(26, i3_3)
                                    rc = T.axis.reduce(256, i4_0 * 8 + i4_1 * 2 + i4_2)
                                    ry, rx = T.axis.remap("RR", [i5_0, i6_1])
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 26, 26], "float32"], ["TENSOR", [256, 256, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 32, 13, 26):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(256, i0_1_i1_1_i2_1_i3_1_fused * 32 + ax1)
                                v2 = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused * 13 + ax2)
                                v3 = T.axis.spatial(26, ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                                T.writes(conv2d_nchw[v0, v1, v2, v3])
                                conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
            for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
                with T.block("T_multiply"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(placeholder_4[ax0, ax1, ax2, ax3], conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_add[ax0, ax1, ax2, ax3])
                    T_add[ax0, ax1, ax2, ax3] = placeholder_4[ax0, ax1, ax2, ax3] + (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="T_add_2", func_name="main")
b8 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l9, l10, l11, l12, l13, l14, l15 = sch.get_loops(block=b1)
v16, v17, v18, v19, v20 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l21, l22, l23, l24, l25 = sch.split(loop=l9, factors=[v16, v17, v18, v19, v20])
v26, v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 8, 1, 8, 4])
l31, l32, l33, l34, l35 = sch.split(loop=l10, factors=[v26, v27, v28, v29, v30])
v36, v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[2, 1, 1, 1, 13])
l41, l42, l43, l44, l45 = sch.split(loop=l11, factors=[v36, v37, v38, v39, v40])
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l12, n=5, max_innermost_factor=64, decision=[1, 1, 1, 26, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l12, factors=[v46, v47, v48, v49, v50])
v56, v57, v58 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[32, 4, 2])
l59, l60, l61 = sch.split(loop=l13, factors=[v56, v57, v58])
v62, v63, v64 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l65, l66, l67 = sch.split(loop=l14, factors=[v62, v63, v64])
v68, v69, v70 = sch.sample_perfect_tile(loop=l15, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l71, l72, l73 = sch.split(loop=l15, factors=[v68, v69, v70])
sch.reorder(l21, l31, l41, l51, l22, l32, l42, l52, l23, l33, l43, l53, l59, l65, l71, l60, l66, l72, l24, l34, l44, l54, l61, l67, l73, l25, l35, l45, l55)
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="blockIdx.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="vthread.x")
l76 = sch.fuse(l23, l33, l43, l53)
sch.bind(loop=l76, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b77 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b77, loop=l76, preserve_unit_loops=True)
b78 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b78, loop=l71, preserve_unit_loops=True)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b78)
l89 = sch.fuse(l85, l86, l87, l88)
v90 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b78, ann_key="meta_schedule.cooperative_fetch", ann_val=v90)
b91 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b91, loop=l71, preserve_unit_loops=True)
l92, l93, l94, l95, l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b91)
l102 = sch.fuse(l98, l99, l100, l101)
v103 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b91, ann_key="meta_schedule.cooperative_fetch", ann_val=v103)
sch.reverse_compute_inline(block=b7)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v104 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b8, ann_key="meta_schedule.unroll_explicit", ann_val=v104)
[13:33:05] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"
[13:33:05] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 26, 26), "float32"], placeholder_1: T.Buffer[(256, 256, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 256, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
        T_add = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
        T_exp = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
        T_log = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
        T_tanh = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[i0_1, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 256, 26, 26, 256, 1, 1):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 26, 26], "float32"], ["TENSOR", [256, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
            with T.block("T_exp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_exp[ax0, ax1, ax2, ax3])
                T_exp[ax0, ax1, ax2, ax3] = T.exp(T_add[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_3[ax0, 0, 0, 0], T_exp[ax0, ax1, ax2, ax3])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = placeholder_3[ax0, 0, 0, 0] + T_exp[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
            with T.block("T_log"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3])
                T.writes(T_log[ax0, ax1, ax2, ax3])
                T_log[ax0, ax1, ax2, ax3] = T.log(T_add_1[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
            with T.block("T_tanh"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_log[ax0, ax1, ax2, ax3])
                T.writes(T_tanh[ax0, ax1, ax2, ax3])
                T_tanh[ax0, ax1, ax2, ax3] = T.tanh(T_log[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3], T_tanh[ax0, ax1, ax2, ax3])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = T_add[ax0, ax1, ax2, ax3] * T_tanh[ax0, ax1, ax2, ax3]
    

[13:33:06] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:06] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 26, 26), "float32"], placeholder_1: T.Buffer[(256, 256, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 256, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":0})
            conv2d_nchw = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
            conv2d_nchw_local = T.alloc_buffer([1, 256, 26, 26], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 256, 26, 26], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([256, 256, 1, 1], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(16, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(26, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(104, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(1, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(86528):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(256, ax0_ax1_ax2_ax3_fused // 338)
                                    v2 = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused % 2 * 13 + ax0_ax1_ax2_ax3_fused % 338 // 26)
                                    v3 = T.axis.spatial(26, ax0_ax1_ax2_ax3_fused % 26)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":3})
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in T.serial(8192):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 2 * 32 + ax0_ax1_ax2_ax3_fused // 256)
                                    v1 = T.axis.spatial(256, ax0_ax1_ax2_ax3_fused % 256)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":1})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(128, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 2 * 32 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 2 + i1_4)
                                    yy = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused % 2 * 13 + i0_1_i1_1_i2_1_i3_1_fused % 13)
                                    xx = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused % 13 * 2 + i3_4)
                                    rc = T.axis.reduce(256, i4_1 * 2 + i4_2)
                                    ry = T.axis.reduce(1, 0)
                                    rx = T.axis.reduce(1, 0)
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 26, 26], "float32"], ["TENSOR", [256, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 2, 1, 2):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 2 * 32 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 2 + ax1)
                                v2 = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused % 2 * 13 + i0_1_i1_1_i2_1_i3_1_fused % 13 + ax2)
                                v3 = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused % 13 * 2 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                                T.writes(conv2d_nchw[v0, v1, v2, v3])
                                conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
            for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
                with T.block("T_multiply"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_multiply[ax0, ax1, ax2, ax3])
                    T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[8, 2, 8, 1, 2])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[2, 13, 1, 1, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 1, 13, 1, 2])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[1, 128, 2])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
[13:33:06] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #32: "fused_concatenate_3"
[13:33:06] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 26, 26), "float32"], placeholder_1: T.Buffer[(1, 256, 26, 26), "float32"], T_concat: T.Buffer[(1, 512, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3 in T.grid(1, 512, 26, 26):
            with T.block("T_concat"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_1[ax0, ax1 - 256, ax2, ax3], placeholder[ax0, ax1, ax2, ax3])
                T.writes(T_concat[ax0, ax1, ax2, ax3])
                T_concat[ax0, ax1, ax2, ax3] = T.if_then_else(256 <= ax1, placeholder_1[ax0, ax1 - 256, ax2, ax3], placeholder[ax0, ax1, ax2, ax3], dtype="float32")
    

[13:33:06] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:06] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 26, 26), "float32"], placeholder_1: T.Buffer[(1, 256, 26, 26), "float32"], T_concat: T.Buffer[(1, 512, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":0})
            for i0, i1, i2, i3 in T.grid(1, 512, 26, 26):
                with T.block("T_concat"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(placeholder_1[ax0, ax1 - 256, ax2, ax3], placeholder[ax0, ax1, ax2, ax3])
                    T.writes(T_concat[ax0, ax1, ax2, ax3])
                    T_concat[ax0, ax1, ax2, ax3] = T.if_then_else(256 <= ax1, placeholder_1[ax0, ax1 - 256, ax2, ax3], placeholder[ax0, ax1, ax2, ax3], dtype="float32")
    

b0 = sch.get_block(name="root", func_name="main")
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
[13:33:06] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"
[13:33:06] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 26, 26), "float32"], placeholder_1: T.Buffer[(512, 512, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 512, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 512, 26, 26], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 512, 26, 26], dtype="float32")
        T_add = T.alloc_buffer([1, 512, 26, 26], dtype="float32")
        T_exp = T.alloc_buffer([1, 512, 26, 26], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 512, 26, 26], dtype="float32")
        T_log = T.alloc_buffer([1, 512, 26, 26], dtype="float32")
        T_tanh = T.alloc_buffer([1, 512, 26, 26], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 26, 26):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[i0_1, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 512, 26, 26, 512, 1, 1):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 26, 26], "float32"], ["TENSOR", [512, 512, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 512, 26, 26):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 512, 26, 26):
            with T.block("T_exp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_exp[ax0, ax1, ax2, ax3])
                T_exp[ax0, ax1, ax2, ax3] = T.exp(T_add[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 26, 26):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_3[ax0, 0, 0, 0], T_exp[ax0, ax1, ax2, ax3])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = placeholder_3[ax0, 0, 0, 0] + T_exp[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 512, 26, 26):
            with T.block("T_log"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3])
                T.writes(T_log[ax0, ax1, ax2, ax3])
                T_log[ax0, ax1, ax2, ax3] = T.log(T_add_1[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 26, 26):
            with T.block("T_tanh"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_log[ax0, ax1, ax2, ax3])
                T.writes(T_tanh[ax0, ax1, ax2, ax3])
                T_tanh[ax0, ax1, ax2, ax3] = T.tanh(T_log[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 26, 26):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3], T_tanh[ax0, ax1, ax2, ax3])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = T_add[ax0, ax1, ax2, ax3] * T_tanh[ax0, ax1, ax2, ax3]
    

[13:33:06] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:06] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 26, 26), "float32"], placeholder_1: T.Buffer[(512, 512, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 512, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":1024})
            conv2d_nchw = T.alloc_buffer([1, 512, 26, 26], dtype="float32")
            conv2d_nchw_local = T.alloc_buffer([1, 512, 26, 26], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 512, 26, 26], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([512, 512, 1, 1], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(4, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(13, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(1, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(346112):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(512, ax0_ax1_ax2_ax3_fused // 676)
                                    v2 = T.axis.spatial(26, ax0_ax1_ax2_ax3_fused % 676 // 26)
                                    v3 = T.axis.spatial(26, ax0_ax1_ax2_ax3_fused % 26)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":3})
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in T.serial(65536):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused * 128 + ax0_ax1_ax2_ax3_fused // 512)
                                    v1 = T.axis.spatial(512, ax0_ax1_ax2_ax3_fused % 512)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":1})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(64, 1, 1, 1, 8, 26, 1, 8, 1, 1, 1, 1, 1, 1):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused * 128 + i0_2_i1_2_i2_2_i3_2_fused // 2 * 8 + i1_3)
                                    yy = T.axis.spatial(26, i2_3)
                                    xx = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused * 2 + i0_2_i1_2_i2_2_i3_2_fused % 2)
                                    rc = T.axis.reduce(512, i4_1 * 8 + i4_2)
                                    ry = T.axis.reduce(1, 0)
                                    rx = T.axis.reduce(1, 0)
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 26, 26], "float32"], ["TENSOR", [512, 512, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 8, 26, 1):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused * 128 + i0_2_i1_2_i2_2_i3_2_fused // 2 * 8 + ax1)
                                v2 = T.axis.spatial(26, ax2)
                                v3 = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused * 2 + i0_2_i1_2_i2_2_i3_2_fused % 2 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                                T.writes(conv2d_nchw[v0, v1, v2, v3])
                                conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
            for i0, i1, i2, i3 in T.grid(1, 512, 26, 26):
                with T.block("T_multiply"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_multiply[ax0, ax1, ax2, ax3])
                    T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[4, 1, 16, 8, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 1, 1, 26, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 13, 2, 1, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[1, 64, 8])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
[13:33:06] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"
[13:33:06] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 26, 26), "float32"], placeholder_1: T.Buffer[(1024, 512, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 1024, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 1024, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 512, 27, 27], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 1024, 13, 13], dtype="float32")
        T_add = T.alloc_buffer([1, 1024, 13, 13], dtype="float32")
        T_exp = T.alloc_buffer([1, 1024, 13, 13], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 1024, 13, 13], dtype="float32")
        T_log = T.alloc_buffer([1, 1024, 13, 13], dtype="float32")
        T_tanh = T.alloc_buffer([1, 1024, 13, 13], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 27, 27):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = T.if_then_else(1 <= i2_1 and i2_1 < 27 and 1 <= i3_1 and i3_1 < 27, placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 1024, 13, 13, 512, 3, 3):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 26, 26], "float32"], ["TENSOR", [1024, 512, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 1024, 13, 13):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 1024, 13, 13):
            with T.block("T_exp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_exp[ax0, ax1, ax2, ax3])
                T_exp[ax0, ax1, ax2, ax3] = T.exp(T_add[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 1024, 13, 13):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_3[ax0, 0, 0, 0], T_exp[ax0, ax1, ax2, ax3])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = placeholder_3[ax0, 0, 0, 0] + T_exp[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 1024, 13, 13):
            with T.block("T_log"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3])
                T.writes(T_log[ax0, ax1, ax2, ax3])
                T_log[ax0, ax1, ax2, ax3] = T.log(T_add_1[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 1024, 13, 13):
            with T.block("T_tanh"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_log[ax0, ax1, ax2, ax3])
                T.writes(T_tanh[ax0, ax1, ax2, ax3])
                T_tanh[ax0, ax1, ax2, ax3] = T.tanh(T_log[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 1024, 13, 13):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3], T_tanh[ax0, ax1, ax2, ax3])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = T_add[ax0, ax1, ax2, ax3] * T_tanh[ax0, ax1, ax2, ax3]
    

[13:33:07] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:07] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 26, 26), "float32"], placeholder_1: T.Buffer[(1024, 512, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 1024, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 1024, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":512})
            conv2d_nchw = T.alloc_buffer([1, 1024, 13, 13], dtype="float32")
            conv2d_nchw_local = T.alloc_buffer([1, 1024, 13, 13], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 512, 27, 27], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([1024, 512, 3, 3], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(4, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(32, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(1, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(32, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(11664):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(512, i4_0 * 16 + ax0_ax1_ax2_ax3_fused // 729)
                                    v2 = T.axis.spatial(27, ax0_ax1_ax2_ax3_fused % 729 // 27)
                                    v3 = T.axis.spatial(27, ax0_ax1_ax2_ax3_fused % 27)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":3})
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 27 and 1 <= v3 and v3 < 27, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                            for ax0_ax1_ax2_ax3_fused in T.serial(36864):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused * 256 + ax0_ax1_ax2_ax3_fused // 144)
                                    v1 = T.axis.spatial(512, i4_0 * 16 + ax0_ax1_ax2_ax3_fused % 144 // 9)
                                    v2 = T.axis.spatial(3, ax0_ax1_ax2_ax3_fused % 9 // 3)
                                    v3 = T.axis.spatial(3, ax0_ax1_ax2_ax3_fused % 3)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":3})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(2, 1, 1, 1, 2, 13, 1, 8, 3, 3, 1, 4, 1, 13):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused * 256 + i0_1_i1_1_i2_1_i3_1_fused * 8 + i1_3 * 4 + i1_4)
                                    yy, xx = T.axis.remap("SS", [i2_3, i3_4])
                                    rc = T.axis.reduce(512, i4_0 * 16 + i4_1 * 8 + i4_2)
                                    ry, rx = T.axis.remap("RR", [i5_2, i6_2])
                                    T.reads(pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 26, 26], "float32"], ["TENSOR", [1024, 512, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 8, 13, 13):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused * 256 + i0_1_i1_1_i2_1_i3_1_fused * 8 + ax1)
                                v2, v3 = T.axis.remap("SS", [ax2, ax3])
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                                T.writes(conv2d_nchw[v0, v1, v2, v3])
                                conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
            for i0, i1, i2, i3 in T.grid(1, 1024, 13, 13):
                with T.block("T_multiply"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_multiply[ax0, ax1, ax2, ax3])
                    T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[4, 32, 1, 2, 4])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 1, 1, 13, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 13])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[32, 2, 8])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
[13:33:07] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"
[13:33:07] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1024, 13, 13), "float32"], placeholder_1: T.Buffer[(512, 1024, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 512, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 1024, 13, 13], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        T_add = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        T_exp = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        T_log = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        T_tanh = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 1024, 13, 13):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[i0_1, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 512, 13, 13, 1024, 1, 1):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 1024, 13, 13], "float32"], ["TENSOR", [512, 1024, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
            with T.block("T_exp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_exp[ax0, ax1, ax2, ax3])
                T_exp[ax0, ax1, ax2, ax3] = T.exp(T_add[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_3[ax0, 0, 0, 0], T_exp[ax0, ax1, ax2, ax3])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = placeholder_3[ax0, 0, 0, 0] + T_exp[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
            with T.block("T_log"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3])
                T.writes(T_log[ax0, ax1, ax2, ax3])
                T_log[ax0, ax1, ax2, ax3] = T.log(T_add_1[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
            with T.block("T_tanh"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_log[ax0, ax1, ax2, ax3])
                T.writes(T_tanh[ax0, ax1, ax2, ax3])
                T_tanh[ax0, ax1, ax2, ax3] = T.tanh(T_log[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3], T_tanh[ax0, ax1, ax2, ax3])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = T_add[ax0, ax1, ax2, ax3] * T_tanh[ax0, ax1, ax2, ax3]
    

[13:33:07] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:07] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1024, 13, 13), "float32"], placeholder_1: T.Buffer[(512, 1024, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 512, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":1024})
            conv2d_nchw = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
            conv2d_nchw_local = T.alloc_buffer([1, 512, 13, 13], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 1024, 13, 13], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([512, 1024, 1, 1], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(1, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(8, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(2, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(32, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(5408):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(1024, i4_0 * 32 + ax0_ax1_ax2_ax3_fused // 169)
                                    v2 = T.axis.spatial(13, ax0_ax1_ax2_ax3_fused % 169 // 13)
                                    v3 = T.axis.spatial(13, ax0_ax1_ax2_ax3_fused % 13)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":4})
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in T.serial(16384):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(512, ax0_ax1_ax2_ax3_fused // 32)
                                    v1 = T.axis.spatial(1024, i4_0 * 32 + ax0_ax1_ax2_ax3_fused % 32)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":3})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(4, 1, 1, 1, 16, 13, 13, 8, 1, 1, 1, 2, 1, 1):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(512, i0_1_i1_1_i2_1_i3_1_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused * 32 + i1_3 * 2 + i1_4)
                                    yy, xx = T.axis.remap("SS", [i2_3, i3_3])
                                    rc = T.axis.reduce(1024, i4_0 * 32 + i4_1 * 8 + i4_2)
                                    ry = T.axis.reduce(1, 0)
                                    rx = T.axis.reduce(1, 0)
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 1024, 13, 13], "float32"], ["TENSOR", [512, 1024, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 32, 13, 13):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(512, i0_1_i1_1_i2_1_i3_1_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused * 32 + ax1)
                                v2, v3 = T.axis.remap("SS", [ax2, ax3])
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                                T.writes(conv2d_nchw[v0, v1, v2, v3])
                                conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
            for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
                with T.block("T_multiply"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_multiply[ax0, ax1, ax2, ax3])
                    T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 8, 2, 16, 2])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 1, 1, 13, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 1, 1, 13, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[32, 4, 8])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
[13:33:07] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"
[13:33:07] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 13, 13), "float32"], placeholder_1: T.Buffer[(512, 512, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], placeholder_4: T.Buffer[(1, 512, 13, 13), "float32"], T_add: T.Buffer[(1, 512, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 512, 15, 15], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        T_exp = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        T_add_2 = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        T_log = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        T_tanh = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        T_multiply = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 15, 15):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = T.if_then_else(1 <= i2_1 and i2_1 < 14 and 1 <= i3_1 and i3_1 < 14, placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 512, 13, 13, 512, 3, 3):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 13, 13], "float32"], ["TENSOR", [512, 512, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
            with T.block("T_exp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3])
                T.writes(T_exp[ax0, ax1, ax2, ax3])
                T_exp[ax0, ax1, ax2, ax3] = T.exp(T_add_1[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_3[ax0, 0, 0, 0], T_exp[ax0, ax1, ax2, ax3])
                T.writes(T_add_2[ax0, ax1, ax2, ax3])
                T_add_2[ax0, ax1, ax2, ax3] = placeholder_3[ax0, 0, 0, 0] + T_exp[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
            with T.block("T_log"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_2[ax0, ax1, ax2, ax3])
                T.writes(T_log[ax0, ax1, ax2, ax3])
                T_log[ax0, ax1, ax2, ax3] = T.log(T_add_2[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
            with T.block("T_tanh"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_log[ax0, ax1, ax2, ax3])
                T.writes(T_tanh[ax0, ax1, ax2, ax3])
                T_tanh[ax0, ax1, ax2, ax3] = T.tanh(T_log[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3], T_tanh[ax0, ax1, ax2, ax3])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = T_add_1[ax0, ax1, ax2, ax3] * T_tanh[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
            with T.block("T_add_2"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_4[ax0, ax1, ax2, ax3], T_multiply[ax0, ax1, ax2, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = placeholder_4[ax0, ax1, ax2, ax3] + T_multiply[ax0, ax1, ax2, ax3]
    

[13:33:08] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:08] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 13, 13), "float32"], placeholder_1: T.Buffer[(512, 512, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], placeholder_4: T.Buffer[(1, 512, 13, 13), "float32"], T_add: T.Buffer[(1, 512, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":1024})
            conv2d_nchw = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
            conv2d_nchw_local = T.alloc_buffer([1, 512, 13, 13], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 512, 15, 15], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([512, 512, 3, 3], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(2, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(4, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(8, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(256, 1, 3):
                            for ax0_ax1_ax2_ax3_fused in T.serial(390):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(512, i4_0 * 2 + ax0_ax1_ax2_ax3_fused % 390 // 195)
                                    v2 = T.axis.spatial(15, ax0_ax1_ax2_ax3_fused % 195 // 13)
                                    v3 = T.axis.spatial(15, i6_0 + ax0_ax1_ax2_ax3_fused % 13)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":1})
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 14 and 1 <= v3 and v3 < 14, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                            for ax0_ax1_ax2_ax3_fused in T.serial(1536):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused * 256 + ax0_ax1_ax2_ax3_fused // 6)
                                    v1 = T.axis.spatial(512, i4_0 * 2 + ax0_ax1_ax2_ax3_fused % 6 // 3)
                                    v2 = T.axis.spatial(3, ax0_ax1_ax2_ax3_fused % 3)
                                    v3 = T.axis.spatial(3, i6_0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":4})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 8, 1, 13, 2, 3, 1, 1, 1, 13, 1):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused * 256 + i0_1_i1_1_i2_1_i3_1_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused * 8 + i1_3)
                                    yy, xx = T.axis.remap("SS", [i2_4, i3_3])
                                    rc = T.axis.reduce(512, i4_0 * 2 + i4_2)
                                    ry, rx = T.axis.remap("RR", [i5_2, i6_0])
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 13, 13], "float32"], ["TENSOR", [512, 512, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 8, 13, 13):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused * 256 + i0_1_i1_1_i2_1_i3_1_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused * 8 + ax1)
                                v2, v3 = T.axis.remap("SS", [ax2, ax3])
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                                T.writes(conv2d_nchw[v0, v1, v2, v3])
                                conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
            for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
                with T.block("T_multiply"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(placeholder_4[ax0, ax1, ax2, ax3], conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_add[ax0, ax1, ax2, ax3])
                    T_add[ax0, ax1, ax2, ax3] = placeholder_4[ax0, ax1, ax2, ax3] + (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="T_add_2", func_name="main")
b8 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l9, l10, l11, l12, l13, l14, l15 = sch.get_loops(block=b1)
v16, v17, v18, v19, v20 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l21, l22, l23, l24, l25 = sch.split(loop=l9, factors=[v16, v17, v18, v19, v20])
v26, v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[2, 4, 8, 8, 1])
l31, l32, l33, l34, l35 = sch.split(loop=l10, factors=[v26, v27, v28, v29, v30])
v36, v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 13])
l41, l42, l43, l44, l45 = sch.split(loop=l11, factors=[v36, v37, v38, v39, v40])
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l12, n=5, max_innermost_factor=64, decision=[1, 1, 1, 13, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l12, factors=[v46, v47, v48, v49, v50])
v56, v57, v58 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[256, 1, 2])
l59, l60, l61 = sch.split(loop=l13, factors=[v56, v57, v58])
v62, v63, v64 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l65, l66, l67 = sch.split(loop=l14, factors=[v62, v63, v64])
v68, v69, v70 = sch.sample_perfect_tile(loop=l15, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l71, l72, l73 = sch.split(loop=l15, factors=[v68, v69, v70])
sch.reorder(l21, l31, l41, l51, l22, l32, l42, l52, l23, l33, l43, l53, l59, l65, l71, l60, l66, l72, l24, l34, l44, l54, l61, l67, l73, l25, l35, l45, l55)
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="blockIdx.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="vthread.x")
l76 = sch.fuse(l23, l33, l43, l53)
sch.bind(loop=l76, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b77 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b77, loop=l76, preserve_unit_loops=True)
b78 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b78, loop=l71, preserve_unit_loops=True)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b78)
l89 = sch.fuse(l85, l86, l87, l88)
v90 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b78, ann_key="meta_schedule.cooperative_fetch", ann_val=v90)
b91 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b91, loop=l71, preserve_unit_loops=True)
l92, l93, l94, l95, l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b91)
l102 = sch.fuse(l98, l99, l100, l101)
v103 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b91, ann_key="meta_schedule.cooperative_fetch", ann_val=v103)
sch.reverse_compute_inline(block=b7)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v104 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b8, ann_key="meta_schedule.unroll_explicit", ann_val=v104)
[13:33:08] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"
[13:33:08] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 13, 13), "float32"], placeholder_1: T.Buffer[(512, 512, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 512, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        T_add = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        T_exp = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        T_log = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        T_tanh = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[i0_1, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 512, 13, 13, 512, 1, 1):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 13, 13], "float32"], ["TENSOR", [512, 512, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
            with T.block("T_exp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_exp[ax0, ax1, ax2, ax3])
                T_exp[ax0, ax1, ax2, ax3] = T.exp(T_add[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_3[ax0, 0, 0, 0], T_exp[ax0, ax1, ax2, ax3])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = placeholder_3[ax0, 0, 0, 0] + T_exp[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
            with T.block("T_log"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3])
                T.writes(T_log[ax0, ax1, ax2, ax3])
                T_log[ax0, ax1, ax2, ax3] = T.log(T_add_1[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
            with T.block("T_tanh"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_log[ax0, ax1, ax2, ax3])
                T.writes(T_tanh[ax0, ax1, ax2, ax3])
                T_tanh[ax0, ax1, ax2, ax3] = T.tanh(T_log[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3], T_tanh[ax0, ax1, ax2, ax3])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = T_add[ax0, ax1, ax2, ax3] * T_tanh[ax0, ax1, ax2, ax3]
    

[13:33:09] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:09] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 13, 13), "float32"], placeholder_1: T.Buffer[(512, 512, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 512, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":0})
            conv2d_nchw = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
            conv2d_nchw_local = T.alloc_buffer([1, 512, 13, 13], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 512, 13, 13], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([512, 512, 1, 1], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(26, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(1, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(1, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(16, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(416):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(512, i4_0 * 32 + ax0_ax1_ax2_ax3_fused // 13)
                                    v2 = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_fused % 13)
                                    v3 = T.axis.spatial(13, ax0_ax1_ax2_ax3_fused % 13)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":3})
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in T.serial(8192):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused // 13 * 256 + ax0_ax1_ax2_ax3_fused // 32)
                                    v1 = T.axis.spatial(512, i4_0 * 32 + ax0_ax1_ax2_ax3_fused % 32)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":1})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 8, 1, 13, 32, 1, 1, 1, 32, 1, 1):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused // 13 * 256 + i1_3 * 32 + i1_4)
                                    yy = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_fused % 13)
                                    xx = T.axis.spatial(13, i3_3)
                                    rc = T.axis.reduce(512, i4_0 * 32 + i4_2)
                                    ry = T.axis.reduce(1, 0)
                                    rx = T.axis.reduce(1, 0)
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 13, 13], "float32"], ["TENSOR", [512, 512, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 256, 1, 13):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused // 13 * 256 + ax1)
                                v2 = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_fused % 13 + ax2)
                                v3 = T.axis.spatial(13, ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                                T.writes(conv2d_nchw[v0, v1, v2, v3])
                                conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
            for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
                with T.block("T_multiply"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_multiply[ax0, ax1, ax2, ax3])
                    T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[2, 1, 1, 8, 32])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[13, 1, 1, 1, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 1, 1, 13, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[16, 1, 32])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
[13:33:09] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #38: "fused_concatenate_4"
[13:33:09] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 13, 13), "float32"], placeholder_1: T.Buffer[(1, 512, 13, 13), "float32"], T_concat: T.Buffer[(1, 1024, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3 in T.grid(1, 1024, 13, 13):
            with T.block("T_concat"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_1[ax0, ax1 - 512, ax2, ax3], placeholder[ax0, ax1, ax2, ax3])
                T.writes(T_concat[ax0, ax1, ax2, ax3])
                T_concat[ax0, ax1, ax2, ax3] = T.if_then_else(512 <= ax1, placeholder_1[ax0, ax1 - 512, ax2, ax3], placeholder[ax0, ax1, ax2, ax3], dtype="float32")
    

[13:33:09] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:09] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 13, 13), "float32"], placeholder_1: T.Buffer[(1, 512, 13, 13), "float32"], T_concat: T.Buffer[(1, 1024, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":16})
            for i0, i1, i2, i3 in T.grid(1, 1024, 13, 13):
                with T.block("T_concat"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(placeholder_1[ax0, ax1 - 512, ax2, ax3], placeholder[ax0, ax1, ax2, ax3])
                    T.writes(T_concat[ax0, ax1, ax2, ax3])
                    T_concat[ax0, ax1, ax2, ax3] = T.if_then_else(512 <= ax1, placeholder_1[ax0, ax1 - 512, ax2, ax3], placeholder[ax0, ax1, ax2, ax3], dtype="float32")
    

b0 = sch.get_block(name="root", func_name="main")
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
[13:33:09] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"
[13:33:09] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1024, 13, 13), "float32"], placeholder_1: T.Buffer[(1024, 1024, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 1024, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 1024, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 1024, 13, 13], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 1024, 13, 13], dtype="float32")
        T_add = T.alloc_buffer([1, 1024, 13, 13], dtype="float32")
        T_exp = T.alloc_buffer([1, 1024, 13, 13], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 1024, 13, 13], dtype="float32")
        T_log = T.alloc_buffer([1, 1024, 13, 13], dtype="float32")
        T_tanh = T.alloc_buffer([1, 1024, 13, 13], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 1024, 13, 13):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[i0_1, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 1024, 13, 13, 1024, 1, 1):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 1024, 13, 13], "float32"], ["TENSOR", [1024, 1024, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 1024, 13, 13):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 1024, 13, 13):
            with T.block("T_exp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_exp[ax0, ax1, ax2, ax3])
                T_exp[ax0, ax1, ax2, ax3] = T.exp(T_add[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 1024, 13, 13):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_3[ax0, 0, 0, 0], T_exp[ax0, ax1, ax2, ax3])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = placeholder_3[ax0, 0, 0, 0] + T_exp[ax0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 1024, 13, 13):
            with T.block("T_log"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[ax0, ax1, ax2, ax3])
                T.writes(T_log[ax0, ax1, ax2, ax3])
                T_log[ax0, ax1, ax2, ax3] = T.log(T_add_1[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 1024, 13, 13):
            with T.block("T_tanh"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_log[ax0, ax1, ax2, ax3])
                T.writes(T_tanh[ax0, ax1, ax2, ax3])
                T_tanh[ax0, ax1, ax2, ax3] = T.tanh(T_log[ax0, ax1, ax2, ax3], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 1024, 13, 13):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3], T_tanh[ax0, ax1, ax2, ax3])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = T_add[ax0, ax1, ax2, ax3] * T_tanh[ax0, ax1, ax2, ax3]
    

[13:33:09] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:09] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1024, 13, 13), "float32"], placeholder_1: T.Buffer[(1024, 1024, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 1024, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 1024, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":1024})
            conv2d_nchw = T.alloc_buffer([1, 1024, 13, 13], dtype="float32")
            conv2d_nchw_local = T.alloc_buffer([1, 1024, 13, 13], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 1024, 13, 13], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([1024, 1024, 1, 1], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(16, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(169, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(2, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(4, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(43264):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(1024, i4_0 * 256 + ax0_ax1_ax2_ax3_fused // 169)
                                    v2 = T.axis.spatial(13, ax0_ax1_ax2_ax3_fused % 169 // 13)
                                    v3 = T.axis.spatial(13, ax0_ax1_ax2_ax3_fused % 13)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":2})
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in T.serial(16384):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused * 64 + ax0_ax1_ax2_ax3_fused // 256)
                                    v1 = T.axis.spatial(1024, i4_0 * 256 + ax0_ax1_ax2_ax3_fused % 256)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":2})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(4, 1, 1, 1, 2, 1, 1, 64, 1, 1, 1, 16, 1, 1):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused * 32 + i1_3 * 16 + i1_4)
                                    yy = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused // 13)
                                    xx = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 13)
                                    rc = T.axis.reduce(1024, i4_0 * 256 + i4_1 * 64 + i4_2)
                                    ry = T.axis.reduce(1, 0)
                                    rx = T.axis.reduce(1, 0)
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 1024, 13, 13], "float32"], ["TENSOR", [1024, 1024, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 32, 1, 1):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused * 32 + ax1)
                                v2 = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused // 13 + ax2)
                                v3 = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 13 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                                T.writes(conv2d_nchw[v0, v1, v2, v3])
                                conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
            for i0, i1, i2, i3 in T.grid(1, 1024, 13, 13):
                with T.block("T_multiply"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_multiply[ax0, ax1, ax2, ax3])
                    T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[16, 1, 2, 2, 16])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 13, 1, 1, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 13, 1, 1, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[4, 4, 64])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
[13:33:09] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #40: "fused_nn_max_pool2d_2"
[13:33:09] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 13, 13), "float32"], tensor: T.Buffer[(1, 512, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 512, 25, 25], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 25, 25):
            with T.block("pad_temp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[ax0, ax1, ax2 - 6, ax3 - 6])
                T.writes(pad_temp[ax0, ax1, ax2, ax3])
                pad_temp[ax0, ax1, ax2, ax3] = T.if_then_else(6 <= ax2 and ax2 < 19 and 6 <= ax3 and ax3 < 19, placeholder[ax0, ax1, ax2 - 6, ax3 - 6], T.float32(-3.4028234663852886e+38), dtype="float32")
        for i0, i1, i2, i3, i4, i5 in T.grid(1, 512, 13, 13, 13, 13):
            with T.block("tensor"):
                ax0, ax1, ax2, ax3, rv0, rv1 = T.axis.remap("SSSSRR", [i0, i1, i2, i3, i4, i5])
                T.reads(pad_temp[ax0, ax1, ax2 + rv0, ax3 + rv1])
                T.writes(tensor[ax0, ax1, ax2, ax3])
                with T.init():
                    tensor[ax0, ax1, ax2, ax3] = T.float32(-3.4028234663852886e+38)
                tensor[ax0, ax1, ax2, ax3] = T.max(tensor[ax0, ax1, ax2, ax3], pad_temp[ax0, ax1, ax2 + rv0, ax3 + rv1])
    

[13:33:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 2 design space(s) generated
[13:33:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 13, 13), "float32"], tensor: T.Buffer[(1, 512, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":0})
            for i0, i1, i2, i3, i4_i5_fused_0 in T.grid(1, 512, 13, 13, 11):
                for i4_i5_fused_1 in T.thread_binding(16, thread="threadIdx.x"):
                    with T.block("tensor"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1, ax2, ax3 = T.axis.remap("SSS", [i1, i2, i3])
                        rv0 = T.axis.reduce(13, (i4_i5_fused_0 * 16 + i4_i5_fused_1) // 13)
                        rv1 = T.axis.reduce(13, (i4_i5_fused_0 * 16 + i4_i5_fused_1) % 13)
                        T.where(i4_i5_fused_0 * 16 + i4_i5_fused_1 < 169)
                        T.reads(placeholder[ax0, ax1, ax2 + rv0 - 6, ax3 + rv1 - 6])
                        T.writes(tensor[ax0, ax1, ax2, ax3])
                        with T.init():
                            tensor[ax0, ax1, ax2, ax3] = T.float32(-3.4028234663852886e+38)
                        tensor[ax0, ax1, ax2, ax3] = T.max(tensor[ax0, ax1, ax2, ax3], T.if_then_else(6 <= ax2 + rv0 and ax2 + rv0 < 19 and 6 <= ax3 + rv1 and ax3 + rv1 < 19, placeholder[ax0, ax1, ax2 + rv0 - 6, ax3 + rv1 - 6], T.float32(-3.4028234663852886e+38), dtype="float32"))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="tensor", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b0)
v3 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=2)
l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b1)
l10 = sch.fuse(l8, l9)
l11, l12 = sch.split(loop=l10, factors=[None, v3])
sch.bind(loop=l12, thread_axis="threadIdx.x")
v13 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v13)
[13:33:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #1:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 13, 13), "float32"], tensor: T.Buffer[(1, 512, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":16})
            for i0, i1, i2, i3, i4, i5 in T.grid(1, 512, 13, 13, 13, 13):
                with T.block("tensor"):
                    ax0, ax1, ax2, ax3, rv0, rv1 = T.axis.remap("SSSSRR", [i0, i1, i2, i3, i4, i5])
                    T.reads(placeholder[ax0, ax1, ax2 + rv0 - 6, ax3 + rv1 - 6])
                    T.writes(tensor[ax0, ax1, ax2, ax3])
                    with T.init():
                        tensor[ax0, ax1, ax2, ax3] = T.float32(-3.4028234663852886e+38)
                    tensor[ax0, ax1, ax2, ax3] = T.max(tensor[ax0, ax1, ax2, ax3], T.if_then_else(6 <= ax2 + rv0 and ax2 + rv0 < 19 and 6 <= ax3 + rv1 and ax3 + rv1 < 19, placeholder[ax0, ax1, ax2 + rv0 - 6, ax3 + rv1 - 6], T.float32(-3.4028234663852886e+38), dtype="float32"))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b0)
v2 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v2)
[13:33:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #41: "fused_concatenate_5"
[13:33:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 13, 13), "float32"], placeholder_1: T.Buffer[(1, 512, 13, 13), "float32"], placeholder_2: T.Buffer[(1, 512, 13, 13), "float32"], placeholder_3: T.Buffer[(1, 512, 13, 13), "float32"], T_concat: T.Buffer[(1, 2048, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3 in T.grid(1, 2048, 13, 13):
            with T.block("T_concat"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder_3[ax0, ax1 - 1536, ax2, ax3], placeholder_2[ax0, ax1 - 1024, ax2, ax3], placeholder_1[ax0, ax1 - 512, ax2, ax3], placeholder[ax0, ax1, ax2, ax3])
                T.writes(T_concat[ax0, ax1, ax2, ax3])
                T_concat[ax0, ax1, ax2, ax3] = T.if_then_else(1536 <= ax1, placeholder_3[ax0, ax1 - 1536, ax2, ax3], T.if_then_else(1024 <= ax1, placeholder_2[ax0, ax1 - 1024, ax2, ax3], T.if_then_else(512 <= ax1, placeholder_1[ax0, ax1 - 512, ax2, ax3], placeholder[ax0, ax1, ax2, ax3], dtype="float32"), dtype="float32"), dtype="float32")
    

[13:33:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 13, 13), "float32"], placeholder_1: T.Buffer[(1, 512, 13, 13), "float32"], placeholder_2: T.Buffer[(1, 512, 13, 13), "float32"], placeholder_3: T.Buffer[(1, 512, 13, 13), "float32"], T_concat: T.Buffer[(1, 2048, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":64})
            for i0, i1, i2, i3 in T.grid(1, 2048, 13, 13):
                with T.block("T_concat"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(placeholder_3[ax0, ax1 - 1536, ax2, ax3], placeholder_2[ax0, ax1 - 1024, ax2, ax3], placeholder_1[ax0, ax1 - 512, ax2, ax3], placeholder[ax0, ax1, ax2, ax3])
                    T.writes(T_concat[ax0, ax1, ax2, ax3])
                    T_concat[ax0, ax1, ax2, ax3] = T.if_then_else(1536 <= ax1, placeholder_3[ax0, ax1 - 1536, ax2, ax3], T.if_then_else(1024 <= ax1, placeholder_2[ax0, ax1 - 1024, ax2, ax3], T.if_then_else(512 <= ax1, placeholder_1[ax0, ax1 - 512, ax2, ax3], placeholder[ax0, ax1, ax2, ax3], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="root", func_name="main")
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
[13:33:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"
[13:33:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 2048, 13, 13), "float32"], placeholder_1: T.Buffer[(512, 2048, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 512, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 2048, 13, 13], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        T_add = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 2048, 13, 13):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[i0_1, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 512, 13, 13, 2048, 1, 1):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 2048, 13, 13], "float32"], ["TENSOR", [512, 2048, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
            with T.block("T_leaky_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_leaky_relu[ax0, ax1, ax2, ax3])
                T_leaky_relu[ax0, ax1, ax2, ax3] = T.Select(T.float32(0) < T_add[ax0, ax1, ax2, ax3], T_add[ax0, ax1, ax2, ax3], T_add[ax0, ax1, ax2, ax3] * T.float32(0.10000000149011612))
    

[13:33:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 2048, 13, 13), "float32"], placeholder_1: T.Buffer[(512, 2048, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 512, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":512})
            conv2d_nchw_local = T.alloc_buffer([1, 512, 13, 13], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 2048, 13, 13], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([512, 2048, 1, 1], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(8, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(26, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(1, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(8, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(43264):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(2048, i4_0 * 256 + ax0_ax1_ax2_ax3_fused // 169)
                                    v2 = T.axis.spatial(13, ax0_ax1_ax2_ax3_fused % 169 // 13)
                                    v3 = T.axis.spatial(13, ax0_ax1_ax2_ax3_fused % 13)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":4})
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in T.serial(16384):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused * 64 + ax0_ax1_ax2_ax3_fused // 256)
                                    v1 = T.axis.spatial(2048, i4_0 * 256 + ax0_ax1_ax2_ax3_fused % 256)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":2})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(16, 1, 1, 1, 4, 1, 1, 16, 1, 1, 1, 8, 1, 13):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused * 64 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 32 + i1_3 * 8 + i1_4)
                                    yy = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 13)
                                    xx = T.axis.spatial(13, i3_4)
                                    rc = T.axis.reduce(2048, i4_0 * 256 + i4_1 * 16 + i4_2)
                                    ry = T.axis.reduce(1, 0)
                                    rx = T.axis.reduce(1, 0)
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 2048, 13, 13], "float32"], ["TENSOR", [512, 2048, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 32, 1, 13):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused * 64 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 32 + ax1)
                                v2 = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 13 + ax2)
                                v3 = T.axis.spatial(13, ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                                T.writes(T_leaky_relu[v0, v1, v2, v3])
                                T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[8, 2, 1, 4, 8])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 13, 1, 1, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 13])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[8, 16, 16])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
[13:33:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"
[13:33:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 13, 13), "float32"], placeholder_1: T.Buffer[(1024, 512, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 1024, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 1024, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 512, 15, 15], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 1024, 13, 13], dtype="float32")
        T_add = T.alloc_buffer([1, 1024, 13, 13], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 15, 15):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = T.if_then_else(1 <= i2_1 and i2_1 < 14 and 1 <= i3_1 and i3_1 < 14, placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 1024, 13, 13, 512, 3, 3):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 13, 13], "float32"], ["TENSOR", [1024, 512, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 1024, 13, 13):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 1024, 13, 13):
            with T.block("T_leaky_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_leaky_relu[ax0, ax1, ax2, ax3])
                T_leaky_relu[ax0, ax1, ax2, ax3] = T.Select(T.float32(0) < T_add[ax0, ax1, ax2, ax3], T_add[ax0, ax1, ax2, ax3], T_add[ax0, ax1, ax2, ax3] * T.float32(0.10000000149011612))
    

[13:33:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 13, 13), "float32"], placeholder_1: T.Buffer[(1024, 512, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 1024, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 1024, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":16})
            conv2d_nchw_local = T.alloc_buffer([1, 1024, 13, 13], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 512, 15, 15], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([1024, 512, 3, 3], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(104, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(1, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(16, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(16, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(1440):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(512, i4_0 * 32 + ax0_ax1_ax2_ax3_fused % 1440 // 45)
                                    v2 = T.axis.spatial(15, ax0_ax1_ax2_ax3_fused % 45 // 3)
                                    v3 = T.axis.spatial(15, i0_0_i1_0_i2_0_i3_0_fused % 13 + ax0_ax1_ax2_ax3_fused % 3)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":3})
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 14 and 1 <= v3 and v3 < 14, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                            for ax0_ax1_ax2_ax3_fused in T.serial(36864):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused // 13 * 128 + ax0_ax1_ax2_ax3_fused // 288)
                                    v1 = T.axis.spatial(512, i4_0 * 32 + ax0_ax1_ax2_ax3_fused % 288 // 9)
                                    v2 = T.axis.spatial(3, ax0_ax1_ax2_ax3_fused % 9 // 3)
                                    v3 = T.axis.spatial(3, ax0_ax1_ax2_ax3_fused % 3)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":1})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(16, 3, 3, 1, 2, 1, 1, 2, 1, 1, 1, 4, 13, 1):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused // 13 * 128 + i0_2_i1_2_i2_2_i3_2_fused * 8 + i1_3 * 4 + i1_4)
                                    yy = T.axis.spatial(13, i2_4)
                                    xx = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_fused % 13)
                                    rc = T.axis.reduce(512, i4_0 * 32 + i4_1 * 2 + i4_2)
                                    ry, rx = T.axis.remap("RR", [i5_1, i6_1])
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 13, 13], "float32"], ["TENSOR", [1024, 512, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 8, 13, 1):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused // 13 * 128 + i0_2_i1_2_i2_2_i3_2_fused * 8 + ax1)
                                v2 = T.axis.spatial(13, ax2)
                                v3 = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_fused % 13 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                                T.writes(T_leaky_relu[v0, v1, v2, v3])
                                T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[8, 1, 16, 2, 4])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 13])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[13, 1, 1, 1, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[16, 16, 2])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
[13:33:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"
[13:33:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1024, 13, 13), "float32"], placeholder_1: T.Buffer[(512, 1024, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 512, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 1024, 13, 13], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        T_add = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 1024, 13, 13):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[i0_1, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 512, 13, 13, 1024, 1, 1):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 1024, 13, 13], "float32"], ["TENSOR", [512, 1024, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
            with T.block("T_leaky_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_leaky_relu[ax0, ax1, ax2, ax3])
                T_leaky_relu[ax0, ax1, ax2, ax3] = T.Select(T.float32(0) < T_add[ax0, ax1, ax2, ax3], T_add[ax0, ax1, ax2, ax3], T_add[ax0, ax1, ax2, ax3] * T.float32(0.10000000149011612))
    

[13:33:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1024, 13, 13), "float32"], placeholder_1: T.Buffer[(512, 1024, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 512, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":512})
            conv2d_nchw_local = T.alloc_buffer([1, 512, 13, 13], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 1024, 13, 13], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([512, 1024, 1, 1], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(128, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(26, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(1, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(8, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(21632):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(1024, i4_0 * 128 + ax0_ax1_ax2_ax3_fused // 169)
                                    v2 = T.axis.spatial(13, ax0_ax1_ax2_ax3_fused % 169 // 13)
                                    v3 = T.axis.spatial(13, ax0_ax1_ax2_ax3_fused % 13)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":4})
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in T.serial(512):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused * 4 + ax0_ax1_ax2_ax3_fused // 128)
                                    v1 = T.axis.spatial(1024, i4_0 * 128 + ax0_ax1_ax2_ax3_fused % 128)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":3})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(64, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 13):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused * 4 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 2 + i1_3)
                                    yy = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 13)
                                    xx = T.axis.spatial(13, i3_4)
                                    rc = T.axis.reduce(1024, i4_0 * 128 + i4_1 * 2 + i4_2)
                                    ry = T.axis.reduce(1, 0)
                                    rx = T.axis.reduce(1, 0)
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 1024, 13, 13], "float32"], ["TENSOR", [512, 1024, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 2, 1, 13):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused * 4 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 2 + ax1)
                                v2 = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 13 + ax2)
                                v3 = T.axis.spatial(13, ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                                T.writes(T_leaky_relu[v0, v1, v2, v3])
                                T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[128, 2, 1, 2, 1])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 13, 1, 1, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 13])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[8, 64, 2])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
[13:33:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"
[13:33:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 13, 13), "float32"], placeholder_1: T.Buffer[(256, 512, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 256, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 256, 13, 13], dtype="float32")
        T_add = T.alloc_buffer([1, 256, 13, 13], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 13, 13):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[i0_1, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 256, 13, 13, 512, 1, 1):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 13, 13], "float32"], ["TENSOR", [256, 512, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 256, 13, 13):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 256, 13, 13):
            with T.block("T_leaky_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_leaky_relu[ax0, ax1, ax2, ax3])
                T_leaky_relu[ax0, ax1, ax2, ax3] = T.Select(T.float32(0) < T_add[ax0, ax1, ax2, ax3], T_add[ax0, ax1, ax2, ax3], T_add[ax0, ax1, ax2, ax3] * T.float32(0.10000000149011612))
    

[13:33:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 13, 13), "float32"], placeholder_1: T.Buffer[(256, 512, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 256, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":64})
            conv2d_nchw_local = T.alloc_buffer([1, 256, 13, 13], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 512, 13, 13], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([256, 512, 1, 1], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(26, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(52, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(1, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(128, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(52):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(512, i4_0 * 4 + ax0_ax1_ax2_ax3_fused // 13)
                                    v2 = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_fused % 13)
                                    v3 = T.axis.spatial(13, ax0_ax1_ax2_ax3_fused % 13)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":3})
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in T.serial(512):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 13 * 128 + ax0_ax1_ax2_ax3_fused // 4)
                                    v1 = T.axis.spatial(512, i4_0 * 4 + ax0_ax1_ax2_ax3_fused % 4)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":3})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(4, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 8, 1, 1):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 13 * 128 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 32 + i1_3 * 8 + i1_4)
                                    yy = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_fused % 13)
                                    xx = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 13)
                                    rc = T.axis.reduce(512, i4_0 * 4 + i4_1)
                                    ry = T.axis.reduce(1, 0)
                                    rx = T.axis.reduce(1, 0)
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 13, 13], "float32"], ["TENSOR", [256, 512, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 32, 1, 1):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 13 * 128 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 32 + ax1)
                                v2 = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_fused % 13 + ax2)
                                v3 = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 13 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                                T.writes(T_leaky_relu[v0, v1, v2, v3])
                                T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[2, 4, 1, 4, 8])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[13, 1, 1, 1, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 13, 1, 1, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[128, 4, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
[13:33:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #46: "fused_image_resize2d_concatenate"
[13:33:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 13, 13), "float32"], placeholder_1: T.Buffer[(1, 256, 26, 26), "float32"], T_concat: T.Buffer[(1, 512, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        resize = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
            with T.block("resize"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, 0 : 13, 0 : 13])
                T.writes(resize[i0_1, i1_1, i2_1, i3_1])
                resize[i0_1, i1_1, i2_1, i3_1] = placeholder[i0_1, i1_1, T.max(T.min(T.cast(T.floor((T.cast(i2_1, "float32") + T.float32(0.5)) * T.float32(0.5) - T.float32(0.5) + T.float32(9.9999997473787516e-06), dtype="float32"), "int32"), 12), 0), T.max(T.min(T.cast(T.floor((T.cast(i3_1, "float32") + T.float32(0.5)) * T.float32(0.5) - T.float32(0.5) + T.float32(9.9999997473787516e-06), dtype="float32"), "int32"), 12), 0)]
        for i0, i1, i2, i3 in T.grid(1, 512, 26, 26):
            with T.block("T_concat"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(resize[ax0, ax1 - 256, ax2, ax3], placeholder_1[ax0, ax1, ax2, ax3])
                T.writes(T_concat[ax0, ax1, ax2, ax3])
                T_concat[ax0, ax1, ax2, ax3] = T.if_then_else(256 <= ax1, resize[ax0, ax1 - 256, ax2, ax3], placeholder_1[ax0, ax1, ax2, ax3], dtype="float32")
    

[13:33:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 13, 13), "float32"], placeholder_1: T.Buffer[(1, 256, 26, 26), "float32"], T_concat: T.Buffer[(1, 512, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":512})
            for i0, i1, i2, i3 in T.grid(1, 512, 26, 26):
                with T.block("T_concat"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(placeholder[ax0, ax1 - 256, 0 : 13, 0 : 13], placeholder_1[ax0, ax1, ax2, ax3])
                    T.writes(T_concat[ax0, ax1, ax2, ax3])
                    T_concat[ax0, ax1, ax2, ax3] = T.if_then_else(256 <= ax1, placeholder[ax0, ax1 - 256, T.max(T.min(T.cast(T.floor((T.cast(ax2, "float32") + T.float32(0.5)) * T.float32(0.5) - T.float32(0.5) + T.float32(9.9999997473787516e-06), dtype="float32"), "int32"), 12), 0), T.max(T.min(T.cast(T.floor((T.cast(ax3, "float32") + T.float32(0.5)) * T.float32(0.5) - T.float32(0.5) + T.float32(9.9999997473787516e-06), dtype="float32"), "int32"), 12), 0)], placeholder_1[ax0, ax1, ax2, ax3], dtype="float32")
    

b0 = sch.get_block(name="resize", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b0)
v2 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v2)
[13:33:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"
[13:33:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 26, 26), "float32"], placeholder_1: T.Buffer[(512, 256, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 512, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 256, 28, 28], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 512, 26, 26], dtype="float32")
        T_add = T.alloc_buffer([1, 512, 26, 26], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 28, 28):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = T.if_then_else(1 <= i2_1 and i2_1 < 27 and 1 <= i3_1 and i3_1 < 27, placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 512, 26, 26, 256, 3, 3):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 26, 26], "float32"], ["TENSOR", [512, 256, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 512, 26, 26):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 512, 26, 26):
            with T.block("T_leaky_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_leaky_relu[ax0, ax1, ax2, ax3])
                T_leaky_relu[ax0, ax1, ax2, ax3] = T.Select(T.float32(0) < T_add[ax0, ax1, ax2, ax3], T_add[ax0, ax1, ax2, ax3], T_add[ax0, ax1, ax2, ax3] * T.float32(0.10000000149011612))
    

[13:33:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 26, 26), "float32"], placeholder_1: T.Buffer[(512, 256, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 512, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":0})
            conv2d_nchw_local = T.alloc_buffer([1, 512, 26, 26], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 256, 28, 28], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([512, 256, 3, 3], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(4, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(8, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(26, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(4, 3, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(46592):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(256, i4_0 * 64 + ax0_ax1_ax2_ax3_fused % 46592 // 728)
                                    v2 = T.axis.spatial(28, i5_0 + ax0_ax1_ax2_ax3_fused % 728 // 28)
                                    v3 = T.axis.spatial(28, ax0_ax1_ax2_ax3_fused % 28)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":4})
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 27 and 1 <= v3 and v3 < 27, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                            for ax0_ax1_ax2_ax3_fused in T.serial(24576):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused * 128 + ax0_ax1_ax2_ax3_fused // 192)
                                    v1 = T.axis.spatial(256, i4_0 * 64 + ax0_ax1_ax2_ax3_fused % 192 // 3)
                                    v2 = T.axis.spatial(3, i5_0)
                                    v3 = T.axis.spatial(3, ax0_ax1_ax2_ax3_fused % 3)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":2})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(16, 1, 1, 1, 2, 1, 13, 4, 1, 3, 1, 8, 1, 2):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused * 128 + i0_1_i1_1_i2_1_i3_1_fused * 16 + i1_3 * 8 + i1_4)
                                    yy = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused)
                                    xx = T.axis.spatial(26, i3_3 * 2 + i3_4)
                                    rc = T.axis.reduce(256, i4_0 * 64 + i4_1 * 4 + i4_2)
                                    ry, rx = T.axis.remap("RR", [i5_0, i6_2])
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 26, 26], "float32"], ["TENSOR", [512, 256, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 16, 1, 26):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused * 128 + i0_1_i1_1_i2_1_i3_1_fused * 16 + ax1)
                                v2 = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused + ax2)
                                v3 = T.axis.spatial(26, ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                                T.writes(T_leaky_relu[v0, v1, v2, v3])
                                T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[4, 8, 1, 2, 8])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 1, 26, 1, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 13, 2])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[4, 16, 4])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
[13:33:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"
[13:33:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 26, 26), "float32"], placeholder_1: T.Buffer[(256, 512, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 256, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 512, 26, 26], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
        T_add = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 26, 26):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[i0_1, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 256, 26, 26, 512, 1, 1):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 26, 26], "float32"], ["TENSOR", [256, 512, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
            with T.block("T_leaky_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_leaky_relu[ax0, ax1, ax2, ax3])
                T_leaky_relu[ax0, ax1, ax2, ax3] = T.Select(T.float32(0) < T_add[ax0, ax1, ax2, ax3], T_add[ax0, ax1, ax2, ax3], T_add[ax0, ax1, ax2, ax3] * T.float32(0.10000000149011612))
    

[13:33:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 26, 26), "float32"], placeholder_1: T.Buffer[(256, 512, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 256, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":1024})
            conv2d_nchw_local = T.alloc_buffer([1, 256, 26, 26], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 512, 26, 26], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([256, 512, 1, 1], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(416, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(16, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(1, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(4, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(6656):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(512, i4_0 * 128 + ax0_ax1_ax2_ax3_fused // 52)
                                    v2 = T.axis.spatial(26, ax0_ax1_ax2_ax3_fused % 52 // 2)
                                    v3 = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused % 13 * 2 + ax0_ax1_ax2_ax3_fused % 2)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":4})
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in T.serial(1024):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 13 * 8 + ax0_ax1_ax2_ax3_fused // 128)
                                    v1 = T.axis.spatial(512, i4_0 * 128 + ax0_ax1_ax2_ax3_fused % 128)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":4})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(32, 1, 1, 1, 1, 13, 1, 4, 1, 1, 1, 1, 1, 2):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 13 * 8 + i0_1_i1_1_i2_1_i3_1_fused // 2)
                                    yy = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused % 2 * 13 + i2_3)
                                    xx = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused % 13 * 2 + i3_4)
                                    rc = T.axis.reduce(512, i4_0 * 128 + i4_1 * 4 + i4_2)
                                    ry = T.axis.reduce(1, 0)
                                    rx = T.axis.reduce(1, 0)
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 26, 26], "float32"], ["TENSOR", [256, 512, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 1, 13, 2):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 13 * 8 + i0_1_i1_1_i2_1_i3_1_fused // 2 + ax1)
                                v2 = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused % 2 * 13 + ax2)
                                v3 = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused % 13 * 2 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                                T.writes(T_leaky_relu[v0, v1, v2, v3])
                                T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[32, 8, 1, 1, 1])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 2, 1, 13, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[13, 1, 1, 1, 2])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[4, 32, 4])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
[13:33:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"
[13:33:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 26, 26), "float32"], placeholder_1: T.Buffer[(128, 256, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 128, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 256, 26, 26], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 128, 26, 26], dtype="float32")
        T_add = T.alloc_buffer([1, 128, 26, 26], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 26, 26):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[i0_1, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 128, 26, 26, 256, 1, 1):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 26, 26], "float32"], ["TENSOR", [128, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 128, 26, 26):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 128, 26, 26):
            with T.block("T_leaky_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_leaky_relu[ax0, ax1, ax2, ax3])
                T_leaky_relu[ax0, ax1, ax2, ax3] = T.Select(T.float32(0) < T_add[ax0, ax1, ax2, ax3], T_add[ax0, ax1, ax2, ax3], T_add[ax0, ax1, ax2, ax3] * T.float32(0.10000000149011612))
    

[13:33:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 26, 26), "float32"], placeholder_1: T.Buffer[(128, 256, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 128, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":64})
            conv2d_nchw_local = T.alloc_buffer([1, 128, 26, 26], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 256, 26, 26], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([128, 256, 1, 1], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(52, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(2, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(26, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(16, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(208):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(256, i4_0 * 16 + ax0_ax1_ax2_ax3_fused // 13)
                                    v2 = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused // 26 * 13 + ax0_ax1_ax2_ax3_fused % 13)
                                    v3 = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused % 26)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":1})
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in T.serial(2048):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(128, ax0_ax1_ax2_ax3_fused // 16)
                                    v1 = T.axis.spatial(256, i4_0 * 16 + ax0_ax1_ax2_ax3_fused % 16)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":1})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(8, 1, 1, 1, 8, 1, 1, 2, 1, 1, 1, 4, 1, 1):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 32 + i1_3 * 4 + i1_4)
                                    yy = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused // 26 * 13 + i0_2_i1_2_i2_2_i3_2_fused % 13)
                                    xx = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused % 26)
                                    rc = T.axis.reduce(256, i4_0 * 16 + i4_1 * 2 + i4_2)
                                    ry = T.axis.reduce(1, 0)
                                    rx = T.axis.reduce(1, 0)
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 26, 26], "float32"], ["TENSOR", [128, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 32, 1, 1):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 32 + ax1)
                                v2 = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused // 26 * 13 + i0_2_i1_2_i2_2_i3_2_fused % 13 + ax2)
                                v3 = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused % 26 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                                T.writes(T_leaky_relu[v0, v1, v2, v3])
                                T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 2, 2, 8, 4])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[2, 1, 13, 1, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[26, 1, 1, 1, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[16, 8, 2])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
[13:33:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #50: "fused_image_resize2d_concatenate_1"
[13:33:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 26, 26), "float32"], placeholder_1: T.Buffer[(1, 128, 52, 52), "float32"], T_concat: T.Buffer[(1, 256, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        resize = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 128, 52, 52):
            with T.block("resize"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, 0 : 26, 0 : 26])
                T.writes(resize[i0_1, i1_1, i2_1, i3_1])
                resize[i0_1, i1_1, i2_1, i3_1] = placeholder[i0_1, i1_1, T.max(T.min(T.cast(T.floor((T.cast(i2_1, "float32") + T.float32(0.5)) * T.float32(0.5) - T.float32(0.5) + T.float32(9.9999997473787516e-06), dtype="float32"), "int32"), 25), 0), T.max(T.min(T.cast(T.floor((T.cast(i3_1, "float32") + T.float32(0.5)) * T.float32(0.5) - T.float32(0.5) + T.float32(9.9999997473787516e-06), dtype="float32"), "int32"), 25), 0)]
        for i0, i1, i2, i3 in T.grid(1, 256, 52, 52):
            with T.block("T_concat"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(resize[ax0, ax1 - 128, ax2, ax3], placeholder_1[ax0, ax1, ax2, ax3])
                T.writes(T_concat[ax0, ax1, ax2, ax3])
                T_concat[ax0, ax1, ax2, ax3] = T.if_then_else(128 <= ax1, resize[ax0, ax1 - 128, ax2, ax3], placeholder_1[ax0, ax1, ax2, ax3], dtype="float32")
    

[13:33:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 26, 26), "float32"], placeholder_1: T.Buffer[(1, 128, 52, 52), "float32"], T_concat: T.Buffer[(1, 256, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":64})
            for i0, i1, i2, i3 in T.grid(1, 256, 52, 52):
                with T.block("T_concat"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(placeholder[ax0, ax1 - 128, 0 : 26, 0 : 26], placeholder_1[ax0, ax1, ax2, ax3])
                    T.writes(T_concat[ax0, ax1, ax2, ax3])
                    T_concat[ax0, ax1, ax2, ax3] = T.if_then_else(128 <= ax1, placeholder[ax0, ax1 - 128, T.max(T.min(T.cast(T.floor((T.cast(ax2, "float32") + T.float32(0.5)) * T.float32(0.5) - T.float32(0.5) + T.float32(9.9999997473787516e-06), dtype="float32"), "int32"), 25), 0), T.max(T.min(T.cast(T.floor((T.cast(ax3, "float32") + T.float32(0.5)) * T.float32(0.5) - T.float32(0.5) + T.float32(9.9999997473787516e-06), dtype="float32"), "int32"), 25), 0)], placeholder_1[ax0, ax1, ax2, ax3], dtype="float32")
    

b0 = sch.get_block(name="resize", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b0)
v2 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v2)
[13:33:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"
[13:33:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 52, 52), "float32"], placeholder_1: T.Buffer[(128, 256, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 128, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 256, 52, 52], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        T_add = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 52, 52):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[i0_1, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 128, 52, 52, 256, 1, 1):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [128, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 128, 52, 52):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 128, 52, 52):
            with T.block("T_leaky_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_leaky_relu[ax0, ax1, ax2, ax3])
                T_leaky_relu[ax0, ax1, ax2, ax3] = T.Select(T.float32(0) < T_add[ax0, ax1, ax2, ax3], T_add[ax0, ax1, ax2, ax3], T_add[ax0, ax1, ax2, ax3] * T.float32(0.10000000149011612))
    

[13:33:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 52, 52), "float32"], placeholder_1: T.Buffer[(128, 256, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 128, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":1024})
            conv2d_nchw_local = T.alloc_buffer([1, 128, 52, 52], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 256, 52, 52], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([128, 256, 1, 1], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(1, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(104, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(104, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(4, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(173056):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(256, i4_0 * 64 + ax0_ax1_ax2_ax3_fused // 2704)
                                    v2 = T.axis.spatial(52, ax0_ax1_ax2_ax3_fused % 2704 // 52)
                                    v3 = T.axis.spatial(52, ax0_ax1_ax2_ax3_fused % 52)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":3})
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in T.serial(8192):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(128, ax0_ax1_ax2_ax3_fused // 64)
                                    v1 = T.axis.spatial(256, i4_0 * 64 + ax0_ax1_ax2_ax3_fused % 64)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":4})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 2, 2, 2, 64, 1, 1, 1, 4, 1, 1):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 26 * 32 + i0_2_i1_2_i2_2_i3_2_fused // 26 * 8 + i1_3 * 4 + i1_4)
                                    yy = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 26 // 2 * 4 + i0_2_i1_2_i2_2_i3_2_fused % 26 // 13 * 2 + i2_3)
                                    xx = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 2 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 13 * 2 + i3_3)
                                    rc = T.axis.reduce(256, i4_0 * 64 + i4_2)
                                    ry = T.axis.reduce(1, 0)
                                    rx = T.axis.reduce(1, 0)
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [128, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 8, 2, 2):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 26 * 32 + i0_2_i1_2_i2_2_i3_2_fused // 26 * 8 + ax1)
                                v2 = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 26 // 2 * 4 + i0_2_i1_2_i2_2_i3_2_fused % 26 // 13 * 2 + ax2)
                                v3 = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 2 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 13 * 2 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                                T.writes(T_leaky_relu[v0, v1, v2, v3])
                                T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 4, 4, 2, 4])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 13, 2, 2, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 2, 13, 2, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[4, 1, 64])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
[13:33:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"
[13:33:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 52, 52), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 256, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 128, 54, 54], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 256, 52, 52], dtype="float32")
        T_add = T.alloc_buffer([1, 256, 52, 52], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 128, 54, 54):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = T.if_then_else(1 <= i2_1 and i2_1 < 53 and 1 <= i3_1 and i3_1 < 53, placeholder[i0_1, i1_1, i2_1 - 1, i3_1 - 1], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 256, 52, 52, 128, 3, 3):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 256, 52, 52):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 256, 52, 52):
            with T.block("T_leaky_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[ax0, ax1, ax2, ax3])
                T.writes(T_leaky_relu[ax0, ax1, ax2, ax3])
                T_leaky_relu[ax0, ax1, ax2, ax3] = T.Select(T.float32(0) < T_add[ax0, ax1, ax2, ax3], T_add[ax0, ax1, ax2, ax3], T_add[ax0, ax1, ax2, ax3] * T.float32(0.10000000149011612))
    

[13:33:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 52, 52), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 256, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":0})
            conv2d_nchw_local = T.alloc_buffer([1, 256, 52, 52], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 128, 54, 54], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([256, 128, 3, 3], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(4, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(8, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(8, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(32, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(3136):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(128, i4_0 * 4 + ax0_ax1_ax2_ax3_fused % 3136 // 784)
                                    v2 = T.axis.spatial(54, i0_0_i1_0_i2_0_i3_0_fused // 2 * 26 + ax0_ax1_ax2_ax3_fused % 784 // 28)
                                    v3 = T.axis.spatial(54, i0_0_i1_0_i2_0_i3_0_fused % 2 * 26 + ax0_ax1_ax2_ax3_fused % 28)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":1})
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 53 and 1 <= v3 and v3 < 53, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                            for ax0_ax1_ax2_ax3_fused in T.serial(9216):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(256, ax0_ax1_ax2_ax3_fused // 36)
                                    v1 = T.axis.spatial(128, i4_0 * 4 + ax0_ax1_ax2_ax3_fused % 36 // 9)
                                    v2 = T.axis.spatial(3, ax0_ax1_ax2_ax3_fused % 9 // 3)
                                    v3 = T.axis.spatial(3, ax0_ax1_ax2_ax3_fused % 3)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":1})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(2, 1, 1, 1, 2, 26, 13, 2, 3, 3, 1, 4, 1, 1):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(256, i0_1_i1_1_i2_1_i3_1_fused // 2 * 64 + i0_2_i1_2_i2_2_i3_2_fused * 8 + i1_3 * 4 + i1_4)
                                    yy = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused // 2 * 26 + i2_3)
                                    xx = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 2 * 26 + i0_1_i1_1_i2_1_i3_1_fused % 2 * 13 + i3_3)
                                    rc = T.axis.reduce(128, i4_0 * 4 + i4_1 * 2 + i4_2)
                                    ry, rx = T.axis.remap("RR", [i5_2, i6_2])
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 8, 26, 13):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(256, i0_1_i1_1_i2_1_i3_1_fused // 2 * 64 + i0_2_i1_2_i2_2_i3_2_fused * 8 + ax1)
                                v2 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused // 2 * 26 + ax2)
                                v3 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 2 * 26 + i0_1_i1_1_i2_1_i3_1_fused % 2 * 13 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                                T.writes(T_leaky_relu[v0, v1, v2, v3])
                                T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 4, 8, 2, 4])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[2, 1, 1, 26, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[2, 2, 1, 13, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[32, 2, 2])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
[13:33:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #53: "fused_nn_conv2d_add_2"
[13:33:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 52, 52), "float32"], placeholder_1: T.Buffer[(255, 256, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 255, 1, 1), "float32"], T_add: T.Buffer[(1, 255, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 256, 52, 52], dtype="float32")
        conv2d_nchw = T.alloc_buffer([1, 255, 52, 52], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 52, 52):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[i0_1, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 255, 52, 52, 256, 1, 1):
            with T.block("conv2d_nchw"):
                nn, ff, yy, xx, rc, ry, rx = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[nn, rc, yy + ry, xx + rx], placeholder_1[ff, rc, ry, rx])
                T.writes(conv2d_nchw[nn, ff, yy, xx])
                T.block_attr({"workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [255, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                with T.init():
                    conv2d_nchw[nn, ff, yy, xx] = T.float32(0)
                conv2d_nchw[nn, ff, yy, xx] = conv2d_nchw[nn, ff, yy, xx] + pad_temp[nn, rc, yy + ry, xx + rx] * placeholder_1[ff, rc, ry, rx]
        for i0, i1, i2, i3 in T.grid(1, 255, 52, 52):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]
    

[13:33:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 52, 52), "float32"], placeholder_1: T.Buffer[(255, 256, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 255, 1, 1), "float32"], T_add: T.Buffer[(1, 255, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":512})
            conv2d_nchw_local = T.alloc_buffer([1, 255, 52, 52], dtype="float32", scope="local")
            pad_temp_shared = T.alloc_buffer([1, 256, 52, 52], dtype="float32", scope="shared")
            placeholder_shared = T.alloc_buffer([255, 256, 1, 1], dtype="float32", scope="shared")
            for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(4, thread="blockIdx.x"):
                for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(1, thread="vthread.x"):
                    for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(260, thread="threadIdx.x"):
                        for i4_0, i5_0, i6_0 in T.grid(8, 1, 1):
                            for ax0_ax1_ax2_ax3_fused in T.serial(21632):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(256, i4_0 * 32 + ax0_ax1_ax2_ax3_fused // 676)
                                    v2 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 13 + ax0_ax1_ax2_ax3_fused % 676 // 52)
                                    v3 = T.axis.spatial(52, ax0_ax1_ax2_ax3_fused % 52)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":1})
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in T.serial(8160):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(255, ax0_ax1_ax2_ax3_fused // 32)
                                    v1 = T.axis.spatial(256, i4_0 * 32 + ax0_ax1_ax2_ax3_fused % 32)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch":3})
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                            for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(16, 1, 1, 1, 1, 1, 13, 2, 1, 1, 1, 51, 1, 1):
                                with T.block("conv2d_nchw"):
                                    nn = T.axis.spatial(1, 0)
                                    ff = T.axis.spatial(255, i0_2_i1_2_i2_2_i3_2_fused // 52 * 51 + i1_4)
                                    yy = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 13 + i0_2_i1_2_i2_2_i3_2_fused % 52 // 4)
                                    xx = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 4 * 13 + i3_3)
                                    rc = T.axis.reduce(256, i4_0 * 32 + i4_1 * 2 + i4_2)
                                    ry = T.axis.reduce(1, 0)
                                    rx = T.axis.reduce(1, 0)
                                    T.reads(pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                    T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [255, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                    with T.init():
                                        conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                                    conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                        for ax0, ax1, ax2, ax3 in T.grid(1, 51, 1, 13):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(1, ax0)
                                v1 = T.axis.spatial(255, i0_2_i1_2_i2_2_i3_2_fused // 52 * 51 + ax1)
                                v2 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 13 + i0_2_i1_2_i2_2_i3_2_fused % 52 // 4 + ax2)
                                v3 = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 4 * 13 + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                                T.writes(T_add[v0, v1, v2, v3])
                                T_add[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b1)
v11, v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l16, l17, l18, l19, l20 = sch.split(loop=l4, factors=[v11, v12, v13, v14, v15])
v21, v22, v23, v24, v25 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 5, 1, 51])
l26, l27, l28, l29, l30 = sch.split(loop=l5, factors=[v21, v22, v23, v24, v25])
v31, v32, v33, v34, v35 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[4, 1, 13, 1, 1])
l36, l37, l38, l39, l40 = sch.split(loop=l6, factors=[v31, v32, v33, v34, v35])
v41, v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 1, 4, 13, 1])
l46, l47, l48, l49, l50 = sch.split(loop=l7, factors=[v41, v42, v43, v44, v45])
v51, v52, v53 = sch.sample_perfect_tile(loop=l8, n=3, max_innermost_factor=64, decision=[8, 16, 2])
l54, l55, l56 = sch.split(loop=l8, factors=[v51, v52, v53])
v57, v58, v59 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l60, l61, l62 = sch.split(loop=l9, factors=[v57, v58, v59])
v63, v64, v65 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l66, l67, l68 = sch.split(loop=l10, factors=[v63, v64, v65])
sch.reorder(l16, l26, l36, l46, l17, l27, l37, l47, l18, l28, l38, l48, l54, l60, l66, l55, l61, l67, l19, l29, l39, l49, l56, l62, l68, l20, l30, l40, l50)
l69 = sch.fuse(l16, l26, l36, l46)
sch.bind(loop=l69, thread_axis="blockIdx.x")
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="vthread.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b72 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b72, loop=l71, preserve_unit_loops=True)
b73 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b73, loop=l66, preserve_unit_loops=True)
l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b73)
l84 = sch.fuse(l80, l81, l82, l83)
v85 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b73, ann_key="meta_schedule.cooperative_fetch", ann_val=v85)
b86 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b86, loop=l66, preserve_unit_loops=True)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96 = sch.get_loops(block=b86)
l97 = sch.fuse(l93, l94, l95, l96)
v98 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b86, ann_key="meta_schedule.cooperative_fetch", ann_val=v98)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v99 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v99)
[13:33:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"
[13:33:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 255, 52, 52), "float32"], T_concat: T.Buffer[(1, 52, 52, 3, 85), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        T_transpose = T.alloc_buffer([1, 52, 52, 255], dtype="float32")
        T_reshape = T.alloc_buffer([1, 52, 52, 3, 85], dtype="float32")
        T_split = T.alloc_buffer([1, 52, 52, 3, 80], dtype="float32")
        T_sigmoid = T.alloc_buffer([1, 52, 52, 3, 80], dtype="float32")
        T_split_1 = T.alloc_buffer([1, 52, 52, 3, 1], dtype="float32")
        T_sigmoid_1 = T.alloc_buffer([1, 52, 52, 3, 1], dtype="float32")
        T_split_2 = T.alloc_buffer([1, 52, 52, 3, 4], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 52, 52, 255):
            with T.block("T_transpose"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[ax0, ax3, ax1, ax2])
                T.writes(T_transpose[ax0, ax1, ax2, ax3])
                T_transpose[ax0, ax1, ax2, ax3] = placeholder[ax0, ax3, ax1, ax2]
        for i0, i1, i2, i3, i4 in T.grid(1, 52, 52, 3, 85):
            with T.block("T_reshape"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_transpose[0, ((ax2 * 255 + ax3 * 85 + ax4) // 13260 + ax1) % 52, ((ax3 * 85 + ax4) // 255 + ax2) % 52, (ax3 * 85 + ax4) % 255])
                T.writes(T_reshape[ax0, ax1, ax2, ax3, ax4])
                T_reshape[ax0, ax1, ax2, ax3, ax4] = T_transpose[0, ((ax2 * 255 + ax3 * 85 + ax4) // 13260 + ax1) % 52, ((ax3 * 85 + ax4) // 255 + ax2) % 52, (ax3 * 85 + ax4) % 255]
        for i0, i1, i2, i3, i4 in T.grid(1, 52, 52, 3, 80):
            with T.block("T_split"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_reshape[ax0, ax1, ax2, ax3, ax4 + 5])
                T.writes(T_split[ax0, ax1, ax2, ax3, ax4])
                T_split[ax0, ax1, ax2, ax3, ax4] = T_reshape[ax0, ax1, ax2, ax3, ax4 + 5]
        for i0, i1, i2, i3, i4 in T.grid(1, 52, 52, 3, 80):
            with T.block("T_sigmoid"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_split[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_sigmoid[ax0, ax1, ax2, ax3, ax4])
                T_sigmoid[ax0, ax1, ax2, ax3, ax4] = T.sigmoid(T_split[ax0, ax1, ax2, ax3, ax4], dtype="float32")
        for i0, i1, i2, i3, i4 in T.grid(1, 52, 52, 3, 1):
            with T.block("T_split_1"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_reshape[ax0, ax1, ax2, ax3, ax4 + 4])
                T.writes(T_split_1[ax0, ax1, ax2, ax3, ax4])
                T_split_1[ax0, ax1, ax2, ax3, ax4] = T_reshape[ax0, ax1, ax2, ax3, ax4 + 4]
        for i0, i1, i2, i3, i4 in T.grid(1, 52, 52, 3, 1):
            with T.block("T_sigmoid_1"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_split_1[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_sigmoid_1[ax0, ax1, ax2, ax3, ax4])
                T_sigmoid_1[ax0, ax1, ax2, ax3, ax4] = T.sigmoid(T_split_1[ax0, ax1, ax2, ax3, ax4], dtype="float32")
        for i0, i1, i2, i3, i4 in T.grid(1, 52, 52, 3, 4):
            with T.block("T_split_2"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_reshape[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_split_2[ax0, ax1, ax2, ax3, ax4])
                T_split_2[ax0, ax1, ax2, ax3, ax4] = T_reshape[ax0, ax1, ax2, ax3, ax4]
        for i0, i1, i2, i3, i4 in T.grid(1, 52, 52, 3, 85):
            with T.block("T_concat"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_sigmoid[ax0, ax1, ax2, ax3, ax4 - 5], T_sigmoid_1[ax0, ax1, ax2, ax3, ax4 - 4], T_split_2[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_concat[ax0, ax1, ax2, ax3, ax4])
                T_concat[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(5 <= ax4, T_sigmoid[ax0, ax1, ax2, ax3, ax4 - 5], T.if_then_else(4 <= ax4, T_sigmoid_1[ax0, ax1, ax2, ax3, ax4 - 4], T_split_2[ax0, ax1, ax2, ax3, ax4], dtype="float32"), dtype="float32")
    

[13:33:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[13:33:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 255, 52, 52), "float32"], T_concat: T.Buffer[(1, 52, 52, 3, 85), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":1024})
            for i0, i1, i2, i3, i4 in T.grid(1, 52, 52, 3, 85):
                with T.block("T_concat"):
                    ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(placeholder[0, (ax3 * 85 + ax4) % 255, ((ax2 * 255 + ax3 * 85 + ax4) // 13260 + ax1) % 52, ((ax3 * 85 + ax4) // 255 + ax2) % 52])
                    T.writes(T_concat[ax0, ax1, ax2, ax3, ax4])
                    T_concat[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(5 <= ax4, T.sigmoid(placeholder[0, (ax3 * 85 + (ax4 - 5 + 5)) % 255, ((ax2 * 255 + ax3 * 85 + (ax4 - 5 + 5)) // 13260 + ax1) % 52, ((ax3 * 85 + (ax4 - 5 + 5)) // 255 + ax2) % 52], dtype="float32"), T.if_then_else(4 <= ax4, T.sigmoid(placeholder[0, (ax3 * 85 + (ax4 - 4 + 4)) % 255, ((ax2 * 255 + ax3 * 85 + (ax4 - 4 + 4)) // 13260 + ax1) % 52, ((ax3 * 85 + (ax4 - 4 + 4)) // 255 + ax2) % 52], dtype="float32"), placeholder[0, (ax3 * 85 + ax4) % 255, ((ax2 * 255 + ax3 * 85 + ax4) // 13260 + ax1) % 52, ((ax3 * 85 + ax4) // 255 + ax2) % 52], dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="T_transpose", func_name="main")
b1 = sch.get_block(name="T_reshape", func_name="main")
b2 = sch.get_block(name="T_split", func_name="main")
b3 = sch.get_block(name="T_sigmoid", func_name="main")
b4 = sch.get_block(name="T_split_1", func_name="main")
b5 = sch.get_block(name="T_sigmoid_1", func_name="main")
b6 = sch.get_block(name="T_split_2", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
v8 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v8)
[13:33:14] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:111: 
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |            N/A |          N/A |                   N/A |      0 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |            N/A |          N/A |                   N/A |      0 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |            N/A |          N/A |                   N/A |      0 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                             fused_transpose |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                           fused_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |            N/A |          N/A |                   N/A |      0 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |            N/A |          N/A |                   N/A |      0 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 0
Total latency (us): 0

[13:33:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #0: "fused_nn_conv2d_add_nn_leaky_relu"
[13:33:19] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:33:42] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:33:52] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #1: "fused_nn_conv2d_add"
[13:33:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:34:04] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:34:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"
[13:34:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:34:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:34:21] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"
[13:34:29] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:35:00] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
terminate called after throwing an instance of 'tvm::runtime::InternalError'
  what():  [13:35:01] /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61: CUDAError: cuModuleUnload(module_[i]) failed with error: CUDA_ERROR_MISALIGNED_ADDRESS
Stack trace:
  0: tvm::runtime::CUDAModuleNode::~CUDAModuleNode()
        at /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61
  1: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::CUDAModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  2: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  3: tvm::runtime::ObjectPtr<tvm::runtime::Object>::reset()
        at /home/yj/tvm/include/tvm/runtime/object.h:451
  4: tvm::runtime::ObjectPtr<tvm::runtime::Object>::~ObjectPtr()
        at /home/yj/tvm/include/tvm/runtime/object.h:400
  5: tvm::runtime::ObjectRef::~ObjectRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:511
  6: tvm::runtime::Module::~Module()
        at /home/yj/tvm/include/tvm/runtime/module.h:48
  7: void std::_Destroy<tvm::runtime::Module>(tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:98
  8: void std::_Destroy_aux<false>::__destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:108
  9: void std::_Destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:137
  10: void std::_Destroy<tvm::runtime::Module*, tvm::runtime::Module>(tvm::runtime::Module*, tvm::runtime::Module*, std::allocator<tvm::runtime::Module>&)
        at /usr/include/c++/9/bits/stl_construct.h:206
  11: std::vector<tvm::runtime::Module, std::allocator<tvm::runtime::Module> >::~vector()
        at /usr/include/c++/9/bits/stl_vector.h:677
  12: tvm::runtime::ModuleNode::~ModuleNode()
        at /home/yj/tvm/include/tvm/runtime/module.h:114
  13: tvm::runtime::LibraryModuleNode::~LibraryModuleNode()
        at /home/yj/tvm/src/runtime/library_module.cc:38
  14: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::LibraryModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  15: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  16: tvm::runtime::ObjectInternal::ObjectFree(void*)
        at /home/yj/tvm/src/runtime/object_internal.h:56
  17: TVMObjectFree
        at /home/yj/tvm/src/runtime/object.cc:249
  18: TVMModFree
        at /home/yj/tvm/src/runtime/c_runtime_api.cc:422
  19: ffi_call_unix64
  20: ffi_call_int
  21: _call_function_pointer
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:920
  22: _ctypes_callproc
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:1263
  23: PyCFuncPtr_call
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/_ctypes.c:4201
  24: _PyObject_MakeTpCall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:191
  25: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:116
  26: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  27: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  28: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3487
  29: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  30: function_code_fastcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:330
  31: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:367
  32: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  33: PyObject_CallOneArg
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:188
  34: call_unbound_noarg
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1527
  35: slot_tp_finalize
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:7007
  36: PyObject_CallFinalizer
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:195
  37: PyObject_CallFinalizerFromDealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:213
  38: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1273
  39: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  40: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  41: frame_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/frameobject.c:582
  42: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  43: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  44: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  45: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:167
  46: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  47: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  48: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  49: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:166
  50: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  51: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  52: BaseException_clear
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:78
  53: BaseException_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:88
  54: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1351
  55: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  56: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  57: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  58: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:1498
  59: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  60: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  61: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  62: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  63: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  64: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  65: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  66: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  67: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  68: _PyEval_EvalCodeWithName
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4359
  69: PyEval_EvalCodeEx
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4375
  70: PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:826
  71: builtin_exec_impl.isra.17
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/bltinmodule.c:1026
  72: builtin_exec
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/clinic/bltinmodule.c.h:396
  73: cfunction_vectorcall_FASTCALL
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/methodobject.c:430
  74: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  75: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  76: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  77: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  78: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  79: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  80: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  81: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  82: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  83: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  84: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  85: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  86: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  87: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  88: PyVectorcall_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:231
  89: _PyObject_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:266
  90: pymain_run_module
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:297
  91: pymain_run_python
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:598
  92: Py_RunMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:683
  93: Py_BytesMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:1129
  94: __libc_start_main
  95: 0x00005607b84cfbc2
  96: 0xffffffffffffffff


terminate called after throwing an instance of 'tvm::runtime::InternalError'
  what():  [13:35:03] /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61: CUDAError: cuModuleUnload(module_[i]) failed with error: CUDA_ERROR_MISALIGNED_ADDRESS
Stack trace:
  0: tvm::runtime::CUDAModuleNode::~CUDAModuleNode()
        at /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61
  1: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::CUDAModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  2: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  3: tvm::runtime::ObjectPtr<tvm::runtime::Object>::reset()
        at /home/yj/tvm/include/tvm/runtime/object.h:451
  4: tvm::runtime::ObjectPtr<tvm::runtime::Object>::~ObjectPtr()
        at /home/yj/tvm/include/tvm/runtime/object.h:400
  5: tvm::runtime::ObjectRef::~ObjectRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:511
  6: tvm::runtime::Module::~Module()
        at /home/yj/tvm/include/tvm/runtime/module.h:48
  7: void std::_Destroy<tvm::runtime::Module>(tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:98
  8: void std::_Destroy_aux<false>::__destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:108
  9: void std::_Destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:137
  10: void std::_Destroy<tvm::runtime::Module*, tvm::runtime::Module>(tvm::runtime::Module*, tvm::runtime::Module*, std::allocator<tvm::runtime::Module>&)
        at /usr/include/c++/9/bits/stl_construct.h:206
  11: std::vector<tvm::runtime::Module, std::allocator<tvm::runtime::Module> >::~vector()
        at /usr/include/c++/9/bits/stl_vector.h:677
  12: tvm::runtime::ModuleNode::~ModuleNode()
        at /home/yj/tvm/include/tvm/runtime/module.h:114
  13: tvm::runtime::LibraryModuleNode::~LibraryModuleNode()
        at /home/yj/tvm/src/runtime/library_module.cc:38
  14: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::LibraryModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  15: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  16: tvm::runtime::ObjectInternal::ObjectFree(void*)
        at /home/yj/tvm/src/runtime/object_internal.h:56
  17: TVMObjectFree
        at /home/yj/tvm/src/runtime/object.cc:249
  18: TVMModFree
        at /home/yj/tvm/src/runtime/c_runtime_api.cc:422
  19: ffi_call_unix64
  20: ffi_call_int
  21: _call_function_pointer
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:920
  22: _ctypes_callproc
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:1263
  23: PyCFuncPtr_call
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/_ctypes.c:4201
  24: _PyObject_MakeTpCall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:191
  25: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:116
  26: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  27: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  28: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3487
  29: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  30: function_code_fastcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:330
  31: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:367
  32: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  33: PyObject_CallOneArg
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:188
  34: call_unbound_noarg
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1527
  35: slot_tp_finalize
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:7007
  36: PyObject_CallFinalizer
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:195
  37: PyObject_CallFinalizerFromDealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:213
  38: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1273
  39: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  40: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  41: frame_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/frameobject.c:582
  42: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  43: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  44: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  45: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:167
  46: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  47: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  48: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  49: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:166
  50: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  51: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  52: BaseException_clear
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:78
  53: BaseException_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:88
  54: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1351
  55: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  56: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  57: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  58: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:1498
  59: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  60: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  61: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  62: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  63: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  64: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  65: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  66: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  67: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  68: _PyEval_EvalCodeWithName
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4359
  69: PyEval_EvalCodeEx
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4375
  70: PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:826
  71: builtin_exec_impl.isra.17
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/bltinmodule.c:1026
  72: builtin_exec
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/clinic/bltinmodule.c.h:396
  73: cfunction_vectorcall_FASTCALL
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/methodobject.c:430
  74: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  75: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  76: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  77: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  78: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  79: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  80: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  81: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  82: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  83: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  84: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  85: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  86: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  87: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  88: PyVectorcall_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:231
  89: _PyObject_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:266
  90: pymain_run_module
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:297
  91: pymain_run_python
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:598
  92: Py_RunMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:683
  93: Py_BytesMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:1129
  94: __libc_start_main
  95: 0x0000558ade271bc2
  96: 0xffffffffffffffff


terminate called after throwing an instance of 'tvm::runtime::InternalError'
  what():  [13:35:06] /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61: CUDAError: cuModuleUnload(module_[i]) failed with error: CUDA_ERROR_MISALIGNED_ADDRESS
Stack trace:
  0: tvm::runtime::CUDAModuleNode::~CUDAModuleNode()
        at /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61
  1: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::CUDAModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  2: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  3: tvm::runtime::ObjectPtr<tvm::runtime::Object>::reset()
        at /home/yj/tvm/include/tvm/runtime/object.h:451
  4: tvm::runtime::ObjectPtr<tvm::runtime::Object>::~ObjectPtr()
        at /home/yj/tvm/include/tvm/runtime/object.h:400
  5: tvm::runtime::ObjectRef::~ObjectRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:511
  6: tvm::runtime::Module::~Module()
        at /home/yj/tvm/include/tvm/runtime/module.h:48
  7: void std::_Destroy<tvm::runtime::Module>(tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:98
  8: void std::_Destroy_aux<false>::__destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:108
  9: void std::_Destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:137
  10: void std::_Destroy<tvm::runtime::Module*, tvm::runtime::Module>(tvm::runtime::Module*, tvm::runtime::Module*, std::allocator<tvm::runtime::Module>&)
        at /usr/include/c++/9/bits/stl_construct.h:206
  11: std::vector<tvm::runtime::Module, std::allocator<tvm::runtime::Module> >::~vector()
        at /usr/include/c++/9/bits/stl_vector.h:677
  12: tvm::runtime::ModuleNode::~ModuleNode()
        at /home/yj/tvm/include/tvm/runtime/module.h:114
  13: tvm::runtime::LibraryModuleNode::~LibraryModuleNode()
        at /home/yj/tvm/src/runtime/library_module.cc:38
  14: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::LibraryModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  15: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  16: tvm::runtime::ObjectInternal::ObjectFree(void*)
        at /home/yj/tvm/src/runtime/object_internal.h:56
  17: TVMObjectFree
        at /home/yj/tvm/src/runtime/object.cc:249
  18: TVMModFree
        at /home/yj/tvm/src/runtime/c_runtime_api.cc:422
  19: ffi_call_unix64
  20: ffi_call_int
  21: _call_function_pointer
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:920
  22: _ctypes_callproc
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:1263
  23: PyCFuncPtr_call
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/_ctypes.c:4201
  24: _PyObject_MakeTpCall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:191
  25: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:116
  26: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  27: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  28: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3487
  29: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  30: function_code_fastcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:330
  31: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:367
  32: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  33: PyObject_CallOneArg
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:188
  34: call_unbound_noarg
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1527
  35: slot_tp_finalize
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:7007
  36: PyObject_CallFinalizer
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:195
  37: PyObject_CallFinalizerFromDealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:213
  38: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1273
  39: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  40: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  41: frame_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/frameobject.c:582
  42: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  43: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  44: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  45: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:167
  46: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  47: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  48: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  49: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:166
  50: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  51: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  52: BaseException_clear
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:78
  53: BaseException_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:88
  54: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1351
  55: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  56: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  57: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  58: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:1498
  59: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  60: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  61: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  62: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  63: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  64: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  65: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  66: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  67: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  68: _PyEval_EvalCodeWithName
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4359
  69: PyEval_EvalCodeEx
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4375
  70: PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:826
  71: builtin_exec_impl.isra.17
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/bltinmodule.c:1026
  72: builtin_exec
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/clinic/bltinmodule.c.h:396
  73: cfunction_vectorcall_FASTCALL
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/methodobject.c:430
  74: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  75: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  76: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  77: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  78: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  79: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  80: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  81: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  82: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  83: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  84: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  85: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  86: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  87: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  88: PyVectorcall_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:231
  89: _PyObject_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:266
  90: pymain_run_module
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:297
  91: pymain_run_python
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:598
  92: Py_RunMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:683
  93: Py_BytesMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:1129
  94: __libc_start_main
  95: 0x0000558ed9713bc2
  96: 0xffffffffffffffff


[13:35:08] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #4: "fused_nn_conv2d_add_1"
[13:35:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:35:22] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:35:31] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"
[13:35:31] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:35:32] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:35:41] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #6: "fused_nn_max_pool2d"
[13:35:42] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:35:44] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:35:50] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #7: "fused_nn_max_pool2d_1"
[13:35:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:35:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:36:02] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #8: "fused_transpose"
[13:36:02] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:36:04] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:36:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"
[13:36:18] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:36:39] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:36:55] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"
[13:37:25] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:37:46] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:38:02] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"
[13:38:08] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:38:28] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:38:41] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"
[13:38:50] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:39:20] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:39:42] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"
[13:39:59] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:40:30] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:40:41] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #14: "fused_concatenate"
[13:40:42] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:40:43] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:41:04] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"
[13:41:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:41:41] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:41:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"
[13:42:05] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:42:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
terminate called after throwing an instance of 'tvm::runtime::InternalError'
  what():  [13:42:36] /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61: CUDAError: cuModuleUnload(module_[i]) failed with error: CUDA_ERROR_MISALIGNED_ADDRESS
Stack trace:
  0: tvm::runtime::CUDAModuleNode::~CUDAModuleNode()
        at /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61
  1: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::CUDAModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  2: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  3: tvm::runtime::ObjectPtr<tvm::runtime::Object>::reset()
        at /home/yj/tvm/include/tvm/runtime/object.h:451
  4: tvm::runtime::ObjectPtr<tvm::runtime::Object>::~ObjectPtr()
        at /home/yj/tvm/include/tvm/runtime/object.h:400
  5: tvm::runtime::ObjectRef::~ObjectRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:511
  6: tvm::runtime::Module::~Module()
        at /home/yj/tvm/include/tvm/runtime/module.h:48
  7: void std::_Destroy<tvm::runtime::Module>(tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:98
  8: void std::_Destroy_aux<false>::__destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:108
  9: void std::_Destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:137
  10: void std::_Destroy<tvm::runtime::Module*, tvm::runtime::Module>(tvm::runtime::Module*, tvm::runtime::Module*, std::allocator<tvm::runtime::Module>&)
        at /usr/include/c++/9/bits/stl_construct.h:206
  11: std::vector<tvm::runtime::Module, std::allocator<tvm::runtime::Module> >::~vector()
        at /usr/include/c++/9/bits/stl_vector.h:677
  12: tvm::runtime::ModuleNode::~ModuleNode()
        at /home/yj/tvm/include/tvm/runtime/module.h:114
  13: tvm::runtime::LibraryModuleNode::~LibraryModuleNode()
        at /home/yj/tvm/src/runtime/library_module.cc:38
  14: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::LibraryModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  15: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  16: tvm::runtime::ObjectInternal::ObjectFree(void*)
        at /home/yj/tvm/src/runtime/object_internal.h:56
  17: TVMObjectFree
        at /home/yj/tvm/src/runtime/object.cc:249
  18: TVMModFree
        at /home/yj/tvm/src/runtime/c_runtime_api.cc:422
  19: ffi_call_unix64
  20: ffi_call_int
  21: _call_function_pointer
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:920
  22: _ctypes_callproc
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:1263
  23: PyCFuncPtr_call
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/_ctypes.c:4201
  24: _PyObject_MakeTpCall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:191
  25: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:116
  26: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  27: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  28: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3487
  29: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  30: function_code_fastcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:330
  31: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:367
  32: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  33: PyObject_CallOneArg
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:188
  34: call_unbound_noarg
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1527
  35: slot_tp_finalize
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:7007
  36: PyObject_CallFinalizer
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:195
  37: PyObject_CallFinalizerFromDealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:213
  38: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1273
  39: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  40: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  41: frame_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/frameobject.c:582
  42: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  43: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  44: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  45: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:167
  46: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  47: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  48: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  49: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:166
  50: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  51: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  52: BaseException_clear
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:78
  53: BaseException_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:88
  54: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1351
  55: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  56: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  57: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  58: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:1498
  59: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  60: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  61: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  62: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  63: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  64: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  65: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  66: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  67: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  68: _PyEval_EvalCodeWithName
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4359
  69: PyEval_EvalCodeEx
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4375
  70: PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:826
  71: builtin_exec_impl.isra.17
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/bltinmodule.c:1026
  72: builtin_exec
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/clinic/bltinmodule.c.h:396
  73: cfunction_vectorcall_FASTCALL
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/methodobject.c:430
  74: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  75: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  76: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  77: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  78: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  79: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  80: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  81: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  82: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  83: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  84: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  85: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  86: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  87: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  88: PyVectorcall_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:231
  89: _PyObject_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:266
  90: pymain_run_module
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:297
  91: pymain_run_python
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:598
  92: Py_RunMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:683
  93: Py_BytesMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:1129
  94: __libc_start_main
  95: 0x00005631369f4bc2
  96: 0xffffffffffffffff


terminate called after throwing an instance of 'tvm::runtime::InternalError'
  what():  [13:42:38] /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61: CUDAError: cuModuleUnload(module_[i]) failed with error: CUDA_ERROR_MISALIGNED_ADDRESS
Stack trace:
  0: tvm::runtime::CUDAModuleNode::~CUDAModuleNode()
        at /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61
  1: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::CUDAModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  2: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  3: tvm::runtime::ObjectPtr<tvm::runtime::Object>::reset()
        at /home/yj/tvm/include/tvm/runtime/object.h:451
  4: tvm::runtime::ObjectPtr<tvm::runtime::Object>::~ObjectPtr()
        at /home/yj/tvm/include/tvm/runtime/object.h:400
  5: tvm::runtime::ObjectRef::~ObjectRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:511
  6: tvm::runtime::Module::~Module()
        at /home/yj/tvm/include/tvm/runtime/module.h:48
  7: void std::_Destroy<tvm::runtime::Module>(tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:98
  8: void std::_Destroy_aux<false>::__destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:108
  9: void std::_Destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:137
  10: void std::_Destroy<tvm::runtime::Module*, tvm::runtime::Module>(tvm::runtime::Module*, tvm::runtime::Module*, std::allocator<tvm::runtime::Module>&)
        at /usr/include/c++/9/bits/stl_construct.h:206
  11: std::vector<tvm::runtime::Module, std::allocator<tvm::runtime::Module> >::~vector()
        at /usr/include/c++/9/bits/stl_vector.h:677
  12: tvm::runtime::ModuleNode::~ModuleNode()
        at /home/yj/tvm/include/tvm/runtime/module.h:114
  13: tvm::runtime::LibraryModuleNode::~LibraryModuleNode()
        at /home/yj/tvm/src/runtime/library_module.cc:38
  14: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::LibraryModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  15: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  16: tvm::runtime::ObjectInternal::ObjectFree(void*)
        at /home/yj/tvm/src/runtime/object_internal.h:56
  17: TVMObjectFree
        at /home/yj/tvm/src/runtime/object.cc:249
  18: TVMModFree
        at /home/yj/tvm/src/runtime/c_runtime_api.cc:422
  19: ffi_call_unix64
  20: ffi_call_int
  21: _call_function_pointer
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:920
  22: _ctypes_callproc
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:1263
  23: PyCFuncPtr_call
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/_ctypes.c:4201
  24: _PyObject_MakeTpCall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:191
  25: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:116
  26: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  27: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  28: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3487
  29: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  30: function_code_fastcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:330
  31: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:367
  32: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  33: PyObject_CallOneArg
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:188
  34: call_unbound_noarg
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1527
  35: slot_tp_finalize
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:7007
  36: PyObject_CallFinalizer
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:195
  37: PyObject_CallFinalizerFromDealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:213
  38: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1273
  39: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  40: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  41: frame_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/frameobject.c:582
  42: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  43: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  44: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  45: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:167
  46: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  47: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  48: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  49: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:166
  50: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  51: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  52: BaseException_clear
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:78
  53: BaseException_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:88
  54: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1351
  55: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  56: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  57: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  58: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:1498
  59: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  60: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  61: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  62: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  63: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  64: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  65: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  66: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  67: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  68: _PyEval_EvalCodeWithName
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4359
  69: PyEval_EvalCodeEx
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4375
  70: PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:826
  71: builtin_exec_impl.isra.17
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/bltinmodule.c:1026
  72: builtin_exec
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/clinic/bltinmodule.c.h:396
  73: cfunction_vectorcall_FASTCALL
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/methodobject.c:430
  74: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  75: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  76: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  77: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  78: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  79: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  80: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  81: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  82: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  83: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  84: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  85: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  86: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  87: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  88: PyVectorcall_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:231
  89: _PyObject_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:266
  90: pymain_run_module
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:297
  91: pymain_run_python
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:598
  92: Py_RunMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:683
  93: Py_BytesMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:1129
  94: __libc_start_main
  95: 0x000055f067919bc2
  96: 0xffffffffffffffff


terminate called after throwing an instance of 'tvm::runtime::InternalError'
  what():  [13:42:45] /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61: CUDAError: cuModuleUnload(module_[i]) failed with error: CUDA_ERROR_MISALIGNED_ADDRESS
Stack trace:
  0: tvm::runtime::CUDAModuleNode::~CUDAModuleNode()
        at /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61
  1: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::CUDAModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  2: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  3: tvm::runtime::ObjectPtr<tvm::runtime::Object>::reset()
        at /home/yj/tvm/include/tvm/runtime/object.h:451
  4: tvm::runtime::ObjectPtr<tvm::runtime::Object>::~ObjectPtr()
        at /home/yj/tvm/include/tvm/runtime/object.h:400
  5: tvm::runtime::ObjectRef::~ObjectRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:511
  6: tvm::runtime::Module::~Module()
        at /home/yj/tvm/include/tvm/runtime/module.h:48
  7: void std::_Destroy<tvm::runtime::Module>(tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:98
  8: void std::_Destroy_aux<false>::__destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:108
  9: void std::_Destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:137
  10: void std::_Destroy<tvm::runtime::Module*, tvm::runtime::Module>(tvm::runtime::Module*, tvm::runtime::Module*, std::allocator<tvm::runtime::Module>&)
        at /usr/include/c++/9/bits/stl_construct.h:206
  11: std::vector<tvm::runtime::Module, std::allocator<tvm::runtime::Module> >::~vector()
        at /usr/include/c++/9/bits/stl_vector.h:677
  12: tvm::runtime::ModuleNode::~ModuleNode()
        at /home/yj/tvm/include/tvm/runtime/module.h:114
  13: tvm::runtime::LibraryModuleNode::~LibraryModuleNode()
        at /home/yj/tvm/src/runtime/library_module.cc:38
  14: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::LibraryModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  15: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  16: tvm::runtime::ObjectInternal::ObjectFree(void*)
        at /home/yj/tvm/src/runtime/object_internal.h:56
  17: TVMObjectFree
        at /home/yj/tvm/src/runtime/object.cc:249
  18: TVMModFree
        at /home/yj/tvm/src/runtime/c_runtime_api.cc:422
  19: ffi_call_unix64
  20: ffi_call_int
  21: _call_function_pointer
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:920
  22: _ctypes_callproc
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:1263
  23: PyCFuncPtr_call
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/_ctypes.c:4201
  24: _PyObject_MakeTpCall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:191
  25: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:116
  26: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  27: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  28: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3487
  29: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  30: function_code_fastcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:330
  31: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:367
  32: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  33: PyObject_CallOneArg
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:188
  34: call_unbound_noarg
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1527
  35: slot_tp_finalize
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:7007
  36: PyObject_CallFinalizer
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:195
  37: PyObject_CallFinalizerFromDealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:213
  38: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1273
  39: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  40: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  41: frame_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/frameobject.c:582
  42: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  43: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  44: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  45: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:167
  46: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  47: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  48: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  49: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:166
  50: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  51: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  52: BaseException_clear
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:78
  53: BaseException_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:88
  54: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1351
  55: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  56: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  57: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  58: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:1498
  59: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  60: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  61: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  62: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  63: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  64: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  65: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  66: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  67: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  68: _PyEval_EvalCodeWithName
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4359
  69: PyEval_EvalCodeEx
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4375
  70: PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:826
  71: builtin_exec_impl.isra.17
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/bltinmodule.c:1026
  72: builtin_exec
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/clinic/bltinmodule.c.h:396
  73: cfunction_vectorcall_FASTCALL
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/methodobject.c:430
  74: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  75: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  76: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  77: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  78: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  79: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  80: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  81: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  82: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  83: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  84: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  85: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  86: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  87: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  88: PyVectorcall_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:231
  89: _PyObject_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:266
  90: pymain_run_module
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:297
  91: pymain_run_python
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:598
  92: Py_RunMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:683
  93: Py_BytesMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:1129
  94: __libc_start_main
  95: 0x00005601abe67bc2
  96: 0xffffffffffffffff


[13:42:47] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"
[13:42:52] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:43:22] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:43:33] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"
[13:43:40] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:43:58] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:44:09] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"
[13:44:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:44:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:44:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #20: "fused_concatenate_1"
[13:44:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:44:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:45:03] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"
[13:45:07] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:45:37] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:45:44] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"
[13:45:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:46:24] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
terminate called after throwing an instance of 'tvm::runtime::InternalError'
  what():  [13:46:32] /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61: CUDAError: cuModuleUnload(module_[i]) failed with error: CUDA_ERROR_MISALIGNED_ADDRESS
Stack trace:
  0: tvm::runtime::CUDAModuleNode::~CUDAModuleNode()
        at /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61
  1: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::CUDAModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  2: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  3: tvm::runtime::ObjectPtr<tvm::runtime::Object>::reset()
        at /home/yj/tvm/include/tvm/runtime/object.h:451
  4: tvm::runtime::ObjectPtr<tvm::runtime::Object>::~ObjectPtr()
        at /home/yj/tvm/include/tvm/runtime/object.h:400
  5: tvm::runtime::ObjectRef::~ObjectRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:511
  6: tvm::runtime::Module::~Module()
        at /home/yj/tvm/include/tvm/runtime/module.h:48
  7: void std::_Destroy<tvm::runtime::Module>(tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:98
  8: void std::_Destroy_aux<false>::__destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:108
  9: void std::_Destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:137
  10: void std::_Destroy<tvm::runtime::Module*, tvm::runtime::Module>(tvm::runtime::Module*, tvm::runtime::Module*, std::allocator<tvm::runtime::Module>&)
        at /usr/include/c++/9/bits/stl_construct.h:206
  11: std::vector<tvm::runtime::Module, std::allocator<tvm::runtime::Module> >::~vector()
        at /usr/include/c++/9/bits/stl_vector.h:677
  12: tvm::runtime::ModuleNode::~ModuleNode()
        at /home/yj/tvm/include/tvm/runtime/module.h:114
  13: tvm::runtime::LibraryModuleNode::~LibraryModuleNode()
        at /home/yj/tvm/src/runtime/library_module.cc:38
  14: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::LibraryModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  15: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  16: tvm::runtime::ObjectInternal::ObjectFree(void*)
        at /home/yj/tvm/src/runtime/object_internal.h:56
  17: TVMObjectFree
        at /home/yj/tvm/src/runtime/object.cc:249
  18: TVMModFree
        at /home/yj/tvm/src/runtime/c_runtime_api.cc:422
  19: ffi_call_unix64
  20: ffi_call_int
  21: _call_function_pointer
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:920
  22: _ctypes_callproc
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:1263
  23: PyCFuncPtr_call
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/_ctypes.c:4201
  24: _PyObject_MakeTpCall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:191
  25: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:116
  26: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  27: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  28: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3487
  29: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  30: function_code_fastcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:330
  31: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:367
  32: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  33: PyObject_CallOneArg
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:188
  34: call_unbound_noarg
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1527
  35: slot_tp_finalize
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:7007
  36: PyObject_CallFinalizer
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:195
  37: PyObject_CallFinalizerFromDealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:213
  38: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1273
  39: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  40: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  41: frame_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/frameobject.c:582
  42: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  43: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  44: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  45: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:167
  46: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  47: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  48: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  49: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:166
  50: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  51: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  52: BaseException_clear
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:78
  53: BaseException_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:88
  54: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1351
  55: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  56: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  57: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  58: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:1498
  59: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  60: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  61: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  62: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  63: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  64: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  65: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  66: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  67: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  68: _PyEval_EvalCodeWithName
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4359
  69: PyEval_EvalCodeEx
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4375
  70: PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:826
  71: builtin_exec_impl.isra.17
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/bltinmodule.c:1026
  72: builtin_exec
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/clinic/bltinmodule.c.h:396
  73: cfunction_vectorcall_FASTCALL
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/methodobject.c:430
  74: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  75: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  76: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  77: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  78: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  79: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  80: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  81: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  82: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  83: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  84: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  85: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  86: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  87: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  88: PyVectorcall_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:231
  89: _PyObject_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:266
  90: pymain_run_module
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:297
  91: pymain_run_python
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:598
  92: Py_RunMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:683
  93: Py_BytesMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:1129
  94: __libc_start_main
  95: 0x000055a327311bc2
  96: 0xffffffffffffffff


terminate called after throwing an instance of 'tvm::runtime::InternalError'
  what():  [13:46:33] /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61: CUDAError: cuModuleUnload(module_[i]) failed with error: CUDA_ERROR_MISALIGNED_ADDRESS
Stack trace:
  0: tvm::runtime::CUDAModuleNode::~CUDAModuleNode()
        at /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61
  1: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::CUDAModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  2: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  3: tvm::runtime::ObjectPtr<tvm::runtime::Object>::reset()
        at /home/yj/tvm/include/tvm/runtime/object.h:451
  4: tvm::runtime::ObjectPtr<tvm::runtime::Object>::~ObjectPtr()
        at /home/yj/tvm/include/tvm/runtime/object.h:400
  5: tvm::runtime::ObjectRef::~ObjectRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:511
  6: tvm::runtime::Module::~Module()
        at /home/yj/tvm/include/tvm/runtime/module.h:48
  7: void std::_Destroy<tvm::runtime::Module>(tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:98
  8: void std::_Destroy_aux<false>::__destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:108
  9: void std::_Destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:137
  10: void std::_Destroy<tvm::runtime::Module*, tvm::runtime::Module>(tvm::runtime::Module*, tvm::runtime::Module*, std::allocator<tvm::runtime::Module>&)
        at /usr/include/c++/9/bits/stl_construct.h:206
  11: std::vector<tvm::runtime::Module, std::allocator<tvm::runtime::Module> >::~vector()
        at /usr/include/c++/9/bits/stl_vector.h:677
  12: tvm::runtime::ModuleNode::~ModuleNode()
        at /home/yj/tvm/include/tvm/runtime/module.h:114
  13: tvm::runtime::LibraryModuleNode::~LibraryModuleNode()
        at /home/yj/tvm/src/runtime/library_module.cc:38
  14: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::LibraryModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  15: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  16: tvm::runtime::ObjectInternal::ObjectFree(void*)
        at /home/yj/tvm/src/runtime/object_internal.h:56
  17: TVMObjectFree
        at /home/yj/tvm/src/runtime/object.cc:249
  18: TVMModFree
        at /home/yj/tvm/src/runtime/c_runtime_api.cc:422
  19: ffi_call_unix64
  20: ffi_call_int
  21: _call_function_pointer
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:920
  22: _ctypes_callproc
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:1263
  23: PyCFuncPtr_call
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/_ctypes.c:4201
  24: _PyObject_MakeTpCall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:191
  25: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:116
  26: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  27: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  28: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3487
  29: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  30: function_code_fastcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:330
  31: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:367
  32: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  33: PyObject_CallOneArg
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:188
  34: call_unbound_noarg
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1527
  35: slot_tp_finalize
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:7007
  36: PyObject_CallFinalizer
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:195
  37: PyObject_CallFinalizerFromDealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:213
  38: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1273
  39: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  40: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  41: frame_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/frameobject.c:582
  42: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  43: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  44: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  45: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:167
  46: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  47: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  48: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  49: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:166
  50: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  51: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  52: BaseException_clear
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:78
  53: BaseException_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:88
  54: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1351
  55: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  56: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  57: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  58: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:1498
  59: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  60: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  61: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  62: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  63: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  64: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  65: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  66: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  67: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  68: _PyEval_EvalCodeWithName
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4359
  69: PyEval_EvalCodeEx
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4375
  70: PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:826
  71: builtin_exec_impl.isra.17
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/bltinmodule.c:1026
  72: builtin_exec
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/clinic/bltinmodule.c.h:396
  73: cfunction_vectorcall_FASTCALL
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/methodobject.c:430
  74: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  75: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  76: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  77: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  78: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  79: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  80: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  81: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  82: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  83: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  84: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  85: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  86: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  87: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  88: PyVectorcall_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:231
  89: _PyObject_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:266
  90: pymain_run_module
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:297
  91: pymain_run_python
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:598
  92: Py_RunMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:683
  93: Py_BytesMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:1129
  94: __libc_start_main
  95: 0x0000561be7b50bc2
  96: 0xffffffffffffffff


terminate called after throwing an instance of 'tvm::runtime::InternalError'
  what():  [13:46:34] /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61: CUDAError: cuModuleUnload(module_[i]) failed with error: CUDA_ERROR_MISALIGNED_ADDRESS
Stack trace:
  0: tvm::runtime::CUDAModuleNode::~CUDAModuleNode()
        at /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61
  1: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::CUDAModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  2: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  3: tvm::runtime::ObjectPtr<tvm::runtime::Object>::reset()
        at /home/yj/tvm/include/tvm/runtime/object.h:451
  4: tvm::runtime::ObjectPtr<tvm::runtime::Object>::~ObjectPtr()
        at /home/yj/tvm/include/tvm/runtime/object.h:400
  5: tvm::runtime::ObjectRef::~ObjectRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:511
  6: tvm::runtime::Module::~Module()
        at /home/yj/tvm/include/tvm/runtime/module.h:48
  7: void std::_Destroy<tvm::runtime::Module>(tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:98
  8: void std::_Destroy_aux<false>::__destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:108
  9: void std::_Destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:137
  10: void std::_Destroy<tvm::runtime::Module*, tvm::runtime::Module>(tvm::runtime::Module*, tvm::runtime::Module*, std::allocator<tvm::runtime::Module>&)
        at /usr/include/c++/9/bits/stl_construct.h:206
  11: std::vector<tvm::runtime::Module, std::allocator<tvm::runtime::Module> >::~vector()
        at /usr/include/c++/9/bits/stl_vector.h:677
  12: tvm::runtime::ModuleNode::~ModuleNode()
        at /home/yj/tvm/include/tvm/runtime/module.h:114
  13: tvm::runtime::LibraryModuleNode::~LibraryModuleNode()
        at /home/yj/tvm/src/runtime/library_module.cc:38
  14: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::LibraryModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  15: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  16: tvm::runtime::ObjectInternal::ObjectFree(void*)
        at /home/yj/tvm/src/runtime/object_internal.h:56
  17: TVMObjectFree
        at /home/yj/tvm/src/runtime/object.cc:249
  18: TVMModFree
        at /home/yj/tvm/src/runtime/c_runtime_api.cc:422
  19: ffi_call_unix64
  20: ffi_call_int
  21: _call_function_pointer
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:920
  22: _ctypes_callproc
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:1263
  23: PyCFuncPtr_call
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/_ctypes.c:4201
  24: _PyObject_MakeTpCall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:191
  25: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:116
  26: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  27: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  28: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3487
  29: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  30: function_code_fastcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:330
  31: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:367
  32: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  33: PyObject_CallOneArg
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:188
  34: call_unbound_noarg
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1527
  35: slot_tp_finalize
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:7007
  36: PyObject_CallFinalizer
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:195
  37: PyObject_CallFinalizerFromDealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:213
  38: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1273
  39: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  40: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  41: frame_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/frameobject.c:582
  42: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  43: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  44: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  45: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:167
  46: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  47: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  48: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  49: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:166
  50: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  51: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  52: BaseException_clear
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:78
  53: BaseException_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:88
  54: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1351
  55: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  56: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  57: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  58: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:1498
  59: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  60: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  61: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  62: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  63: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  64: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  65: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  66: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  67: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  68: _PyEval_EvalCodeWithName
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4359
  69: PyEval_EvalCodeEx
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4375
  70: PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:826
  71: builtin_exec_impl.isra.17
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/bltinmodule.c:1026
  72: builtin_exec
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/clinic/bltinmodule.c.h:396
  73: cfunction_vectorcall_FASTCALL
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/methodobject.c:430
  74: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  75: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  76: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  77: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  78: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  79: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  80: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  81: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  82: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  83: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  84: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  85: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  86: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  87: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  88: PyVectorcall_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:231
  89: _PyObject_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:266
  90: pymain_run_module
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:297
  91: pymain_run_python
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:598
  92: Py_RunMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:683
  93: Py_BytesMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:1129
  94: __libc_start_main
  95: 0x000055bd9bdadbc2
  96: 0xffffffffffffffff


[13:46:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"
[13:46:36] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:47:08] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:47:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"
[13:47:19] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:47:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:47:58] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"
[13:48:01] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:48:32] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:48:37] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #26: "fused_concatenate_2"
[13:48:37] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:48:38] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:48:48] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"
[13:48:50] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:49:21] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:49:28] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"
[13:49:37] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:50:08] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
terminate called after throwing an instance of 'tvm::runtime::InternalError'
  what():  [13:50:08] /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61: CUDAError: cuModuleUnload(module_[i]) failed with error: CUDA_ERROR_MISALIGNED_ADDRESS
Stack trace:
  0: tvm::runtime::CUDAModuleNode::~CUDAModuleNode()
        at /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61
  1: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::CUDAModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  2: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  3: tvm::runtime::ObjectPtr<tvm::runtime::Object>::reset()
        at /home/yj/tvm/include/tvm/runtime/object.h:451
  4: tvm::runtime::ObjectPtr<tvm::runtime::Object>::~ObjectPtr()
        at /home/yj/tvm/include/tvm/runtime/object.h:400
  5: tvm::runtime::ObjectRef::~ObjectRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:511
  6: tvm::runtime::Module::~Module()
        at /home/yj/tvm/include/tvm/runtime/module.h:48
  7: void std::_Destroy<tvm::runtime::Module>(tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:98
  8: void std::_Destroy_aux<false>::__destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:108
  9: void std::_Destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:137
  10: void std::_Destroy<tvm::runtime::Module*, tvm::runtime::Module>(tvm::runtime::Module*, tvm::runtime::Module*, std::allocator<tvm::runtime::Module>&)
        at /usr/include/c++/9/bits/stl_construct.h:206
  11: std::vector<tvm::runtime::Module, std::allocator<tvm::runtime::Module> >::~vector()
        at /usr/include/c++/9/bits/stl_vector.h:677
  12: tvm::runtime::ModuleNode::~ModuleNode()
        at /home/yj/tvm/include/tvm/runtime/module.h:114
  13: tvm::runtime::LibraryModuleNode::~LibraryModuleNode()
        at /home/yj/tvm/src/runtime/library_module.cc:38
  14: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::LibraryModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  15: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  16: tvm::runtime::ObjectInternal::ObjectFree(void*)
        at /home/yj/tvm/src/runtime/object_internal.h:56
  17: TVMObjectFree
        at /home/yj/tvm/src/runtime/object.cc:249
  18: TVMModFree
        at /home/yj/tvm/src/runtime/c_runtime_api.cc:422
  19: ffi_call_unix64
  20: ffi_call_int
  21: _call_function_pointer
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:920
  22: _ctypes_callproc
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:1263
  23: PyCFuncPtr_call
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/_ctypes.c:4201
  24: _PyObject_MakeTpCall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:191
  25: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:116
  26: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  27: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  28: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3487
  29: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  30: function_code_fastcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:330
  31: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:367
  32: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  33: PyObject_CallOneArg
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:188
  34: call_unbound_noarg
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1527
  35: slot_tp_finalize
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:7007
  36: PyObject_CallFinalizer
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:195
  37: PyObject_CallFinalizerFromDealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:213
  38: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1273
  39: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  40: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  41: frame_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/frameobject.c:582
  42: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  43: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  44: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  45: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:167
  46: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  47: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  48: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  49: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:166
  50: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  51: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  52: BaseException_clear
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:78
  53: BaseException_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:88
  54: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1351
  55: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  56: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  57: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  58: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:1498
  59: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  60: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  61: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  62: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  63: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  64: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  65: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  66: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  67: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  68: _PyEval_EvalCodeWithName
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4359
  69: PyEval_EvalCodeEx
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4375
  70: PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:826
  71: builtin_exec_impl.isra.17
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/bltinmodule.c:1026
  72: builtin_exec
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/clinic/bltinmodule.c.h:396
  73: cfunction_vectorcall_FASTCALL
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/methodobject.c:430
  74: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  75: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  76: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  77: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  78: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  79: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  80: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  81: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  82: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  83: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  84: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  85: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  86: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  87: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  88: PyVectorcall_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:231
  89: _PyObject_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:266
  90: pymain_run_module
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:297
  91: pymain_run_python
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:598
  92: Py_RunMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:683
  93: Py_BytesMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:1129
  94: __libc_start_main
  95: 0x000056554ba6abc2
  96: 0xffffffffffffffff


[13:50:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"
[13:50:19] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:50:41] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:50:47] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"
[13:50:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:51:07] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:51:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"
[13:51:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:51:28] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:51:33] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #32: "fused_concatenate_3"
[13:51:33] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:51:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:51:42] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"
[13:51:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:52:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:52:22] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"
[13:52:31] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:53:01] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:53:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"
[13:53:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:53:25] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:53:31] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"
[13:53:40] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:54:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
terminate called after throwing an instance of 'tvm::runtime::InternalError'
  what():  [13:54:12] /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61: CUDAError: cuModuleUnload(module_[i]) failed with error: CUDA_ERROR_MISALIGNED_ADDRESS
Stack trace:
  0: tvm::runtime::CUDAModuleNode::~CUDAModuleNode()
        at /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61
  1: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::CUDAModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  2: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  3: tvm::runtime::ObjectPtr<tvm::runtime::Object>::reset()
        at /home/yj/tvm/include/tvm/runtime/object.h:451
  4: tvm::runtime::ObjectPtr<tvm::runtime::Object>::~ObjectPtr()
        at /home/yj/tvm/include/tvm/runtime/object.h:400
  5: tvm::runtime::ObjectRef::~ObjectRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:511
  6: tvm::runtime::Module::~Module()
        at /home/yj/tvm/include/tvm/runtime/module.h:48
  7: void std::_Destroy<tvm::runtime::Module>(tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:98
  8: void std::_Destroy_aux<false>::__destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:108
  9: void std::_Destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:137
  10: void std::_Destroy<tvm::runtime::Module*, tvm::runtime::Module>(tvm::runtime::Module*, tvm::runtime::Module*, std::allocator<tvm::runtime::Module>&)
        at /usr/include/c++/9/bits/stl_construct.h:206
  11: std::vector<tvm::runtime::Module, std::allocator<tvm::runtime::Module> >::~vector()
        at /usr/include/c++/9/bits/stl_vector.h:677
  12: tvm::runtime::ModuleNode::~ModuleNode()
        at /home/yj/tvm/include/tvm/runtime/module.h:114
  13: tvm::runtime::LibraryModuleNode::~LibraryModuleNode()
        at /home/yj/tvm/src/runtime/library_module.cc:38
  14: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::LibraryModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  15: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  16: tvm::runtime::ObjectInternal::ObjectFree(void*)
        at /home/yj/tvm/src/runtime/object_internal.h:56
  17: TVMObjectFree
        at /home/yj/tvm/src/runtime/object.cc:249
  18: TVMModFree
        at /home/yj/tvm/src/runtime/c_runtime_api.cc:422
  19: ffi_call_unix64
  20: ffi_call_int
  21: _call_function_pointer
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:920
  22: _ctypes_callproc
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:1263
  23: PyCFuncPtr_call
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/_ctypes.c:4201
  24: _PyObject_MakeTpCall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:191
  25: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:116
  26: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  27: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  28: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3487
  29: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  30: function_code_fastcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:330
  31: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:367
  32: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  33: PyObject_CallOneArg
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:188
  34: call_unbound_noarg
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1527
  35: slot_tp_finalize
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:7007
  36: PyObject_CallFinalizer
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:195
  37: PyObject_CallFinalizerFromDealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:213
  38: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1273
  39: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  40: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  41: frame_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/frameobject.c:582
  42: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  43: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  44: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  45: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:167
  46: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  47: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  48: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  49: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:166
  50: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  51: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  52: BaseException_clear
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:78
  53: BaseException_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:88
  54: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1351
  55: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  56: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  57: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  58: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:1498
  59: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  60: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  61: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  62: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  63: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  64: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  65: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  66: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  67: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  68: _PyEval_EvalCodeWithName
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4359
  69: PyEval_EvalCodeEx
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4375
  70: PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:826
  71: builtin_exec_impl.isra.17
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/bltinmodule.c:1026
  72: builtin_exec
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/clinic/bltinmodule.c.h:396
  73: cfunction_vectorcall_FASTCALL
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/methodobject.c:430
  74: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  75: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  76: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  77: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  78: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  79: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  80: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  81: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  82: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  83: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  84: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  85: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  86: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  87: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  88: PyVectorcall_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:231
  89: _PyObject_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:266
  90: pymain_run_module
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:297
  91: pymain_run_python
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:598
  92: Py_RunMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:683
  93: Py_BytesMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:1129
  94: __libc_start_main
  95: 0x000055b4ed7eabc2
  96: 0xffffffffffffffff


[13:54:20] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"
[13:54:22] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:54:53] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:54:58] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #38: "fused_concatenate_4"
[13:54:59] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:54:59] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:55:07] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"
[13:55:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:55:40] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:55:48] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #40: "fused_nn_max_pool2d_2"
[13:55:48] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:55:52] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:55:58] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #41: "fused_concatenate_5"
[13:55:58] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:55:59] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:56:07] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"
[13:56:09] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:56:28] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:56:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"
[13:56:44] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:57:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
terminate called after throwing an instance of 'tvm::runtime::InternalError'
  what():  [13:57:19] /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61: CUDAError: cuModuleUnload(module_[i]) failed with error: CUDA_ERROR_MISALIGNED_ADDRESS
Stack trace:
  0: tvm::runtime::CUDAModuleNode::~CUDAModuleNode()
        at /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61
  1: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::CUDAModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  2: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  3: tvm::runtime::ObjectPtr<tvm::runtime::Object>::reset()
        at /home/yj/tvm/include/tvm/runtime/object.h:451
  4: tvm::runtime::ObjectPtr<tvm::runtime::Object>::~ObjectPtr()
        at /home/yj/tvm/include/tvm/runtime/object.h:400
  5: tvm::runtime::ObjectRef::~ObjectRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:511
  6: tvm::runtime::Module::~Module()
        at /home/yj/tvm/include/tvm/runtime/module.h:48
  7: void std::_Destroy<tvm::runtime::Module>(tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:98
  8: void std::_Destroy_aux<false>::__destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:108
  9: void std::_Destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:137
  10: void std::_Destroy<tvm::runtime::Module*, tvm::runtime::Module>(tvm::runtime::Module*, tvm::runtime::Module*, std::allocator<tvm::runtime::Module>&)
        at /usr/include/c++/9/bits/stl_construct.h:206
  11: std::vector<tvm::runtime::Module, std::allocator<tvm::runtime::Module> >::~vector()
        at /usr/include/c++/9/bits/stl_vector.h:677
  12: tvm::runtime::ModuleNode::~ModuleNode()
        at /home/yj/tvm/include/tvm/runtime/module.h:114
  13: tvm::runtime::LibraryModuleNode::~LibraryModuleNode()
        at /home/yj/tvm/src/runtime/library_module.cc:38
  14: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::LibraryModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  15: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  16: tvm::runtime::ObjectInternal::ObjectFree(void*)
        at /home/yj/tvm/src/runtime/object_internal.h:56
  17: TVMObjectFree
        at /home/yj/tvm/src/runtime/object.cc:249
  18: TVMModFree
        at /home/yj/tvm/src/runtime/c_runtime_api.cc:422
  19: ffi_call_unix64
  20: ffi_call_int
  21: _call_function_pointer
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:920
  22: _ctypes_callproc
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:1263
  23: PyCFuncPtr_call
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/_ctypes.c:4201
  24: _PyObject_MakeTpCall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:191
  25: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:116
  26: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  27: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  28: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3487
  29: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  30: function_code_fastcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:330
  31: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:367
  32: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  33: PyObject_CallOneArg
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:188
  34: call_unbound_noarg
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1527
  35: slot_tp_finalize
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:7007
  36: PyObject_CallFinalizer
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:195
  37: PyObject_CallFinalizerFromDealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:213
  38: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1273
  39: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  40: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  41: frame_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/frameobject.c:582
  42: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  43: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  44: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  45: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:167
  46: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  47: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  48: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  49: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:166
  50: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  51: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  52: BaseException_clear
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:78
  53: BaseException_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:88
  54: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1351
  55: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  56: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  57: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  58: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:1498
  59: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  60: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  61: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  62: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  63: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  64: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  65: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  66: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  67: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  68: _PyEval_EvalCodeWithName
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4359
  69: PyEval_EvalCodeEx
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4375
  70: PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:826
  71: builtin_exec_impl.isra.17
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/bltinmodule.c:1026
  72: builtin_exec
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/clinic/bltinmodule.c.h:396
  73: cfunction_vectorcall_FASTCALL
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/methodobject.c:430
  74: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  75: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  76: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  77: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  78: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  79: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  80: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  81: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  82: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  83: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  84: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  85: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  86: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  87: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  88: PyVectorcall_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:231
  89: _PyObject_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:266
  90: pymain_run_module
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:297
  91: pymain_run_python
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:598
  92: Py_RunMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:683
  93: Py_BytesMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:1129
  94: __libc_start_main
  95: 0x00005649fd009bc2
  96: 0xffffffffffffffff


terminate called after throwing an instance of 'tvm::runtime::InternalError'
  what():  [13:57:25] /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61: CUDAError: cuModuleUnload(module_[i]) failed with error: CUDA_ERROR_MISALIGNED_ADDRESS
Stack trace:
  0: tvm::runtime::CUDAModuleNode::~CUDAModuleNode()
        at /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61
  1: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::CUDAModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  2: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  3: tvm::runtime::ObjectPtr<tvm::runtime::Object>::reset()
        at /home/yj/tvm/include/tvm/runtime/object.h:451
  4: tvm::runtime::ObjectPtr<tvm::runtime::Object>::~ObjectPtr()
        at /home/yj/tvm/include/tvm/runtime/object.h:400
  5: tvm::runtime::ObjectRef::~ObjectRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:511
  6: tvm::runtime::Module::~Module()
        at /home/yj/tvm/include/tvm/runtime/module.h:48
  7: void std::_Destroy<tvm::runtime::Module>(tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:98
  8: void std::_Destroy_aux<false>::__destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:108
  9: void std::_Destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:137
  10: void std::_Destroy<tvm::runtime::Module*, tvm::runtime::Module>(tvm::runtime::Module*, tvm::runtime::Module*, std::allocator<tvm::runtime::Module>&)
        at /usr/include/c++/9/bits/stl_construct.h:206
  11: std::vector<tvm::runtime::Module, std::allocator<tvm::runtime::Module> >::~vector()
        at /usr/include/c++/9/bits/stl_vector.h:677
  12: tvm::runtime::ModuleNode::~ModuleNode()
        at /home/yj/tvm/include/tvm/runtime/module.h:114
  13: tvm::runtime::LibraryModuleNode::~LibraryModuleNode()
        at /home/yj/tvm/src/runtime/library_module.cc:38
  14: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::LibraryModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  15: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  16: tvm::runtime::ObjectInternal::ObjectFree(void*)
        at /home/yj/tvm/src/runtime/object_internal.h:56
  17: TVMObjectFree
        at /home/yj/tvm/src/runtime/object.cc:249
  18: TVMModFree
        at /home/yj/tvm/src/runtime/c_runtime_api.cc:422
  19: ffi_call_unix64
  20: ffi_call_int
  21: _call_function_pointer
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:920
  22: _ctypes_callproc
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:1263
  23: PyCFuncPtr_call
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/_ctypes.c:4201
  24: _PyObject_MakeTpCall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:191
  25: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:116
  26: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  27: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  28: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3487
  29: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  30: function_code_fastcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:330
  31: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:367
  32: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  33: PyObject_CallOneArg
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:188
  34: call_unbound_noarg
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1527
  35: slot_tp_finalize
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:7007
  36: PyObject_CallFinalizer
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:195
  37: PyObject_CallFinalizerFromDealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:213
  38: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1273
  39: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  40: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  41: frame_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/frameobject.c:582
  42: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  43: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  44: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  45: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:167
  46: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  47: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  48: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  49: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:166
  50: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  51: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  52: BaseException_clear
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:78
  53: BaseException_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:88
  54: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1351
  55: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  56: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  57: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  58: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:1498
  59: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  60: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  61: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  62: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  63: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  64: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  65: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  66: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  67: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  68: _PyEval_EvalCodeWithName
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4359
  69: PyEval_EvalCodeEx
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4375
  70: PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:826
  71: builtin_exec_impl.isra.17
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/bltinmodule.c:1026
  72: builtin_exec
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/clinic/bltinmodule.c.h:396
  73: cfunction_vectorcall_FASTCALL
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/methodobject.c:430
  74: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  75: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  76: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  77: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  78: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  79: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  80: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  81: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  82: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  83: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  84: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  85: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  86: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  87: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  88: PyVectorcall_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:231
  89: _PyObject_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:266
  90: pymain_run_module
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:297
  91: pymain_run_python
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:598
  92: Py_RunMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:683
  93: Py_BytesMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:1129
  94: __libc_start_main
  95: 0x000055ee598f3bc2
  96: 0xffffffffffffffff


[13:57:30] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"
[13:57:31] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:58:02] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
terminate called after throwing an instance of 'tvm::runtime::InternalError'
  what():  [13:58:06] /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61: CUDAError: cuModuleUnload(module_[i]) failed with error: CUDA_ERROR_MISALIGNED_ADDRESS
Stack trace:
  0: tvm::runtime::CUDAModuleNode::~CUDAModuleNode()
        at /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61
  1: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::CUDAModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  2: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  3: tvm::runtime::ObjectPtr<tvm::runtime::Object>::reset()
        at /home/yj/tvm/include/tvm/runtime/object.h:451
  4: tvm::runtime::ObjectPtr<tvm::runtime::Object>::~ObjectPtr()
        at /home/yj/tvm/include/tvm/runtime/object.h:400
  5: tvm::runtime::ObjectRef::~ObjectRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:511
  6: tvm::runtime::Module::~Module()
        at /home/yj/tvm/include/tvm/runtime/module.h:48
  7: void std::_Destroy<tvm::runtime::Module>(tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:98
  8: void std::_Destroy_aux<false>::__destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:108
  9: void std::_Destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:137
  10: void std::_Destroy<tvm::runtime::Module*, tvm::runtime::Module>(tvm::runtime::Module*, tvm::runtime::Module*, std::allocator<tvm::runtime::Module>&)
        at /usr/include/c++/9/bits/stl_construct.h:206
  11: std::vector<tvm::runtime::Module, std::allocator<tvm::runtime::Module> >::~vector()
        at /usr/include/c++/9/bits/stl_vector.h:677
  12: tvm::runtime::ModuleNode::~ModuleNode()
        at /home/yj/tvm/include/tvm/runtime/module.h:114
  13: tvm::runtime::LibraryModuleNode::~LibraryModuleNode()
        at /home/yj/tvm/src/runtime/library_module.cc:38
  14: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::LibraryModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  15: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  16: tvm::runtime::ObjectInternal::ObjectFree(void*)
        at /home/yj/tvm/src/runtime/object_internal.h:56
  17: TVMObjectFree
        at /home/yj/tvm/src/runtime/object.cc:249
  18: TVMModFree
        at /home/yj/tvm/src/runtime/c_runtime_api.cc:422
  19: ffi_call_unix64
  20: ffi_call_int
  21: _call_function_pointer
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:920
  22: _ctypes_callproc
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:1263
  23: PyCFuncPtr_call
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/_ctypes.c:4201
  24: _PyObject_MakeTpCall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:191
  25: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:116
  26: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  27: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  28: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3487
  29: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  30: function_code_fastcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:330
  31: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:367
  32: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  33: PyObject_CallOneArg
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:188
  34: call_unbound_noarg
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1527
  35: slot_tp_finalize
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:7007
  36: PyObject_CallFinalizer
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:195
  37: PyObject_CallFinalizerFromDealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:213
  38: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1273
  39: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  40: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  41: frame_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/frameobject.c:582
  42: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  43: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  44: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  45: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:167
  46: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  47: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  48: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  49: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:166
  50: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  51: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  52: BaseException_clear
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:78
  53: BaseException_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:88
  54: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1351
  55: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  56: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  57: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  58: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:1498
  59: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  60: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  61: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  62: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  63: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  64: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  65: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  66: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  67: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  68: _PyEval_EvalCodeWithName
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4359
  69: PyEval_EvalCodeEx
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4375
  70: PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:826
  71: builtin_exec_impl.isra.17
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/bltinmodule.c:1026
  72: builtin_exec
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/clinic/bltinmodule.c.h:396
  73: cfunction_vectorcall_FASTCALL
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/methodobject.c:430
  74: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  75: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  76: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  77: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  78: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  79: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  80: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  81: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  82: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  83: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  84: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  85: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  86: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  87: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  88: PyVectorcall_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:231
  89: _PyObject_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:266
  90: pymain_run_module
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:297
  91: pymain_run_python
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:598
  92: Py_RunMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:683
  93: Py_BytesMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:1129
  94: __libc_start_main
  95: 0x0000563ec7c34bc2
  96: 0xffffffffffffffff


terminate called after throwing an instance of 'tvm::runtime::InternalError'
  what():  [13:58:09] /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61: CUDAError: cuModuleUnload(module_[i]) failed with error: CUDA_ERROR_MISALIGNED_ADDRESS
Stack trace:
  0: tvm::runtime::CUDAModuleNode::~CUDAModuleNode()
        at /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61
  1: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::CUDAModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  2: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  3: tvm::runtime::ObjectPtr<tvm::runtime::Object>::reset()
        at /home/yj/tvm/include/tvm/runtime/object.h:451
  4: tvm::runtime::ObjectPtr<tvm::runtime::Object>::~ObjectPtr()
        at /home/yj/tvm/include/tvm/runtime/object.h:400
  5: tvm::runtime::ObjectRef::~ObjectRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:511
  6: tvm::runtime::Module::~Module()
        at /home/yj/tvm/include/tvm/runtime/module.h:48
  7: void std::_Destroy<tvm::runtime::Module>(tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:98
  8: void std::_Destroy_aux<false>::__destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:108
  9: void std::_Destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:137
  10: void std::_Destroy<tvm::runtime::Module*, tvm::runtime::Module>(tvm::runtime::Module*, tvm::runtime::Module*, std::allocator<tvm::runtime::Module>&)
        at /usr/include/c++/9/bits/stl_construct.h:206
  11: std::vector<tvm::runtime::Module, std::allocator<tvm::runtime::Module> >::~vector()
        at /usr/include/c++/9/bits/stl_vector.h:677
  12: tvm::runtime::ModuleNode::~ModuleNode()
        at /home/yj/tvm/include/tvm/runtime/module.h:114
  13: tvm::runtime::LibraryModuleNode::~LibraryModuleNode()
        at /home/yj/tvm/src/runtime/library_module.cc:38
  14: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::LibraryModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  15: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  16: tvm::runtime::ObjectInternal::ObjectFree(void*)
        at /home/yj/tvm/src/runtime/object_internal.h:56
  17: TVMObjectFree
        at /home/yj/tvm/src/runtime/object.cc:249
  18: TVMModFree
        at /home/yj/tvm/src/runtime/c_runtime_api.cc:422
  19: ffi_call_unix64
  20: ffi_call_int
  21: _call_function_pointer
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:920
  22: _ctypes_callproc
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:1263
  23: PyCFuncPtr_call
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/_ctypes.c:4201
  24: _PyObject_MakeTpCall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:191
  25: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:116
  26: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  27: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  28: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3487
  29: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  30: function_code_fastcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:330
  31: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:367
  32: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  33: PyObject_CallOneArg
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:188
  34: call_unbound_noarg
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1527
  35: slot_tp_finalize
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:7007
  36: PyObject_CallFinalizer
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:195
  37: PyObject_CallFinalizerFromDealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:213
  38: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1273
  39: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  40: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  41: frame_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/frameobject.c:582
  42: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  43: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  44: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  45: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:167
  46: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  47: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  48: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  49: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:166
  50: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  51: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  52: BaseException_clear
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:78
  53: BaseException_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:88
  54: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1351
  55: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  56: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  57: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  58: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:1498
  59: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  60: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  61: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  62: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  63: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  64: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  65: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  66: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  67: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  68: _PyEval_EvalCodeWithName
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4359
  69: PyEval_EvalCodeEx
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4375
  70: PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:826
  71: builtin_exec_impl.isra.17
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/bltinmodule.c:1026
  72: builtin_exec
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/clinic/bltinmodule.c.h:396
  73: cfunction_vectorcall_FASTCALL
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/methodobject.c:430
  74: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  75: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  76: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  77: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  78: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  79: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  80: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  81: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  82: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  83: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  84: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  85: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  86: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  87: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  88: PyVectorcall_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:231
  89: _PyObject_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:266
  90: pymain_run_module
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:297
  91: pymain_run_python
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:598
  92: Py_RunMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:683
  93: Py_BytesMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:1129
  94: __libc_start_main
  95: 0x000055aee2db3bc2
  96: 0xffffffffffffffff


[13:58:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"
[13:58:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:58:26] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:58:32] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #46: "fused_image_resize2d_concatenate"
[13:58:32] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:58:33] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:58:40] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"
[13:58:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:59:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[13:59:24] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"
[13:59:25] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[13:59:55] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
terminate called after throwing an instance of 'tvm::runtime::InternalError'
  what():  [14:00:01] /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61: CUDAError: cuModuleUnload(module_[i]) failed with error: CUDA_ERROR_MISALIGNED_ADDRESS
Stack trace:
  0: tvm::runtime::CUDAModuleNode::~CUDAModuleNode()
        at /home/yj/tvm/src/runtime/cuda/cuda_module.cc:61
  1: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::CUDAModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  2: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  3: tvm::runtime::ObjectPtr<tvm::runtime::Object>::reset()
        at /home/yj/tvm/include/tvm/runtime/object.h:451
  4: tvm::runtime::ObjectPtr<tvm::runtime::Object>::~ObjectPtr()
        at /home/yj/tvm/include/tvm/runtime/object.h:400
  5: tvm::runtime::ObjectRef::~ObjectRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:511
  6: tvm::runtime::Module::~Module()
        at /home/yj/tvm/include/tvm/runtime/module.h:48
  7: void std::_Destroy<tvm::runtime::Module>(tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:98
  8: void std::_Destroy_aux<false>::__destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:108
  9: void std::_Destroy<tvm::runtime::Module*>(tvm::runtime::Module*, tvm::runtime::Module*)
        at /usr/include/c++/9/bits/stl_construct.h:137
  10: void std::_Destroy<tvm::runtime::Module*, tvm::runtime::Module>(tvm::runtime::Module*, tvm::runtime::Module*, std::allocator<tvm::runtime::Module>&)
        at /usr/include/c++/9/bits/stl_construct.h:206
  11: std::vector<tvm::runtime::Module, std::allocator<tvm::runtime::Module> >::~vector()
        at /usr/include/c++/9/bits/stl_vector.h:677
  12: tvm::runtime::ModuleNode::~ModuleNode()
        at /home/yj/tvm/include/tvm/runtime/module.h:114
  13: tvm::runtime::LibraryModuleNode::~LibraryModuleNode()
        at /home/yj/tvm/src/runtime/library_module.cc:38
  14: tvm::runtime::SimpleObjAllocator::Handler<tvm::runtime::LibraryModuleNode>::Deleter_(tvm::runtime::Object*)
        at /home/yj/tvm/include/tvm/runtime/memory.h:138
  15: tvm::runtime::Object::DecRef()
        at /home/yj/tvm/include/tvm/runtime/object.h:805
  16: tvm::runtime::ObjectInternal::ObjectFree(void*)
        at /home/yj/tvm/src/runtime/object_internal.h:56
  17: TVMObjectFree
        at /home/yj/tvm/src/runtime/object.cc:249
  18: TVMModFree
        at /home/yj/tvm/src/runtime/c_runtime_api.cc:422
  19: ffi_call_unix64
  20: ffi_call_int
  21: _call_function_pointer
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:920
  22: _ctypes_callproc
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/callproc.c:1263
  23: PyCFuncPtr_call
        at /usr/local/src/conda/python-3.9.7/Modules/_ctypes/_ctypes.c:4201
  24: _PyObject_MakeTpCall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:191
  25: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:116
  26: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  27: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  28: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3487
  29: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  30: function_code_fastcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:330
  31: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:367
  32: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  33: PyObject_CallOneArg
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:188
  34: call_unbound_noarg
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1527
  35: slot_tp_finalize
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:7007
  36: PyObject_CallFinalizer
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:195
  37: PyObject_CallFinalizerFromDealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:213
  38: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1273
  39: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  40: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  41: frame_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/frameobject.c:582
  42: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  43: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  44: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  45: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:167
  46: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  47: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  48: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  49: tb_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/traceback.c:166
  50: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  51: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  52: BaseException_clear
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:78
  53: BaseException_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/exceptions.c:88
  54: subtype_dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/typeobject.c:1351
  55: _Py_Dealloc
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/object.c:2209
  56: _Py_DECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:430
  57: _Py_XDECREF
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/object.h:497
  58: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:1498
  59: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  60: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  61: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  62: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  63: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  64: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  65: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  66: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  67: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  68: _PyEval_EvalCodeWithName
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4359
  69: PyEval_EvalCodeEx
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4375
  70: PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:826
  71: builtin_exec_impl.isra.17
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/bltinmodule.c:1026
  72: builtin_exec
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/clinic/bltinmodule.c.h:396
  73: cfunction_vectorcall_FASTCALL
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/methodobject.c:430
  74: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  75: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  76: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  77: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  78: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  79: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  80: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  81: _PyObject_VectorcallTstate
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:118
  82: PyObject_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/cpython/abstract.h:127
  83: call_function
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:5075
  84: _PyEval_EvalFrameDefault
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:3518
  85: _PyEval_EvalFrame
        at /tmp/build/80754af9/python-split_1631797238431/work/Include/internal/pycore_ceval.h:40
  86: _PyEval_EvalCode
        at /tmp/build/80754af9/python-split_1631797238431/work/Python/ceval.c:4327
  87: _PyFunction_Vectorcall
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:396
  88: PyVectorcall_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:231
  89: _PyObject_Call
        at /tmp/build/80754af9/python-split_1631797238431/work/Objects/call.c:266
  90: pymain_run_module
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:297
  91: pymain_run_python
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:598
  92: Py_RunMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:683
  93: Py_BytesMain
        at /tmp/build/80754af9/python-split_1631797238431/work/Modules/main.c:1129
  94: __libc_start_main
  95: 0x0000562519cf2bc2
  96: 0xffffffffffffffff


[14:00:02] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"
[14:00:04] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[14:00:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[14:00:39] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #50: "fused_image_resize2d_concatenate_1"
[14:00:39] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[14:00:40] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[14:00:50] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"
[14:00:52] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[14:01:23] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[14:01:29] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"
[14:01:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[14:02:07] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[14:02:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #53: "fused_nn_conv2d_add_2"
[14:02:18] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[14:02:48] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[14:02:54] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"
[14:02:55] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[14:02:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #0: GFLOPs: 162.8744. Time: 2.4491 ms. Best GFLOPs: 162.8744
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #1: GFLOPs: 151.3330. Time: 2.6359 ms. Best GFLOPs: 162.8744
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #2: GFLOPs: 1182.9589. Time: 0.3372 ms. Best GFLOPs: 1182.9589
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #3: GFLOPs: 196.1114. Time: 2.0340 ms. Best GFLOPs: 1182.9589
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #4: GFLOPs: 343.3546. Time: 1.1618 ms. Best GFLOPs: 1182.9589
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #5: GFLOPs: 18.2975. Time: 21.8005 ms. Best GFLOPs: 1182.9589
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #6: GFLOPs: 128.5036. Time: 3.1041 ms. Best GFLOPs: 1182.9589
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #7: GFLOPs: 761.4330. Time: 0.5239 ms. Best GFLOPs: 1182.9589
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #8: GFLOPs: 119.0564. Time: 3.3505 ms. Best GFLOPs: 1182.9589
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #9: GFLOPs: 1883.1598. Time: 0.2118 ms. Best GFLOPs: 1883.1598
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #10: GFLOPs: 598.9468. Time: 0.6660 ms. Best GFLOPs: 1883.1598
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #11: GFLOPs: 132.1562. Time: 3.0184 ms. Best GFLOPs: 1883.1598
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #12: GFLOPs: 35.0406. Time: 11.3838 ms. Best GFLOPs: 1883.1598
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #13: GFLOPs: 496.1287. Time: 0.8040 ms. Best GFLOPs: 1883.1598
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #14: GFLOPs: 274.3145. Time: 1.4541 ms. Best GFLOPs: 1883.1598
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #15: GFLOPs: 616.9921. Time: 0.6465 ms. Best GFLOPs: 1883.1598
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #16: GFLOPs: 943.7720. Time: 0.4227 ms. Best GFLOPs: 1883.1598
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #17: GFLOPs: 1178.3096. Time: 0.3385 ms. Best GFLOPs: 1883.1598
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #18: GFLOPs: 1391.8899. Time: 0.2866 ms. Best GFLOPs: 1883.1598
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #19: GFLOPs: 911.9832. Time: 0.4374 ms. Best GFLOPs: 1883.1598
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #20: GFLOPs: 53.6376. Time: 7.4368 ms. Best GFLOPs: 1883.1598
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #21: GFLOPs: 86.2217. Time: 4.6264 ms. Best GFLOPs: 1883.1598
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #22: GFLOPs: 812.5365. Time: 0.4909 ms. Best GFLOPs: 1883.1598
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #23: GFLOPs: 206.2622. Time: 1.9339 ms. Best GFLOPs: 1883.1598
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #24: GFLOPs: 1242.5707. Time: 0.3210 ms. Best GFLOPs: 1883.1598
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #25: GFLOPs: 15.3708. Time: 25.9514 ms. Best GFLOPs: 1883.1598
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #26: GFLOPs: 1065.6977. Time: 0.3743 ms. Best GFLOPs: 1883.1598
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #27: GFLOPs: 27.4174. Time: 14.5490 ms. Best GFLOPs: 1883.1598
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #28: GFLOPs: 69.8591. Time: 5.7100 ms. Best GFLOPs: 1883.1598
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #29: GFLOPs: 43.6883. Time: 9.1305 ms. Best GFLOPs: 1883.1598
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #30: GFLOPs: 496.2225. Time: 0.8039 ms. Best GFLOPs: 1883.1598
[14:03:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_nn_conv2d_add_nn_leaky_relu"] Trial #31: GFLOPs: 170.0945. Time: 2.3451 ms. Best GFLOPs: 1883.1598
/home/yj/anaconda3/lib/python3.9/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html
  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)
[14:03:06] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #0: "fused_nn_conv2d_add_nn_leaky_relu"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |            N/A |          N/A |                   N/A |      0 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |            N/A |          N/A |                   N/A |      0 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                             fused_transpose |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                           fused_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |            N/A |          N/A |                   N/A |      0 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |            N/A |          N/A |                   N/A |      0 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 32
Total latency (us): 211.822

[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #0: GFLOPs: 5.8931. Time: 14.9840 ms. Best GFLOPs: 5.8931
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #1: GFLOPs: 472.3585. Time: 0.1869 ms. Best GFLOPs: 472.3585
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #2: GFLOPs: 25.2897. Time: 3.4916 ms. Best GFLOPs: 472.3585
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #3: GFLOPs: 606.5706. Time: 0.1456 ms. Best GFLOPs: 606.5706
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #4: GFLOPs: 9.5206. Time: 9.2748 ms. Best GFLOPs: 606.5706
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #5: GFLOPs: 41.6423. Time: 2.1205 ms. Best GFLOPs: 606.5706
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #6: GFLOPs: 681.3792. Time: 0.1296 ms. Best GFLOPs: 681.3792
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #7: GFLOPs: 528.7990. Time: 0.1670 ms. Best GFLOPs: 681.3792
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #8: GFLOPs: 91.4247. Time: 0.9658 ms. Best GFLOPs: 681.3792
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #9: GFLOPs: 361.8979. Time: 0.2440 ms. Best GFLOPs: 681.3792
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #10: GFLOPs: 27.0520. Time: 3.2641 ms. Best GFLOPs: 681.3792
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #11: GFLOPs: 246.1033. Time: 0.3588 ms. Best GFLOPs: 681.3792
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #12: GFLOPs: 937.5241. Time: 0.0942 ms. Best GFLOPs: 937.5241
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #13: GFLOPs: 871.5125. Time: 0.1013 ms. Best GFLOPs: 937.5241
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #14: GFLOPs: 2.4371. Time: 36.2317 ms. Best GFLOPs: 937.5241
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #15: GFLOPs: 90.3159. Time: 0.9777 ms. Best GFLOPs: 937.5241
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #16: GFLOPs: 279.6242. Time: 0.3158 ms. Best GFLOPs: 937.5241
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #17: GFLOPs: 189.3327. Time: 0.4664 ms. Best GFLOPs: 937.5241
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #18: GFLOPs: 251.0849. Time: 0.3517 ms. Best GFLOPs: 937.5241
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #19: GFLOPs: 133.1043. Time: 0.6634 ms. Best GFLOPs: 937.5241
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #20: GFLOPs: 331.5058. Time: 0.2664 ms. Best GFLOPs: 937.5241
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #21: GFLOPs: 109.7003. Time: 0.8049 ms. Best GFLOPs: 937.5241
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #22: GFLOPs: 130.7404. Time: 0.6754 ms. Best GFLOPs: 937.5241
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #23: GFLOPs: 128.3521. Time: 0.6880 ms. Best GFLOPs: 937.5241
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #24: GFLOPs: 59.5397. Time: 1.4831 ms. Best GFLOPs: 937.5241
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #25: GFLOPs: 126.2956. Time: 0.6992 ms. Best GFLOPs: 937.5241
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #26: GFLOPs: 489.2424. Time: 0.1805 ms. Best GFLOPs: 937.5241
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #27: GFLOPs: 330.0613. Time: 0.2675 ms. Best GFLOPs: 937.5241
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #28: GFLOPs: 200.3265. Time: 0.4408 ms. Best GFLOPs: 937.5241
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #29: GFLOPs: 593.4487. Time: 0.1488 ms. Best GFLOPs: 937.5241
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #30: GFLOPs: 118.1030. Time: 0.7477 ms. Best GFLOPs: 937.5241
[14:03:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_nn_conv2d_add"] Trial #31: GFLOPs: 297.9492. Time: 0.2964 ms. Best GFLOPs: 937.5241
[14:03:07] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #1: "fused_nn_conv2d_add"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |            N/A |          N/A |                   N/A |      0 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                             fused_transpose |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                           fused_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |            N/A |          N/A |                   N/A |      0 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |            N/A |          N/A |                   N/A |      0 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 64
Total latency (us): 306.008

[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #0: GFLOPs: 0.0000. Time: 0.0033 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #1: GFLOPs: 0.0000. Time: 0.0033 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #2: GFLOPs: 0.0000. Time: 0.0023 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #3: GFLOPs: 0.0000. Time: 0.0027 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #4: GFLOPs: 0.0000. Time: 0.0032 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #5: GFLOPs: 0.0000. Time: 0.0036 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #6: GFLOPs: 0.0000. Time: 0.0036 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #7: GFLOPs: 0.0000. Time: 0.0034 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #8: GFLOPs: 0.0000. Time: 0.0035 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #9: GFLOPs: 0.0000. Time: 0.0034 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #10: GFLOPs: 0.0000. Time: 0.0034 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #11: GFLOPs: 0.0000. Time: 0.0038 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #12: GFLOPs: 0.0000. Time: 0.0047 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #13: GFLOPs: 0.0000. Time: 0.0043 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #14: GFLOPs: 0.0000. Time: 0.0041 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #15: GFLOPs: 0.0000. Time: 0.0039 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #16: GFLOPs: 0.0000. Time: 0.0036 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #17: GFLOPs: 0.0000. Time: 0.0034 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #18: GFLOPs: 0.0000. Time: 0.0031 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #19: GFLOPs: 0.0000. Time: 0.0031 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #20: GFLOPs: 0.0000. Time: 0.0045 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #21: GFLOPs: 0.0000. Time: 0.0036 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #22: GFLOPs: 0.0000. Time: 0.0038 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #23: GFLOPs: 0.0000. Time: 0.0039 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #24: GFLOPs: 0.0000. Time: 0.0038 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #25: GFLOPs: 0.0000. Time: 0.0040 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #26: GFLOPs: 0.0000. Time: 0.0038 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #27: GFLOPs: 0.0000. Time: 0.0038 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #28: GFLOPs: 0.0000. Time: 0.0042 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #29: GFLOPs: 0.0000. Time: 0.0041 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #30: GFLOPs: 0.0000. Time: 0.0036 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"] Trial #31: GFLOPs: 0.0000. Time: 0.0035 ms. Best GFLOPs: 0.0000
[14:03:07] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |            N/A |          N/A |                   N/A |      0 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                             fused_transpose |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                           fused_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |            N/A |          N/A |                   N/A |      0 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |            N/A |          N/A |                   N/A |      0 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 96
Total latency (us): 308.261

[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #0: Error in building: LocalRunner: An exception occurred
Subprocess terminated
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 52, 52), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 256, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw_local = T.alloc_buffer([1, 256, 26, 26], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 53, 53], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([256, 128, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(1, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(16, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i2_4_init, i3_4_init in T.grid(13, 26):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(256, i0_1_i1_1_i2_1_i3_1_fused // 2 * 32 + i0_2_i1_2_i2_2_i3_2_fused)
                            yy = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused % 2 * 13 + i2_4_init)
                            xx = T.axis.spatial(26, i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(128, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(88):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(128, i4_0)
                                    v2 = T.axis.spatial(53, (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) // 53)
                                    v3 = T.axis.spatial(53, (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 53)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1 < 2809)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 53 and 1 <= v3 and v3 < 53, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(18):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(256, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 9)
                                        v1 = T.axis.spatial(128, i4_0)
                                        v2 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 9 // 3)
                                        v3 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 3)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 1, 1, 13, 26):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(256, i0_1_i1_1_i2_1_i3_1_fused // 2 * 32 + i0_2_i1_2_i2_2_i3_2_fused)
                                yy = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused % 2 * 13 + i2_4)
                                xx, rc, ry, rx = T.axis.remap("SRRR", [i3_4, i4_0, i5_2, i6_2])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 1, 13, 26):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(256, i0_1_i1_1_i2_1_i3_1_fused // 2 * 32 + i0_2_i1_2_i2_2_i3_2_fused + ax1)
                            v2 = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused % 2 * 13 + ax2)
                            v3 = T.axis.spatial(26, ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                            T.writes(T_leaky_relu[v0, v1, v2, v3])
                            T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 8, 32, 1, 1])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 2, 1, 1, 13])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 26])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[128, 1, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109 = sch.split(loop=l107, factors=[None, 32])
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b87)
l117, l118, l119 = sch.split(loop=l116, factors=[None, 32, 4])
sch.vectorize(loop=l119)
sch.bind(loop=l118, thread_axis="threadIdx.x")
b120 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b120, ann_key="meta_schedule.unroll_explicit")
b121, b122, b123, b124 = sch.get_child_blocks(b120)
l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b121)
sch.annotate(block_or_loop=l125, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l125, ann_key="pragma_unroll_explicit", ann_val=1)
l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l133, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l133, ann_key="pragma_unroll_explicit", ann_val=1)
l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l142, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l142, ann_key="pragma_unroll_explicit", ann_val=1)
l162, l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
b169 = sch.get_block(name="conv2d_nchw", func_name="main")
l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b169)
b190 = sch.decompose_reduction(block=b169, loop=l173)
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #1: GFLOPs: 1985.9610. Time: 0.2009 ms. Best GFLOPs: 1985.9610
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #2: GFLOPs: 191.3012. Time: 2.0861 ms. Best GFLOPs: 1985.9610
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #3: GFLOPs: 384.9280. Time: 1.0367 ms. Best GFLOPs: 1985.9610
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #4: GFLOPs: 162.7483. Time: 2.4521 ms. Best GFLOPs: 1985.9610
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #5: GFLOPs: 2077.5825. Time: 0.1921 ms. Best GFLOPs: 2077.5825
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #6: GFLOPs: 571.8305. Time: 0.6979 ms. Best GFLOPs: 2077.5825
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #7: GFLOPs: 358.5039. Time: 1.1131 ms. Best GFLOPs: 2077.5825
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #8: GFLOPs: 2480.6822. Time: 0.1609 ms. Best GFLOPs: 2480.6822
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #9: GFLOPs: 1081.3127. Time: 0.3691 ms. Best GFLOPs: 2480.6822
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #10: Error in building: LocalRunner: An exception occurred
Subprocess terminated
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 52, 52), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 256, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw_local = T.alloc_buffer([1, 256, 26, 26], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 53, 53], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([256, 128, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(1, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(13, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i1_3_init, i2_3_init, i3_3_init, i1_4_init in T.grid(4, 2, 13, 4):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(256, i0_2_i1_2_i2_2_i3_2_fused // 2 * 16 + i1_3_init * 4 + i1_4_init)
                            yy = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused * 2 + i2_3_init)
                            xx = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused % 2 * 13 + i3_3_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(128, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(88):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(128, i4_0)
                                    v2 = T.axis.spatial(53, (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) // 53)
                                    v3 = T.axis.spatial(53, (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 53)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1 < 2809)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 53 and 1 <= v3 and v3 < 53, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(18):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(256, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 9)
                                        v1 = T.axis.spatial(128, i4_0)
                                        v2 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 9 // 3)
                                        v3 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 3)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 4, 2, 13, 1, 3, 3, 1, 4, 1, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(256, i0_2_i1_2_i2_2_i3_2_fused // 2 * 16 + i1_3 * 4 + i1_4)
                                yy = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused * 2 + i2_3)
                                xx = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused % 2 * 13 + i3_3)
                                rc, ry, rx = T.axis.remap("RRR", [i4_0, i5_2, i6_2])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 16, 2, 13):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(256, i0_2_i1_2_i2_2_i3_2_fused // 2 * 16 + ax1)
                            v2 = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused * 2 + ax2)
                            v3 = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused % 2 * 13 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                            T.writes(T_leaky_relu[v0, v1, v2, v3])
                            T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 1, 16, 4, 4])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 13, 1, 2, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 2, 13, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[128, 1, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109 = sch.split(loop=l107, factors=[None, 32])
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b87)
l117, l118, l119 = sch.split(loop=l116, factors=[None, 32, 4])
sch.vectorize(loop=l119)
sch.bind(loop=l118, thread_axis="threadIdx.x")
b120 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b120, ann_key="meta_schedule.unroll_explicit")
b121, b122, b123, b124 = sch.get_child_blocks(b120)
l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b121)
sch.annotate(block_or_loop=l125, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l125, ann_key="pragma_unroll_explicit", ann_val=1)
l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l133, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l133, ann_key="pragma_unroll_explicit", ann_val=1)
l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l142, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l142, ann_key="pragma_unroll_explicit", ann_val=1)
l162, l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
b169 = sch.get_block(name="conv2d_nchw", func_name="main")
l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b169)
b190 = sch.decompose_reduction(block=b169, loop=l173)
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #11: GFLOPs: 72.8370. Time: 5.4789 ms. Best GFLOPs: 2480.6822
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #12: GFLOPs: 1372.5609. Time: 0.2907 ms. Best GFLOPs: 2480.6822
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #13: GFLOPs: 263.5790. Time: 1.5140 ms. Best GFLOPs: 2480.6822
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #14: GFLOPs: 867.6587. Time: 0.4599 ms. Best GFLOPs: 2480.6822
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #15: GFLOPs: 926.3890. Time: 0.4308 ms. Best GFLOPs: 2480.6822
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #16: GFLOPs: 1556.6745. Time: 0.2564 ms. Best GFLOPs: 2480.6822
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #17: GFLOPs: 1412.7251. Time: 0.2825 ms. Best GFLOPs: 2480.6822
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #18: Error in building: LocalRunner: An exception occurred
Subprocess terminated
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 52, 52), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 256, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw_local = T.alloc_buffer([1, 256, 26, 26], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 53, 53], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([256, 128, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(13, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(4, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i1_3_init, i3_3_init, i1_4_init in T.grid(2, 13, 4):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(256, i0_1_i1_1_i2_1_i3_1_fused // 2 * 128 + i0_2_i1_2_i2_2_i3_2_fused // 2 * 8 + i1_3_init * 4 + i1_4_init)
                            yy = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused * 2 + i0_1_i1_1_i2_1_i3_1_fused % 2)
                            xx = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused % 2 * 13 + i3_3_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(64, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(17):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(128, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 530 // 265)
                                    v2 = T.axis.spatial(53, i0_0_i1_0_i2_0_i3_0_fused * 4 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 265 // 53)
                                    v3 = T.axis.spatial(53, (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 53)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1 < 530)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 53 and 1 <= v3 and v3 < 53, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(36):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(256, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 18)
                                        v1 = T.axis.spatial(128, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 18 // 9)
                                        v2 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 9 // 3)
                                        v3 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 3)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(2, 1, 3, 1, 2, 1, 13, 1, 3, 1, 1, 4, 1, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(256, i0_1_i1_1_i2_1_i3_1_fused // 2 * 128 + i0_2_i1_2_i2_2_i3_2_fused // 2 * 8 + i1_3 * 4 + i1_4)
                                yy = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused * 2 + i0_1_i1_1_i2_1_i3_1_fused % 2)
                                xx = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused % 2 * 13 + i3_3)
                                rc = T.axis.reduce(128, i4_0 * 2 + i4_1)
                                ry, rx = T.axis.remap("RR", [i5_2, i6_1])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 8, 1, 13):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(256, i0_1_i1_1_i2_1_i3_1_fused // 2 * 128 + i0_2_i1_2_i2_2_i3_2_fused // 2 * 8 + ax1)
                            v2 = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused * 2 + i0_1_i1_1_i2_1_i3_1_fused % 2 + ax2)
                            v3 = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused % 2 * 13 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                            T.writes(T_leaky_relu[v0, v1, v2, v3])
                            T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 2, 16, 2, 4])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[13, 2, 1, 1, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 2, 13, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[64, 2, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109 = sch.split(loop=l107, factors=[None, 32])
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b87)
l117, l118, l119 = sch.split(loop=l116, factors=[None, 32, 4])
sch.vectorize(loop=l119)
sch.bind(loop=l118, thread_axis="threadIdx.x")
b120 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b120, ann_key="meta_schedule.unroll_explicit")
b121, b122, b123, b124 = sch.get_child_blocks(b120)
l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b121)
sch.annotate(block_or_loop=l125, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l125, ann_key="pragma_unroll_explicit", ann_val=1)
l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l133, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l133, ann_key="pragma_unroll_explicit", ann_val=1)
l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l142, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l142, ann_key="pragma_unroll_explicit", ann_val=1)
l162, l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
b169 = sch.get_block(name="conv2d_nchw", func_name="main")
l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b169)
b190 = sch.decompose_reduction(block=b169, loop=l173)
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #19: GFLOPs: 48.8289. Time: 8.1728 ms. Best GFLOPs: 2480.6822
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #20: GFLOPs: 35.7957. Time: 11.1485 ms. Best GFLOPs: 2480.6822
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #21: GFLOPs: 406.2319. Time: 0.9824 ms. Best GFLOPs: 2480.6822
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #22: GFLOPs: 1853.0233. Time: 0.2154 ms. Best GFLOPs: 2480.6822
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #23: GFLOPs: 566.0762. Time: 0.7050 ms. Best GFLOPs: 2480.6822
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #24: GFLOPs: 882.0238. Time: 0.4524 ms. Best GFLOPs: 2480.6822
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #25: GFLOPs: 47.5762. Time: 8.3880 ms. Best GFLOPs: 2480.6822
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #26: GFLOPs: 93.5562. Time: 4.2655 ms. Best GFLOPs: 2480.6822
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #27: GFLOPs: 145.8761. Time: 2.7357 ms. Best GFLOPs: 2480.6822
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #28: GFLOPs: 2088.0352. Time: 0.1911 ms. Best GFLOPs: 2480.6822
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #29: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 52, 52), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 256, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw_local = T.alloc_buffer([1, 256, 26, 26], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 53, 53], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([256, 128, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(8, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(1, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i2_3_init, i3_3_init, i1_4_init, i3_4_init in T.grid(13, 2, 2, 13):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused * 32 + i0_2_i1_2_i2_2_i3_2_fused // 2 * 2 + i1_4_init)
                            yy = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused % 2 * 13 + i2_3_init)
                            xx = T.axis.spatial(26, i3_3_init * 13 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(32, 1, 3):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(169):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(2):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(128, i4_0 * 4 + ((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 2 + ax0_ax1_ax2_ax3_fused_2) % 10812 // 2703)
                                        v2 = T.axis.spatial(53, ((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 2 + ax0_ax1_ax2_ax3_fused_2) % 2703 // 51)
                                        v3 = T.axis.spatial(53, i6_0 + ((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 2 + ax0_ax1_ax2_ax3_fused_2) % 51)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 2 + ax0_ax1_ax2_ax3_fused_2 < 10812)
                                        T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 53 and 1 <= v3 and v3 < 53, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(3):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused * 32 + (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 12)
                                        v1 = T.axis.spatial(128, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 12 // 3)
                                        v2 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 3)
                                        v3 = T.axis.spatial(3, i6_0)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 1, 13, 2, 4, 3, 1, 1, 2, 1, 13):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused * 32 + i0_2_i1_2_i2_2_i3_2_fused // 2 * 2 + i1_4)
                                yy = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused % 2 * 13 + i2_3)
                                xx = T.axis.spatial(26, i3_3 * 13 + i3_4)
                                rc = T.axis.reduce(128, i4_0 * 4 + i4_2)
                                ry, rx = T.axis.remap("RR", [i5_2, i6_0])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 2, 13, 26):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused * 32 + i0_2_i1_2_i2_2_i3_2_fused // 2 * 2 + ax1)
                            v2 = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused % 2 * 13 + ax2)
                            v3 = T.axis.spatial(26, ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                            T.writes(T_leaky_relu[v0, v1, v2, v3])
                            T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[8, 1, 16, 1, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 1, 2, 13, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 2, 13])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[32, 1, 4])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109, l110 = sch.split(loop=l107, factors=[None, 32, 2])
sch.vectorize(loop=l110)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b87)
l118, l119, l120 = sch.split(loop=l117, factors=[None, 32, 4])
sch.vectorize(loop=l120)
sch.bind(loop=l119, thread_axis="threadIdx.x")
b121 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b121, ann_key="meta_schedule.unroll_explicit")
b122, b123, b124, b125 = sch.get_child_blocks(b121)
l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l126, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l126, ann_key="pragma_unroll_explicit", ann_val=1)
l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l135, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l135, ann_key="pragma_unroll_explicit", ann_val=1)
l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161, l162, l163 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l144, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l144, ann_key="pragma_unroll_explicit", ann_val=1)
l164, l165, l166, l167, l168, l169, l170 = sch.get_loops(block=b125)
sch.annotate(block_or_loop=l164, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l164, ann_key="pragma_unroll_explicit", ann_val=1)
b171 = sch.get_block(name="conv2d_nchw", func_name="main")
l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189, l190, l191 = sch.get_loops(block=b171)
b192 = sch.decompose_reduction(block=b171, loop=l175)
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #30: GFLOPs: 1528.6201. Time: 0.2611 ms. Best GFLOPs: 2480.6822
[14:03:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"] Trial #31: GFLOPs: 37.3455. Time: 10.6858 ms. Best GFLOPs: 2480.6822
[14:03:08] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                             fused_transpose |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                           fused_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |            N/A |          N/A |                   N/A |      0 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |            N/A |          N/A |                   N/A |      0 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 128
Total latency (us): 469.131

[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #0: GFLOPs: 58.9890. Time: 2.9953 ms. Best GFLOPs: 58.9890
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #1: GFLOPs: 3140.4327. Time: 0.0563 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #2: GFLOPs: 21.2707. Time: 8.3067 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #3: GFLOPs: 693.4051. Time: 0.2548 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #4: GFLOPs: 1841.1499. Time: 0.0960 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #5: GFLOPs: 527.7552. Time: 0.3348 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #6: GFLOPs: 1827.0725. Time: 0.0967 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #7: GFLOPs: 1477.4417. Time: 0.1196 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #8: GFLOPs: 450.8284. Time: 0.3919 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #9: GFLOPs: 1333.3009. Time: 0.1325 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #10: GFLOPs: 52.9869. Time: 3.3346 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #11: GFLOPs: 129.0106. Time: 1.3696 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #12: GFLOPs: 1551.6593. Time: 0.1139 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #13: GFLOPs: 77.7902. Time: 2.2714 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #14: GFLOPs: 295.8362. Time: 0.5973 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #15: GFLOPs: 209.9153. Time: 0.8417 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #16: GFLOPs: 1827.0313. Time: 0.0967 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #17: GFLOPs: 330.5221. Time: 0.5346 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #18: GFLOPs: 19.6567. Time: 8.9888 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #19: GFLOPs: 174.9954. Time: 1.0097 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #20: GFLOPs: 318.9282. Time: 0.5540 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #21: GFLOPs: 31.6908. Time: 5.5754 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #22: GFLOPs: 8.7415. Time: 20.2127 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #23: GFLOPs: 974.1789. Time: 0.1814 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #24: GFLOPs: 36.6517. Time: 4.8208 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #25: GFLOPs: 1296.5623. Time: 0.1363 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #26: GFLOPs: 559.4331. Time: 0.3158 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #27: GFLOPs: 242.3774. Time: 0.7290 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #28: GFLOPs: 44.6867. Time: 3.9540 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #29: GFLOPs: 1381.8879. Time: 0.1279 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #30: GFLOPs: 800.9104. Time: 0.2206 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_nn_conv2d_add_1"] Trial #31: GFLOPs: 16.2064. Time: 10.9024 ms. Best GFLOPs: 3140.4327
[14:03:09] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #4: "fused_nn_conv2d_add_1"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                             fused_transpose |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                           fused_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |            N/A |          N/A |                   N/A |      0 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |            N/A |          N/A |                   N/A |      0 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 160
Total latency (us): 525.394

[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #0: GFLOPs: 0.0000. Time: 0.0049 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #1: GFLOPs: 0.0000. Time: 0.0050 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #2: GFLOPs: 0.0000. Time: 0.0071 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #3: GFLOPs: 0.0000. Time: 0.0049 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #4: GFLOPs: 0.0000. Time: 0.0050 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #5: GFLOPs: 0.0000. Time: 0.0096 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #6: GFLOPs: 0.0000. Time: 0.0097 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #7: GFLOPs: 0.0000. Time: 0.0089 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #8: GFLOPs: 0.0000. Time: 0.0066 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #9: GFLOPs: 0.0000. Time: 0.0086 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #10: GFLOPs: 0.0000. Time: 0.0079 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #11: GFLOPs: 0.0000. Time: 0.0066 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #12: GFLOPs: 0.0000. Time: 0.0080 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #13: GFLOPs: 0.0000. Time: 0.0087 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #14: GFLOPs: 0.0000. Time: 0.0092 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #15: GFLOPs: 0.0000. Time: 0.0103 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #16: GFLOPs: 0.0000. Time: 0.0082 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #17: GFLOPs: 0.0000. Time: 0.0105 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #18: GFLOPs: 0.0000. Time: 0.0098 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #19: GFLOPs: 0.0000. Time: 0.0094 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #20: GFLOPs: 0.0000. Time: 0.0107 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #21: GFLOPs: 0.0000. Time: 0.0090 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #22: GFLOPs: 0.0000. Time: 0.0102 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #23: GFLOPs: 0.0000. Time: 0.0081 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #24: GFLOPs: 0.0000. Time: 0.0104 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #25: GFLOPs: 0.0000. Time: 0.0096 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #26: GFLOPs: 0.0000. Time: 0.0092 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #27: GFLOPs: 0.0000. Time: 0.0103 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #28: GFLOPs: 0.0000. Time: 0.0076 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #29: GFLOPs: 0.0000. Time: 0.0104 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #30: GFLOPs: 0.0000. Time: 0.0095 ms. Best GFLOPs: 0.0000
[14:03:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"] Trial #31: GFLOPs: 0.0000. Time: 0.0099 ms. Best GFLOPs: 0.0000
[14:03:10] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                             fused_transpose |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                           fused_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |            N/A |          N/A |                   N/A |      0 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |            N/A |          N/A |                   N/A |      0 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 192
Total latency (us): 530.331

[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #0: GFLOPs: 376.8213. Time: 0.0057 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #1: GFLOPs: 206.4882. Time: 0.0105 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #2: GFLOPs: 213.2511. Time: 0.0101 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #3: GFLOPs: 231.1883. Time: 0.0094 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #4: GFLOPs: 179.7210. Time: 0.0120 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #5: GFLOPs: 215.1085. Time: 0.0101 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #6: GFLOPs: 178.7654. Time: 0.0121 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #7: GFLOPs: 189.9204. Time: 0.0114 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #8: GFLOPs: 169.1208. Time: 0.0128 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #9: GFLOPs: 166.7615. Time: 0.0130 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #10: GFLOPs: 177.8701. Time: 0.0122 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #11: GFLOPs: 202.9090. Time: 0.0107 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #12: GFLOPs: 189.4142. Time: 0.0114 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #13: GFLOPs: 180.6131. Time: 0.0120 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #14: GFLOPs: 173.6572. Time: 0.0125 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #15: GFLOPs: 180.7815. Time: 0.0120 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #16: GFLOPs: 182.0333. Time: 0.0119 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #17: GFLOPs: 178.8559. Time: 0.0121 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #18: GFLOPs: 179.5917. Time: 0.0120 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #19: GFLOPs: 202.8096. Time: 0.0107 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #20: GFLOPs: 192.1957. Time: 0.0113 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #21: GFLOPs: 166.5821. Time: 0.0130 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #22: GFLOPs: 178.7044. Time: 0.0121 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #23: GFLOPs: 208.3699. Time: 0.0104 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #24: GFLOPs: 165.5172. Time: 0.0131 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #25: GFLOPs: 180.3766. Time: 0.0120 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #26: GFLOPs: 179.9756. Time: 0.0120 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #27: GFLOPs: 207.4343. Time: 0.0104 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #28: GFLOPs: 181.6380. Time: 0.0119 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #29: GFLOPs: 179.2609. Time: 0.0121 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #30: GFLOPs: 207.6661. Time: 0.0104 ms. Best GFLOPs: 376.8213
[14:03:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_nn_max_pool2d"] Trial #31: GFLOPs: 209.6338. Time: 0.0103 ms. Best GFLOPs: 376.8213
[14:03:11] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #6: "fused_nn_max_pool2d"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                             fused_transpose |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                           fused_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |            N/A |          N/A |                   N/A |      0 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |            N/A |          N/A |                   N/A |      0 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 224
Total latency (us): 536.072

[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #0: GFLOPs: 23.5144. Time: 0.2981 ms. Best GFLOPs: 23.5144
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #1: GFLOPs: 164.6495. Time: 0.0426 ms. Best GFLOPs: 164.6495
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #2: GFLOPs: 216.4625. Time: 0.0324 ms. Best GFLOPs: 216.4625
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #3: GFLOPs: 33.3661. Time: 0.2101 ms. Best GFLOPs: 216.4625
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #4: GFLOPs: 19.3474. Time: 0.3623 ms. Best GFLOPs: 216.4625
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #5: GFLOPs: 178.7217. Time: 0.0392 ms. Best GFLOPs: 216.4625
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #6: GFLOPs: 185.9979. Time: 0.0377 ms. Best GFLOPs: 216.4625
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #7: GFLOPs: 21.8275. Time: 0.3211 ms. Best GFLOPs: 216.4625
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #8: GFLOPs: 23.1057. Time: 0.3033 ms. Best GFLOPs: 216.4625
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #9: GFLOPs: 26.3979. Time: 0.2655 ms. Best GFLOPs: 216.4625
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #10: GFLOPs: 147.3781. Time: 0.0476 ms. Best GFLOPs: 216.4625
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #11: GFLOPs: 193.7010. Time: 0.0362 ms. Best GFLOPs: 216.4625
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #12: GFLOPs: 194.7530. Time: 0.0360 ms. Best GFLOPs: 216.4625
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #13: GFLOPs: 14.7302. Time: 0.4758 ms. Best GFLOPs: 216.4625
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #14: GFLOPs: 170.2294. Time: 0.0412 ms. Best GFLOPs: 216.4625
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #15: GFLOPs: 14.0026. Time: 0.5005 ms. Best GFLOPs: 216.4625
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #16: GFLOPs: 191.4411. Time: 0.0366 ms. Best GFLOPs: 216.4625
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #17: GFLOPs: 7.3499. Time: 0.9536 ms. Best GFLOPs: 216.4625
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #18: GFLOPs: 30.2761. Time: 0.2315 ms. Best GFLOPs: 216.4625
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #19: GFLOPs: 17.5005. Time: 0.4005 ms. Best GFLOPs: 216.4625
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #20: GFLOPs: 8.9617. Time: 0.7821 ms. Best GFLOPs: 216.4625
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #21: GFLOPs: 176.9091. Time: 0.0396 ms. Best GFLOPs: 216.4625
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #22: GFLOPs: 151.5058. Time: 0.0463 ms. Best GFLOPs: 216.4625
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #23: GFLOPs: 4.6410. Time: 1.5102 ms. Best GFLOPs: 216.4625
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #24: GFLOPs: 6.7970. Time: 1.0312 ms. Best GFLOPs: 216.4625
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #25: GFLOPs: 236.9291. Time: 0.0296 ms. Best GFLOPs: 236.9291
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #26: GFLOPs: 7.1365. Time: 0.9821 ms. Best GFLOPs: 236.9291
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #27: GFLOPs: 19.3686. Time: 0.3619 ms. Best GFLOPs: 236.9291
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #28: GFLOPs: 16.9089. Time: 0.4145 ms. Best GFLOPs: 236.9291
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #29: GFLOPs: 30.5448. Time: 0.2295 ms. Best GFLOPs: 236.9291
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #30: GFLOPs: 4.6553. Time: 1.5055 ms. Best GFLOPs: 236.9291
[14:03:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_max_pool2d_1"] Trial #31: GFLOPs: 15.0927. Time: 0.4644 ms. Best GFLOPs: 236.9291
[14:03:11] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #7: "fused_nn_max_pool2d_1"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                           fused_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |            N/A |          N/A |                   N/A |      0 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |            N/A |          N/A |                   N/A |      0 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 256
Total latency (us): 565.654

[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #0: GFLOPs: 0.0000. Time: 0.0094 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #1: GFLOPs: 0.0000. Time: 0.0069 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #2: GFLOPs: 0.0000. Time: 0.0081 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #3: GFLOPs: 0.0000. Time: 0.0067 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #4: GFLOPs: 0.0000. Time: 0.0067 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #5: GFLOPs: 0.0000. Time: 0.0067 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #6: GFLOPs: 0.0000. Time: 0.0068 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #7: GFLOPs: 0.0000. Time: 0.0067 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #8: GFLOPs: 0.0000. Time: 0.0068 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #9: GFLOPs: 0.0000. Time: 0.0069 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #10: GFLOPs: 0.0000. Time: 0.0128 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #11: GFLOPs: 0.0000. Time: 0.0141 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #12: GFLOPs: 0.0000. Time: 0.0100 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #13: GFLOPs: 0.0000. Time: 0.0131 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #14: GFLOPs: 0.0000. Time: 0.0155 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #15: GFLOPs: 0.0000. Time: 0.0144 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #16: GFLOPs: 0.0000. Time: 0.0103 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #17: GFLOPs: 0.0000. Time: 0.0124 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #18: GFLOPs: 0.0000. Time: 0.0116 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #19: GFLOPs: 0.0000. Time: 0.0106 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #20: GFLOPs: 0.0000. Time: 0.0101 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #21: GFLOPs: 0.0000. Time: 0.0141 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #22: GFLOPs: 0.0000. Time: 0.0102 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #23: GFLOPs: 0.0000. Time: 0.0093 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #24: GFLOPs: 0.0000. Time: 0.0136 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #25: GFLOPs: 0.0000. Time: 0.0098 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #26: GFLOPs: 0.0000. Time: 0.0134 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #27: GFLOPs: 0.0000. Time: 0.0145 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #28: GFLOPs: 0.0000. Time: 0.0131 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #29: GFLOPs: 0.0000. Time: 0.0145 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #30: GFLOPs: 0.0000. Time: 0.0100 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_transpose"] Trial #31: GFLOPs: 0.0000. Time: 0.0125 ms. Best GFLOPs: 0.0000
[14:03:12] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #8: "fused_transpose"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                           fused_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |            N/A |          N/A |                   N/A |      0 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |            N/A |          N/A |                   N/A |      0 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 288
Total latency (us): 572.331

[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #0: GFLOPs: 731.8462. Time: 0.4313 ms. Best GFLOPs: 731.8462
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #1: GFLOPs: 590.2401. Time: 0.5348 ms. Best GFLOPs: 731.8462
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #2: GFLOPs: 542.2320. Time: 0.5821 ms. Best GFLOPs: 731.8462
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #3: GFLOPs: 697.3932. Time: 0.4526 ms. Best GFLOPs: 731.8462
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #4: GFLOPs: 98.7519. Time: 3.1964 ms. Best GFLOPs: 731.8462
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #5: GFLOPs: 49.1673. Time: 6.4200 ms. Best GFLOPs: 731.8462
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #6: GFLOPs: 46.3895. Time: 6.8044 ms. Best GFLOPs: 731.8462
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #7: GFLOPs: 439.6367. Time: 0.7180 ms. Best GFLOPs: 731.8462
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #8: GFLOPs: 52.6383. Time: 5.9967 ms. Best GFLOPs: 731.8462
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #9: GFLOPs: 655.1666. Time: 0.4818 ms. Best GFLOPs: 731.8462
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #10: GFLOPs: 582.3608. Time: 0.5420 ms. Best GFLOPs: 731.8462
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #11: GFLOPs: 78.5860. Time: 4.0167 ms. Best GFLOPs: 731.8462
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #12: GFLOPs: 104.4827. Time: 3.0211 ms. Best GFLOPs: 731.8462
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #13: GFLOPs: 264.3131. Time: 1.1942 ms. Best GFLOPs: 731.8462
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #14: GFLOPs: 325.8883. Time: 0.9686 ms. Best GFLOPs: 731.8462
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #15: GFLOPs: 132.4852. Time: 2.3826 ms. Best GFLOPs: 731.8462
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #16: GFLOPs: 173.8122. Time: 1.8161 ms. Best GFLOPs: 731.8462
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #17: GFLOPs: 165.1830. Time: 1.9109 ms. Best GFLOPs: 731.8462
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #18: GFLOPs: 755.1255. Time: 0.4180 ms. Best GFLOPs: 755.1255
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #19: GFLOPs: 812.1060. Time: 0.3887 ms. Best GFLOPs: 812.1060
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #20: GFLOPs: 867.4983. Time: 0.3639 ms. Best GFLOPs: 867.4983
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #21: GFLOPs: 411.5123. Time: 0.7671 ms. Best GFLOPs: 867.4983
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #22: GFLOPs: 723.5001. Time: 0.4363 ms. Best GFLOPs: 867.4983
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #23: GFLOPs: 1192.2380. Time: 0.2648 ms. Best GFLOPs: 1192.2380
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #24: GFLOPs: 226.2578. Time: 1.3951 ms. Best GFLOPs: 1192.2380
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #25: GFLOPs: 94.2195. Time: 3.3502 ms. Best GFLOPs: 1192.2380
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #26: GFLOPs: 986.4806. Time: 0.3200 ms. Best GFLOPs: 1192.2380
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #27: GFLOPs: 1361.3116. Time: 0.2319 ms. Best GFLOPs: 1361.3116
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #28: GFLOPs: 695.4813. Time: 0.4539 ms. Best GFLOPs: 1361.3116
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #29: GFLOPs: 1289.4696. Time: 0.2448 ms. Best GFLOPs: 1361.3116
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #30: GFLOPs: 1126.4313. Time: 0.2802 ms. Best GFLOPs: 1361.3116
[14:03:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"] Trial #31: GFLOPs: 64.9350. Time: 4.8611 ms. Best GFLOPs: 1361.3116
[14:03:13] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                           fused_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |            N/A |          N/A |                   N/A |      0 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |            N/A |          N/A |                   N/A |      0 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 320
Total latency (us): 804.206

[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #0: GFLOPs: 589.8127. Time: 2.7181 ms. Best GFLOPs: 589.8127
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #1: GFLOPs: 1197.3407. Time: 1.3390 ms. Best GFLOPs: 1197.3407
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #2: GFLOPs: 119.8009. Time: 13.3821 ms. Best GFLOPs: 1197.3407
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #3: GFLOPs: 382.1171. Time: 4.1955 ms. Best GFLOPs: 1197.3407
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #4: GFLOPs: 260.2480. Time: 6.1602 ms. Best GFLOPs: 1197.3407
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #5: GFLOPs: 887.6980. Time: 1.8060 ms. Best GFLOPs: 1197.3407
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #6: GFLOPs: 868.3488. Time: 1.8463 ms. Best GFLOPs: 1197.3407
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #7: GFLOPs: 3904.6945. Time: 0.4106 ms. Best GFLOPs: 3904.6945
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #8: GFLOPs: 657.9050. Time: 2.4368 ms. Best GFLOPs: 3904.6945
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #9: GFLOPs: 4858.9061. Time: 0.3299 ms. Best GFLOPs: 4858.9061
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #10: GFLOPs: 1453.8261. Time: 1.1027 ms. Best GFLOPs: 4858.9061
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #11: GFLOPs: 91.0468. Time: 17.6084 ms. Best GFLOPs: 4858.9061
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #12: GFLOPs: 1650.7925. Time: 0.9712 ms. Best GFLOPs: 4858.9061
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #13: GFLOPs: 172.7974. Time: 9.2779 ms. Best GFLOPs: 4858.9061
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #14: GFLOPs: 89.2016. Time: 17.9727 ms. Best GFLOPs: 4858.9061
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #15: GFLOPs: 271.8672. Time: 5.8970 ms. Best GFLOPs: 4858.9061
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #16: GFLOPs: 2583.5302. Time: 0.6205 ms. Best GFLOPs: 4858.9061
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #17: GFLOPs: 2469.6072. Time: 0.6492 ms. Best GFLOPs: 4858.9061
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #18: GFLOPs: 1327.0561. Time: 1.2081 ms. Best GFLOPs: 4858.9061
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #19: GFLOPs: 2244.0371. Time: 0.7144 ms. Best GFLOPs: 4858.9061
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #20: GFLOPs: 627.9575. Time: 2.5530 ms. Best GFLOPs: 4858.9061
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #21: GFLOPs: 198.2583. Time: 8.0864 ms. Best GFLOPs: 4858.9061
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #22: GFLOPs: 91.2466. Time: 17.5699 ms. Best GFLOPs: 4858.9061
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #23: GFLOPs: 686.2514. Time: 2.3362 ms. Best GFLOPs: 4858.9061
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #24: GFLOPs: 1405.6779. Time: 1.1405 ms. Best GFLOPs: 4858.9061
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #25: GFLOPs: 2269.9361. Time: 0.7063 ms. Best GFLOPs: 4858.9061
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #26: GFLOPs: 287.4060. Time: 5.5781 ms. Best GFLOPs: 4858.9061
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #27: GFLOPs: 80.5588. Time: 19.9009 ms. Best GFLOPs: 4858.9061
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #28: GFLOPs: 180.3409. Time: 8.8898 ms. Best GFLOPs: 4858.9061
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #29: GFLOPs: 205.8995. Time: 7.7863 ms. Best GFLOPs: 4858.9061
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #30: GFLOPs: 2790.0667. Time: 0.5746 ms. Best GFLOPs: 4858.9061
[14:03:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"] Trial #31: GFLOPs: 467.1903. Time: 3.4316 ms. Best GFLOPs: 4858.9061
[14:03:14] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                           fused_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |            N/A |          N/A |                   N/A |      0 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |            N/A |          N/A |                   N/A |      0 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 352
Total latency (us): 1134.15

[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #0: GFLOPs: 179.4144. Time: 1.0109 ms. Best GFLOPs: 179.4144
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #1: GFLOPs: 36.4151. Time: 4.9804 ms. Best GFLOPs: 179.4144
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #2: GFLOPs: 252.6496. Time: 0.7178 ms. Best GFLOPs: 252.6496
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #3: GFLOPs: 1173.3686. Time: 0.1546 ms. Best GFLOPs: 1173.3686
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #4: GFLOPs: 308.0033. Time: 0.5888 ms. Best GFLOPs: 1173.3686
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #5: GFLOPs: 214.5872. Time: 0.8452 ms. Best GFLOPs: 1173.3686
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #6: GFLOPs: 630.3036. Time: 0.2877 ms. Best GFLOPs: 1173.3686
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #7: GFLOPs: 83.3902. Time: 2.1749 ms. Best GFLOPs: 1173.3686
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #8: GFLOPs: 55.9288. Time: 3.2427 ms. Best GFLOPs: 1173.3686
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #9: GFLOPs: 1425.5750. Time: 0.1272 ms. Best GFLOPs: 1425.5750
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #10: GFLOPs: 460.1127. Time: 0.3942 ms. Best GFLOPs: 1425.5750
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #11: GFLOPs: 226.9040. Time: 0.7993 ms. Best GFLOPs: 1425.5750
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #12: GFLOPs: 524.7864. Time: 0.3456 ms. Best GFLOPs: 1425.5750
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #13: GFLOPs: 749.8607. Time: 0.2419 ms. Best GFLOPs: 1425.5750
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #14: GFLOPs: 1015.1793. Time: 0.1787 ms. Best GFLOPs: 1425.5750
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #15: GFLOPs: 30.6679. Time: 5.9138 ms. Best GFLOPs: 1425.5750
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #16: GFLOPs: 643.3227. Time: 0.2819 ms. Best GFLOPs: 1425.5750
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #17: GFLOPs: 321.5756. Time: 0.5640 ms. Best GFLOPs: 1425.5750
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #18: GFLOPs: 365.6628. Time: 0.4960 ms. Best GFLOPs: 1425.5750
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #19: GFLOPs: 142.9683. Time: 1.2686 ms. Best GFLOPs: 1425.5750
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #20: GFLOPs: 1172.3388. Time: 0.1547 ms. Best GFLOPs: 1425.5750
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #21: GFLOPs: 1670.6234. Time: 0.1086 ms. Best GFLOPs: 1670.6234
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #22: GFLOPs: 583.2860. Time: 0.3109 ms. Best GFLOPs: 1670.6234
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #23: GFLOPs: 772.8208. Time: 0.2347 ms. Best GFLOPs: 1670.6234
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #24: GFLOPs: 294.6521. Time: 0.6155 ms. Best GFLOPs: 1670.6234
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #25: GFLOPs: 944.2717. Time: 0.1921 ms. Best GFLOPs: 1670.6234
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #26: GFLOPs: 203.4407. Time: 0.8915 ms. Best GFLOPs: 1670.6234
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #27: GFLOPs: 112.6671. Time: 1.6097 ms. Best GFLOPs: 1670.6234
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #28: GFLOPs: 255.3363. Time: 0.7103 ms. Best GFLOPs: 1670.6234
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #29: GFLOPs: 1140.1220. Time: 0.1591 ms. Best GFLOPs: 1670.6234
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #30: GFLOPs: 80.7876. Time: 2.2449 ms. Best GFLOPs: 1670.6234
[14:03:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"] Trial #31: GFLOPs: 91.5166. Time: 1.9817 ms. Best GFLOPs: 1670.6234
[14:03:15] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                           fused_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |            N/A |          N/A |                   N/A |      0 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |            N/A |          N/A |                   N/A |      0 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 384
Total latency (us): 1242.71

[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #0: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 32, 208, 208), "float32"], placeholder_1: T.Buffer[(64, 32, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], placeholder_4: T.Buffer[(1, 64, 208, 208), "float32"], T_add: T.Buffer[(1, 64, 208, 208), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 64, 208, 208], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 32, 210, 210], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([64, 32, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(104, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(1, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i1_3_init, i2_3_init, i1_4_init, i2_4_init, i3_4_init in T.grid(2, 2, 2, 8, 13):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(64, i0_2_i1_2_i2_2_i3_2_fused // 2 * 4 + i1_3_init * 2 + i1_4_init)
                            yy = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused // 8 * 16 + i2_3_init * 8 + i2_4_init)
                            xx = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 8 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 13 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 32, 208, 208], "float32"], ["TENSOR", [64, 32, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(8, 3, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(56):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(32, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 1792 // 448)
                                    v2 = T.axis.spatial(210, i0_0_i1_0_i2_0_i3_0_fused // 8 * 16 + i5_0 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 448 // 28)
                                    v3 = T.axis.spatial(210, i0_0_i1_0_i2_0_i3_0_fused % 8 * 26 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 28)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 209 and 1 <= v3 and v3 < 209, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(6):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(64, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 12)
                                        v1 = T.axis.spatial(32, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 12 // 3)
                                        v2 = T.axis.spatial(3, i5_0)
                                        v3 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 3)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(4, 1, 3, 1, 2, 2, 1, 1, 1, 1, 1, 2, 8, 13):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(64, i0_2_i1_2_i2_2_i3_2_fused // 2 * 4 + i1_3 * 2 + i1_4)
                                yy = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused // 8 * 16 + i2_3 * 8 + i2_4)
                                xx = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 8 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 13 + i3_4)
                                rc = T.axis.reduce(32, i4_0 * 4 + i4_1)
                                ry, rx = T.axis.remap("RR", [i5_0, i6_1])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 32, 208, 208], "float32"], ["TENSOR", [64, 32, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 4, 16, 13):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(64, i0_2_i1_2_i2_2_i3_2_fused // 2 * 4 + ax1)
                            v2 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused // 8 * 16 + ax2)
                            v3 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 8 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 13 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(11):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(64, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 43264)
                        ax2 = T.axis.spatial(208, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 43264 // 208)
                        ax3 = T.axis.spatial(208, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 208)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 2768896)
                        T.reads(placeholder_4[ax0, ax1, ax2, ax3], conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_add[ax0, ax1, ax2, ax3])
                        T_add[ax0, ax1, ax2, ax3] = placeholder_4[ax0, ax1, ax2, ax3] + (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="T_add_2", func_name="main")
b8 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l9, l10, l11, l12, l13, l14, l15 = sch.get_loops(block=b1)
v16, v17, v18, v19, v20 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l21, l22, l23, l24, l25 = sch.split(loop=l9, factors=[v16, v17, v18, v19, v20])
v26, v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 1, 16, 2, 2])
l31, l32, l33, l34, l35 = sch.split(loop=l10, factors=[v26, v27, v28, v29, v30])
v36, v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[13, 1, 1, 2, 8])
l41, l42, l43, l44, l45 = sch.split(loop=l11, factors=[v36, v37, v38, v39, v40])
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l12, n=5, max_innermost_factor=64, decision=[8, 1, 2, 1, 13])
l51, l52, l53, l54, l55 = sch.split(loop=l12, factors=[v46, v47, v48, v49, v50])
v56, v57, v58 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[8, 4, 1])
l59, l60, l61 = sch.split(loop=l13, factors=[v56, v57, v58])
v62, v63, v64 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l65, l66, l67 = sch.split(loop=l14, factors=[v62, v63, v64])
v68, v69, v70 = sch.sample_perfect_tile(loop=l15, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l71, l72, l73 = sch.split(loop=l15, factors=[v68, v69, v70])
sch.reorder(l21, l31, l41, l51, l22, l32, l42, l52, l23, l33, l43, l53, l59, l65, l71, l60, l66, l72, l24, l34, l44, l54, l61, l67, l73, l25, l35, l45, l55)
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="blockIdx.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="vthread.x")
l76 = sch.fuse(l23, l33, l43, l53)
sch.bind(loop=l76, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b77 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b77, loop=l76, preserve_unit_loops=True)
b78 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b78, loop=l71, preserve_unit_loops=True)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b78)
l89 = sch.fuse(l85, l86, l87, l88)
v90 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b78, ann_key="meta_schedule.cooperative_fetch", ann_val=v90)
b91 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b91, loop=l71, preserve_unit_loops=True)
l92, l93, l94, l95, l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b91)
l102 = sch.fuse(l98, l99, l100, l101)
v103 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b91, ann_key="meta_schedule.cooperative_fetch", ann_val=v103)
sch.reverse_compute_inline(block=b7)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v104 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b8, ann_key="meta_schedule.unroll_explicit", ann_val=v104)
sch.enter_postproc()
sch.unannotate(block_or_loop=b78, ann_key="meta_schedule.cooperative_fetch")
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b78)
l112, l113 = sch.split(loop=l111, factors=[None, 32])
sch.bind(loop=l113, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b91, ann_key="meta_schedule.cooperative_fetch")
l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b91)
l121, l122, l123 = sch.split(loop=l120, factors=[None, 32, 4])
sch.vectorize(loop=l123)
sch.bind(loop=l122, thread_axis="threadIdx.x")
b124 = sch.get_block(name="T_multiply", func_name="main")
l125, l126, l127, l128 = sch.get_loops(block=b124)
l129 = sch.fuse(l125, l126, l127, l128)
l130, l131, l132 = sch.split(loop=l129, factors=[None, 256, 1024])
sch.reorder(l131, l132, l130)
sch.bind(loop=l131, thread_axis="blockIdx.x")
sch.bind(loop=l132, thread_axis="threadIdx.x")
b133 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b133, ann_key="meta_schedule.unroll_explicit")
b134, b135, b136, b137, b138 = sch.get_child_blocks(b133)
l139, l140, l141, l142, l143, l144, l145, l146 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l139, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l139, ann_key="pragma_unroll_explicit", ann_val=1)
l147, l148, l149, l150, l151, l152, l153, l154, l155 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l147, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l147, ann_key="pragma_unroll_explicit", ann_val=1)
l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174, l175 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l156, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l156, ann_key="pragma_unroll_explicit", ann_val=1)
l176, l177, l178, l179, l180, l181, l182 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l176, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l176, ann_key="pragma_unroll_explicit", ann_val=1)
l183, l184, l185 = sch.get_loops(block=b138)
sch.annotate(block_or_loop=l183, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l183, ann_key="pragma_unroll_explicit", ann_val=1)
b186 = sch.get_block(name="conv2d_nchw", func_name="main")
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b186)
b207 = sch.decompose_reduction(block=b186, loop=l190)
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #1: GFLOPs: 169.7556. Time: 9.4604 ms. Best GFLOPs: 169.7556
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #2: GFLOPs: 78.5712. Time: 20.4395 ms. Best GFLOPs: 169.7556
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #3: GFLOPs: 275.4380. Time: 5.8306 ms. Best GFLOPs: 275.4380
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #4: GFLOPs: 2306.4317. Time: 0.6963 ms. Best GFLOPs: 2306.4317
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #5: GFLOPs: 956.8489. Time: 1.6784 ms. Best GFLOPs: 2306.4317
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #6: GFLOPs: 81.7687. Time: 19.6403 ms. Best GFLOPs: 2306.4317
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #7: GFLOPs: 9.8816. Time: 162.5203 ms. Best GFLOPs: 2306.4317
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #8: GFLOPs: 1775.4363. Time: 0.9045 ms. Best GFLOPs: 2306.4317
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #9: GFLOPs: 84.6559. Time: 18.9704 ms. Best GFLOPs: 2306.4317
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #10: GFLOPs: 216.5598. Time: 7.4158 ms. Best GFLOPs: 2306.4317
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #11: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 32, 208, 208), "float32"], placeholder_1: T.Buffer[(64, 32, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], placeholder_4: T.Buffer[(1, 64, 208, 208), "float32"], T_add: T.Buffer[(1, 64, 208, 208), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 64, 208, 208], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 32, 210, 210], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([64, 32, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(52, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(16, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(64, thread="threadIdx.x"):
                    for i2_3_init, i1_4_init, i3_4_init in T.grid(2, 2, 13):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(64, i0_2_i1_2_i2_2_i3_2_fused // 2 * 2 + i1_4_init)
                            yy = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused * 4 + i0_1_i1_1_i2_1_i3_1_fused // 8 * 2 + i2_3_init)
                            xx = T.axis.spatial(208, i0_1_i1_1_i2_1_i3_1_fused % 8 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 13 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 32, 208, 208], "float32"], ["TENSOR", [64, 32, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(8, 1, 3):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(39):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(64, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(2):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(32, i4_0 * 4 + ((ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1) * 2 + ax0_ax1_ax2_ax3_fused_2) % 4992 // 1248)
                                        v2 = T.axis.spatial(210, i0_0_i1_0_i2_0_i3_0_fused * 4 + ((ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1) * 2 + ax0_ax1_ax2_ax3_fused_2) % 1248 // 208)
                                        v3 = T.axis.spatial(210, i6_0 + ((ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1) * 2 + ax0_ax1_ax2_ax3_fused_2) % 208)
                                        T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 209 and 1 <= v3 and v3 < 209, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(12):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(64, thread="threadIdx.x"):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(64, (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1) // 12)
                                    v1 = T.axis.spatial(32, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1) % 12 // 3)
                                    v2 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1) % 3)
                                    v3 = T.axis.spatial(3, i6_0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 3, 1, 1, 1, 2, 1, 4, 1, 1, 1, 2, 1, 13):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(64, i0_2_i1_2_i2_2_i3_2_fused // 2 * 2 + i1_4)
                                yy = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused * 4 + i0_1_i1_1_i2_1_i3_1_fused // 8 * 2 + i2_3)
                                xx = T.axis.spatial(208, i0_1_i1_1_i2_1_i3_1_fused % 8 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 13 + i3_4)
                                rc = T.axis.reduce(32, i4_0 * 4 + i4_2)
                                ry, rx = T.axis.remap("RR", [i5_1, i6_0])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 32, 208, 208], "float32"], ["TENSOR", [64, 32, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 2, 2, 13):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(64, i0_2_i1_2_i2_2_i3_2_fused // 2 * 2 + ax1)
                            v2 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused * 4 + i0_1_i1_1_i2_1_i3_1_fused // 8 * 2 + ax2)
                            v3 = T.axis.spatial(208, i0_1_i1_1_i2_1_i3_1_fused % 8 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 13 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(11):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(64, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 43264)
                        ax2 = T.axis.spatial(208, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 43264 // 208)
                        ax3 = T.axis.spatial(208, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 208)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 2768896)
                        T.reads(placeholder_4[ax0, ax1, ax2, ax3], conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_add[ax0, ax1, ax2, ax3])
                        T_add[ax0, ax1, ax2, ax3] = placeholder_4[ax0, ax1, ax2, ax3] + (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="T_add_2", func_name="main")
b8 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l9, l10, l11, l12, l13, l14, l15 = sch.get_loops(block=b1)
v16, v17, v18, v19, v20 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l21, l22, l23, l24, l25 = sch.split(loop=l9, factors=[v16, v17, v18, v19, v20])
v26, v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 1, 32, 1, 2])
l31, l32, l33, l34, l35 = sch.split(loop=l10, factors=[v26, v27, v28, v29, v30])
v36, v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[52, 2, 1, 2, 1])
l41, l42, l43, l44, l45 = sch.split(loop=l11, factors=[v36, v37, v38, v39, v40])
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l12, n=5, max_innermost_factor=64, decision=[1, 8, 2, 1, 13])
l51, l52, l53, l54, l55 = sch.split(loop=l12, factors=[v46, v47, v48, v49, v50])
v56, v57, v58 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[8, 1, 4])
l59, l60, l61 = sch.split(loop=l13, factors=[v56, v57, v58])
v62, v63, v64 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l65, l66, l67 = sch.split(loop=l14, factors=[v62, v63, v64])
v68, v69, v70 = sch.sample_perfect_tile(loop=l15, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l71, l72, l73 = sch.split(loop=l15, factors=[v68, v69, v70])
sch.reorder(l21, l31, l41, l51, l22, l32, l42, l52, l23, l33, l43, l53, l59, l65, l71, l60, l66, l72, l24, l34, l44, l54, l61, l67, l73, l25, l35, l45, l55)
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="blockIdx.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="vthread.x")
l76 = sch.fuse(l23, l33, l43, l53)
sch.bind(loop=l76, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b77 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b77, loop=l76, preserve_unit_loops=True)
b78 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b78, loop=l71, preserve_unit_loops=True)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b78)
l89 = sch.fuse(l85, l86, l87, l88)
v90 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b78, ann_key="meta_schedule.cooperative_fetch", ann_val=v90)
b91 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b91, loop=l71, preserve_unit_loops=True)
l92, l93, l94, l95, l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b91)
l102 = sch.fuse(l98, l99, l100, l101)
v103 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b91, ann_key="meta_schedule.cooperative_fetch", ann_val=v103)
sch.reverse_compute_inline(block=b7)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v104 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b8, ann_key="meta_schedule.unroll_explicit", ann_val=v104)
sch.enter_postproc()
sch.unannotate(block_or_loop=b78, ann_key="meta_schedule.cooperative_fetch")
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b78)
l112, l113, l114 = sch.split(loop=l111, factors=[None, 64, 2])
sch.vectorize(loop=l114)
sch.bind(loop=l113, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b91, ann_key="meta_schedule.cooperative_fetch")
l115, l116, l117, l118, l119, l120, l121 = sch.get_loops(block=b91)
l122, l123 = sch.split(loop=l121, factors=[None, 64])
sch.bind(loop=l123, thread_axis="threadIdx.x")
b124 = sch.get_block(name="T_multiply", func_name="main")
l125, l126, l127, l128 = sch.get_loops(block=b124)
l129 = sch.fuse(l125, l126, l127, l128)
l130, l131, l132 = sch.split(loop=l129, factors=[None, 256, 1024])
sch.reorder(l131, l132, l130)
sch.bind(loop=l131, thread_axis="blockIdx.x")
sch.bind(loop=l132, thread_axis="threadIdx.x")
b133 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b133, ann_key="meta_schedule.unroll_explicit")
b134, b135, b136, b137, b138 = sch.get_child_blocks(b133)
l139, l140, l141, l142, l143, l144, l145, l146, l147 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l139, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l139, ann_key="pragma_unroll_explicit", ann_val=1)
l148, l149, l150, l151, l152, l153, l154, l155 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l148, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l148, ann_key="pragma_unroll_explicit", ann_val=1)
l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174, l175 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l156, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l156, ann_key="pragma_unroll_explicit", ann_val=1)
l176, l177, l178, l179, l180, l181, l182 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l176, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l176, ann_key="pragma_unroll_explicit", ann_val=1)
l183, l184, l185 = sch.get_loops(block=b138)
sch.annotate(block_or_loop=l183, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l183, ann_key="pragma_unroll_explicit", ann_val=1)
b186 = sch.get_block(name="conv2d_nchw", func_name="main")
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b186)
b207 = sch.decompose_reduction(block=b186, loop=l190)
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #12: GFLOPs: 2763.1452. Time: 0.5812 ms. Best GFLOPs: 2763.1452
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #13: GFLOPs: 83.8689. Time: 19.1485 ms. Best GFLOPs: 2763.1452
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #14: GFLOPs: 2712.2158. Time: 0.5921 ms. Best GFLOPs: 2763.1452
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #15: GFLOPs: 4564.6346. Time: 0.3518 ms. Best GFLOPs: 4564.6346
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #16: Error in building: LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home/yj/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/yj/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 153, in _worker_func
    costs: List[float] = f_run_evaluator(
  File "/home/yj/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 379, in default_run_evaluator
    return run_evaluator_common(rt_mod, device, evaluator_config, repeated_args)
  File "/home/yj/tvm/python/tvm/meta_schedule/runner/utils.py", line 117, in run_evaluator_common
    profile_result = evaluator(*args)
  File "/home/yj/tvm/python/tvm/runtime/module.py", line 297, in evaluator
    blob = feval(*args)
  File "/home/yj/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  7: TVMFuncCall
        at /home/yj/tvm/src/runtime/c_runtime_api.cc:477
  6: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /home/yj/tvm/include/tvm/runtime/packed_func.h:1217
  5: Call
        at /home/yj/tvm/include/tvm/runtime/packed_func.h:1213
  4: operator()
        at /home/yj/tvm/src/runtime/rpc/rpc_module.cc:375
  3: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /home/yj/tvm/include/tvm/runtime/packed_func.h:1221
...
  1: Call
        at /home/yj/tvm/include/tvm/runtime/packed_func.h:1213
  0: operator()
        at /home/yj/tvm/src/runtime/library_module.cc:80
  4: TVMFuncCall
        at /home/yj/tvm/src/runtime/c_runtime_api.cc:477
  3: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /home/yj/tvm/include/tvm/runtime/packed_func.h:1217
  2: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::detail::PackFuncVoidAddr_<4, tvm::runtime::CUDAWrappedFunc>(tvm::runtime::CUDAWrappedFunc, std::vector<tvm::runtime::detail::ArgConvertCode, std::allocator<tvm::runtime::detail::ArgConvertCode> > const&)::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /home/yj/tvm/include/tvm/runtime/packed_func.h:1213
  1: tvm::runtime::detail::PackFuncVoidAddr_<4, tvm::runtime::CUDAWrappedFunc>(tvm::runtime::CUDAWrappedFunc, std::vector<tvm::runtime::detail::ArgConvertCode, std::allocator<tvm::runtime::detail::ArgConvertCode> > const&)::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /home/yj/tvm/src/runtime/cuda/../pack_args.h:183
  0: tvm::runtime::CUDAWrappedFunc::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*, void**) const
        at /home/yj/tvm/src/runtime/cuda/cuda_module.cc:190
  File "/home/yj/tvm/src/runtime/cuda/cuda_module.cc", line 190
  File "/home/yj/tvm/src/runtime/library_module.cc", line 80
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------

  Check failed: ret == 0 (-1 vs. 0) : TVMError: CUDALaunch Error: CUDA_ERROR_OUT_OF_MEMORY
 grid=(8,1,1),  block=(32,1,1)

# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 32, 208, 208), "float32"], placeholder_1: T.Buffer[(64, 32, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], placeholder_4: T.Buffer[(1, 64, 208, 208), "float32"], T_add: T.Buffer[(1, 64, 208, 208), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 64, 208, 208], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 32, 210, 210], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([64, 32, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(8, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(104, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i1_3_init, i2_4_init, i3_4_init in T.grid(2, 2, 26):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused // 4 * 32 + i0_2_i1_2_i2_2_i3_2_fused // 2 * 2 + i1_3_init)
                            yy = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 4 // 2 * 104 + i0_1_i1_1_i2_1_i3_1_fused // 2 * 2 + i2_4_init)
                            xx = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 2 * 104 + i0_1_i1_1_i2_1_i3_1_fused % 2 * 52 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 26 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 32, 208, 208], "float32"], ["TENSOR", [64, 32, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(32, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(88):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(32, i4_0 + 0)
                                        v2 = T.axis.spatial(210, i0_0_i1_0_i2_0_i3_0_fused % 4 // 2 * 104 + ((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 4 + ax0_ax1_ax2_ax3_fused_2) % 11236 // 106)
                                        v3 = T.axis.spatial(210, i0_0_i1_0_i2_0_i3_0_fused % 2 * 104 + ((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 4 + ax0_ax1_ax2_ax3_fused_2) % 106)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 4 + ax0_ax1_ax2_ax3_fused_2 < 11236)
                                        T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 209 and 1 <= v3 and v3 < 209, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(3):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(3):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused // 4 * 32 + (ax0_ax1_ax2_ax3_fused_0 * 96 + ax0_ax1_ax2_ax3_fused_1 * 3 + ax0_ax1_ax2_ax3_fused_2) // 9)
                                        v1 = T.axis.spatial(32, i4_0)
                                        v2 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 96 + ax0_ax1_ax2_ax3_fused_1 * 3 + ax0_ax1_ax2_ax3_fused_2) % 9 // 3)
                                        v3 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 96 + ax0_ax1_ax2_ax3_fused_1 * 3 + ax0_ax1_ax2_ax3_fused_2) % 3)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 3, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 26):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused // 4 * 32 + i0_2_i1_2_i2_2_i3_2_fused // 2 * 2 + i1_3)
                                yy = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 4 // 2 * 104 + i0_1_i1_1_i2_1_i3_1_fused // 2 * 2 + i2_4)
                                xx = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 2 * 104 + i0_1_i1_1_i2_1_i3_1_fused % 2 * 52 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 26 + i3_4)
                                rc, ry, rx = T.axis.remap("RRR", [i4_0, i5_1, i6_1])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 32, 208, 208], "float32"], ["TENSOR", [64, 32, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 2, 2, 26):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused // 4 * 32 + i0_2_i1_2_i2_2_i3_2_fused // 2 * 2 + ax1)
                            v2 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 4 // 2 * 104 + i0_1_i1_1_i2_1_i3_1_fused // 2 * 2 + ax2)
                            v3 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 2 * 104 + i0_1_i1_1_i2_1_i3_1_fused % 2 * 52 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 26 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(11):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(64, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 43264)
                        ax2 = T.axis.spatial(208, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 43264 // 208)
                        ax3 = T.axis.spatial(208, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 208)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 2768896)
                        T.reads(placeholder_4[ax0, ax1, ax2, ax3], conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_add[ax0, ax1, ax2, ax3])
                        T_add[ax0, ax1, ax2, ax3] = placeholder_4[ax0, ax1, ax2, ax3] + (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="T_add_2", func_name="main")
b8 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l9, l10, l11, l12, l13, l14, l15 = sch.get_loops(block=b1)
v16, v17, v18, v19, v20 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l21, l22, l23, l24, l25 = sch.split(loop=l9, factors=[v16, v17, v18, v19, v20])
v26, v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[2, 1, 16, 2, 1])
l31, l32, l33, l34, l35 = sch.split(loop=l10, factors=[v26, v27, v28, v29, v30])
v36, v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[2, 52, 1, 1, 2])
l41, l42, l43, l44, l45 = sch.split(loop=l11, factors=[v36, v37, v38, v39, v40])
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l12, n=5, max_innermost_factor=64, decision=[2, 2, 2, 1, 26])
l51, l52, l53, l54, l55 = sch.split(loop=l12, factors=[v46, v47, v48, v49, v50])
v56, v57, v58 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[32, 1, 1])
l59, l60, l61 = sch.split(loop=l13, factors=[v56, v57, v58])
v62, v63, v64 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l65, l66, l67 = sch.split(loop=l14, factors=[v62, v63, v64])
v68, v69, v70 = sch.sample_perfect_tile(loop=l15, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l71, l72, l73 = sch.split(loop=l15, factors=[v68, v69, v70])
sch.reorder(l21, l31, l41, l51, l22, l32, l42, l52, l23, l33, l43, l53, l59, l65, l71, l60, l66, l72, l24, l34, l44, l54, l61, l67, l73, l25, l35, l45, l55)
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="blockIdx.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="vthread.x")
l76 = sch.fuse(l23, l33, l43, l53)
sch.bind(loop=l76, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b77 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b77, loop=l76, preserve_unit_loops=True)
b78 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b78, loop=l71, preserve_unit_loops=True)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b78)
l89 = sch.fuse(l85, l86, l87, l88)
v90 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b78, ann_key="meta_schedule.cooperative_fetch", ann_val=v90)
b91 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b91, loop=l71, preserve_unit_loops=True)
l92, l93, l94, l95, l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b91)
l102 = sch.fuse(l98, l99, l100, l101)
v103 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b91, ann_key="meta_schedule.cooperative_fetch", ann_val=v103)
sch.reverse_compute_inline(block=b7)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v104 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b8, ann_key="meta_schedule.unroll_explicit", ann_val=v104)
sch.enter_postproc()
sch.unannotate(block_or_loop=b78, ann_key="meta_schedule.cooperative_fetch")
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b78)
l112, l113, l114 = sch.split(loop=l111, factors=[None, 32, 4])
sch.vectorize(loop=l114)
sch.bind(loop=l113, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b91, ann_key="meta_schedule.cooperative_fetch")
l115, l116, l117, l118, l119, l120, l121 = sch.get_loops(block=b91)
l122, l123, l124 = sch.split(loop=l121, factors=[None, 32, 3])
sch.vectorize(loop=l124)
sch.bind(loop=l123, thread_axis="threadIdx.x")
b125 = sch.get_block(name="T_multiply", func_name="main")
l126, l127, l128, l129 = sch.get_loops(block=b125)
l130 = sch.fuse(l126, l127, l128, l129)
l131, l132, l133 = sch.split(loop=l130, factors=[None, 256, 1024])
sch.reorder(l132, l133, l131)
sch.bind(loop=l132, thread_axis="blockIdx.x")
sch.bind(loop=l133, thread_axis="threadIdx.x")
b134 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b134, ann_key="meta_schedule.unroll_explicit")
b135, b136, b137, b138, b139 = sch.get_child_blocks(b134)
l140, l141, l142, l143, l144, l145, l146, l147, l148 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l140, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l140, ann_key="pragma_unroll_explicit", ann_val=1)
l149, l150, l151, l152, l153, l154, l155, l156, l157 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l149, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l149, ann_key="pragma_unroll_explicit", ann_val=1)
l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174, l175, l176, l177 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l158, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l158, ann_key="pragma_unroll_explicit", ann_val=1)
l178, l179, l180, l181, l182, l183, l184 = sch.get_loops(block=b138)
sch.annotate(block_or_loop=l178, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l178, ann_key="pragma_unroll_explicit", ann_val=1)
l185, l186, l187 = sch.get_loops(block=b139)
sch.annotate(block_or_loop=l185, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l185, ann_key="pragma_unroll_explicit", ann_val=1)
b188 = sch.get_block(name="conv2d_nchw", func_name="main")
l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b188)
b209 = sch.decompose_reduction(block=b188, loop=l192)
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #17: GFLOPs: 97.2113. Time: 16.5203 ms. Best GFLOPs: 4564.6346
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #18: GFLOPs: 368.2892. Time: 4.3606 ms. Best GFLOPs: 4564.6346
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #19: GFLOPs: 637.1881. Time: 2.5204 ms. Best GFLOPs: 4564.6346
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #20: GFLOPs: 327.7758. Time: 4.8996 ms. Best GFLOPs: 4564.6346
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #21: GFLOPs: 2892.8330. Time: 0.5552 ms. Best GFLOPs: 4564.6346
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #22: GFLOPs: 85.4780. Time: 18.7880 ms. Best GFLOPs: 4564.6346
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #23: GFLOPs: 4102.7104. Time: 0.3914 ms. Best GFLOPs: 4564.6346
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #24: GFLOPs: 2599.0095. Time: 0.6179 ms. Best GFLOPs: 4564.6346
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #25: GFLOPs: 1331.8337. Time: 1.2058 ms. Best GFLOPs: 4564.6346
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #26: GFLOPs: 64.3217. Time: 24.9676 ms. Best GFLOPs: 4564.6346
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #27: GFLOPs: 3891.0647. Time: 0.4127 ms. Best GFLOPs: 4564.6346
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #28: GFLOPs: 86.5621. Time: 18.5527 ms. Best GFLOPs: 4564.6346
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #29: GFLOPs: 94.5034. Time: 16.9937 ms. Best GFLOPs: 4564.6346
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #30: GFLOPs: 60.5323. Time: 26.5306 ms. Best GFLOPs: 4564.6346
[14:03:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"] Trial #31: GFLOPs: 1776.2848. Time: 0.9041 ms. Best GFLOPs: 4564.6346
[14:03:17] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |                                           fused_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |            N/A |          N/A |                   N/A |      0 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |            N/A |          N/A |                   N/A |      0 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 416
Total latency (us): 1594.54

[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #0: GFLOPs: 1385.7545. Time: 0.2618 ms. Best GFLOPs: 1385.7545
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #1: GFLOPs: 616.8198. Time: 0.5881 ms. Best GFLOPs: 1385.7545
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #2: GFLOPs: 1616.5903. Time: 0.2244 ms. Best GFLOPs: 1616.5903
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #3: GFLOPs: 1361.5179. Time: 0.2664 ms. Best GFLOPs: 1616.5903
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #4: GFLOPs: 12.3018. Time: 29.4856 ms. Best GFLOPs: 1616.5903
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #5: GFLOPs: 821.1760. Time: 0.4417 ms. Best GFLOPs: 1616.5903
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #6: GFLOPs: 15.9511. Time: 22.7399 ms. Best GFLOPs: 1616.5903
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #7: GFLOPs: 1063.0792. Time: 0.3412 ms. Best GFLOPs: 1616.5903
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #8: GFLOPs: 169.3537. Time: 2.1418 ms. Best GFLOPs: 1616.5903
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #9: GFLOPs: 1149.3799. Time: 0.3156 ms. Best GFLOPs: 1616.5903
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #10: GFLOPs: 433.9937. Time: 0.8358 ms. Best GFLOPs: 1616.5903
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #11: GFLOPs: 86.5568. Time: 4.1906 ms. Best GFLOPs: 1616.5903
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #12: GFLOPs: 149.5934. Time: 2.4247 ms. Best GFLOPs: 1616.5903
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #13: GFLOPs: 2259.7785. Time: 0.1605 ms. Best GFLOPs: 2259.7785
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #14: GFLOPs: 170.8386. Time: 2.1232 ms. Best GFLOPs: 2259.7785
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #15: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 208, 208), "float32"], placeholder_1: T.Buffer[(64, 64, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 64, 208, 208), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 64, 208, 208], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 64, 208, 208], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([64, 64, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(16, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(208, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(208, thread="threadIdx.x"):
                    for i2_3_init in T.serial(4):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused // 8 * 32 + i0_1_i1_1_i2_1_i3_1_fused // 52 * 8 + i0_2_i1_2_i2_2_i3_2_fused // 26)
                            yy = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 8 // 4 * 104 + i0_2_i1_2_i2_2_i3_2_fused % 26 * 4 + i2_3_init)
                            xx = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 4 * 52 + i0_1_i1_1_i2_1_i3_1_fused % 52)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 208, 208], "float32"], ["TENSOR", [64, 64, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(32, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(13):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(208, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(64, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 832 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 5408)
                                        v2 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 8 // 4 * 104 + (ax0_ax1_ax2_ax3_fused_0 * 832 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 5408 // 52)
                                        v3 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 4 * 52 + (ax0_ax1_ax2_ax3_fused_0 * 832 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 52)
                                        T.reads(placeholder[v0, v1, v2, v3])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(1):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(208, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(2):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused // 8 * 32 + (ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) // 2)
                                        v1 = T.axis.spatial(64, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 2)
                                        v2 = T.axis.spatial(1, 0)
                                        v3 = T.axis.spatial(1, 0)
                                        T.where(ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2 < 64)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 1, 4, 1, 2, 1, 1, 1, 1, 1, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused // 8 * 32 + i0_1_i1_1_i2_1_i3_1_fused // 52 * 8 + i0_2_i1_2_i2_2_i3_2_fused // 26)
                                yy = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 8 // 4 * 104 + i0_2_i1_2_i2_2_i3_2_fused % 26 * 4 + i2_3)
                                xx = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 4 * 52 + i0_1_i1_1_i2_1_i3_1_fused % 52)
                                rc = T.axis.reduce(64, i4_0 * 2 + i4_2)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 208, 208], "float32"], ["TENSOR", [64, 64, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 1, 4, 1):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused // 8 * 32 + i0_1_i1_1_i2_1_i3_1_fused // 52 * 8 + i0_2_i1_2_i2_2_i3_2_fused // 26 + ax1)
                            v2 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 8 // 4 * 104 + i0_2_i1_2_i2_2_i3_2_fused % 26 * 4 + ax2)
                            v3 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 4 * 52 + i0_1_i1_1_i2_1_i3_1_fused % 52 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(11):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(64, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 43264)
                        ax2 = T.axis.spatial(208, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 43264 // 208)
                        ax3 = T.axis.spatial(208, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 208)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 2768896)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[2, 4, 8, 1, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[2, 1, 26, 4, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[4, 52, 1, 1, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[32, 1, 2])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112, l113 = sch.split(loop=l110, factors=[None, 208, 4])
sch.vectorize(loop=l113)
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b90)
l121, l122, l123 = sch.split(loop=l120, factors=[None, 208, 2])
sch.vectorize(loop=l123)
sch.bind(loop=l122, thread_axis="threadIdx.x")
b124 = sch.get_block(name="T_multiply", func_name="main")
l125, l126, l127, l128 = sch.get_loops(block=b124)
l129 = sch.fuse(l125, l126, l127, l128)
l130, l131, l132 = sch.split(loop=l129, factors=[None, 256, 1024])
sch.reorder(l131, l132, l130)
sch.bind(loop=l131, thread_axis="blockIdx.x")
sch.bind(loop=l132, thread_axis="threadIdx.x")
b133 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b133, ann_key="meta_schedule.unroll_explicit")
b134, b135, b136, b137, b138 = sch.get_child_blocks(b133)
l139, l140, l141, l142, l143, l144, l145, l146, l147 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l139, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l139, ann_key="pragma_unroll_explicit", ann_val=1)
l148, l149, l150, l151, l152, l153, l154, l155, l156 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l148, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l148, ann_key="pragma_unroll_explicit", ann_val=1)
l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174, l175, l176 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l157, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l157, ann_key="pragma_unroll_explicit", ann_val=1)
l177, l178, l179, l180, l181, l182, l183 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l177, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l177, ann_key="pragma_unroll_explicit", ann_val=1)
l184, l185, l186 = sch.get_loops(block=b138)
sch.annotate(block_or_loop=l184, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l184, ann_key="pragma_unroll_explicit", ann_val=1)
b187 = sch.get_block(name="conv2d_nchw", func_name="main")
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b187)
b208 = sch.decompose_reduction(block=b187, loop=l191)
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #16: GFLOPs: 837.4889. Time: 0.4331 ms. Best GFLOPs: 2259.7785
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #17: GFLOPs: 1538.4411. Time: 0.2358 ms. Best GFLOPs: 2259.7785
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #18: GFLOPs: 310.1622. Time: 1.1695 ms. Best GFLOPs: 2259.7785
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #19: GFLOPs: 371.4885. Time: 0.9764 ms. Best GFLOPs: 2259.7785
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #20: GFLOPs: 177.6702. Time: 2.0416 ms. Best GFLOPs: 2259.7785
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #21: GFLOPs: 2065.1122. Time: 0.1756 ms. Best GFLOPs: 2259.7785
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #22: GFLOPs: 2302.5946. Time: 0.1575 ms. Best GFLOPs: 2302.5946
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #23: GFLOPs: 90.0198. Time: 4.0294 ms. Best GFLOPs: 2302.5946
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #24: GFLOPs: 1491.7901. Time: 0.2431 ms. Best GFLOPs: 2302.5946
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #25: GFLOPs: 283.5252. Time: 1.2793 ms. Best GFLOPs: 2302.5946
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #26: GFLOPs: 108.0071. Time: 3.3583 ms. Best GFLOPs: 2302.5946
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #27: GFLOPs: 42.9317. Time: 8.4489 ms. Best GFLOPs: 2302.5946
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #28: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 208, 208), "float32"], placeholder_1: T.Buffer[(64, 64, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 64, 208, 208), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 64, 208, 208], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 64, 208, 208], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([64, 64, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(64, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(1, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(64, thread="threadIdx.x"):
                    for i1_3_init, i3_3_init, i2_4_init in T.grid(2, 13, 26):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused // 16 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 8 * 2 + i1_3_init)
                            yy = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 16 // 2 * 26 + i2_4_init)
                            xx = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 2 * 104 + i0_2_i1_2_i2_2_i3_2_fused % 8 * 13 + i3_3_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 208, 208], "float32"], ["TENSOR", [64, 64, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(32, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(85):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(64, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(64, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1) // 2704)
                                    v2 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 16 // 2 * 26 + (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1) % 2704 // 104)
                                    v3 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 2 * 104 + (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1) % 104)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1 < 5408)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(1):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(64, thread="threadIdx.x"):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused // 16 * 16 + ax0_ax1_ax2_ax3_fused_1 // 2)
                                    v1 = T.axis.spatial(64, i4_0 * 2 + ax0_ax1_ax2_ax3_fused_1 % 2)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.where(ax0_ax1_ax2_ax3_fused_1 < 32)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 2, 1, 13, 2, 1, 1, 1, 1, 26, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused // 16 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 8 * 2 + i1_3)
                                yy = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 16 // 2 * 26 + i2_4)
                                xx = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 2 * 104 + i0_2_i1_2_i2_2_i3_2_fused % 8 * 13 + i3_3)
                                rc = T.axis.reduce(64, i4_0 * 2 + i4_2)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 208, 208], "float32"], ["TENSOR", [64, 64, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 2, 26, 13):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused // 16 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 8 * 2 + ax1)
                            v2 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 16 // 2 * 26 + ax2)
                            v3 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 2 * 104 + i0_2_i1_2_i2_2_i3_2_fused % 8 * 13 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(11):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(64, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 43264)
                        ax2 = T.axis.spatial(208, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 43264 // 208)
                        ax3 = T.axis.spatial(208, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 208)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 2768896)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[4, 1, 8, 2, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[8, 1, 1, 1, 26])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[2, 1, 8, 13, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[32, 1, 2])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112 = sch.split(loop=l110, factors=[None, 64])
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b90)
l120, l121 = sch.split(loop=l119, factors=[None, 64])
sch.bind(loop=l121, thread_axis="threadIdx.x")
b122 = sch.get_block(name="T_multiply", func_name="main")
l123, l124, l125, l126 = sch.get_loops(block=b122)
l127 = sch.fuse(l123, l124, l125, l126)
l128, l129, l130 = sch.split(loop=l127, factors=[None, 256, 1024])
sch.reorder(l129, l130, l128)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
b131 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b131, ann_key="meta_schedule.unroll_explicit")
b132, b133, b134, b135, b136 = sch.get_child_blocks(b131)
l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b132)
sch.annotate(block_or_loop=l137, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l137, ann_key="pragma_unroll_explicit", ann_val=1)
l145, l146, l147, l148, l149, l150, l151, l152 = sch.get_loops(block=b133)
sch.annotate(block_or_loop=l145, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l145, ann_key="pragma_unroll_explicit", ann_val=1)
l153, l154, l155, l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l153, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l153, ann_key="pragma_unroll_explicit", ann_val=1)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l173, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l173, ann_key="pragma_unroll_explicit", ann_val=1)
l180, l181, l182 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l180, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l180, ann_key="pragma_unroll_explicit", ann_val=1)
b183 = sch.get_block(name="conv2d_nchw", func_name="main")
l184, l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203 = sch.get_loops(block=b183)
b204 = sch.decompose_reduction(block=b183, loop=l187)
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #29: GFLOPs: 2229.1017. Time: 0.1627 ms. Best GFLOPs: 2302.5946
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #30: GFLOPs: 1956.3055. Time: 0.1854 ms. Best GFLOPs: 2302.5946
[14:03:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"] Trial #31: GFLOPs: 438.3230. Time: 0.8275 ms. Best GFLOPs: 2302.5946
[14:03:18] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |            N/A |          N/A |                   N/A |      0 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |            N/A |          N/A |                   N/A |      0 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 448
Total latency (us): 2067.13

[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #0: GFLOPs: 0.0000. Time: 0.1163 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #1: GFLOPs: 0.0000. Time: 0.1141 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #2: GFLOPs: 0.0000. Time: 0.1165 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #3: GFLOPs: 0.0000. Time: 0.1143 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #4: GFLOPs: 0.0000. Time: 0.2078 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #5: GFLOPs: 0.0000. Time: 0.1587 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #6: GFLOPs: 0.0000. Time: 0.1253 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #7: GFLOPs: 0.0000. Time: 0.1475 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #8: GFLOPs: 0.0000. Time: 0.2415 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #9: GFLOPs: 0.0000. Time: 0.1170 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #10: GFLOPs: 0.0000. Time: 0.1999 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #11: GFLOPs: 0.0000. Time: 0.1167 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #12: GFLOPs: 0.0000. Time: 0.1841 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #13: GFLOPs: 0.0000. Time: 0.1208 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #14: GFLOPs: 0.0000. Time: 0.2037 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #15: GFLOPs: 0.0000. Time: 0.2294 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #16: GFLOPs: 0.0000. Time: 0.1551 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #17: GFLOPs: 0.0000. Time: 0.2538 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #18: GFLOPs: 0.0000. Time: 0.1169 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #19: GFLOPs: 0.0000. Time: 0.1163 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #20: GFLOPs: 0.0000. Time: 0.2112 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #21: GFLOPs: 0.0000. Time: 0.1740 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #22: GFLOPs: 0.0000. Time: 0.1768 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #23: GFLOPs: 0.0000. Time: 0.1679 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #24: GFLOPs: 0.0000. Time: 0.1979 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #25: GFLOPs: 0.0000. Time: 0.1602 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #26: GFLOPs: 0.0000. Time: 0.2428 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #27: GFLOPs: 0.0000. Time: 0.2250 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #28: GFLOPs: 0.0000. Time: 0.2054 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #29: GFLOPs: 0.0000. Time: 0.2396 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #30: GFLOPs: 0.0000. Time: 0.1926 ms. Best GFLOPs: 0.0000
[14:03:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_concatenate"] Trial #31: GFLOPs: 0.0000. Time: 0.1729 ms. Best GFLOPs: 0.0000
[14:03:19] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #14: "fused_concatenate"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |            N/A |          N/A |                   N/A |      0 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |            N/A |          N/A |                   N/A |      0 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 480
Total latency (us): 2181.23

[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #0: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 208, 208), "float32"], placeholder_1: T.Buffer[(64, 128, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 64, 208, 208), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 64, 208, 208], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 64, 208, 208], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 208, 208], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([64, 128, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(52, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(208, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i1_4_init, i2_4_init, i3_4_init in T.grid(2, 2, 2):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused // 26 * 32 + i0_1_i1_1_i2_1_i3_1_fused // 104 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 4 * 2 + i1_4_init)
                            yy = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 26 // 2 * 16 + i0_1_i1_1_i2_1_i3_1_fused % 104 // 26 * 4 + i0_2_i1_2_i2_2_i3_2_fused % 4 // 2 * 2 + i2_4_init)
                            xx = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 2 * 104 + i0_1_i1_1_i2_1_i3_1_fused % 26 * 4 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 2 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 208, 208], "float32"], ["TENSOR", [64, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(32, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(104):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(2):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(128, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) // 1664)
                                        v2 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 26 // 2 * 16 + (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 1664 // 104)
                                        v3 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 2 * 104 + (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 104)
                                        T.reads(placeholder[v0, v1, v2, v3])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(2):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(2):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused // 26 * 32 + (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) // 4)
                                        v1 = T.axis.spatial(128, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 4)
                                        v2 = T.axis.spatial(1, 0)
                                        v3 = T.axis.spatial(1, 0)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused // 26 * 32 + i0_1_i1_1_i2_1_i3_1_fused // 104 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 4 * 2 + i1_4)
                                yy = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 26 // 2 * 16 + i0_1_i1_1_i2_1_i3_1_fused % 104 // 26 * 4 + i0_2_i1_2_i2_2_i3_2_fused % 4 // 2 * 2 + i2_4)
                                xx = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 2 * 104 + i0_1_i1_1_i2_1_i3_1_fused % 26 * 4 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 2 + i3_4)
                                rc = T.axis.reduce(128, i4_0 * 4 + i4_1)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 208, 208], "float32"], ["TENSOR", [64, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 2, 2, 2):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_fused // 26 * 32 + i0_1_i1_1_i2_1_i3_1_fused // 104 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 4 * 2 + ax1)
                            v2 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 26 // 2 * 16 + i0_1_i1_1_i2_1_i3_1_fused % 104 // 26 * 4 + i0_2_i1_2_i2_2_i3_2_fused % 4 // 2 * 2 + ax2)
                            v3 = T.axis.spatial(208, i0_0_i1_0_i2_0_i3_0_fused % 2 * 104 + i0_1_i1_1_i2_1_i3_1_fused % 26 * 4 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 2 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(11):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(64, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 43264)
                        ax2 = T.axis.spatial(208, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 43264 // 208)
                        ax3 = T.axis.spatial(208, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 208)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 2768896)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[2, 2, 8, 1, 2])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[13, 4, 2, 1, 2])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[2, 26, 2, 1, 2])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[32, 4, 1])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112, l113 = sch.split(loop=l110, factors=[None, 32, 2])
sch.vectorize(loop=l113)
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b90)
l121, l122, l123 = sch.split(loop=l120, factors=[None, 32, 2])
sch.vectorize(loop=l123)
sch.bind(loop=l122, thread_axis="threadIdx.x")
b124 = sch.get_block(name="T_multiply", func_name="main")
l125, l126, l127, l128 = sch.get_loops(block=b124)
l129 = sch.fuse(l125, l126, l127, l128)
l130, l131, l132 = sch.split(loop=l129, factors=[None, 256, 1024])
sch.reorder(l131, l132, l130)
sch.bind(loop=l131, thread_axis="blockIdx.x")
sch.bind(loop=l132, thread_axis="threadIdx.x")
b133 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b133, ann_key="meta_schedule.unroll_explicit")
b134, b135, b136, b137, b138 = sch.get_child_blocks(b133)
l139, l140, l141, l142, l143, l144, l145, l146, l147 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l139, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l139, ann_key="pragma_unroll_explicit", ann_val=1)
l148, l149, l150, l151, l152, l153, l154, l155, l156 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l148, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l148, ann_key="pragma_unroll_explicit", ann_val=1)
l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174, l175, l176 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l157, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l157, ann_key="pragma_unroll_explicit", ann_val=1)
l177, l178, l179, l180, l181, l182, l183 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l177, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l177, ann_key="pragma_unroll_explicit", ann_val=1)
l184, l185, l186 = sch.get_loops(block=b138)
sch.annotate(block_or_loop=l184, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l184, ann_key="pragma_unroll_explicit", ann_val=1)
b187 = sch.get_block(name="conv2d_nchw", func_name="main")
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b187)
b208 = sch.decompose_reduction(block=b187, loop=l191)
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #1: GFLOPs: 91.0455. Time: 7.8768 ms. Best GFLOPs: 91.0455
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #2: GFLOPs: 935.6137. Time: 0.7665 ms. Best GFLOPs: 935.6137
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #3: GFLOPs: 1881.6533. Time: 0.3811 ms. Best GFLOPs: 1881.6533
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #4: GFLOPs: 2608.1929. Time: 0.2750 ms. Best GFLOPs: 2608.1929
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #5: GFLOPs: 372.1997. Time: 1.9268 ms. Best GFLOPs: 2608.1929
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #6: GFLOPs: 94.7084. Time: 7.5721 ms. Best GFLOPs: 2608.1929
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #7: GFLOPs: 75.9886. Time: 9.4375 ms. Best GFLOPs: 2608.1929
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #8: GFLOPs: 80.3674. Time: 8.9233 ms. Best GFLOPs: 2608.1929
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #9: GFLOPs: 1200.0612. Time: 0.5976 ms. Best GFLOPs: 2608.1929
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #10: GFLOPs: 156.4345. Time: 4.5843 ms. Best GFLOPs: 2608.1929
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #11: GFLOPs: 2908.2808. Time: 0.2466 ms. Best GFLOPs: 2908.2808
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #12: GFLOPs: 120.9258. Time: 5.9304 ms. Best GFLOPs: 2908.2808
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #13: GFLOPs: 1531.3005. Time: 0.4683 ms. Best GFLOPs: 2908.2808
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #14: GFLOPs: 95.0816. Time: 7.5424 ms. Best GFLOPs: 2908.2808
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #15: GFLOPs: 3367.8870. Time: 0.2129 ms. Best GFLOPs: 3367.8870
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #16: GFLOPs: 1866.7385. Time: 0.3842 ms. Best GFLOPs: 3367.8870
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #17: GFLOPs: 361.7576. Time: 1.9824 ms. Best GFLOPs: 3367.8870
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #18: GFLOPs: 191.3491. Time: 3.7478 ms. Best GFLOPs: 3367.8870
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #19: GFLOPs: 85.8931. Time: 8.3493 ms. Best GFLOPs: 3367.8870
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #20: GFLOPs: 181.7391. Time: 3.9460 ms. Best GFLOPs: 3367.8870
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #21: GFLOPs: 1319.2383. Time: 0.5436 ms. Best GFLOPs: 3367.8870
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #22: GFLOPs: 358.2827. Time: 2.0016 ms. Best GFLOPs: 3367.8870
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #23: GFLOPs: 2012.2008. Time: 0.3564 ms. Best GFLOPs: 3367.8870
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #24: GFLOPs: 2156.4853. Time: 0.3326 ms. Best GFLOPs: 3367.8870
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #25: GFLOPs: 1609.9331. Time: 0.4454 ms. Best GFLOPs: 3367.8870
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #26: GFLOPs: 426.0736. Time: 1.6831 ms. Best GFLOPs: 3367.8870
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #27: GFLOPs: 109.9903. Time: 6.5201 ms. Best GFLOPs: 3367.8870
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #28: GFLOPs: 1481.5828. Time: 0.4840 ms. Best GFLOPs: 3367.8870
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #29: GFLOPs: 1562.4071. Time: 0.4590 ms. Best GFLOPs: 3367.8870
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #30: GFLOPs: 92.5791. Time: 7.7463 ms. Best GFLOPs: 3367.8870
[14:03:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"] Trial #31: GFLOPs: 1015.3138. Time: 0.7063 ms. Best GFLOPs: 3367.8870
[14:03:20] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |            N/A |          N/A |                   N/A |      0 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |            N/A |          N/A |                   N/A |      0 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 512
Total latency (us): 2394.17

[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #0: GFLOPs: 79.1851. Time: 20.1937 ms. Best GFLOPs: 79.1851
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #1: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 208, 208), "float32"], placeholder_1: T.Buffer[(128, 64, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 128, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 128, 104, 104], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 128, 104, 104], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 64, 209, 209], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([128, 64, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(4, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(104, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(52, thread="threadIdx.x"):
                    for i1_3_init, i1_4_init, i2_4_init, i3_4_init in T.grid(8, 2, 2, 2):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 13 * 16 + i1_3_init * 2 + i1_4_init)
                            yy = T.axis.spatial(104, i0_2_i1_2_i2_2_i3_2_fused * 2 + i2_4_init)
                            xx = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 26 + i0_1_i1_1_i2_1_i3_1_fused % 13 * 2 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 208, 208], "float32"], ["TENSOR", [128, 64, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(64, 3, 3):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(68):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(3):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(64, i4_0 + 0)
                                        v2 = T.axis.spatial(209, i5_0 + ((ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) * 3 + ax0_ax1_ax2_ax3_fused_2) % 10557 // 51)
                                        v3 = T.axis.spatial(209, i0_0_i1_0_i2_0_i3_0_fused * 52 + i6_0 + ((ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) * 3 + ax0_ax1_ax2_ax3_fused_2) % 51)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) * 3 + ax0_ax1_ax2_ax3_fused_2 < 10557)
                                        T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 209 and 1 <= v3 and v3 < 209, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(3):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(128, ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1)
                                    v1, v2, v3 = T.axis.remap("SSS", [i4_0, i5_0, i6_0])
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1 < 128)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 1, 2, 2, 2):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 13 * 16 + i1_3 * 2 + i1_4)
                                yy = T.axis.spatial(104, i0_2_i1_2_i2_2_i3_2_fused * 2 + i2_4)
                                xx = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 26 + i0_1_i1_1_i2_1_i3_1_fused % 13 * 2 + i3_4)
                                rc, ry, rx = T.axis.remap("RRR", [i4_0, i5_0, i6_0])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 208, 208], "float32"], ["TENSOR", [128, 64, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 16, 2, 2):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 13 * 16 + ax1)
                            v2 = T.axis.spatial(104, i0_2_i1_2_i2_2_i3_2_fused * 2 + ax2)
                            v3 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 26 + i0_1_i1_1_i2_1_i3_1_fused % 13 * 2 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(6):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(128, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 10816)
                        ax2 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 10816 // 104)
                        ax3 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 104)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 1384448)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 8, 1, 8, 2])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 1, 52, 1, 2])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[4, 13, 1, 1, 2])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[64, 1, 1])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112, l113 = sch.split(loop=l110, factors=[None, 52, 3])
sch.vectorize(loop=l113)
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b90)
l121, l122 = sch.split(loop=l120, factors=[None, 52])
sch.bind(loop=l122, thread_axis="threadIdx.x")
b123 = sch.get_block(name="T_multiply", func_name="main")
l124, l125, l126, l127 = sch.get_loops(block=b123)
l128 = sch.fuse(l124, l125, l126, l127)
l129, l130, l131 = sch.split(loop=l128, factors=[None, 256, 1024])
sch.reorder(l130, l131, l129)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
b132 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b132, ann_key="meta_schedule.unroll_explicit")
b133, b134, b135, b136, b137 = sch.get_child_blocks(b132)
l138, l139, l140, l141, l142, l143, l144, l145, l146 = sch.get_loops(block=b133)
sch.annotate(block_or_loop=l138, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l138, ann_key="pragma_unroll_explicit", ann_val=1)
l147, l148, l149, l150, l151, l152, l153, l154 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l147, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l147, ann_key="pragma_unroll_explicit", ann_val=1)
l155, l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l155, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l155, ann_key="pragma_unroll_explicit", ann_val=1)
l175, l176, l177, l178, l179, l180, l181 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l175, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l175, ann_key="pragma_unroll_explicit", ann_val=1)
l182, l183, l184 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l182, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l182, ann_key="pragma_unroll_explicit", ann_val=1)
b185 = sch.get_block(name="conv2d_nchw", func_name="main")
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b185)
b206 = sch.decompose_reduction(block=b185, loop=l189)
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #2: Error in building: LocalRunner: An exception occurred
Subprocess terminated
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 208, 208), "float32"], placeholder_1: T.Buffer[(128, 64, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 128, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 128, 104, 104], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 128, 104, 104], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 64, 209, 209], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([128, 64, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(13, thread="blockIdx.x"):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(2, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(64, thread="threadIdx.x"):
                    for i1_3_init, i2_3_init, i3_3_init, i1_4_init, i2_4_init in T.grid(2, 52, 2, 2, 2):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(128, i0_2_i1_2_i2_2_i3_2_fused // 2 * 4 + i1_3_init * 2 + i1_4_init)
                            yy = T.axis.spatial(104, i2_3_init * 2 + i2_4_init)
                            xx = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 8 + i0_1_i1_1_i2_1_i3_1_fused * 4 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 2 + i3_3_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 208, 208], "float32"], ["TENSOR", [128, 64, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(32, 3, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(110):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(64, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(64, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1) % 7038 // 3519)
                                    v2 = T.axis.spatial(209, i5_0 + (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1) % 3519 // 17)
                                    v3 = T.axis.spatial(209, i0_0_i1_0_i2_0_i3_0_fused * 16 + (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1) % 17)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1 < 7038)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 209 and 1 <= v3 and v3 < 209, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(3):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(64, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(128, (ax0_ax1_ax2_ax3_fused_0 * 256 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 6)
                                        v1 = T.axis.spatial(64, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 256 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 6 // 3)
                                        v2 = T.axis.spatial(3, i5_0)
                                        v3 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 256 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 3)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(2, 1, 3, 1, 2, 52, 2, 1, 1, 1, 1, 2, 2, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(128, i0_2_i1_2_i2_2_i3_2_fused // 2 * 4 + i1_3 * 2 + i1_4)
                                yy = T.axis.spatial(104, i2_3 * 2 + i2_4)
                                xx = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 8 + i0_1_i1_1_i2_1_i3_1_fused * 4 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 2 + i3_3)
                                rc = T.axis.reduce(64, i4_0 * 2 + i4_1)
                                ry, rx = T.axis.remap("RR", [i5_0, i6_1])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 208, 208], "float32"], ["TENSOR", [128, 64, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 4, 104, 2):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(128, i0_2_i1_2_i2_2_i3_2_fused // 2 * 4 + ax1)
                            v2 = T.axis.spatial(104, ax2)
                            v3 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 8 + i0_1_i1_1_i2_1_i3_1_fused * 4 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 2 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(6):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(128, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 10816)
                        ax2 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 10816 // 104)
                        ax3 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 104)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 1384448)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 1, 32, 2, 2])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 1, 1, 52, 2])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[13, 2, 2, 2, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[32, 2, 1])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112 = sch.split(loop=l110, factors=[None, 64])
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b90)
l120, l121, l122 = sch.split(loop=l119, factors=[None, 64, 4])
sch.vectorize(loop=l122)
sch.bind(loop=l121, thread_axis="threadIdx.x")
b123 = sch.get_block(name="T_multiply", func_name="main")
l124, l125, l126, l127 = sch.get_loops(block=b123)
l128 = sch.fuse(l124, l125, l126, l127)
l129, l130, l131 = sch.split(loop=l128, factors=[None, 256, 1024])
sch.reorder(l130, l131, l129)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
b132 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b132, ann_key="meta_schedule.unroll_explicit")
b133, b134, b135, b136, b137 = sch.get_child_blocks(b132)
l138, l139, l140, l141, l142, l143, l144, l145 = sch.get_loops(block=b133)
l146, l147, l148, l149, l150, l151, l152, l153, l154 = sch.get_loops(block=b134)
l155, l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b135)
l175, l176, l177, l178, l179, l180, l181 = sch.get_loops(block=b136)
l182, l183, l184 = sch.get_loops(block=b137)
b185 = sch.get_block(name="conv2d_nchw", func_name="main")
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b185)
b206 = sch.decompose_reduction(block=b185, loop=l189)
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #3: GFLOPs: 3231.7607. Time: 0.4948 ms. Best GFLOPs: 3231.7607
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #4: GFLOPs: 4362.4353. Time: 0.3665 ms. Best GFLOPs: 4362.4353
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #5: Error in building: LocalRunner: An exception occurred
Subprocess terminated
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 208, 208), "float32"], placeholder_1: T.Buffer[(128, 64, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 128, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 128, 104, 104], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 128, 104, 104], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 64, 209, 209], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([128, 64, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(338, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(16, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(64, thread="threadIdx.x"):
                    for i3_4_init in T.serial(4):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused * 8 + i0_2_i1_2_i2_2_i3_2_fused // 8)
                            yy = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused // 26 * 8 + i0_2_i1_2_i2_2_i3_2_fused % 8)
                            xx = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 26 * 4 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 208, 208], "float32"], ["TENSOR", [128, 64, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(32, 3, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(2):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(64, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(3):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(64, i4_0 * 2 + ((ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1) * 3 + ax0_ax1_ax2_ax3_fused_2) % 270 // 135)
                                        v2 = T.axis.spatial(209, i0_0_i1_0_i2_0_i3_0_fused // 26 * 16 + i5_0 + ((ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1) * 3 + ax0_ax1_ax2_ax3_fused_2) % 135 // 9)
                                        v3 = T.axis.spatial(209, i0_0_i1_0_i2_0_i3_0_fused % 26 * 8 + ((ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1) * 3 + ax0_ax1_ax2_ax3_fused_2) % 9)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1) * 3 + ax0_ax1_ax2_ax3_fused_2 < 270)
                                        T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 209 and 1 <= v3 and v3 < 209, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(3):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(64, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(128, (ax0_ax1_ax2_ax3_fused_0 * 256 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 6)
                                        v1 = T.axis.spatial(64, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 256 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 6 // 3)
                                        v2 = T.axis.spatial(3, i5_0)
                                        v3 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 256 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 3)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused * 8 + i0_2_i1_2_i2_2_i3_2_fused // 8)
                                yy = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused // 26 * 8 + i0_2_i1_2_i2_2_i3_2_fused % 8)
                                xx = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 26 * 4 + i3_4)
                                rc = T.axis.reduce(64, i4_0 * 2 + i4_1)
                                ry, rx = T.axis.remap("RR", [i5_0, i6_1])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 208, 208], "float32"], ["TENSOR", [128, 64, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 1, 1, 4):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused * 8 + i0_2_i1_2_i2_2_i3_2_fused // 8 + ax1)
                            v2 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused // 26 * 8 + i0_2_i1_2_i2_2_i3_2_fused % 8 + ax2)
                            v3 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 26 * 4 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(6):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(128, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 10816)
                        ax2 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 10816 // 104)
                        ax3 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 104)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 1384448)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 16, 8, 1, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[13, 1, 8, 1, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[26, 1, 1, 1, 4])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[32, 2, 1])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112, l113 = sch.split(loop=l110, factors=[None, 64, 3])
sch.vectorize(loop=l113)
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b90)
l121, l122, l123 = sch.split(loop=l120, factors=[None, 64, 4])
sch.vectorize(loop=l123)
sch.bind(loop=l122, thread_axis="threadIdx.x")
b124 = sch.get_block(name="T_multiply", func_name="main")
l125, l126, l127, l128 = sch.get_loops(block=b124)
l129 = sch.fuse(l125, l126, l127, l128)
l130, l131, l132 = sch.split(loop=l129, factors=[None, 256, 1024])
sch.reorder(l131, l132, l130)
sch.bind(loop=l131, thread_axis="blockIdx.x")
sch.bind(loop=l132, thread_axis="threadIdx.x")
b133 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b133, ann_key="meta_schedule.unroll_explicit")
b134, b135, b136, b137, b138 = sch.get_child_blocks(b133)
l139, l140, l141, l142, l143, l144, l145, l146, l147 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l139, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l139, ann_key="pragma_unroll_explicit", ann_val=1)
l148, l149, l150, l151, l152, l153, l154, l155, l156 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l148, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l148, ann_key="pragma_unroll_explicit", ann_val=1)
l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174, l175, l176 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l157, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l157, ann_key="pragma_unroll_explicit", ann_val=1)
l177, l178, l179, l180, l181, l182, l183 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l177, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l177, ann_key="pragma_unroll_explicit", ann_val=1)
l184, l185, l186 = sch.get_loops(block=b138)
sch.annotate(block_or_loop=l184, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l184, ann_key="pragma_unroll_explicit", ann_val=1)
b187 = sch.get_block(name="conv2d_nchw", func_name="main")
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b187)
b208 = sch.decompose_reduction(block=b187, loop=l191)
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #6: GFLOPs: 793.3215. Time: 2.0156 ms. Best GFLOPs: 4362.4353
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #7: GFLOPs: 312.2437. Time: 5.1211 ms. Best GFLOPs: 4362.4353
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #8: GFLOPs: 1770.0418. Time: 0.9034 ms. Best GFLOPs: 4362.4353
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #9: GFLOPs: 221.1393. Time: 7.2309 ms. Best GFLOPs: 4362.4353
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #10: GFLOPs: 4798.6985. Time: 0.3332 ms. Best GFLOPs: 4798.6985
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #11: GFLOPs: 2198.1408. Time: 0.7274 ms. Best GFLOPs: 4798.6985
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #12: GFLOPs: 93.8663. Time: 17.0353 ms. Best GFLOPs: 4798.6985
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #13: GFLOPs: 1918.3524. Time: 0.8335 ms. Best GFLOPs: 4798.6985
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #14: GFLOPs: 768.1229. Time: 2.0817 ms. Best GFLOPs: 4798.6985
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #15: GFLOPs: 4699.6034. Time: 0.3402 ms. Best GFLOPs: 4798.6985
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #16: GFLOPs: 87.6226. Time: 18.2492 ms. Best GFLOPs: 4798.6985
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #17: GFLOPs: 1096.8114. Time: 1.4579 ms. Best GFLOPs: 4798.6985
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #18: GFLOPs: 3199.2975. Time: 0.4998 ms. Best GFLOPs: 4798.6985
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #19: GFLOPs: 2807.0466. Time: 0.5697 ms. Best GFLOPs: 4798.6985
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #20: GFLOPs: 420.9882. Time: 3.7983 ms. Best GFLOPs: 4798.6985
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #21: GFLOPs: 1021.1509. Time: 1.5659 ms. Best GFLOPs: 4798.6985
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #22: GFLOPs: 841.2202. Time: 1.9009 ms. Best GFLOPs: 4798.6985
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #23: GFLOPs: 528.7978. Time: 3.0239 ms. Best GFLOPs: 4798.6985
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #24: Error in building: LocalRunner: An exception occurred
Subprocess terminated
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 208, 208), "float32"], placeholder_1: T.Buffer[(128, 64, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 128, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 128, 104, 104], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 128, 104, 104], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 64, 209, 209], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([128, 64, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(13, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(208, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i2_3_init, i3_3_init, i2_4_init in T.grid(2, 4, 2):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 13 * 8 + i0_2_i1_2_i2_2_i3_2_fused // 4)
                            yy = T.axis.spatial(104, i0_1_i1_1_i2_1_i3_1_fused % 13 * 8 + i0_2_i1_2_i2_2_i3_2_fused % 4 // 2 * 4 + i2_3_init * 2 + i2_4_init)
                            xx = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 8 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 4 + i3_3_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 208, 208], "float32"], ["TENSOR", [128, 64, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(64, 1, 3):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(98):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(64, i4_0 + 0)
                                    v2 = T.axis.spatial(209, (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 3135 // 15)
                                    v3 = T.axis.spatial(209, i0_0_i1_0_i2_0_i3_0_fused * 16 + i6_0 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 15)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1 < 3135)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 209 and 1 <= v3 and v3 < 209, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(3):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(128, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 3)
                                        v1 = T.axis.spatial(64, i4_0)
                                        v2 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 3)
                                        v3 = T.axis.spatial(3, i6_0)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 1, 2, 4, 1, 3, 1, 1, 1, 2, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 13 * 8 + i0_2_i1_2_i2_2_i3_2_fused // 4)
                                yy = T.axis.spatial(104, i0_1_i1_1_i2_1_i3_1_fused % 13 * 8 + i0_2_i1_2_i2_2_i3_2_fused % 4 // 2 * 4 + i2_3 * 2 + i2_4)
                                xx = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 8 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 4 + i3_3)
                                rc, ry, rx = T.axis.remap("RRR", [i4_0, i5_2, i6_0])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 208, 208], "float32"], ["TENSOR", [128, 64, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 1, 4, 4):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 13 * 8 + i0_2_i1_2_i2_2_i3_2_fused // 4 + ax1)
                            v2 = T.axis.spatial(104, i0_1_i1_1_i2_1_i3_1_fused % 13 * 8 + i0_2_i1_2_i2_2_i3_2_fused % 4 // 2 * 4 + ax2)
                            v3 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 8 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 4 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(6):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(128, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 10816)
                        ax2 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 10816 // 104)
                        ax3 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 104)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 1384448)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 16, 8, 1, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 13, 2, 2, 2])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[13, 1, 2, 4, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[64, 1, 1])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112 = sch.split(loop=l110, factors=[None, 32])
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b90)
l120, l121, l122 = sch.split(loop=l119, factors=[None, 32, 4])
sch.vectorize(loop=l122)
sch.bind(loop=l121, thread_axis="threadIdx.x")
b123 = sch.get_block(name="T_multiply", func_name="main")
l124, l125, l126, l127 = sch.get_loops(block=b123)
l128 = sch.fuse(l124, l125, l126, l127)
l129, l130, l131 = sch.split(loop=l128, factors=[None, 256, 1024])
sch.reorder(l130, l131, l129)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
b132 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b132, ann_key="meta_schedule.unroll_explicit")
b133, b134, b135, b136, b137 = sch.get_child_blocks(b132)
l138, l139, l140, l141, l142, l143, l144, l145 = sch.get_loops(block=b133)
sch.annotate(block_or_loop=l138, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l138, ann_key="pragma_unroll_explicit", ann_val=1)
l146, l147, l148, l149, l150, l151, l152, l153, l154 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l146, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l146, ann_key="pragma_unroll_explicit", ann_val=1)
l155, l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l155, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l155, ann_key="pragma_unroll_explicit", ann_val=1)
l175, l176, l177, l178, l179, l180, l181 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l175, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l175, ann_key="pragma_unroll_explicit", ann_val=1)
l182, l183, l184 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l182, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l182, ann_key="pragma_unroll_explicit", ann_val=1)
b185 = sch.get_block(name="conv2d_nchw", func_name="main")
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b185)
b206 = sch.decompose_reduction(block=b185, loop=l189)
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #25: GFLOPs: 264.2618. Time: 6.0510 ms. Best GFLOPs: 4798.6985
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #26: GFLOPs: 578.8192. Time: 2.7626 ms. Best GFLOPs: 4798.6985
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #27: GFLOPs: 1747.8696. Time: 0.9148 ms. Best GFLOPs: 4798.6985
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #28: GFLOPs: 95.2342. Time: 16.7906 ms. Best GFLOPs: 4798.6985
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #29: GFLOPs: 278.6732. Time: 5.7380 ms. Best GFLOPs: 4798.6985
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #30: GFLOPs: 286.3705. Time: 5.5838 ms. Best GFLOPs: 4798.6985
[14:03:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"] Trial #31: GFLOPs: 260.2487. Time: 6.1443 ms. Best GFLOPs: 4798.6985
[14:03:21] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |            N/A |          N/A |                   N/A |      0 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |            N/A |          N/A |                   N/A |      0 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 544
Total latency (us): 2727.39

[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #0: GFLOPs: 90.0981. Time: 1.9899 ms. Best GFLOPs: 90.0981
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #1: GFLOPs: 110.8854. Time: 1.6169 ms. Best GFLOPs: 110.8854
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #2: GFLOPs: 1839.5593. Time: 0.0975 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #3: GFLOPs: 22.4338. Time: 7.9918 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #4: GFLOPs: 566.5263. Time: 0.3165 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #5: GFLOPs: 20.2688. Time: 8.8454 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #6: GFLOPs: 57.4296. Time: 3.1218 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #7: GFLOPs: 146.9013. Time: 1.2205 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #8: GFLOPs: 823.7997. Time: 0.2176 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #9: GFLOPs: 19.5608. Time: 9.1656 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #10: GFLOPs: 28.1275. Time: 6.3740 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #11: GFLOPs: 755.4798. Time: 0.2373 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #12: GFLOPs: 68.0570. Time: 2.6344 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #13: GFLOPs: 140.6010. Time: 1.2751 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #14: GFLOPs: 771.9271. Time: 0.2323 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #15: GFLOPs: 53.9355. Time: 3.3241 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #16: GFLOPs: 60.4281. Time: 2.9669 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #17: GFLOPs: 458.6611. Time: 0.3909 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #18: GFLOPs: 15.1371. Time: 11.8442 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #19: GFLOPs: 120.7245. Time: 1.4851 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #20: GFLOPs: 1241.4039. Time: 0.1444 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #21: GFLOPs: 744.0707. Time: 0.2410 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #22: GFLOPs: 1502.4764. Time: 0.1193 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #23: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 104, 104), "float32"], placeholder_1: T.Buffer[(64, 128, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 64, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 64, 104, 104], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 104, 104], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([64, 128, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(4, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(16, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(104, thread="threadIdx.x"):
                    for i2_3_init, i3_3_init, i1_4_init in T.grid(2, 13, 4):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(64, i0_1_i1_1_i2_1_i3_1_fused // 2 * 8 + i0_2_i1_2_i2_2_i3_2_fused // 52 * 4 + i1_4_init)
                            yy = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused // 2 * 52 + i0_1_i1_1_i2_1_i3_1_fused % 2 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 52 // 4 * 2 + i2_3_init)
                            xx = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 2 * 52 + i0_2_i1_2_i2_2_i3_2_fused % 4 * 13 + i3_3_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [64, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(128, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(13):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(104, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(2):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(128, i4_0)
                                        v2 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused // 2 * 52 + (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) // 52)
                                        v3 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 2 * 52 + (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 52)
                                        T.reads(placeholder[v0, v1, v2, v3])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(1):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(104, thread="threadIdx.x"):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(64, ax0_ax1_ax2_ax3_fused_1)
                                    v1 = T.axis.spatial(128, i4_0)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.where(ax0_ax1_ax2_ax3_fused_1 < 64)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 1, 2, 13, 1, 1, 1, 1, 4, 1, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(64, i0_1_i1_1_i2_1_i3_1_fused // 2 * 8 + i0_2_i1_2_i2_2_i3_2_fused // 52 * 4 + i1_4)
                                yy = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused // 2 * 52 + i0_1_i1_1_i2_1_i3_1_fused % 2 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 52 // 4 * 2 + i2_3)
                                xx = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 2 * 52 + i0_2_i1_2_i2_2_i3_2_fused % 4 * 13 + i3_3)
                                rc = T.axis.reduce(128, i4_0)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [64, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 4, 2, 13):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(64, i0_1_i1_1_i2_1_i3_1_fused // 2 * 8 + i0_2_i1_2_i2_2_i3_2_fused // 52 * 4 + ax1)
                            v2 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused // 2 * 52 + i0_1_i1_1_i2_1_i3_1_fused % 2 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 52 // 4 * 2 + ax2)
                            v3 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 2 * 52 + i0_2_i1_2_i2_2_i3_2_fused % 4 * 13 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(3):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(64, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 10816)
                        ax2 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 10816 // 104)
                        ax3 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 104)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 692224)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 8, 2, 1, 4])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[2, 2, 13, 2, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[2, 1, 4, 13, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[128, 1, 1])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112, l113 = sch.split(loop=l110, factors=[None, 104, 2])
sch.vectorize(loop=l113)
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b90)
l121, l122 = sch.split(loop=l120, factors=[None, 104])
sch.bind(loop=l122, thread_axis="threadIdx.x")
b123 = sch.get_block(name="T_multiply", func_name="main")
l124, l125, l126, l127 = sch.get_loops(block=b123)
l128 = sch.fuse(l124, l125, l126, l127)
l129, l130, l131 = sch.split(loop=l128, factors=[None, 256, 1024])
sch.reorder(l130, l131, l129)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
b132 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b132, ann_key="meta_schedule.unroll_explicit")
b133, b134, b135, b136, b137 = sch.get_child_blocks(b132)
l138, l139, l140, l141, l142, l143, l144, l145, l146 = sch.get_loops(block=b133)
sch.annotate(block_or_loop=l138, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l138, ann_key="pragma_unroll_explicit", ann_val=1)
l147, l148, l149, l150, l151, l152, l153, l154 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l147, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l147, ann_key="pragma_unroll_explicit", ann_val=1)
l155, l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l155, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l155, ann_key="pragma_unroll_explicit", ann_val=1)
l175, l176, l177, l178, l179, l180, l181 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l175, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l175, ann_key="pragma_unroll_explicit", ann_val=1)
l182, l183, l184 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l182, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l182, ann_key="pragma_unroll_explicit", ann_val=1)
b185 = sch.get_block(name="conv2d_nchw", func_name="main")
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b185)
b206 = sch.decompose_reduction(block=b185, loop=l189)
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #24: GFLOPs: 1427.0388. Time: 0.1256 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #25: GFLOPs: 185.3362. Time: 0.9674 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #26: GFLOPs: 306.1041. Time: 0.5857 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #27: GFLOPs: 788.2761. Time: 0.2274 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #28: GFLOPs: 398.7910. Time: 0.4496 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #29: GFLOPs: 3.2939. Time: 54.4297 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #30: GFLOPs: 193.1143. Time: 0.9284 ms. Best GFLOPs: 1839.5593
[14:03:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"] Trial #31: GFLOPs: 55.6344. Time: 3.2226 ms. Best GFLOPs: 1839.5593
[14:03:23] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |            N/A |          N/A |                   N/A |      0 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 576
Total latency (us): 2922.31

[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #0: GFLOPs: 3479.5967. Time: 0.2300 ms. Best GFLOPs: 3479.5967
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #1: GFLOPs: 2830.4957. Time: 0.2827 ms. Best GFLOPs: 3479.5967
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #2: GFLOPs: 753.9086. Time: 1.0614 ms. Best GFLOPs: 3479.5967
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #3: GFLOPs: 2631.4301. Time: 0.3041 ms. Best GFLOPs: 3479.5967
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #4: GFLOPs: 1962.3855. Time: 0.4078 ms. Best GFLOPs: 3479.5967
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #5: GFLOPs: 2098.4206. Time: 0.3813 ms. Best GFLOPs: 3479.5967
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #6: GFLOPs: 1815.2328. Time: 0.4408 ms. Best GFLOPs: 3479.5967
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #7: GFLOPs: 464.5992. Time: 1.7224 ms. Best GFLOPs: 3479.5967
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #8: GFLOPs: 2253.7960. Time: 0.3551 ms. Best GFLOPs: 3479.5967
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #9: GFLOPs: 125.5745. Time: 6.3724 ms. Best GFLOPs: 3479.5967
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #10: GFLOPs: 767.3473. Time: 1.0428 ms. Best GFLOPs: 3479.5967
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #11: GFLOPs: 141.7848. Time: 5.6438 ms. Best GFLOPs: 3479.5967
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #12: GFLOPs: 2680.1950. Time: 0.2986 ms. Best GFLOPs: 3479.5967
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #13: GFLOPs: 1562.8506. Time: 0.5120 ms. Best GFLOPs: 3479.5967
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #14: GFLOPs: 107.9875. Time: 7.4102 ms. Best GFLOPs: 3479.5967
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #15: GFLOPs: 268.4714. Time: 2.9806 ms. Best GFLOPs: 3479.5967
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #16: GFLOPs: 41.8886. Time: 19.1033 ms. Best GFLOPs: 3479.5967
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #17: Error in building: LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home/yj/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/yj/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 153, in _worker_func
    costs: List[float] = f_run_evaluator(
  File "/home/yj/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 379, in default_run_evaluator
    return run_evaluator_common(rt_mod, device, evaluator_config, repeated_args)
  File "/home/yj/tvm/python/tvm/meta_schedule/runner/utils.py", line 117, in run_evaluator_common
    profile_result = evaluator(*args)
  File "/home/yj/tvm/python/tvm/runtime/module.py", line 297, in evaluator
    blob = feval(*args)
  File "/home/yj/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  7: TVMFuncCall
        at /home/yj/tvm/src/runtime/c_runtime_api.cc:477
  6: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /home/yj/tvm/include/tvm/runtime/packed_func.h:1217
  5: Call
        at /home/yj/tvm/include/tvm/runtime/packed_func.h:1213
  4: operator()
        at /home/yj/tvm/src/runtime/rpc/rpc_module.cc:375
  3: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /home/yj/tvm/include/tvm/runtime/packed_func.h:1221
...
  1: Call
        at /home/yj/tvm/include/tvm/runtime/packed_func.h:1213
  0: operator()
        at /home/yj/tvm/src/runtime/library_module.cc:80
  4: TVMFuncCall
        at /home/yj/tvm/src/runtime/c_runtime_api.cc:477
  3: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /home/yj/tvm/include/tvm/runtime/packed_func.h:1217
  2: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::detail::PackFuncVoidAddr_<4, tvm::runtime::CUDAWrappedFunc>(tvm::runtime::CUDAWrappedFunc, std::vector<tvm::runtime::detail::ArgConvertCode, std::allocator<tvm::runtime::detail::ArgConvertCode> > const&)::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /home/yj/tvm/include/tvm/runtime/packed_func.h:1213
  1: tvm::runtime::detail::PackFuncVoidAddr_<4, tvm::runtime::CUDAWrappedFunc>(tvm::runtime::CUDAWrappedFunc, std::vector<tvm::runtime::detail::ArgConvertCode, std::allocator<tvm::runtime::detail::ArgConvertCode> > const&)::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /home/yj/tvm/src/runtime/cuda/../pack_args.h:183
  0: tvm::runtime::CUDAWrappedFunc::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*, void**) const
        at /home/yj/tvm/src/runtime/cuda/cuda_module.cc:190
  File "/home/yj/tvm/src/runtime/cuda/cuda_module.cc", line 190
  File "/home/yj/tvm/src/runtime/library_module.cc", line 80
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------

  Check failed: ret == 0 (-1 vs. 0) : TVMError: CUDALaunch Error: CUDA_ERROR_OUT_OF_MEMORY
 grid=(1,1,1),  block=(32,1,1)

# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 104, 104), "float32"], placeholder_1: T.Buffer[(64, 64, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], placeholder_4: T.Buffer[(1, 64, 104, 104), "float32"], T_add: T.Buffer[(1, 64, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 64, 104, 104], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 64, 106, 106], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([64, 64, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(1, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(26, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i2_3_init, i3_3_init, i1_4_init, i2_4_init, i3_4_init in T.grid(2, 2, 2, 2, 52):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(64, i0_2_i1_2_i2_2_i3_2_fused * 2 + i1_4_init)
                            yy = T.axis.spatial(104, i0_1_i1_1_i2_1_i3_1_fused * 4 + i2_3_init * 2 + i2_4_init)
                            xx = T.axis.spatial(104, i3_3_init * 52 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 104, 104], "float32"], ["TENSOR", [64, 64, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(64, 1, 3):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(87):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(64, i4_0 + 0)
                                        v2 = T.axis.spatial(106, ((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 4 + ax0_ax1_ax2_ax3_fused_2) % 11024 // 104)
                                        v3 = T.axis.spatial(106, i6_0 + ((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 4 + ax0_ax1_ax2_ax3_fused_2) % 104)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 4 + ax0_ax1_ax2_ax3_fused_2 < 11024)
                                        T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 105 and 1 <= v3 and v3 < 105, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(6):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(64, (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) // 3)
                                    v1 = T.axis.spatial(64, i4_0)
                                    v2 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 3)
                                    v3 = T.axis.spatial(3, i6_0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 3, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 52):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(64, i0_2_i1_2_i2_2_i3_2_fused * 2 + i1_4)
                                yy = T.axis.spatial(104, i0_1_i1_1_i2_1_i3_1_fused * 4 + i2_3 * 2 + i2_4)
                                xx = T.axis.spatial(104, i3_3 * 52 + i3_4)
                                rc, ry, rx = T.axis.remap("RRR", [i4_0, i5_1, i6_0])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 104, 104], "float32"], ["TENSOR", [64, 64, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 2, 4, 104):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(64, i0_2_i1_2_i2_2_i3_2_fused * 2 + ax1)
                            v2 = T.axis.spatial(104, i0_1_i1_1_i2_1_i3_1_fused * 4 + ax2)
                            v3 = T.axis.spatial(104, ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(3):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(64, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 10816)
                        ax2 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 10816 // 104)
                        ax3 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 104)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 692224)
                        T.reads(placeholder_4[ax0, ax1, ax2, ax3], conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_add[ax0, ax1, ax2, ax3])
                        T_add[ax0, ax1, ax2, ax3] = placeholder_4[ax0, ax1, ax2, ax3] + (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="T_add_2", func_name="main")
b8 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l9, l10, l11, l12, l13, l14, l15 = sch.get_loops(block=b1)
v16, v17, v18, v19, v20 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l21, l22, l23, l24, l25 = sch.split(loop=l9, factors=[v16, v17, v18, v19, v20])
v26, v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 1, 32, 1, 2])
l31, l32, l33, l34, l35 = sch.split(loop=l10, factors=[v26, v27, v28, v29, v30])
v36, v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 26, 1, 2, 2])
l41, l42, l43, l44, l45 = sch.split(loop=l11, factors=[v36, v37, v38, v39, v40])
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l12, n=5, max_innermost_factor=64, decision=[1, 1, 1, 2, 52])
l51, l52, l53, l54, l55 = sch.split(loop=l12, factors=[v46, v47, v48, v49, v50])
v56, v57, v58 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[64, 1, 1])
l59, l60, l61 = sch.split(loop=l13, factors=[v56, v57, v58])
v62, v63, v64 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l65, l66, l67 = sch.split(loop=l14, factors=[v62, v63, v64])
v68, v69, v70 = sch.sample_perfect_tile(loop=l15, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l71, l72, l73 = sch.split(loop=l15, factors=[v68, v69, v70])
sch.reorder(l21, l31, l41, l51, l22, l32, l42, l52, l23, l33, l43, l53, l59, l65, l71, l60, l66, l72, l24, l34, l44, l54, l61, l67, l73, l25, l35, l45, l55)
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="blockIdx.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="vthread.x")
l76 = sch.fuse(l23, l33, l43, l53)
sch.bind(loop=l76, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b77 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b77, loop=l76, preserve_unit_loops=True)
b78 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b78, loop=l71, preserve_unit_loops=True)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b78)
l89 = sch.fuse(l85, l86, l87, l88)
v90 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b78, ann_key="meta_schedule.cooperative_fetch", ann_val=v90)
b91 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b91, loop=l71, preserve_unit_loops=True)
l92, l93, l94, l95, l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b91)
l102 = sch.fuse(l98, l99, l100, l101)
v103 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b91, ann_key="meta_schedule.cooperative_fetch", ann_val=v103)
sch.reverse_compute_inline(block=b7)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v104 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b8, ann_key="meta_schedule.unroll_explicit", ann_val=v104)
sch.enter_postproc()
sch.unannotate(block_or_loop=b78, ann_key="meta_schedule.cooperative_fetch")
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b78)
l112, l113, l114 = sch.split(loop=l111, factors=[None, 32, 4])
sch.vectorize(loop=l114)
sch.bind(loop=l113, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b91, ann_key="meta_schedule.cooperative_fetch")
l115, l116, l117, l118, l119, l120, l121 = sch.get_loops(block=b91)
l122, l123 = sch.split(loop=l121, factors=[None, 32])
sch.bind(loop=l123, thread_axis="threadIdx.x")
b124 = sch.get_block(name="T_multiply", func_name="main")
l125, l126, l127, l128 = sch.get_loops(block=b124)
l129 = sch.fuse(l125, l126, l127, l128)
l130, l131, l132 = sch.split(loop=l129, factors=[None, 256, 1024])
sch.reorder(l131, l132, l130)
sch.bind(loop=l131, thread_axis="blockIdx.x")
sch.bind(loop=l132, thread_axis="threadIdx.x")
b133 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b133, ann_key="meta_schedule.unroll_explicit")
b134, b135, b136, b137, b138 = sch.get_child_blocks(b133)
l139, l140, l141, l142, l143, l144, l145, l146, l147 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l139, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l139, ann_key="pragma_unroll_explicit", ann_val=1)
l148, l149, l150, l151, l152, l153, l154, l155 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l148, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l148, ann_key="pragma_unroll_explicit", ann_val=1)
l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174, l175 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l156, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l156, ann_key="pragma_unroll_explicit", ann_val=1)
l176, l177, l178, l179, l180, l181, l182 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l176, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l176, ann_key="pragma_unroll_explicit", ann_val=1)
l183, l184, l185 = sch.get_loops(block=b138)
sch.annotate(block_or_loop=l183, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l183, ann_key="pragma_unroll_explicit", ann_val=1)
b186 = sch.get_block(name="conv2d_nchw", func_name="main")
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b186)
b207 = sch.decompose_reduction(block=b186, loop=l190)
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #18: GFLOPs: 616.2517. Time: 1.2985 ms. Best GFLOPs: 3479.5967
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #19: GFLOPs: 707.5400. Time: 1.1310 ms. Best GFLOPs: 3479.5967
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #20: GFLOPs: 27.8208. Time: 28.7630 ms. Best GFLOPs: 3479.5967
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #21: GFLOPs: 22.8789. Time: 34.9760 ms. Best GFLOPs: 3479.5967
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #22: GFLOPs: 2260.0943. Time: 0.3541 ms. Best GFLOPs: 3479.5967
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #23: GFLOPs: 3139.9586. Time: 0.2548 ms. Best GFLOPs: 3479.5967
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #24: GFLOPs: 1221.6837. Time: 0.6550 ms. Best GFLOPs: 3479.5967
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #25: GFLOPs: 2471.2046. Time: 0.3238 ms. Best GFLOPs: 3479.5967
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #26: GFLOPs: 3620.0905. Time: 0.2210 ms. Best GFLOPs: 3620.0905
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #27: GFLOPs: 2330.2862. Time: 0.3434 ms. Best GFLOPs: 3620.0905
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #28: GFLOPs: 2461.5020. Time: 0.3251 ms. Best GFLOPs: 3620.0905
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #29: GFLOPs: 804.8098. Time: 0.9943 ms. Best GFLOPs: 3620.0905
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #30: GFLOPs: 276.1630. Time: 2.8976 ms. Best GFLOPs: 3620.0905
[14:03:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"] Trial #31: GFLOPs: 1025.9337. Time: 0.7800 ms. Best GFLOPs: 3620.0905
[14:03:24] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |            N/A |          N/A |                   N/A |      0 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 608
Total latency (us): 3364.41

[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #0: GFLOPs: 77.7408. Time: 1.1665 ms. Best GFLOPs: 77.7408
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #1: GFLOPs: 1015.2933. Time: 0.0893 ms. Best GFLOPs: 1015.2933
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #2: GFLOPs: 21.0016. Time: 4.3178 ms. Best GFLOPs: 1015.2933
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #3: GFLOPs: 26.1720. Time: 3.4648 ms. Best GFLOPs: 1015.2933
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #4: GFLOPs: 1348.2941. Time: 0.0673 ms. Best GFLOPs: 1348.2941
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #5: GFLOPs: 891.6752. Time: 0.1017 ms. Best GFLOPs: 1348.2941
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #6: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 104, 104), "float32"], placeholder_1: T.Buffer[(64, 64, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 64, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 64, 104, 104], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 64, 104, 104], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([64, 64, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(26, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(1, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i1_3_init, i3_3_init, i2_4_init, i3_4_init in T.grid(4, 26, 2, 4):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(64, i0_2_i1_2_i2_2_i3_2_fused // 2 * 4 + i1_3_init)
                            yy = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 4 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 2 + i2_4_init)
                            xx = T.axis.spatial(104, i3_3_init * 4 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 104, 104], "float32"], ["TENSOR", [64, 64, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(32, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(7):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(64, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 416)
                                        v2 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 4 + (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 416 // 104)
                                        v3 = T.axis.spatial(104, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 104)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 4 + ax0_ax1_ax2_ax3_fused_2 < 832)
                                        T.reads(placeholder[v0, v1, v2, v3])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(4):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(64, (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) // 2)
                                    v1 = T.axis.spatial(64, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 2)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 4, 1, 26, 2, 1, 1, 1, 1, 2, 4):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(64, i0_2_i1_2_i2_2_i3_2_fused // 2 * 4 + i1_3)
                                yy = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 4 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 2 + i2_4)
                                xx = T.axis.spatial(104, i3_3 * 4 + i3_4)
                                rc = T.axis.reduce(64, i4_0 * 2 + i4_2)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 104, 104], "float32"], ["TENSOR", [64, 64, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 4, 2, 104):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(64, i0_2_i1_2_i2_2_i3_2_fused // 2 * 4 + ax1)
                            v2 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 4 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 2 + ax2)
                            v3 = T.axis.spatial(104, ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(3):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(64, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 10816)
                        ax2 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 10816 // 104)
                        ax3 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 104)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 692224)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 1, 16, 4, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[26, 1, 2, 1, 2])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 1, 1, 26, 4])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[32, 1, 2])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112, l113 = sch.split(loop=l110, factors=[None, 32, 4])
sch.vectorize(loop=l113)
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b90)
l121, l122 = sch.split(loop=l120, factors=[None, 32])
sch.bind(loop=l122, thread_axis="threadIdx.x")
b123 = sch.get_block(name="T_multiply", func_name="main")
l124, l125, l126, l127 = sch.get_loops(block=b123)
l128 = sch.fuse(l124, l125, l126, l127)
l129, l130, l131 = sch.split(loop=l128, factors=[None, 256, 1024])
sch.reorder(l130, l131, l129)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
b132 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b132, ann_key="meta_schedule.unroll_explicit")
b133, b134, b135, b136, b137 = sch.get_child_blocks(b132)
l138, l139, l140, l141, l142, l143, l144, l145, l146 = sch.get_loops(block=b133)
sch.annotate(block_or_loop=l138, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l138, ann_key="pragma_unroll_explicit", ann_val=1)
l147, l148, l149, l150, l151, l152, l153, l154 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l147, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l147, ann_key="pragma_unroll_explicit", ann_val=1)
l155, l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l155, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l155, ann_key="pragma_unroll_explicit", ann_val=1)
l175, l176, l177, l178, l179, l180, l181 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l175, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l175, ann_key="pragma_unroll_explicit", ann_val=1)
l182, l183, l184 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l182, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l182, ann_key="pragma_unroll_explicit", ann_val=1)
b185 = sch.get_block(name="conv2d_nchw", func_name="main")
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b185)
b206 = sch.decompose_reduction(block=b185, loop=l189)
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #7: GFLOPs: 1986.5936. Time: 0.0456 ms. Best GFLOPs: 1986.5936
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #8: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 104, 104), "float32"], placeholder_1: T.Buffer[(64, 64, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 64, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 64, 104, 104], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 64, 104, 104], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([64, 64, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(2, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(26, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i2_3_init, i3_3_init, i1_4_init, i2_4_init in T.grid(2, 2, 4, 26):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(64, i0_1_i1_1_i2_1_i3_1_fused // 13 * 32 + i0_2_i1_2_i2_2_i3_2_fused // 4 * 4 + i1_4_init)
                            yy = T.axis.spatial(104, i0_2_i1_2_i2_2_i3_2_fused % 4 // 2 * 52 + i2_3_init * 26 + i2_4_init)
                            xx = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 52 + i0_1_i1_1_i2_1_i3_1_fused % 13 * 4 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 2 + i3_3_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 104, 104], "float32"], ["TENSOR", [64, 64, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(32, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(169):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(2):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(64, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) // 5408)
                                        v2 = T.axis.spatial(104, (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 5408 // 52)
                                        v3 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 52 + (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 52)
                                        T.reads(placeholder[v0, v1, v2, v3])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(1):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(64, (ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 2)
                                        v1 = T.axis.spatial(64, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 2)
                                        v2 = T.axis.spatial(1, 0)
                                        v3 = T.axis.spatial(1, 0)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 4, 26, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(64, i0_1_i1_1_i2_1_i3_1_fused // 13 * 32 + i0_2_i1_2_i2_2_i3_2_fused // 4 * 4 + i1_4)
                                yy = T.axis.spatial(104, i0_2_i1_2_i2_2_i3_2_fused % 4 // 2 * 52 + i2_3 * 26 + i2_4)
                                xx = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 52 + i0_1_i1_1_i2_1_i3_1_fused % 13 * 4 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 2 + i3_3)
                                rc = T.axis.reduce(64, i4_0 * 2 + i4_2)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 104, 104], "float32"], ["TENSOR", [64, 64, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 4, 52, 2):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(64, i0_1_i1_1_i2_1_i3_1_fused // 13 * 32 + i0_2_i1_2_i2_2_i3_2_fused // 4 * 4 + ax1)
                            v2 = T.axis.spatial(104, i0_2_i1_2_i2_2_i3_2_fused % 4 // 2 * 52 + ax2)
                            v3 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 52 + i0_1_i1_1_i2_1_i3_1_fused % 13 * 4 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 2 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(3):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(64, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 10816)
                        ax2 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 10816 // 104)
                        ax3 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 104)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 692224)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 2, 8, 1, 4])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 1, 2, 2, 26])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[2, 13, 2, 2, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[32, 1, 2])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112, l113 = sch.split(loop=l110, factors=[None, 32, 2])
sch.vectorize(loop=l113)
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b90)
l121, l122, l123 = sch.split(loop=l120, factors=[None, 32, 4])
sch.vectorize(loop=l123)
sch.bind(loop=l122, thread_axis="threadIdx.x")
b124 = sch.get_block(name="T_multiply", func_name="main")
l125, l126, l127, l128 = sch.get_loops(block=b124)
l129 = sch.fuse(l125, l126, l127, l128)
l130, l131, l132 = sch.split(loop=l129, factors=[None, 256, 1024])
sch.reorder(l131, l132, l130)
sch.bind(loop=l131, thread_axis="blockIdx.x")
sch.bind(loop=l132, thread_axis="threadIdx.x")
b133 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b133, ann_key="meta_schedule.unroll_explicit")
b134, b135, b136, b137, b138 = sch.get_child_blocks(b133)
l139, l140, l141, l142, l143, l144, l145, l146, l147 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l139, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l139, ann_key="pragma_unroll_explicit", ann_val=1)
l148, l149, l150, l151, l152, l153, l154, l155, l156 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l148, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l148, ann_key="pragma_unroll_explicit", ann_val=1)
l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174, l175, l176 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l157, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l157, ann_key="pragma_unroll_explicit", ann_val=1)
l177, l178, l179, l180, l181, l182, l183 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l177, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l177, ann_key="pragma_unroll_explicit", ann_val=1)
l184, l185, l186 = sch.get_loops(block=b138)
sch.annotate(block_or_loop=l184, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l184, ann_key="pragma_unroll_explicit", ann_val=1)
b187 = sch.get_block(name="conv2d_nchw", func_name="main")
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b187)
b208 = sch.decompose_reduction(block=b187, loop=l191)
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #9: GFLOPs: 1015.0608. Time: 0.0893 ms. Best GFLOPs: 1986.5936
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #10: GFLOPs: 236.6678. Time: 0.3832 ms. Best GFLOPs: 1986.5936
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #11: GFLOPs: 339.9777. Time: 0.2667 ms. Best GFLOPs: 1986.5936
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #12: GFLOPs: 1966.6110. Time: 0.0461 ms. Best GFLOPs: 1986.5936
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #13: GFLOPs: 1726.4293. Time: 0.0525 ms. Best GFLOPs: 1986.5936
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #14: GFLOPs: 6.9838. Time: 12.9846 ms. Best GFLOPs: 1986.5936
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #15: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 104, 104), "float32"], placeholder_1: T.Buffer[(64, 64, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 64, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 64, 104, 104], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 64, 104, 104], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([64, 64, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(13, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(13, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i1_3_init, i1_4_init, i2_4_init, i3_4_init in T.grid(4, 2, 8, 2):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(64, i0_2_i1_2_i2_2_i3_2_fused // 4 * 8 + i1_3_init * 2 + i1_4_init)
                            yy = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 8 + i2_4_init)
                            xx = T.axis.spatial(104, i0_1_i1_1_i2_1_i3_1_fused * 8 + i0_2_i1_2_i2_2_i3_2_fused % 4 * 2 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 104, 104], "float32"], ["TENSOR", [64, 64, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(8, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(52):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(64, i4_0 * 8 + (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 832)
                                        v2 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 8 + (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 832 // 104)
                                        v3 = T.axis.spatial(104, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 104)
                                        T.reads(placeholder[v0, v1, v2, v3])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(4):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(64, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 8)
                                        v1 = T.axis.spatial(64, i4_0 * 8 + (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 8)
                                        v2 = T.axis.spatial(1, 0)
                                        v3 = T.axis.spatial(1, 0)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(8, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 2, 8, 2):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(64, i0_2_i1_2_i2_2_i3_2_fused // 4 * 8 + i1_3 * 2 + i1_4)
                                yy = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 8 + i2_4)
                                xx = T.axis.spatial(104, i0_1_i1_1_i2_1_i3_1_fused * 8 + i0_2_i1_2_i2_2_i3_2_fused % 4 * 2 + i3_4)
                                rc = T.axis.reduce(64, i4_0 * 8 + i4_1)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 104, 104], "float32"], ["TENSOR", [64, 64, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 8, 8, 2):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(64, i0_2_i1_2_i2_2_i3_2_fused // 4 * 8 + ax1)
                            v2 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 8 + ax2)
                            v3 = T.axis.spatial(104, i0_1_i1_1_i2_1_i3_1_fused * 8 + i0_2_i1_2_i2_2_i3_2_fused % 4 * 2 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(3):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(64, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 10816)
                        ax2 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 10816 // 104)
                        ax3 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 104)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 692224)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 1, 8, 4, 2])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[13, 1, 1, 1, 8])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 13, 4, 1, 2])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[8, 8, 1])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112, l113 = sch.split(loop=l110, factors=[None, 32, 4])
sch.vectorize(loop=l113)
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b90)
l121, l122, l123 = sch.split(loop=l120, factors=[None, 32, 4])
sch.vectorize(loop=l123)
sch.bind(loop=l122, thread_axis="threadIdx.x")
b124 = sch.get_block(name="T_multiply", func_name="main")
l125, l126, l127, l128 = sch.get_loops(block=b124)
l129 = sch.fuse(l125, l126, l127, l128)
l130, l131, l132 = sch.split(loop=l129, factors=[None, 256, 1024])
sch.reorder(l131, l132, l130)
sch.bind(loop=l131, thread_axis="blockIdx.x")
sch.bind(loop=l132, thread_axis="threadIdx.x")
b133 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b133, ann_key="meta_schedule.unroll_explicit")
b134, b135, b136, b137, b138 = sch.get_child_blocks(b133)
l139, l140, l141, l142, l143, l144, l145, l146, l147 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l139, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l139, ann_key="pragma_unroll_explicit", ann_val=1)
l148, l149, l150, l151, l152, l153, l154, l155, l156 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l148, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l148, ann_key="pragma_unroll_explicit", ann_val=1)
l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174, l175, l176 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l157, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l157, ann_key="pragma_unroll_explicit", ann_val=1)
l177, l178, l179, l180, l181, l182, l183 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l177, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l177, ann_key="pragma_unroll_explicit", ann_val=1)
l184, l185, l186 = sch.get_loops(block=b138)
sch.annotate(block_or_loop=l184, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l184, ann_key="pragma_unroll_explicit", ann_val=1)
b187 = sch.get_block(name="conv2d_nchw", func_name="main")
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b187)
b208 = sch.decompose_reduction(block=b187, loop=l191)
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #16: GFLOPs: 35.0403. Time: 2.5879 ms. Best GFLOPs: 1986.5936
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #17: GFLOPs: 1250.4509. Time: 0.0725 ms. Best GFLOPs: 1986.5936
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #18: GFLOPs: 352.6316. Time: 0.2572 ms. Best GFLOPs: 1986.5936
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #19: GFLOPs: 1058.1146. Time: 0.0857 ms. Best GFLOPs: 1986.5936
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #20: GFLOPs: 1162.4250. Time: 0.0780 ms. Best GFLOPs: 1986.5936
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #21: GFLOPs: 121.9289. Time: 0.7437 ms. Best GFLOPs: 1986.5936
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #22: GFLOPs: 1554.2862. Time: 0.0583 ms. Best GFLOPs: 1986.5936
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #23: GFLOPs: 828.1190. Time: 0.1095 ms. Best GFLOPs: 1986.5936
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #24: GFLOPs: 153.4961. Time: 0.5908 ms. Best GFLOPs: 1986.5936
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #25: GFLOPs: 1191.2859. Time: 0.0761 ms. Best GFLOPs: 1986.5936
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #26: GFLOPs: 2166.6358. Time: 0.0419 ms. Best GFLOPs: 2166.6358
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #27: GFLOPs: 1747.5918. Time: 0.0519 ms. Best GFLOPs: 2166.6358
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #28: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 64, 104, 104), "float32"], placeholder_1: T.Buffer[(64, 64, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 64, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 64, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 64, 104, 104], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 64, 104, 104], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 64, 104, 104], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([64, 64, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(26, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(26, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i1_3_init, i1_4_init, i2_4_init in T.grid(2, 4, 4):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(64, i0_1_i1_1_i2_1_i3_1_fused // 13 * 32 + i0_2_i1_2_i2_2_i3_2_fused // 8 * 8 + i1_3_init * 4 + i1_4_init)
                            yy = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused // 13 * 52 + i0_1_i1_1_i2_1_i3_1_fused % 13 * 4 + i2_4_init)
                            xx = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 13 * 8 + i0_2_i1_2_i2_2_i3_2_fused % 8)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 104, 104], "float32"], ["TENSOR", [64, 64, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(32, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(13):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(2):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(64, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) // 416)
                                        v2 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused // 13 * 52 + (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 416 // 8)
                                        v3 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 13 * 8 + (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 8)
                                        T.reads(placeholder[v0, v1, v2, v3])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(4):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(64, (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) // 2)
                                    v1 = T.axis.spatial(64, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 2)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 4, 4, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(64, i0_1_i1_1_i2_1_i3_1_fused // 13 * 32 + i0_2_i1_2_i2_2_i3_2_fused // 8 * 8 + i1_3 * 4 + i1_4)
                                yy = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused // 13 * 52 + i0_1_i1_1_i2_1_i3_1_fused % 13 * 4 + i2_4)
                                xx = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 13 * 8 + i0_2_i1_2_i2_2_i3_2_fused % 8)
                                rc = T.axis.reduce(64, i4_0 * 2 + i4_2)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 64, 104, 104], "float32"], ["TENSOR", [64, 64, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 8, 4, 1):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(64, i0_1_i1_1_i2_1_i3_1_fused // 13 * 32 + i0_2_i1_2_i2_2_i3_2_fused // 8 * 8 + ax1)
                            v2 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused // 13 * 52 + i0_1_i1_1_i2_1_i3_1_fused % 13 * 4 + ax2)
                            v3 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 13 * 8 + i0_2_i1_2_i2_2_i3_2_fused % 8 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(3):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(64, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 10816)
                        ax2 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 10816 // 104)
                        ax3 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 104)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 692224)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 2, 4, 2, 4])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[2, 13, 1, 1, 4])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[13, 1, 8, 1, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[32, 1, 2])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112, l113 = sch.split(loop=l110, factors=[None, 32, 2])
sch.vectorize(loop=l113)
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b90)
l121, l122 = sch.split(loop=l120, factors=[None, 32])
sch.bind(loop=l122, thread_axis="threadIdx.x")
b123 = sch.get_block(name="T_multiply", func_name="main")
l124, l125, l126, l127 = sch.get_loops(block=b123)
l128 = sch.fuse(l124, l125, l126, l127)
l129, l130, l131 = sch.split(loop=l128, factors=[None, 256, 1024])
sch.reorder(l130, l131, l129)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
b132 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b132, ann_key="meta_schedule.unroll_explicit")
b133, b134, b135, b136, b137 = sch.get_child_blocks(b132)
l138, l139, l140, l141, l142, l143, l144, l145, l146 = sch.get_loops(block=b133)
sch.annotate(block_or_loop=l138, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l138, ann_key="pragma_unroll_explicit", ann_val=1)
l147, l148, l149, l150, l151, l152, l153, l154 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l147, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l147, ann_key="pragma_unroll_explicit", ann_val=1)
l155, l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l155, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l155, ann_key="pragma_unroll_explicit", ann_val=1)
l175, l176, l177, l178, l179, l180, l181 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l175, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l175, ann_key="pragma_unroll_explicit", ann_val=1)
l182, l183, l184 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l182, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l182, ann_key="pragma_unroll_explicit", ann_val=1)
b185 = sch.get_block(name="conv2d_nchw", func_name="main")
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b185)
b206 = sch.decompose_reduction(block=b185, loop=l189)
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #29: GFLOPs: 126.0044. Time: 0.7197 ms. Best GFLOPs: 2166.6358
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #30: GFLOPs: 566.2714. Time: 0.1601 ms. Best GFLOPs: 2166.6358
[14:03:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"] Trial #31: GFLOPs: 767.9563. Time: 0.1181 ms. Best GFLOPs: 2166.6358
[14:03:26] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |            N/A |          N/A |                   N/A |      0 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 640
Total latency (us): 3489.97

[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #0: GFLOPs: 0.0000. Time: 0.0316 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #1: GFLOPs: 0.0000. Time: 0.0317 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #2: GFLOPs: 0.0000. Time: 0.0315 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #3: GFLOPs: 0.0000. Time: 0.0312 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #4: GFLOPs: 0.0000. Time: 0.0312 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #5: GFLOPs: 0.0000. Time: 0.0314 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #6: GFLOPs: 0.0000. Time: 0.0311 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #7: GFLOPs: 0.0000. Time: 0.0313 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #8: GFLOPs: 0.0000. Time: 0.0310 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #9: GFLOPs: 0.0000. Time: 0.0312 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #10: GFLOPs: 0.0000. Time: 0.0307 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #11: GFLOPs: 0.0000. Time: 0.0310 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #12: GFLOPs: 0.0000. Time: 0.0309 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #13: GFLOPs: 0.0000. Time: 0.0307 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #14: GFLOPs: 0.0000. Time: 0.0312 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #15: GFLOPs: 0.0000. Time: 0.0313 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #16: GFLOPs: 0.0000. Time: 0.0313 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #17: GFLOPs: 0.0000. Time: 0.0309 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #18: GFLOPs: 0.0000. Time: 0.0313 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #19: GFLOPs: 0.0000. Time: 0.0311 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #20: GFLOPs: 0.0000. Time: 0.0313 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #21: GFLOPs: 0.0000. Time: 0.0305 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #22: GFLOPs: 0.0000. Time: 0.0338 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #23: GFLOPs: 0.0000. Time: 0.0309 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #24: GFLOPs: 0.0000. Time: 0.0313 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #25: GFLOPs: 0.0000. Time: 0.0310 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #26: GFLOPs: 0.0000. Time: 0.0316 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #27: GFLOPs: 0.0000. Time: 0.0314 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #28: GFLOPs: 0.0000. Time: 0.0314 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #29: GFLOPs: 0.0000. Time: 0.0310 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #30: GFLOPs: 0.0000. Time: 0.0327 ms. Best GFLOPs: 0.0000
[14:03:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_concatenate_1"] Trial #31: GFLOPs: 0.0000. Time: 0.0309 ms. Best GFLOPs: 0.0000
[14:03:27] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #20: "fused_concatenate_1"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |            N/A |          N/A |                   N/A |      0 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 672
Total latency (us): 3520.44

[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #0: GFLOPs: 188.7542. Time: 1.8997 ms. Best GFLOPs: 188.7542
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #1: GFLOPs: 3257.8337. Time: 0.1101 ms. Best GFLOPs: 3257.8337
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #2: Error in building: LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home/yj/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/yj/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 153, in _worker_func
    costs: List[float] = f_run_evaluator(
  File "/home/yj/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 379, in default_run_evaluator
    return run_evaluator_common(rt_mod, device, evaluator_config, repeated_args)
  File "/home/yj/tvm/python/tvm/meta_schedule/runner/utils.py", line 117, in run_evaluator_common
    profile_result = evaluator(*args)
  File "/home/yj/tvm/python/tvm/runtime/module.py", line 297, in evaluator
    blob = feval(*args)
  File "/home/yj/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  7: TVMFuncCall
        at /home/yj/tvm/src/runtime/c_runtime_api.cc:477
  6: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /home/yj/tvm/include/tvm/runtime/packed_func.h:1217
  5: Call
        at /home/yj/tvm/include/tvm/runtime/packed_func.h:1213
  4: operator()
        at /home/yj/tvm/src/runtime/rpc/rpc_module.cc:375
  3: tvm::runtime::PackedFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /home/yj/tvm/include/tvm/runtime/packed_func.h:1221
...
  1: Call
        at /home/yj/tvm/include/tvm/runtime/packed_func.h:1213
  0: operator()
        at /home/yj/tvm/src/runtime/library_module.cc:80
  4: TVMFuncCall
        at /home/yj/tvm/src/runtime/c_runtime_api.cc:477
  3: tvm::runtime::PackedFuncObj::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /home/yj/tvm/include/tvm/runtime/packed_func.h:1217
  2: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::detail::PackFuncVoidAddr_<4, tvm::runtime::CUDAWrappedFunc>(tvm::runtime::CUDAWrappedFunc, std::vector<tvm::runtime::detail::ArgConvertCode, std::allocator<tvm::runtime::detail::ArgConvertCode> > const&)::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
        at /home/yj/tvm/include/tvm/runtime/packed_func.h:1213
  1: tvm::runtime::detail::PackFuncVoidAddr_<4, tvm::runtime::CUDAWrappedFunc>(tvm::runtime::CUDAWrappedFunc, std::vector<tvm::runtime::detail::ArgConvertCode, std::allocator<tvm::runtime::detail::ArgConvertCode> > const&)::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const
        at /home/yj/tvm/src/runtime/cuda/../pack_args.h:183
  0: tvm::runtime::CUDAWrappedFunc::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*, void**) const
        at /home/yj/tvm/src/runtime/cuda/cuda_module.cc:190
  File "/home/yj/tvm/src/runtime/cuda/cuda_module.cc", line 190
  File "/home/yj/tvm/src/runtime/library_module.cc", line 80
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------

  Check failed: ret == 0 (-1 vs. 0) : TVMError: CUDALaunch Error: CUDA_ERROR_OUT_OF_MEMORY
 grid=(1,1,1),  block=(32,1,1)

# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 104, 104), "float32"], placeholder_1: T.Buffer[(128, 128, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 128, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 128, 104, 104], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 128, 104, 104], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 104, 104], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([128, 128, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(1, thread="blockIdx.x"):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(52, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i1_3_init, i2_3_init, i3_4_init in T.grid(2, 104, 4):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 26 * 64 + i0_2_i1_2_i2_2_i3_2_fused * 2 + i1_3_init)
                            yy = T.axis.spatial(104, i2_3_init)
                            xx = T.axis.spatial(104, i0_1_i1_1_i2_1_i3_1_fused % 26 * 4 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [128, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(128, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(85):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(128, i4_0)
                                        v2 = T.axis.spatial(104, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 104)
                                        v3 = T.axis.spatial(104, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 104)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 4 + ax0_ax1_ax2_ax3_fused_2 < 10816)
                                        T.reads(placeholder[v0, v1, v2, v3])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(4):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(128, ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1)
                                    v1 = T.axis.spatial(128, i4_0)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 2, 104, 1, 1, 1, 1, 1, 1, 1, 4):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 26 * 64 + i0_2_i1_2_i2_2_i3_2_fused * 2 + i1_3)
                                yy = T.axis.spatial(104, i2_3)
                                xx = T.axis.spatial(104, i0_1_i1_1_i2_1_i3_1_fused % 26 * 4 + i3_4)
                                rc = T.axis.reduce(128, i4_0)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [128, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 2, 104, 4):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 26 * 64 + i0_2_i1_2_i2_2_i3_2_fused * 2 + ax1)
                            v2 = T.axis.spatial(104, ax2)
                            v3 = T.axis.spatial(104, i0_1_i1_1_i2_1_i3_1_fused % 26 * 4 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(6):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(128, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 10816)
                        ax2 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 10816 // 104)
                        ax3 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 104)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 1384448)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 2, 32, 2, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 1, 1, 104, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 26, 1, 1, 4])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[128, 1, 1])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112, l113 = sch.split(loop=l110, factors=[None, 32, 4])
sch.vectorize(loop=l113)
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b90)
l121, l122 = sch.split(loop=l120, factors=[None, 32])
sch.bind(loop=l122, thread_axis="threadIdx.x")
b123 = sch.get_block(name="T_multiply", func_name="main")
l124, l125, l126, l127 = sch.get_loops(block=b123)
l128 = sch.fuse(l124, l125, l126, l127)
l129, l130, l131 = sch.split(loop=l128, factors=[None, 256, 1024])
sch.reorder(l130, l131, l129)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
b132 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b132, ann_key="meta_schedule.unroll_explicit")
b133, b134, b135, b136, b137 = sch.get_child_blocks(b132)
l138, l139, l140, l141, l142, l143, l144, l145, l146 = sch.get_loops(block=b133)
l147, l148, l149, l150, l151, l152, l153, l154 = sch.get_loops(block=b134)
l155, l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b135)
l175, l176, l177, l178, l179, l180, l181 = sch.get_loops(block=b136)
l182, l183, l184 = sch.get_loops(block=b137)
b185 = sch.get_block(name="conv2d_nchw", func_name="main")
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b185)
b206 = sch.decompose_reduction(block=b185, loop=l189)
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #3: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 104, 104), "float32"], placeholder_1: T.Buffer[(128, 128, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 128, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 128, 104, 104], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 128, 104, 104], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 104, 104], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([128, 128, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(52, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(4, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i1_3_init, i2_3_init, i3_3_init, i2_4_init in T.grid(2, 4, 2, 13):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 26 * 64 + i0_1_i1_1_i2_1_i3_1_fused // 2 * 32 + i0_2_i1_2_i2_2_i3_2_fused // 2 * 2 + i1_3_init)
                            yy = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 26 // 13 * 52 + i2_3_init * 13 + i2_4_init)
                            xx = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 13 * 8 + i0_1_i1_1_i2_1_i3_1_fused % 2 * 4 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 2 + i3_3_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [128, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(8, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(208):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(128, i4_0 * 16 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) // 416)
                                    v2 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 26 // 13 * 52 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 416 // 8)
                                    v3 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 13 * 8 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 8)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(32):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 26 * 64 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) // 16)
                                    v1 = T.axis.spatial(128, i4_0 * 16 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 16)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 2, 4, 2, 16, 1, 1, 1, 1, 13, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 26 * 64 + i0_1_i1_1_i2_1_i3_1_fused // 2 * 32 + i0_2_i1_2_i2_2_i3_2_fused // 2 * 2 + i1_3)
                                yy = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 26 // 13 * 52 + i2_3 * 13 + i2_4)
                                xx = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 13 * 8 + i0_1_i1_1_i2_1_i3_1_fused % 2 * 4 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 2 + i3_3)
                                rc = T.axis.reduce(128, i4_0 * 16 + i4_2)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [128, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 2, 52, 2):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 26 * 64 + i0_1_i1_1_i2_1_i3_1_fused // 2 * 32 + i0_2_i1_2_i2_2_i3_2_fused // 2 * 2 + ax1)
                            v2 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 26 // 13 * 52 + ax2)
                            v3 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 13 * 8 + i0_1_i1_1_i2_1_i3_1_fused % 2 * 4 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 2 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(6):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(128, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 10816)
                        ax2 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 10816 // 104)
                        ax3 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 104)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 1384448)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[2, 2, 16, 2, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[2, 1, 1, 4, 13])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[13, 2, 2, 2, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[8, 1, 16])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112 = sch.split(loop=l110, factors=[None, 32])
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b90)
l120, l121 = sch.split(loop=l119, factors=[None, 32])
sch.bind(loop=l121, thread_axis="threadIdx.x")
b122 = sch.get_block(name="T_multiply", func_name="main")
l123, l124, l125, l126 = sch.get_loops(block=b122)
l127 = sch.fuse(l123, l124, l125, l126)
l128, l129, l130 = sch.split(loop=l127, factors=[None, 256, 1024])
sch.reorder(l129, l130, l128)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
b131 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b131, ann_key="meta_schedule.unroll_explicit")
b132, b133, b134, b135, b136 = sch.get_child_blocks(b131)
l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b132)
sch.annotate(block_or_loop=l137, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l137, ann_key="pragma_unroll_explicit", ann_val=1)
l145, l146, l147, l148, l149, l150, l151, l152 = sch.get_loops(block=b133)
sch.annotate(block_or_loop=l145, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l145, ann_key="pragma_unroll_explicit", ann_val=1)
l153, l154, l155, l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l153, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l153, ann_key="pragma_unroll_explicit", ann_val=1)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l173, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l173, ann_key="pragma_unroll_explicit", ann_val=1)
l180, l181, l182 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l180, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l180, ann_key="pragma_unroll_explicit", ann_val=1)
b183 = sch.get_block(name="conv2d_nchw", func_name="main")
l184, l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203 = sch.get_loops(block=b183)
b204 = sch.decompose_reduction(block=b183, loop=l187)
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #4: GFLOPs: 1704.8262. Time: 0.2103 ms. Best GFLOPs: 3257.8337
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #5: GFLOPs: 62.5566. Time: 5.7320 ms. Best GFLOPs: 3257.8337
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #6: GFLOPs: 177.1471. Time: 2.0241 ms. Best GFLOPs: 3257.8337
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #7: GFLOPs: 399.3260. Time: 0.8979 ms. Best GFLOPs: 3257.8337
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #8: GFLOPs: 1750.6532. Time: 0.2048 ms. Best GFLOPs: 3257.8337
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #9: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 104, 104), "float32"], placeholder_1: T.Buffer[(128, 128, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 128, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 128, 104, 104], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 128, 104, 104], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 104, 104], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([128, 128, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(4, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(2, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(128, thread="threadIdx.x"):
                    for i1_3_init, i1_4_init, i2_4_init, i3_4_init in T.grid(2, 2, 26, 13):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused // 8 * 4 + i1_3_init * 2 + i1_4_init)
                            yy = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 26 + i2_4_init)
                            xx = T.axis.spatial(104, i0_2_i1_2_i2_2_i3_2_fused % 8 * 13 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [128, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(32, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(85):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(128, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(128, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1) // 2704)
                                    v2 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 26 + (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1) % 2704 // 104)
                                    v3 = T.axis.spatial(104, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1) % 104)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 < 10816)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(1):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(128, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(128, (ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 4)
                                        v1 = T.axis.spatial(128, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 4)
                                        v2 = T.axis.spatial(1, 0)
                                        v3 = T.axis.spatial(1, 0)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 2, 1, 1, 4, 1, 1, 1, 2, 26, 13):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused // 8 * 4 + i1_3 * 2 + i1_4)
                                yy = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 26 + i2_4)
                                xx = T.axis.spatial(104, i0_2_i1_2_i2_2_i3_2_fused % 8 * 13 + i3_4)
                                rc = T.axis.reduce(128, i4_0 * 4 + i4_2)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [128, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 4, 26, 13):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused // 8 * 4 + ax1)
                            v2 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 26 + ax2)
                            v3 = T.axis.spatial(104, i0_2_i1_2_i2_2_i3_2_fused % 8 * 13 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(6):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(128, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 10816)
                        ax2 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 10816 // 104)
                        ax3 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 104)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 1384448)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 2, 16, 2, 2])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 26])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 1, 8, 1, 13])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[32, 1, 4])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112 = sch.split(loop=l110, factors=[None, 128])
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b90)
l120, l121, l122 = sch.split(loop=l119, factors=[None, 128, 4])
sch.vectorize(loop=l122)
sch.bind(loop=l121, thread_axis="threadIdx.x")
b123 = sch.get_block(name="T_multiply", func_name="main")
l124, l125, l126, l127 = sch.get_loops(block=b123)
l128 = sch.fuse(l124, l125, l126, l127)
l129, l130, l131 = sch.split(loop=l128, factors=[None, 256, 1024])
sch.reorder(l130, l131, l129)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
b132 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b132, ann_key="meta_schedule.unroll_explicit")
b133, b134, b135, b136, b137 = sch.get_child_blocks(b132)
l138, l139, l140, l141, l142, l143, l144, l145 = sch.get_loops(block=b133)
sch.annotate(block_or_loop=l138, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l138, ann_key="pragma_unroll_explicit", ann_val=1)
l146, l147, l148, l149, l150, l151, l152, l153, l154 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l146, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l146, ann_key="pragma_unroll_explicit", ann_val=1)
l155, l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l155, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l155, ann_key="pragma_unroll_explicit", ann_val=1)
l175, l176, l177, l178, l179, l180, l181 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l175, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l175, ann_key="pragma_unroll_explicit", ann_val=1)
l182, l183, l184 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l182, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l182, ann_key="pragma_unroll_explicit", ann_val=1)
b185 = sch.get_block(name="conv2d_nchw", func_name="main")
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b185)
b206 = sch.decompose_reduction(block=b185, loop=l189)
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #10: GFLOPs: 119.0308. Time: 3.0124 ms. Best GFLOPs: 3257.8337
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #11: GFLOPs: 1790.6007. Time: 0.2003 ms. Best GFLOPs: 3257.8337
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #12: GFLOPs: 7.3456. Time: 48.8147 ms. Best GFLOPs: 3257.8337
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #13: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 104, 104), "float32"], placeholder_1: T.Buffer[(128, 128, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 128, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 128, 104, 104], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 128, 104, 104], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 104, 104], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([128, 128, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(26, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(32, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(104, thread="threadIdx.x"):
                    for i1_3_init, i2_3_init, i3_3_init in T.grid(2, 4, 2):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 4 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 2 + i1_3_init)
                            yy = T.axis.spatial(104, i0_1_i1_1_i2_1_i3_1_fused % 4 // 2 * 52 + i0_2_i1_2_i2_2_i3_2_fused % 13 * 4 + i2_3_init)
                            xx = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 4 + i0_1_i1_1_i2_1_i3_1_fused % 2 * 2 + i3_3_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [128, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(32, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(8):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(104, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(2):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(128, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) // 416)
                                        v2 = T.axis.spatial(104, (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 416 // 4)
                                        v3 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 4 + (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 4)
                                        T.reads(placeholder[v0, v1, v2, v3])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(5):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(104, thread="threadIdx.x"):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(128, (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1) // 4)
                                    v1 = T.axis.spatial(128, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1) % 4)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1 < 512)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 2, 4, 2, 4, 1, 1, 1, 1, 1, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 4 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 2 + i1_3)
                                yy = T.axis.spatial(104, i0_1_i1_1_i2_1_i3_1_fused % 4 // 2 * 52 + i0_2_i1_2_i2_2_i3_2_fused % 13 * 4 + i2_3)
                                xx = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 4 + i0_1_i1_1_i2_1_i3_1_fused % 2 * 2 + i3_3)
                                rc = T.axis.reduce(128, i4_0 * 4 + i4_2)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [128, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 2, 4, 2):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 4 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 2 + ax1)
                            v2 = T.axis.spatial(104, i0_1_i1_1_i2_1_i3_1_fused % 4 // 2 * 52 + i0_2_i1_2_i2_2_i3_2_fused % 13 * 4 + ax2)
                            v3 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 4 + i0_1_i1_1_i2_1_i3_1_fused % 2 * 2 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(6):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(128, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 10816)
                        ax2 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 10816 // 104)
                        ax3 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 104)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 1384448)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 8, 8, 2, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 2, 13, 4, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[26, 2, 1, 2, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[32, 1, 4])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112, l113 = sch.split(loop=l110, factors=[None, 104, 2])
sch.vectorize(loop=l113)
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b90)
l121, l122 = sch.split(loop=l120, factors=[None, 104])
sch.bind(loop=l122, thread_axis="threadIdx.x")
b123 = sch.get_block(name="T_multiply", func_name="main")
l124, l125, l126, l127 = sch.get_loops(block=b123)
l128 = sch.fuse(l124, l125, l126, l127)
l129, l130, l131 = sch.split(loop=l128, factors=[None, 256, 1024])
sch.reorder(l130, l131, l129)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
b132 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b132, ann_key="meta_schedule.unroll_explicit")
b133, b134, b135, b136, b137 = sch.get_child_blocks(b132)
l138, l139, l140, l141, l142, l143, l144, l145, l146 = sch.get_loops(block=b133)
sch.annotate(block_or_loop=l138, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l138, ann_key="pragma_unroll_explicit", ann_val=1)
l147, l148, l149, l150, l151, l152, l153, l154 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l147, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l147, ann_key="pragma_unroll_explicit", ann_val=1)
l155, l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l155, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l155, ann_key="pragma_unroll_explicit", ann_val=1)
l175, l176, l177, l178, l179, l180, l181 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l175, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l175, ann_key="pragma_unroll_explicit", ann_val=1)
l182, l183, l184 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l182, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l182, ann_key="pragma_unroll_explicit", ann_val=1)
b185 = sch.get_block(name="conv2d_nchw", func_name="main")
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b185)
b206 = sch.decompose_reduction(block=b185, loop=l189)
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #14: GFLOPs: 2644.4443. Time: 0.1356 ms. Best GFLOPs: 3257.8337
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #15: GFLOPs: 1902.5840. Time: 0.1885 ms. Best GFLOPs: 3257.8337
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #16: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 104, 104), "float32"], placeholder_1: T.Buffer[(128, 128, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 128, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 128, 104, 104], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 128, 104, 104], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 104, 104], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([128, 128, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(13, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(8, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(64, thread="threadIdx.x"):
                    for i3_3_init, i1_4_init, i2_4_init, i3_4_init in T.grid(2, 4, 13, 2):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 4 * 64 + i0_2_i1_2_i2_2_i3_2_fused // 4 * 4 + i1_4_init)
                            yy = T.axis.spatial(104, i0_1_i1_1_i2_1_i3_1_fused % 4 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 4 // 2 * 13 + i2_4_init)
                            xx = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 8 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 4 + i3_3_init * 2 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [128, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(32, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(26):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(64, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(2):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(128, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) // 832)
                                        v2 = T.axis.spatial(104, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 832 // 8)
                                        v3 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 8 + (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 8)
                                        T.reads(placeholder[v0, v1, v2, v3])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(2):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(64, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(128, (ax0_ax1_ax2_ax3_fused_0 * 256 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 4)
                                        v1 = T.axis.spatial(128, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 256 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 4)
                                        v2 = T.axis.spatial(1, 0)
                                        v3 = T.axis.spatial(1, 0)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 1, 1, 2, 4, 1, 1, 1, 4, 13, 2):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 4 * 64 + i0_2_i1_2_i2_2_i3_2_fused // 4 * 4 + i1_4)
                                yy = T.axis.spatial(104, i0_1_i1_1_i2_1_i3_1_fused % 4 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 4 // 2 * 13 + i2_4)
                                xx = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 8 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 4 + i3_3 * 2 + i3_4)
                                rc = T.axis.reduce(128, i4_0 * 4 + i4_2)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [128, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 4, 13, 4):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 4 * 64 + i0_2_i1_2_i2_2_i3_2_fused // 4 * 4 + ax1)
                            v2 = T.axis.spatial(104, i0_1_i1_1_i2_1_i3_1_fused % 4 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 4 // 2 * 13 + ax2)
                            v3 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused * 8 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 4 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(6):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(128, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 10816)
                        ax2 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 10816 // 104)
                        ax3 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 104)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 1384448)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 2, 16, 1, 4])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 4, 2, 1, 13])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[13, 1, 2, 2, 2])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[32, 1, 4])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112, l113 = sch.split(loop=l110, factors=[None, 64, 2])
sch.vectorize(loop=l113)
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b90)
l121, l122, l123 = sch.split(loop=l120, factors=[None, 64, 4])
sch.vectorize(loop=l123)
sch.bind(loop=l122, thread_axis="threadIdx.x")
b124 = sch.get_block(name="T_multiply", func_name="main")
l125, l126, l127, l128 = sch.get_loops(block=b124)
l129 = sch.fuse(l125, l126, l127, l128)
l130, l131, l132 = sch.split(loop=l129, factors=[None, 256, 1024])
sch.reorder(l131, l132, l130)
sch.bind(loop=l131, thread_axis="blockIdx.x")
sch.bind(loop=l132, thread_axis="threadIdx.x")
b133 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b133, ann_key="meta_schedule.unroll_explicit")
b134, b135, b136, b137, b138 = sch.get_child_blocks(b133)
l139, l140, l141, l142, l143, l144, l145, l146, l147 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l139, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l139, ann_key="pragma_unroll_explicit", ann_val=1)
l148, l149, l150, l151, l152, l153, l154, l155, l156 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l148, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l148, ann_key="pragma_unroll_explicit", ann_val=1)
l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174, l175, l176 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l157, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l157, ann_key="pragma_unroll_explicit", ann_val=1)
l177, l178, l179, l180, l181, l182, l183 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l177, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l177, ann_key="pragma_unroll_explicit", ann_val=1)
l184, l185, l186 = sch.get_loops(block=b138)
sch.annotate(block_or_loop=l184, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l184, ann_key="pragma_unroll_explicit", ann_val=1)
b187 = sch.get_block(name="conv2d_nchw", func_name="main")
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b187)
b208 = sch.decompose_reduction(block=b187, loop=l191)
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #17: GFLOPs: 3129.7666. Time: 0.1146 ms. Best GFLOPs: 3257.8337
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #18: GFLOPs: 42.7592. Time: 8.3858 ms. Best GFLOPs: 3257.8337
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #19: GFLOPs: 139.7370. Time: 2.5660 ms. Best GFLOPs: 3257.8337
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #20: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 104, 104), "float32"], placeholder_1: T.Buffer[(128, 128, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 128, 104, 104), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 128, 104, 104], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 128, 104, 104], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 104, 104], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([128, 128, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(4, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(8, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(52, thread="threadIdx.x"):
                    for i2_3_init, i1_4_init, i3_4_init in T.grid(2, 8, 52):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 2 * 64 + i0_1_i1_1_i2_1_i3_1_fused // 2 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 26 * 8 + i1_4_init)
                            yy = T.axis.spatial(104, i0_1_i1_1_i2_1_i3_1_fused % 2 * 52 + i0_2_i1_2_i2_2_i3_2_fused % 26 * 2 + i2_3_init)
                            xx = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 2 * 52 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [128, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(128, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(104):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(128, i4_0)
                                    v2 = T.axis.spatial(104, (ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) // 52)
                                    v3 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 2 * 52 + (ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) % 52)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(2):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 2 * 64 + (ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1))
                                    v1 = T.axis.spatial(128, i4_0)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1 < 64)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 8, 1, 52):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 2 * 64 + i0_1_i1_1_i2_1_i3_1_fused // 2 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 26 * 8 + i1_4)
                                yy = T.axis.spatial(104, i0_1_i1_1_i2_1_i3_1_fused % 2 * 52 + i0_2_i1_2_i2_2_i3_2_fused % 26 * 2 + i2_3)
                                xx = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 2 * 52 + i3_4)
                                rc = T.axis.reduce(128, i4_0)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [128, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 8, 2, 52):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 2 * 64 + i0_1_i1_1_i2_1_i3_1_fused // 2 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 26 * 8 + ax1)
                            v2 = T.axis.spatial(104, i0_1_i1_1_i2_1_i3_1_fused % 2 * 52 + i0_2_i1_2_i2_2_i3_2_fused % 26 * 2 + ax2)
                            v3 = T.axis.spatial(104, i0_0_i1_0_i2_0_i3_0_fused % 2 * 52 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(6):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(128, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 10816)
                        ax2 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 10816 // 104)
                        ax3 = T.axis.spatial(104, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 104)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 1384448)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[2, 4, 2, 1, 8])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 2, 26, 2, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[2, 1, 1, 1, 52])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[128, 1, 1])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112 = sch.split(loop=l110, factors=[None, 52])
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b90)
l120, l121 = sch.split(loop=l119, factors=[None, 52])
sch.bind(loop=l121, thread_axis="threadIdx.x")
b122 = sch.get_block(name="T_multiply", func_name="main")
l123, l124, l125, l126 = sch.get_loops(block=b122)
l127 = sch.fuse(l123, l124, l125, l126)
l128, l129, l130 = sch.split(loop=l127, factors=[None, 256, 1024])
sch.reorder(l129, l130, l128)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
b131 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b131, ann_key="meta_schedule.unroll_explicit")
b132, b133, b134, b135, b136 = sch.get_child_blocks(b131)
l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b132)
sch.annotate(block_or_loop=l137, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l137, ann_key="pragma_unroll_explicit", ann_val=1)
l145, l146, l147, l148, l149, l150, l151, l152 = sch.get_loops(block=b133)
sch.annotate(block_or_loop=l145, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l145, ann_key="pragma_unroll_explicit", ann_val=1)
l153, l154, l155, l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l153, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l153, ann_key="pragma_unroll_explicit", ann_val=1)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l173, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l173, ann_key="pragma_unroll_explicit", ann_val=1)
l180, l181, l182 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l180, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l180, ann_key="pragma_unroll_explicit", ann_val=1)
b183 = sch.get_block(name="conv2d_nchw", func_name="main")
l184, l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203 = sch.get_loops(block=b183)
b204 = sch.decompose_reduction(block=b183, loop=l187)
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #21: GFLOPs: 25.8245. Time: 13.8849 ms. Best GFLOPs: 3257.8337
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #22: GFLOPs: 988.1760. Time: 0.3629 ms. Best GFLOPs: 3257.8337
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #23: GFLOPs: 41.2962. Time: 8.6829 ms. Best GFLOPs: 3257.8337
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #24: GFLOPs: 90.1467. Time: 3.9777 ms. Best GFLOPs: 3257.8337
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #25: GFLOPs: 3419.6236. Time: 0.1049 ms. Best GFLOPs: 3419.6236
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #26: GFLOPs: 2197.0506. Time: 0.1632 ms. Best GFLOPs: 3419.6236
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #27: GFLOPs: 3141.3026. Time: 0.1141 ms. Best GFLOPs: 3419.6236
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #28: GFLOPs: 3226.4265. Time: 0.1111 ms. Best GFLOPs: 3419.6236
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #29: GFLOPs: 1019.6056. Time: 0.3517 ms. Best GFLOPs: 3419.6236
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #30: GFLOPs: 3278.4031. Time: 0.1094 ms. Best GFLOPs: 3419.6236
[14:03:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"] Trial #31: GFLOPs: 1243.4813. Time: 0.2884 ms. Best GFLOPs: 3419.6236
[14:03:28] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |            N/A |          N/A |                   N/A |      0 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 704
Total latency (us): 3625.3

[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #0: GFLOPs: 1617.2988. Time: 0.9874 ms. Best GFLOPs: 1617.2988
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #1: GFLOPs: 3548.8861. Time: 0.4500 ms. Best GFLOPs: 3548.8861
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #2: GFLOPs: 769.5304. Time: 2.0752 ms. Best GFLOPs: 3548.8861
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #3: GFLOPs: 13.1732. Time: 121.2276 ms. Best GFLOPs: 3548.8861
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #4: GFLOPs: 96.0308. Time: 16.6297 ms. Best GFLOPs: 3548.8861
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #5: GFLOPs: 2209.9526. Time: 0.7226 ms. Best GFLOPs: 3548.8861
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #6: GFLOPs: 442.0120. Time: 3.6129 ms. Best GFLOPs: 3548.8861
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #7: GFLOPs: 2894.7199. Time: 0.5517 ms. Best GFLOPs: 3548.8861
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #8: GFLOPs: 407.9167. Time: 3.9149 ms. Best GFLOPs: 3548.8861
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #9: GFLOPs: 74.0982. Time: 21.5519 ms. Best GFLOPs: 3548.8861
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #10: GFLOPs: 357.0197. Time: 4.4730 ms. Best GFLOPs: 3548.8861
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #11: GFLOPs: 2205.0654. Time: 0.7242 ms. Best GFLOPs: 3548.8861
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #12: GFLOPs: 98.6407. Time: 16.1897 ms. Best GFLOPs: 3548.8861
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #13: GFLOPs: 1311.7396. Time: 1.2174 ms. Best GFLOPs: 3548.8861
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #14: GFLOPs: 932.9607. Time: 1.7117 ms. Best GFLOPs: 3548.8861
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #15: GFLOPs: 1082.9216. Time: 1.4747 ms. Best GFLOPs: 3548.8861
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #16: GFLOPs: 759.8364. Time: 2.1017 ms. Best GFLOPs: 3548.8861
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #17: GFLOPs: 919.9771. Time: 1.7359 ms. Best GFLOPs: 3548.8861
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #18: GFLOPs: 1032.9113. Time: 1.5461 ms. Best GFLOPs: 3548.8861
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #19: GFLOPs: 74.7656. Time: 21.3596 ms. Best GFLOPs: 3548.8861
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #20: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 104, 104), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 256, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 256, 52, 52], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 256, 52, 52], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 105, 105], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([256, 128, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(2, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(2, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i1_3_init, i3_3_init, i2_4_init in T.grid(16, 26, 13):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(256, i0_2_i1_2_i2_2_i3_2_fused // 2 * 16 + i1_3_init)
                            yy = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 26 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 13 + i2_4_init)
                            xx = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused * 26 + i3_3_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(128, 3, 3):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(55):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(3):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(128, i4_0 + 0)
                                        v2 = T.axis.spatial(105, i0_0_i1_0_i2_0_i3_0_fused * 52 + i5_0 + ((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 3 + ax0_ax1_ax2_ax3_fused_2) % 5253 // 103)
                                        v3 = T.axis.spatial(105, i6_0 + ((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 3 + ax0_ax1_ax2_ax3_fused_2) % 103)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 3 + ax0_ax1_ax2_ax3_fused_2 < 5253)
                                        T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 105 and 1 <= v3 and v3 < 105, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(2):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(256, ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2)
                                        v1, v2, v3 = T.axis.remap("SSS", [i4_0, i5_0, i6_0])
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 16, 1, 26, 1, 1, 1, 1, 1, 13, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(256, i0_2_i1_2_i2_2_i3_2_fused // 2 * 16 + i1_3)
                                yy = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 26 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 13 + i2_4)
                                xx = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused * 26 + i3_3)
                                rc, ry, rx = T.axis.remap("RRR", [i4_0, i5_0, i6_0])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 16, 13, 26):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(256, i0_2_i1_2_i2_2_i3_2_fused // 2 * 16 + ax1)
                            v2 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 26 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 13 + ax2)
                            v3 = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused * 26 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(3):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(256, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 2704)
                        ax2 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 2704 // 52)
                        ax3 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 52)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 692224)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 1, 16, 16, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 13])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 2, 1, 26, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[128, 1, 1])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112, l113 = sch.split(loop=l110, factors=[None, 32, 3])
sch.vectorize(loop=l113)
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b90)
l121, l122, l123 = sch.split(loop=l120, factors=[None, 32, 4])
sch.vectorize(loop=l123)
sch.bind(loop=l122, thread_axis="threadIdx.x")
b124 = sch.get_block(name="T_multiply", func_name="main")
l125, l126, l127, l128 = sch.get_loops(block=b124)
l129 = sch.fuse(l125, l126, l127, l128)
l130, l131, l132 = sch.split(loop=l129, factors=[None, 256, 1024])
sch.reorder(l131, l132, l130)
sch.bind(loop=l131, thread_axis="blockIdx.x")
sch.bind(loop=l132, thread_axis="threadIdx.x")
b133 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b133, ann_key="meta_schedule.unroll_explicit")
b134, b135, b136, b137, b138 = sch.get_child_blocks(b133)
l139, l140, l141, l142, l143, l144, l145, l146, l147 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l139, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l139, ann_key="pragma_unroll_explicit", ann_val=1)
l148, l149, l150, l151, l152, l153, l154, l155, l156 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l148, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l148, ann_key="pragma_unroll_explicit", ann_val=1)
l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174, l175, l176 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l157, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l157, ann_key="pragma_unroll_explicit", ann_val=1)
l177, l178, l179, l180, l181, l182, l183 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l177, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l177, ann_key="pragma_unroll_explicit", ann_val=1)
l184, l185, l186 = sch.get_loops(block=b138)
sch.annotate(block_or_loop=l184, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l184, ann_key="pragma_unroll_explicit", ann_val=1)
b187 = sch.get_block(name="conv2d_nchw", func_name="main")
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b187)
b208 = sch.decompose_reduction(block=b187, loop=l191)
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #21: GFLOPs: 3547.9406. Time: 0.4501 ms. Best GFLOPs: 3548.8861
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #22: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 104, 104), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 256, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 256, 52, 52], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 256, 52, 52], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 105, 105], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([256, 128, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(13, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(32, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(52, thread="threadIdx.x"):
                    for i1_4_init, i3_4_init in T.grid(16, 2):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(256, i0_1_i1_1_i2_1_i3_1_fused // 2 * 16 + i1_4_init)
                            yy = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused)
                            xx = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 4 + i0_1_i1_1_i2_1_i3_1_fused % 2 * 2 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(64, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(37):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(128, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) % 1890 // 945)
                                    v2 = T.axis.spatial(105, (ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) % 945 // 9)
                                    v3 = T.axis.spatial(105, i0_0_i1_0_i2_0_i3_0_fused * 8 + (ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) % 9)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1 < 1890)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 105 and 1 <= v3 and v3 < 105, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(45):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(2):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(256, (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) // 18)
                                        v1 = T.axis.spatial(128, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 18 // 9)
                                        v2 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 9 // 3)
                                        v3 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 3)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) * 2 + ax0_ax1_ax2_ax3_fused_2 < 4608)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(2, 1, 3, 1, 1, 1, 1, 1, 3, 1, 1, 16, 1, 2):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(256, i0_1_i1_1_i2_1_i3_1_fused // 2 * 16 + i1_4)
                                yy = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused)
                                xx = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 4 + i0_1_i1_1_i2_1_i3_1_fused % 2 * 2 + i3_4)
                                rc = T.axis.reduce(128, i4_0 * 2 + i4_1)
                                ry, rx = T.axis.remap("RR", [i5_2, i6_1])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 16, 1, 2):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(256, i0_1_i1_1_i2_1_i3_1_fused // 2 * 16 + ax1)
                            v2 = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused + ax2)
                            v3 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 4 + i0_1_i1_1_i2_1_i3_1_fused % 2 * 2 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(3):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(256, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 2704)
                        ax2 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 2704 // 52)
                        ax3 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 52)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 692224)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 16, 1, 1, 16])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 1, 52, 1, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[13, 2, 1, 1, 2])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[64, 2, 1])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112 = sch.split(loop=l110, factors=[None, 52])
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b90)
l120, l121, l122 = sch.split(loop=l119, factors=[None, 52, 2])
sch.vectorize(loop=l122)
sch.bind(loop=l121, thread_axis="threadIdx.x")
b123 = sch.get_block(name="T_multiply", func_name="main")
l124, l125, l126, l127 = sch.get_loops(block=b123)
l128 = sch.fuse(l124, l125, l126, l127)
l129, l130, l131 = sch.split(loop=l128, factors=[None, 256, 1024])
sch.reorder(l130, l131, l129)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
b132 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b132, ann_key="meta_schedule.unroll_explicit")
b133, b134, b135, b136, b137 = sch.get_child_blocks(b132)
l138, l139, l140, l141, l142, l143, l144, l145 = sch.get_loops(block=b133)
sch.annotate(block_or_loop=l138, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l138, ann_key="pragma_unroll_explicit", ann_val=1)
l146, l147, l148, l149, l150, l151, l152, l153, l154 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l146, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l146, ann_key="pragma_unroll_explicit", ann_val=1)
l155, l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l155, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l155, ann_key="pragma_unroll_explicit", ann_val=1)
l175, l176, l177, l178, l179, l180, l181 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l175, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l175, ann_key="pragma_unroll_explicit", ann_val=1)
l182, l183, l184 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l182, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l182, ann_key="pragma_unroll_explicit", ann_val=1)
b185 = sch.get_block(name="conv2d_nchw", func_name="main")
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b185)
b206 = sch.decompose_reduction(block=b185, loop=l189)
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #23: GFLOPs: 2932.8459. Time: 0.5445 ms. Best GFLOPs: 3548.8861
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #24: GFLOPs: 1077.9694. Time: 1.4815 ms. Best GFLOPs: 3548.8861
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #25: GFLOPs: 186.7170. Time: 8.5528 ms. Best GFLOPs: 3548.8861
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #26: GFLOPs: 2397.7802. Time: 0.6660 ms. Best GFLOPs: 3548.8861
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #27: Error in building: LocalRunner: An exception occurred
Subprocess terminated
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 104, 104), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 256, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 256, 52, 52], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 256, 52, 52], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 105, 105], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([256, 128, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(13, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(8, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(64, thread="threadIdx.x"):
                    for i1_3_init, i2_3_init, i1_4_init, i3_4_init in T.grid(2, 13, 2, 2):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(256, i0_1_i1_1_i2_1_i3_1_fused * 32 + i0_2_i1_2_i2_2_i3_2_fused // 8 * 4 + i1_3_init * 2 + i1_4_init)
                            yy = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 8 // 2 * 13 + i2_3_init)
                            xx = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 4 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 2 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(64, 3, 3):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(23):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(64, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(128, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1) % 1442 // 721)
                                    v2 = T.axis.spatial(105, i5_0 + (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1) % 721 // 7)
                                    v3 = T.axis.spatial(105, i0_0_i1_0_i2_0_i3_0_fused * 8 + i6_0 + (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1) % 7)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1 < 1442)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 105 and 1 <= v3 and v3 < 105, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(2):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(64, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(256, (ax0_ax1_ax2_ax3_fused_0 * 256 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 2)
                                        v1 = T.axis.spatial(128, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 256 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 2)
                                        v2, v3 = T.axis.remap("SS", [i5_0, i6_0])
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(2, 1, 1, 1, 2, 13, 1, 1, 1, 1, 1, 2, 1, 2):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(256, i0_1_i1_1_i2_1_i3_1_fused * 32 + i0_2_i1_2_i2_2_i3_2_fused // 8 * 4 + i1_3 * 2 + i1_4)
                                yy = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 8 // 2 * 13 + i2_3)
                                xx = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 4 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 2 + i3_4)
                                rc = T.axis.reduce(128, i4_0 * 2 + i4_1)
                                ry, rx = T.axis.remap("RR", [i5_0, i6_0])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 4, 13, 2):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(256, i0_1_i1_1_i2_1_i3_1_fused * 32 + i0_2_i1_2_i2_2_i3_2_fused // 8 * 4 + ax1)
                            v2 = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 8 // 2 * 13 + ax2)
                            v3 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 4 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 2 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(3):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(256, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 2704)
                        ax2 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 2704 // 52)
                        ax3 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 52)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 692224)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 8, 8, 2, 2])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 1, 4, 13, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[13, 1, 2, 1, 2])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[64, 2, 1])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112 = sch.split(loop=l110, factors=[None, 64])
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b90)
l120, l121, l122 = sch.split(loop=l119, factors=[None, 64, 4])
sch.vectorize(loop=l122)
sch.bind(loop=l121, thread_axis="threadIdx.x")
b123 = sch.get_block(name="T_multiply", func_name="main")
l124, l125, l126, l127 = sch.get_loops(block=b123)
l128 = sch.fuse(l124, l125, l126, l127)
l129, l130, l131 = sch.split(loop=l128, factors=[None, 256, 1024])
sch.reorder(l130, l131, l129)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
b132 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b132, ann_key="meta_schedule.unroll_explicit")
b133, b134, b135, b136, b137 = sch.get_child_blocks(b132)
l138, l139, l140, l141, l142, l143, l144, l145 = sch.get_loops(block=b133)
sch.annotate(block_or_loop=l138, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l138, ann_key="pragma_unroll_explicit", ann_val=1)
l146, l147, l148, l149, l150, l151, l152, l153, l154 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l146, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l146, ann_key="pragma_unroll_explicit", ann_val=1)
l155, l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l155, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l155, ann_key="pragma_unroll_explicit", ann_val=1)
l175, l176, l177, l178, l179, l180, l181 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l175, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l175, ann_key="pragma_unroll_explicit", ann_val=1)
l182, l183, l184 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l182, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l182, ann_key="pragma_unroll_explicit", ann_val=1)
b185 = sch.get_block(name="conv2d_nchw", func_name="main")
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b185)
b206 = sch.decompose_reduction(block=b185, loop=l189)
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #28: Error in building: LocalRunner: An exception occurred
Subprocess terminated
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 104, 104), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 256, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 256, 52, 52], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 256, 52, 52], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 105, 105], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([256, 128, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(1352, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(1, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i1_3_init, i2_3_init, i1_4_init, i3_4_init in T.grid(2, 2, 2, 2):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 676 * 128 + i0_2_i1_2_i2_2_i3_2_fused * 4 + i1_3_init * 2 + i1_4_init)
                            yy = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 676 // 26 * 2 + i2_3_init)
                            xx = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 26 * 2 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(64, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(2):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(128, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 50 // 25)
                                    v2 = T.axis.spatial(105, i0_0_i1_0_i2_0_i3_0_fused % 676 // 26 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 25 // 5)
                                    v3 = T.axis.spatial(105, i0_0_i1_0_i2_0_i3_0_fused % 26 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 5)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1 < 50)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 105 and 1 <= v3 and v3 < 105, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(18):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 676 * 128 + (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 18)
                                        v1 = T.axis.spatial(128, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 18 // 9)
                                        v2 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 9 // 3)
                                        v3 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 3)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(2, 1, 1, 1, 2, 2, 1, 1, 3, 3, 1, 2, 1, 2):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 676 * 128 + i0_2_i1_2_i2_2_i3_2_fused * 4 + i1_3 * 2 + i1_4)
                                yy = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 676 // 26 * 2 + i2_3)
                                xx = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 26 * 2 + i3_4)
                                rc = T.axis.reduce(128, i4_0 * 2 + i4_1)
                                ry, rx = T.axis.remap("RR", [i5_2, i6_2])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 4, 2, 2):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 676 * 128 + i0_2_i1_2_i2_2_i3_2_fused * 4 + ax1)
                            v2 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 676 // 26 * 2 + ax2)
                            v3 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 26 * 2 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(3):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(256, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 2704)
                        ax2 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 2704 // 52)
                        ax3 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 52)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 692224)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[2, 1, 32, 2, 2])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[26, 1, 1, 2, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[26, 1, 1, 1, 2])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[64, 2, 1])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112 = sch.split(loop=l110, factors=[None, 32])
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b90)
l120, l121, l122 = sch.split(loop=l119, factors=[None, 32, 4])
sch.vectorize(loop=l122)
sch.bind(loop=l121, thread_axis="threadIdx.x")
b123 = sch.get_block(name="T_multiply", func_name="main")
l124, l125, l126, l127 = sch.get_loops(block=b123)
l128 = sch.fuse(l124, l125, l126, l127)
l129, l130, l131 = sch.split(loop=l128, factors=[None, 256, 1024])
sch.reorder(l130, l131, l129)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
b132 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b132, ann_key="meta_schedule.unroll_explicit")
b133, b134, b135, b136, b137 = sch.get_child_blocks(b132)
l138, l139, l140, l141, l142, l143, l144, l145 = sch.get_loops(block=b133)
sch.annotate(block_or_loop=l138, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l138, ann_key="pragma_unroll_explicit", ann_val=1)
l146, l147, l148, l149, l150, l151, l152, l153, l154 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l146, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l146, ann_key="pragma_unroll_explicit", ann_val=1)
l155, l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l155, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l155, ann_key="pragma_unroll_explicit", ann_val=1)
l175, l176, l177, l178, l179, l180, l181 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l175, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l175, ann_key="pragma_unroll_explicit", ann_val=1)
l182, l183, l184 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l182, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l182, ann_key="pragma_unroll_explicit", ann_val=1)
b185 = sch.get_block(name="conv2d_nchw", func_name="main")
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b185)
b206 = sch.decompose_reduction(block=b185, loop=l189)
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #29: GFLOPs: 3722.3763. Time: 0.4290 ms. Best GFLOPs: 3722.3763
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #30: Error in building: LocalRunner: An exception occurred
Subprocess terminated
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 104, 104), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 256, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 256, 52, 52], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 256, 52, 52], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 105, 105], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([256, 128, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(4, thread="blockIdx.x"):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(104, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i2_4_init, i3_4_init in T.grid(26, 2):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 2 * 128 + i0_1_i1_1_i2_1_i3_1_fused // 26 * 32 + i0_2_i1_2_i2_2_i3_2_fused)
                            yy = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 2 * 26 + i2_4_init)
                            xx = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 26 * 2 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(64, 3, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(335):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(128, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 10710 // 5355)
                                    v2 = T.axis.spatial(105, i0_0_i1_0_i2_0_i3_0_fused % 2 * 52 + i5_0 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 5355 // 105)
                                    v3 = T.axis.spatial(105, (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 105)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1 < 10710)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 105 and 1 <= v3 and v3 < 105, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(6):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 2 * 128 + (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 6)
                                        v1 = T.axis.spatial(128, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 6 // 3)
                                        v2 = T.axis.spatial(3, i5_0)
                                        v3 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 3)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 26, 2):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 2 * 128 + i0_1_i1_1_i2_1_i3_1_fused // 26 * 32 + i0_2_i1_2_i2_2_i3_2_fused)
                                yy = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 2 * 26 + i2_4)
                                xx = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 26 * 2 + i3_4)
                                rc = T.axis.reduce(128, i4_0 * 2 + i4_1)
                                ry, rx = T.axis.remap("RR", [i5_0, i6_1])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 104, 104], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 1, 26, 2):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 2 * 128 + i0_1_i1_1_i2_1_i3_1_fused // 26 * 32 + i0_2_i1_2_i2_2_i3_2_fused + ax1)
                            v2 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 2 * 26 + ax2)
                            v3 = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 26 * 2 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(3):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(256, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 2704)
                        ax2 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 2704 // 52)
                        ax3 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 52)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 692224)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[2, 4, 32, 1, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[2, 1, 1, 1, 26])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 26, 1, 1, 2])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[64, 2, 1])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112 = sch.split(loop=l110, factors=[None, 32])
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b90)
l120, l121, l122 = sch.split(loop=l119, factors=[None, 32, 4])
sch.vectorize(loop=l122)
sch.bind(loop=l121, thread_axis="threadIdx.x")
b123 = sch.get_block(name="T_multiply", func_name="main")
l124, l125, l126, l127 = sch.get_loops(block=b123)
l128 = sch.fuse(l124, l125, l126, l127)
l129, l130, l131 = sch.split(loop=l128, factors=[None, 256, 1024])
sch.reorder(l130, l131, l129)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
b132 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b132, ann_key="meta_schedule.unroll_explicit")
b133, b134, b135, b136, b137 = sch.get_child_blocks(b132)
l138, l139, l140, l141, l142, l143, l144, l145 = sch.get_loops(block=b133)
l146, l147, l148, l149, l150, l151, l152, l153, l154 = sch.get_loops(block=b134)
l155, l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b135)
l175, l176, l177, l178, l179, l180, l181 = sch.get_loops(block=b136)
l182, l183, l184 = sch.get_loops(block=b137)
b185 = sch.get_block(name="conv2d_nchw", func_name="main")
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b185)
b206 = sch.decompose_reduction(block=b185, loop=l189)
[14:03:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"] Trial #31: GFLOPs: 2395.9807. Time: 0.6665 ms. Best GFLOPs: 3722.3763
[14:03:30] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |            N/A |          N/A |                   N/A |      0 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 736
Total latency (us): 4054.31

[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #0: GFLOPs: 2588.3890. Time: 0.0689 ms. Best GFLOPs: 2588.3890
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #1: GFLOPs: 36.6630. Time: 4.8618 ms. Best GFLOPs: 2588.3890
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #2: GFLOPs: 139.9380. Time: 1.2738 ms. Best GFLOPs: 2588.3890
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #3: GFLOPs: 231.5865. Time: 0.7697 ms. Best GFLOPs: 2588.3890
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #4: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 52, 52), "float32"], placeholder_1: T.Buffer[(128, 256, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 128, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 128, 52, 52], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 256, 52, 52], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([128, 256, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(2, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(52, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(104, thread="threadIdx.x"):
                    for i3_3_init, i1_4_init in T.grid(4, 8):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 26 * 64 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 8 + i1_4_init)
                            yy = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 26 + i0_1_i1_1_i2_1_i3_1_fused % 26 // 13 * 13 + i0_2_i1_2_i2_2_i3_2_fused % 13)
                            xx = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 13 * 4 + i3_3_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [128, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(64, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(52):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(104, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(256, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1) // 1352)
                                    v2 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 26 + (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1) % 1352 // 52)
                                    v3 = T.axis.spatial(52, (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1) % 52)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(5):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(104, thread="threadIdx.x"):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(128, (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1) // 4)
                                    v1 = T.axis.spatial(256, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1) % 4)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1 < 512)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 1, 1, 4, 4, 1, 1, 1, 8, 1, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 26 * 64 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 8 + i1_4)
                                yy = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 26 + i0_1_i1_1_i2_1_i3_1_fused % 26 // 13 * 13 + i0_2_i1_2_i2_2_i3_2_fused % 13)
                                xx = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 13 * 4 + i3_3)
                                rc = T.axis.reduce(256, i4_0 * 4 + i4_2)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [128, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 8, 1, 4):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 26 * 64 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 8 + ax1)
                            v2 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 26 + i0_1_i1_1_i2_1_i3_1_fused % 26 // 13 * 13 + i0_2_i1_2_i2_2_i3_2_fused % 13 + ax2)
                            v3 = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 13 * 4 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(2):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(128, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 2704)
                        ax2 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 2704 // 52)
                        ax3 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 52)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 346112)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 2, 8, 1, 8])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[2, 2, 13, 1, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 13, 1, 4, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[64, 1, 4])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112 = sch.split(loop=l110, factors=[None, 104])
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b90)
l120, l121 = sch.split(loop=l119, factors=[None, 104])
sch.bind(loop=l121, thread_axis="threadIdx.x")
b122 = sch.get_block(name="T_multiply", func_name="main")
l123, l124, l125, l126 = sch.get_loops(block=b122)
l127 = sch.fuse(l123, l124, l125, l126)
l128, l129, l130 = sch.split(loop=l127, factors=[None, 256, 1024])
sch.reorder(l129, l130, l128)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
b131 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b131, ann_key="meta_schedule.unroll_explicit")
b132, b133, b134, b135, b136 = sch.get_child_blocks(b131)
l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b132)
sch.annotate(block_or_loop=l137, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l137, ann_key="pragma_unroll_explicit", ann_val=1)
l145, l146, l147, l148, l149, l150, l151, l152 = sch.get_loops(block=b133)
sch.annotate(block_or_loop=l145, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l145, ann_key="pragma_unroll_explicit", ann_val=1)
l153, l154, l155, l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l153, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l153, ann_key="pragma_unroll_explicit", ann_val=1)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l173, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l173, ann_key="pragma_unroll_explicit", ann_val=1)
l180, l181, l182 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l180, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l180, ann_key="pragma_unroll_explicit", ann_val=1)
b183 = sch.get_block(name="conv2d_nchw", func_name="main")
l184, l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203 = sch.get_loops(block=b183)
b204 = sch.decompose_reduction(block=b183, loop=l187)
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #5: GFLOPs: 168.8599. Time: 1.0556 ms. Best GFLOPs: 2588.3890
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #6: GFLOPs: 13.0060. Time: 13.7050 ms. Best GFLOPs: 2588.3890
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #7: GFLOPs: 1700.6004. Time: 0.1048 ms. Best GFLOPs: 2588.3890
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #8: GFLOPs: 15.0941. Time: 11.8091 ms. Best GFLOPs: 2588.3890
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #9: GFLOPs: 775.1038. Time: 0.2300 ms. Best GFLOPs: 2588.3890
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #10: GFLOPs: 21.0522. Time: 8.4670 ms. Best GFLOPs: 2588.3890
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #11: GFLOPs: 2147.0853. Time: 0.0830 ms. Best GFLOPs: 2588.3890
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #12: GFLOPs: 1421.5301. Time: 0.1254 ms. Best GFLOPs: 2588.3890
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #13: GFLOPs: 2979.2711. Time: 0.0598 ms. Best GFLOPs: 2979.2711
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #14: GFLOPs: 88.1684. Time: 2.0217 ms. Best GFLOPs: 2979.2711
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #15: GFLOPs: 2328.2402. Time: 0.0766 ms. Best GFLOPs: 2979.2711
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #16: GFLOPs: 31.8916. Time: 5.5892 ms. Best GFLOPs: 2979.2711
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #17: GFLOPs: 3402.7627. Time: 0.0524 ms. Best GFLOPs: 3402.7627
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #18: GFLOPs: 970.1099. Time: 0.1837 ms. Best GFLOPs: 3402.7627
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #19: GFLOPs: 104.8128. Time: 1.7006 ms. Best GFLOPs: 3402.7627
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #20: GFLOPs: 2957.1312. Time: 0.0603 ms. Best GFLOPs: 3402.7627
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #21: GFLOPs: 19.0010. Time: 9.3810 ms. Best GFLOPs: 3402.7627
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #22: GFLOPs: 1636.3011. Time: 0.1089 ms. Best GFLOPs: 3402.7627
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #23: GFLOPs: 189.8766. Time: 0.9388 ms. Best GFLOPs: 3402.7627
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #24: GFLOPs: 1523.0540. Time: 0.1170 ms. Best GFLOPs: 3402.7627
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #25: GFLOPs: 40.2232. Time: 4.4315 ms. Best GFLOPs: 3402.7627
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #26: GFLOPs: 11.8749. Time: 15.0105 ms. Best GFLOPs: 3402.7627
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #27: GFLOPs: 353.5383. Time: 0.5042 ms. Best GFLOPs: 3402.7627
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #28: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 52, 52), "float32"], placeholder_1: T.Buffer[(128, 256, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 128, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 128, 52, 52], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 256, 52, 52], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([128, 256, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(13, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(128, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(52, thread="threadIdx.x"):
                    for i1_3_init, i2_4_init in T.grid(2, 2):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 8 * 8 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 2 + i1_3_init)
                            yy = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 8 // 4 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 13 * 2 + i2_4_init)
                            xx = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 4 + i0_1_i1_1_i2_1_i3_1_fused % 4)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [128, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(16, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(16):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(256, i4_0 * 16 + (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 208)
                                        v2 = T.axis.spatial(52, (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 208 // 4)
                                        v3 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 4 + (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 4)
                                        T.reads(placeholder[v0, v1, v2, v3])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(20):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(2):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(128, (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) // 16)
                                        v1 = T.axis.spatial(256, i4_0 * 16 + (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 16)
                                        v2 = T.axis.spatial(1, 0)
                                        v3 = T.axis.spatial(1, 0)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) * 2 + ax0_ax1_ax2_ax3_fused_2 < 2048)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(4, 1, 1, 1, 2, 1, 1, 4, 1, 1, 1, 1, 2, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 8 * 8 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 2 + i1_3)
                                yy = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 8 // 4 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 13 * 2 + i2_4)
                                xx = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 4 + i0_1_i1_1_i2_1_i3_1_fused % 4)
                                rc = T.axis.reduce(256, i4_0 * 16 + i4_1 * 4 + i4_2)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [128, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 2, 2, 1):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 8 * 8 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 2 + ax1)
                            v2 = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 8 // 4 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 13 * 2 + ax2)
                            v3 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 4 + i0_1_i1_1_i2_1_i3_1_fused % 4 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(2):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(128, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 2704)
                        ax2 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 2704 // 52)
                        ax3 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 52)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 346112)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 16, 4, 2, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 2, 13, 1, 2])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[13, 4, 1, 1, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[16, 4, 4])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112, l113 = sch.split(loop=l110, factors=[None, 52, 4])
sch.vectorize(loop=l113)
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b90)
l121, l122, l123 = sch.split(loop=l120, factors=[None, 52, 2])
sch.vectorize(loop=l123)
sch.bind(loop=l122, thread_axis="threadIdx.x")
b124 = sch.get_block(name="T_multiply", func_name="main")
l125, l126, l127, l128 = sch.get_loops(block=b124)
l129 = sch.fuse(l125, l126, l127, l128)
l130, l131, l132 = sch.split(loop=l129, factors=[None, 256, 1024])
sch.reorder(l131, l132, l130)
sch.bind(loop=l131, thread_axis="blockIdx.x")
sch.bind(loop=l132, thread_axis="threadIdx.x")
b133 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b133, ann_key="meta_schedule.unroll_explicit")
b134, b135, b136, b137, b138 = sch.get_child_blocks(b133)
l139, l140, l141, l142, l143, l144, l145, l146, l147 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l139, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l139, ann_key="pragma_unroll_explicit", ann_val=1)
l148, l149, l150, l151, l152, l153, l154, l155, l156 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l148, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l148, ann_key="pragma_unroll_explicit", ann_val=1)
l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174, l175, l176 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l157, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l157, ann_key="pragma_unroll_explicit", ann_val=1)
l177, l178, l179, l180, l181, l182, l183 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l177, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l177, ann_key="pragma_unroll_explicit", ann_val=1)
l184, l185, l186 = sch.get_loops(block=b138)
sch.annotate(block_or_loop=l184, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l184, ann_key="pragma_unroll_explicit", ann_val=1)
b187 = sch.get_block(name="conv2d_nchw", func_name="main")
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b187)
b208 = sch.decompose_reduction(block=b187, loop=l191)
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #29: GFLOPs: 2657.1100. Time: 0.0671 ms. Best GFLOPs: 3402.7627
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #30: GFLOPs: 505.5902. Time: 0.3526 ms. Best GFLOPs: 3402.7627
[14:03:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"] Trial #31: GFLOPs: 34.9184. Time: 5.1047 ms. Best GFLOPs: 3402.7627
[14:03:31] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |            N/A |          N/A |                   N/A |      0 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 768
Total latency (us): 4159.08

[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #0: GFLOPs: 3399.5921. Time: 0.2350 ms. Best GFLOPs: 3399.5921
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #1: GFLOPs: 32.6243. Time: 24.4856 ms. Best GFLOPs: 3399.5921
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #2: GFLOPs: 14.5112. Time: 55.0489 ms. Best GFLOPs: 3399.5921
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #3: GFLOPs: 1315.7199. Time: 0.6071 ms. Best GFLOPs: 3399.5921
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #4: GFLOPs: 117.9699. Time: 6.7714 ms. Best GFLOPs: 3399.5921
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #5: GFLOPs: 1558.9932. Time: 0.5124 ms. Best GFLOPs: 3399.5921
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #6: GFLOPs: 835.5291. Time: 0.9561 ms. Best GFLOPs: 3399.5921
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #7: GFLOPs: 765.4028. Time: 1.0437 ms. Best GFLOPs: 3399.5921
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #8: GFLOPs: 1588.2376. Time: 0.5030 ms. Best GFLOPs: 3399.5921
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #9: GFLOPs: 875.0503. Time: 0.9129 ms. Best GFLOPs: 3399.5921
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #10: GFLOPs: 146.6310. Time: 5.4479 ms. Best GFLOPs: 3399.5921
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #11: GFLOPs: 1884.0945. Time: 0.4240 ms. Best GFLOPs: 3399.5921
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #12: GFLOPs: 1943.7382. Time: 0.4110 ms. Best GFLOPs: 3399.5921
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #13: GFLOPs: 18.2581. Time: 43.7519 ms. Best GFLOPs: 3399.5921
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #14: GFLOPs: 1045.5817. Time: 0.7640 ms. Best GFLOPs: 3399.5921
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #15: GFLOPs: 459.5453. Time: 1.7383 ms. Best GFLOPs: 3399.5921
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #16: GFLOPs: 5010.5072. Time: 0.1594 ms. Best GFLOPs: 5010.5072
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #17: GFLOPs: 79.9691. Time: 9.9892 ms. Best GFLOPs: 5010.5072
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #18: GFLOPs: 2279.4137. Time: 0.3505 ms. Best GFLOPs: 5010.5072
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #19: GFLOPs: 1992.6794. Time: 0.4009 ms. Best GFLOPs: 5010.5072
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #20: GFLOPs: 1489.1390. Time: 0.5364 ms. Best GFLOPs: 5010.5072
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #21: GFLOPs: 159.7920. Time: 4.9992 ms. Best GFLOPs: 5010.5072
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #22: GFLOPs: 2804.5329. Time: 0.2848 ms. Best GFLOPs: 5010.5072
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #23: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 52, 52), "float32"], placeholder_1: T.Buffer[(128, 128, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], placeholder_4: T.Buffer[(1, 128, 52, 52), "float32"], T_add: T.Buffer[(1, 128, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 128, 52, 52], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 54, 54], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([128, 128, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(4, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(26, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i1_3_init, i2_3_init, i3_3_init, i3_4_init in T.grid(2, 2, 2, 13):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 13 * 64 + i0_2_i1_2_i2_2_i3_2_fused * 2 + i1_3_init)
                            yy = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused // 2 * 26 + i0_1_i1_1_i2_1_i3_1_fused % 13 * 2 + i2_3_init)
                            xx = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 2 * 26 + i3_3_init * 13 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [128, 128, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(64, 1, 3):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(23):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(2):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(128, i4_0 * 2 + ((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 2 + ax0_ax1_ax2_ax3_fused_2) % 1456 // 728)
                                        v2 = T.axis.spatial(54, i0_0_i1_0_i2_0_i3_0_fused // 2 * 26 + ((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 2 + ax0_ax1_ax2_ax3_fused_2) % 728 // 26)
                                        v3 = T.axis.spatial(54, i0_0_i1_0_i2_0_i3_0_fused % 2 * 26 + i6_0 + ((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 2 + ax0_ax1_ax2_ax3_fused_2) % 26)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 2 + ax0_ax1_ax2_ax3_fused_2 < 1456)
                                        T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 53 and 1 <= v3 and v3 < 53, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(24):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(128, (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) // 6)
                                    v1 = T.axis.spatial(128, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 6 // 3)
                                    v2 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 3)
                                    v3 = T.axis.spatial(3, i6_0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 3, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 13):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 13 * 64 + i0_2_i1_2_i2_2_i3_2_fused * 2 + i1_3)
                                yy = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused // 2 * 26 + i0_1_i1_1_i2_1_i3_1_fused % 13 * 2 + i2_3)
                                xx = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 2 * 26 + i3_3 * 13 + i3_4)
                                rc = T.axis.reduce(128, i4_0 * 2 + i4_2)
                                ry, rx = T.axis.remap("RR", [i5_1, i6_0])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [128, 128, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 2, 2, 26):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 13 * 64 + i0_2_i1_2_i2_2_i3_2_fused * 2 + ax1)
                            v2 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused // 2 * 26 + i0_1_i1_1_i2_1_i3_1_fused % 13 * 2 + ax2)
                            v3 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 2 * 26 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(2):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(128, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 2704)
                        ax2 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 2704 // 52)
                        ax3 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 52)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 346112)
                        T.reads(placeholder_4[ax0, ax1, ax2, ax3], conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_add[ax0, ax1, ax2, ax3])
                        T_add[ax0, ax1, ax2, ax3] = placeholder_4[ax0, ax1, ax2, ax3] + (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="T_add_2", func_name="main")
b8 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l9, l10, l11, l12, l13, l14, l15 = sch.get_loops(block=b1)
v16, v17, v18, v19, v20 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l21, l22, l23, l24, l25 = sch.split(loop=l9, factors=[v16, v17, v18, v19, v20])
v26, v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 2, 32, 2, 1])
l31, l32, l33, l34, l35 = sch.split(loop=l10, factors=[v26, v27, v28, v29, v30])
v36, v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[2, 13, 1, 2, 1])
l41, l42, l43, l44, l45 = sch.split(loop=l11, factors=[v36, v37, v38, v39, v40])
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l12, n=5, max_innermost_factor=64, decision=[2, 1, 1, 2, 13])
l51, l52, l53, l54, l55 = sch.split(loop=l12, factors=[v46, v47, v48, v49, v50])
v56, v57, v58 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[64, 1, 2])
l59, l60, l61 = sch.split(loop=l13, factors=[v56, v57, v58])
v62, v63, v64 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l65, l66, l67 = sch.split(loop=l14, factors=[v62, v63, v64])
v68, v69, v70 = sch.sample_perfect_tile(loop=l15, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l71, l72, l73 = sch.split(loop=l15, factors=[v68, v69, v70])
sch.reorder(l21, l31, l41, l51, l22, l32, l42, l52, l23, l33, l43, l53, l59, l65, l71, l60, l66, l72, l24, l34, l44, l54, l61, l67, l73, l25, l35, l45, l55)
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="blockIdx.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="vthread.x")
l76 = sch.fuse(l23, l33, l43, l53)
sch.bind(loop=l76, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b77 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b77, loop=l76, preserve_unit_loops=True)
b78 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b78, loop=l71, preserve_unit_loops=True)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b78)
l89 = sch.fuse(l85, l86, l87, l88)
v90 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b78, ann_key="meta_schedule.cooperative_fetch", ann_val=v90)
b91 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b91, loop=l71, preserve_unit_loops=True)
l92, l93, l94, l95, l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b91)
l102 = sch.fuse(l98, l99, l100, l101)
v103 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b91, ann_key="meta_schedule.cooperative_fetch", ann_val=v103)
sch.reverse_compute_inline(block=b7)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v104 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b8, ann_key="meta_schedule.unroll_explicit", ann_val=v104)
sch.enter_postproc()
sch.unannotate(block_or_loop=b78, ann_key="meta_schedule.cooperative_fetch")
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b78)
l112, l113, l114 = sch.split(loop=l111, factors=[None, 32, 2])
sch.vectorize(loop=l114)
sch.bind(loop=l113, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b91, ann_key="meta_schedule.cooperative_fetch")
l115, l116, l117, l118, l119, l120, l121 = sch.get_loops(block=b91)
l122, l123 = sch.split(loop=l121, factors=[None, 32])
sch.bind(loop=l123, thread_axis="threadIdx.x")
b124 = sch.get_block(name="T_multiply", func_name="main")
l125, l126, l127, l128 = sch.get_loops(block=b124)
l129 = sch.fuse(l125, l126, l127, l128)
l130, l131, l132 = sch.split(loop=l129, factors=[None, 256, 1024])
sch.reorder(l131, l132, l130)
sch.bind(loop=l131, thread_axis="blockIdx.x")
sch.bind(loop=l132, thread_axis="threadIdx.x")
b133 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b133, ann_key="meta_schedule.unroll_explicit")
b134, b135, b136, b137, b138 = sch.get_child_blocks(b133)
l139, l140, l141, l142, l143, l144, l145, l146, l147 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l139, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l139, ann_key="pragma_unroll_explicit", ann_val=1)
l148, l149, l150, l151, l152, l153, l154, l155 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l148, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l148, ann_key="pragma_unroll_explicit", ann_val=1)
l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174, l175 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l156, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l156, ann_key="pragma_unroll_explicit", ann_val=1)
l176, l177, l178, l179, l180, l181, l182 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l176, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l176, ann_key="pragma_unroll_explicit", ann_val=1)
l183, l184, l185 = sch.get_loops(block=b138)
sch.annotate(block_or_loop=l183, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l183, ann_key="pragma_unroll_explicit", ann_val=1)
b186 = sch.get_block(name="conv2d_nchw", func_name="main")
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b186)
b207 = sch.decompose_reduction(block=b186, loop=l190)
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #24: GFLOPs: 6.0012. Time: 133.1105 ms. Best GFLOPs: 5010.5072
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #25: GFLOPs: 1704.0627. Time: 0.4688 ms. Best GFLOPs: 5010.5072
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #26: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 52, 52), "float32"], placeholder_1: T.Buffer[(128, 128, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], placeholder_4: T.Buffer[(1, 128, 52, 52), "float32"], T_add: T.Buffer[(1, 128, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 128, 52, 52], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 54, 54], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([128, 128, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(2, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(26, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(208, thread="threadIdx.x"):
                    for i2_3_init, i3_3_init, i1_4_init, i3_4_init in T.grid(2, 2, 4, 2):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 4 + i1_4_init)
                            yy = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused * 2 + i2_3_init)
                            xx = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 13 * 4 + i3_3_init * 2 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [128, 128, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(64, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(10):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(208, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(3):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(128, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 624 + ax0_ax1_ax2_ax3_fused_1 * 3 + ax0_ax1_ax2_ax3_fused_2) // 2916)
                                        v2 = T.axis.spatial(54, (ax0_ax1_ax2_ax3_fused_0 * 624 + ax0_ax1_ax2_ax3_fused_1 * 3 + ax0_ax1_ax2_ax3_fused_2) % 2916 // 54)
                                        v3 = T.axis.spatial(54, (ax0_ax1_ax2_ax3_fused_0 * 624 + ax0_ax1_ax2_ax3_fused_1 * 3 + ax0_ax1_ax2_ax3_fused_2) % 54)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1) * 3 + ax0_ax1_ax2_ax3_fused_2 < 5832)
                                        T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 53 and 1 <= v3 and v3 < 53, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(2):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(208, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused * 64 + (ax0_ax1_ax2_ax3_fused_0 * 832 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 18)
                                        v1 = T.axis.spatial(128, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 832 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 18 // 9)
                                        v2 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 832 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 9 // 3)
                                        v3 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 832 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 3)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1) * 4 + ax0_ax1_ax2_ax3_fused_2 < 1152)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(2, 1, 3, 1, 1, 2, 2, 1, 3, 1, 1, 4, 1, 2):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 4 + i1_4)
                                yy = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused * 2 + i2_3)
                                xx = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 13 * 4 + i3_3 * 2 + i3_4)
                                rc = T.axis.reduce(128, i4_0 * 2 + i4_1)
                                ry, rx = T.axis.remap("RR", [i5_2, i6_1])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [128, 128, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 4, 2, 4):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 4 + ax1)
                            v2 = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused * 2 + ax2)
                            v3 = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 13 * 4 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(2):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(128, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 2704)
                        ax2 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 2704 // 52)
                        ax3 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 52)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 346112)
                        T.reads(placeholder_4[ax0, ax1, ax2, ax3], conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_add[ax0, ax1, ax2, ax3])
                        T_add[ax0, ax1, ax2, ax3] = placeholder_4[ax0, ax1, ax2, ax3] + (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="T_add_2", func_name="main")
b8 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l9, l10, l11, l12, l13, l14, l15 = sch.get_loops(block=b1)
v16, v17, v18, v19, v20 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l21, l22, l23, l24, l25 = sch.split(loop=l9, factors=[v16, v17, v18, v19, v20])
v26, v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[2, 1, 16, 1, 4])
l31, l32, l33, l34, l35 = sch.split(loop=l10, factors=[v26, v27, v28, v29, v30])
v36, v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 26, 1, 2, 1])
l41, l42, l43, l44, l45 = sch.split(loop=l11, factors=[v36, v37, v38, v39, v40])
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l12, n=5, max_innermost_factor=64, decision=[1, 1, 13, 2, 2])
l51, l52, l53, l54, l55 = sch.split(loop=l12, factors=[v46, v47, v48, v49, v50])
v56, v57, v58 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[64, 2, 1])
l59, l60, l61 = sch.split(loop=l13, factors=[v56, v57, v58])
v62, v63, v64 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l65, l66, l67 = sch.split(loop=l14, factors=[v62, v63, v64])
v68, v69, v70 = sch.sample_perfect_tile(loop=l15, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l71, l72, l73 = sch.split(loop=l15, factors=[v68, v69, v70])
sch.reorder(l21, l31, l41, l51, l22, l32, l42, l52, l23, l33, l43, l53, l59, l65, l71, l60, l66, l72, l24, l34, l44, l54, l61, l67, l73, l25, l35, l45, l55)
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="blockIdx.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="vthread.x")
l76 = sch.fuse(l23, l33, l43, l53)
sch.bind(loop=l76, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b77 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b77, loop=l76, preserve_unit_loops=True)
b78 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b78, loop=l71, preserve_unit_loops=True)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b78)
l89 = sch.fuse(l85, l86, l87, l88)
v90 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b78, ann_key="meta_schedule.cooperative_fetch", ann_val=v90)
b91 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b91, loop=l71, preserve_unit_loops=True)
l92, l93, l94, l95, l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b91)
l102 = sch.fuse(l98, l99, l100, l101)
v103 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b91, ann_key="meta_schedule.cooperative_fetch", ann_val=v103)
sch.reverse_compute_inline(block=b7)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v104 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b8, ann_key="meta_schedule.unroll_explicit", ann_val=v104)
sch.enter_postproc()
sch.unannotate(block_or_loop=b78, ann_key="meta_schedule.cooperative_fetch")
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b78)
l112, l113, l114 = sch.split(loop=l111, factors=[None, 208, 3])
sch.vectorize(loop=l114)
sch.bind(loop=l113, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b91, ann_key="meta_schedule.cooperative_fetch")
l115, l116, l117, l118, l119, l120, l121 = sch.get_loops(block=b91)
l122, l123, l124 = sch.split(loop=l121, factors=[None, 208, 4])
sch.vectorize(loop=l124)
sch.bind(loop=l123, thread_axis="threadIdx.x")
b125 = sch.get_block(name="T_multiply", func_name="main")
l126, l127, l128, l129 = sch.get_loops(block=b125)
l130 = sch.fuse(l126, l127, l128, l129)
l131, l132, l133 = sch.split(loop=l130, factors=[None, 256, 1024])
sch.reorder(l132, l133, l131)
sch.bind(loop=l132, thread_axis="blockIdx.x")
sch.bind(loop=l133, thread_axis="threadIdx.x")
b134 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b134, ann_key="meta_schedule.unroll_explicit")
b135, b136, b137, b138, b139 = sch.get_child_blocks(b134)
l140, l141, l142, l143, l144, l145, l146, l147, l148 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l140, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l140, ann_key="pragma_unroll_explicit", ann_val=1)
l149, l150, l151, l152, l153, l154, l155, l156, l157 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l149, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l149, ann_key="pragma_unroll_explicit", ann_val=1)
l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174, l175, l176, l177 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l158, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l158, ann_key="pragma_unroll_explicit", ann_val=1)
l178, l179, l180, l181, l182, l183, l184 = sch.get_loops(block=b138)
sch.annotate(block_or_loop=l178, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l178, ann_key="pragma_unroll_explicit", ann_val=1)
l185, l186, l187 = sch.get_loops(block=b139)
sch.annotate(block_or_loop=l185, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l185, ann_key="pragma_unroll_explicit", ann_val=1)
b188 = sch.get_block(name="conv2d_nchw", func_name="main")
l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b188)
b209 = sch.decompose_reduction(block=b188, loop=l192)
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #27: GFLOPs: 1432.9385. Time: 0.5575 ms. Best GFLOPs: 5010.5072
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #28: GFLOPs: 2853.6975. Time: 0.2799 ms. Best GFLOPs: 5010.5072
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #29: GFLOPs: 26.4796. Time: 30.1677 ms. Best GFLOPs: 5010.5072
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #30: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 52, 52), "float32"], placeholder_1: T.Buffer[(128, 128, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], placeholder_4: T.Buffer[(1, 128, 52, 52), "float32"], T_add: T.Buffer[(1, 128, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 128, 52, 52], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 54, 54], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([128, 128, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(8, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(8, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(52, thread="threadIdx.x"):
                    for i1_3_init, i2_4_init, i3_4_init in T.grid(2, 26, 2):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 2 * 32 + i0_1_i1_1_i2_1_i3_1_fused * 4 + i0_2_i1_2_i2_2_i3_2_fused // 26 * 2 + i1_3_init)
                            yy = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 2 * 26 + i2_4_init)
                            xx = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 26 * 2 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [128, 128, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(64, 1, 3):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(56):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(128, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) % 2912 // 1456)
                                    v2 = T.axis.spatial(54, i0_0_i1_0_i2_0_i3_0_fused % 2 * 26 + (ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) % 1456 // 52)
                                    v3 = T.axis.spatial(54, i6_0 + (ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) % 52)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 53 and 1 <= v3 and v3 < 53, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(1):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 2 * 32 + (ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 6)
                                        v1 = T.axis.spatial(128, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 6 // 3)
                                        v2 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 3)
                                        v3 = T.axis.spatial(3, i6_0)
                                        T.where(ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2 < 192)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(2, 1, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 26, 2):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 2 * 32 + i0_1_i1_1_i2_1_i3_1_fused * 4 + i0_2_i1_2_i2_2_i3_2_fused // 26 * 2 + i1_3)
                                yy = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 2 * 26 + i2_4)
                                xx = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 26 * 2 + i3_4)
                                rc = T.axis.reduce(128, i4_0 * 2 + i4_1)
                                ry, rx = T.axis.remap("RR", [i5_2, i6_0])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [128, 128, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 2, 26, 2):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 2 * 32 + i0_1_i1_1_i2_1_i3_1_fused * 4 + i0_2_i1_2_i2_2_i3_2_fused // 26 * 2 + ax1)
                            v2 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 2 * 26 + ax2)
                            v3 = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 26 * 2 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(2):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(128, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 2704)
                        ax2 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 2704 // 52)
                        ax3 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 52)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 346112)
                        T.reads(placeholder_4[ax0, ax1, ax2, ax3], conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_add[ax0, ax1, ax2, ax3])
                        T_add[ax0, ax1, ax2, ax3] = placeholder_4[ax0, ax1, ax2, ax3] + (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="T_add_2", func_name="main")
b8 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l9, l10, l11, l12, l13, l14, l15 = sch.get_loops(block=b1)
v16, v17, v18, v19, v20 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l21, l22, l23, l24, l25 = sch.split(loop=l9, factors=[v16, v17, v18, v19, v20])
v26, v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[4, 8, 2, 2, 1])
l31, l32, l33, l34, l35 = sch.split(loop=l10, factors=[v26, v27, v28, v29, v30])
v36, v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[2, 1, 1, 1, 26])
l41, l42, l43, l44, l45 = sch.split(loop=l11, factors=[v36, v37, v38, v39, v40])
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l12, n=5, max_innermost_factor=64, decision=[1, 1, 26, 1, 2])
l51, l52, l53, l54, l55 = sch.split(loop=l12, factors=[v46, v47, v48, v49, v50])
v56, v57, v58 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[64, 2, 1])
l59, l60, l61 = sch.split(loop=l13, factors=[v56, v57, v58])
v62, v63, v64 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l65, l66, l67 = sch.split(loop=l14, factors=[v62, v63, v64])
v68, v69, v70 = sch.sample_perfect_tile(loop=l15, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l71, l72, l73 = sch.split(loop=l15, factors=[v68, v69, v70])
sch.reorder(l21, l31, l41, l51, l22, l32, l42, l52, l23, l33, l43, l53, l59, l65, l71, l60, l66, l72, l24, l34, l44, l54, l61, l67, l73, l25, l35, l45, l55)
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="blockIdx.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="vthread.x")
l76 = sch.fuse(l23, l33, l43, l53)
sch.bind(loop=l76, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b77 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b77, loop=l76, preserve_unit_loops=True)
b78 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b78, loop=l71, preserve_unit_loops=True)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b78)
l89 = sch.fuse(l85, l86, l87, l88)
v90 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b78, ann_key="meta_schedule.cooperative_fetch", ann_val=v90)
b91 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b91, loop=l71, preserve_unit_loops=True)
l92, l93, l94, l95, l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b91)
l102 = sch.fuse(l98, l99, l100, l101)
v103 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b91, ann_key="meta_schedule.cooperative_fetch", ann_val=v103)
sch.reverse_compute_inline(block=b7)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v104 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b8, ann_key="meta_schedule.unroll_explicit", ann_val=v104)
sch.enter_postproc()
sch.unannotate(block_or_loop=b78, ann_key="meta_schedule.cooperative_fetch")
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b78)
l112, l113 = sch.split(loop=l111, factors=[None, 52])
sch.bind(loop=l113, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b91, ann_key="meta_schedule.cooperative_fetch")
l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b91)
l121, l122, l123 = sch.split(loop=l120, factors=[None, 52, 4])
sch.vectorize(loop=l123)
sch.bind(loop=l122, thread_axis="threadIdx.x")
b124 = sch.get_block(name="T_multiply", func_name="main")
l125, l126, l127, l128 = sch.get_loops(block=b124)
l129 = sch.fuse(l125, l126, l127, l128)
l130, l131, l132 = sch.split(loop=l129, factors=[None, 256, 1024])
sch.reorder(l131, l132, l130)
sch.bind(loop=l131, thread_axis="blockIdx.x")
sch.bind(loop=l132, thread_axis="threadIdx.x")
b133 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b133, ann_key="meta_schedule.unroll_explicit")
b134, b135, b136, b137, b138 = sch.get_child_blocks(b133)
l139, l140, l141, l142, l143, l144, l145, l146 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l139, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l139, ann_key="pragma_unroll_explicit", ann_val=1)
l147, l148, l149, l150, l151, l152, l153, l154, l155 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l147, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l147, ann_key="pragma_unroll_explicit", ann_val=1)
l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174, l175 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l156, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l156, ann_key="pragma_unroll_explicit", ann_val=1)
l176, l177, l178, l179, l180, l181, l182 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l176, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l176, ann_key="pragma_unroll_explicit", ann_val=1)
l183, l184, l185 = sch.get_loops(block=b138)
sch.annotate(block_or_loop=l183, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l183, ann_key="pragma_unroll_explicit", ann_val=1)
b186 = sch.get_block(name="conv2d_nchw", func_name="main")
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b186)
b207 = sch.decompose_reduction(block=b186, loop=l190)
[14:03:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"] Trial #31: GFLOPs: 1782.1120. Time: 0.4482 ms. Best GFLOPs: 5010.5072
[14:03:33] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 800
Total latency (us): 5434.52

[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #0: GFLOPs: 2071.2094. Time: 0.0433 ms. Best GFLOPs: 2071.2094
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #1: GFLOPs: 1447.3096. Time: 0.0619 ms. Best GFLOPs: 2071.2094
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #2: GFLOPs: 8.9546. Time: 10.0108 ms. Best GFLOPs: 2071.2094
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #3: GFLOPs: 1549.0699. Time: 0.0579 ms. Best GFLOPs: 2071.2094
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #4: GFLOPs: 172.6317. Time: 0.5193 ms. Best GFLOPs: 2071.2094
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #5: GFLOPs: 1945.9290. Time: 0.0461 ms. Best GFLOPs: 2071.2094
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #6: GFLOPs: 1892.6010. Time: 0.0474 ms. Best GFLOPs: 2071.2094
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #7: GFLOPs: 25.7966. Time: 3.4750 ms. Best GFLOPs: 2071.2094
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #8: GFLOPs: 17.4400. Time: 5.1401 ms. Best GFLOPs: 2071.2094
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #9: GFLOPs: 899.6798. Time: 0.0996 ms. Best GFLOPs: 2071.2094
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #10: GFLOPs: 38.9555. Time: 2.3012 ms. Best GFLOPs: 2071.2094
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #11: GFLOPs: 35.0434. Time: 2.5581 ms. Best GFLOPs: 2071.2094
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #12: GFLOPs: 1962.1385. Time: 0.0457 ms. Best GFLOPs: 2071.2094
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #13: GFLOPs: 1596.9354. Time: 0.0561 ms. Best GFLOPs: 2071.2094
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #14: GFLOPs: 2041.9175. Time: 0.0439 ms. Best GFLOPs: 2071.2094
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #15: GFLOPs: 2728.7975. Time: 0.0329 ms. Best GFLOPs: 2728.7975
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #16: GFLOPs: 520.6070. Time: 0.1722 ms. Best GFLOPs: 2728.7975
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #17: GFLOPs: 641.7793. Time: 0.1397 ms. Best GFLOPs: 2728.7975
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #18: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 52, 52), "float32"], placeholder_1: T.Buffer[(128, 128, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 128, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 128, 52, 52], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 52, 52], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([128, 128, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(2, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(338, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i1_3_init, i1_4_init, i3_4_init in T.grid(4, 2, 2):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(128, i0_2_i1_2_i2_2_i3_2_fused // 2 * 8 + i1_3_init * 2 + i1_4_init)
                            yy = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 26 + i0_1_i1_1_i2_1_i3_1_fused // 26 * 2 + i0_2_i1_2_i2_2_i3_2_fused % 2)
                            xx = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 26 * 2 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [128, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(32, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(169):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(128, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) // 1352)
                                    v2 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 26 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 1352 // 52)
                                    v3 = T.axis.spatial(52, (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 52)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(8):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(2):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(128, (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) // 4)
                                        v1 = T.axis.spatial(128, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 4)
                                        v2 = T.axis.spatial(1, 0)
                                        v3 = T.axis.spatial(1, 0)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 4, 1, 1, 4, 1, 1, 1, 2, 1, 2):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(128, i0_2_i1_2_i2_2_i3_2_fused // 2 * 8 + i1_3 * 2 + i1_4)
                                yy = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 26 + i0_1_i1_1_i2_1_i3_1_fused // 26 * 2 + i0_2_i1_2_i2_2_i3_2_fused % 2)
                                xx = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 26 * 2 + i3_4)
                                rc = T.axis.reduce(128, i4_0 * 4 + i4_2)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [128, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 8, 1, 2):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(128, i0_2_i1_2_i2_2_i3_2_fused // 2 * 8 + ax1)
                            v2 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 26 + i0_1_i1_1_i2_1_i3_1_fused // 26 * 2 + i0_2_i1_2_i2_2_i3_2_fused % 2 + ax2)
                            v3 = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 26 * 2 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(2):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(128, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 2704)
                        ax2 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 2704 // 52)
                        ax3 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 52)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 346112)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 1, 16, 4, 2])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[2, 13, 2, 1, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 26, 1, 1, 2])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[32, 1, 4])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112 = sch.split(loop=l110, factors=[None, 32])
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b90)
l120, l121, l122 = sch.split(loop=l119, factors=[None, 32, 2])
sch.vectorize(loop=l122)
sch.bind(loop=l121, thread_axis="threadIdx.x")
b123 = sch.get_block(name="T_multiply", func_name="main")
l124, l125, l126, l127 = sch.get_loops(block=b123)
l128 = sch.fuse(l124, l125, l126, l127)
l129, l130, l131 = sch.split(loop=l128, factors=[None, 256, 1024])
sch.reorder(l130, l131, l129)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
b132 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b132, ann_key="meta_schedule.unroll_explicit")
b133, b134, b135, b136, b137 = sch.get_child_blocks(b132)
l138, l139, l140, l141, l142, l143, l144, l145 = sch.get_loops(block=b133)
sch.annotate(block_or_loop=l138, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l138, ann_key="pragma_unroll_explicit", ann_val=1)
l146, l147, l148, l149, l150, l151, l152, l153, l154 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l146, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l146, ann_key="pragma_unroll_explicit", ann_val=1)
l155, l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l155, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l155, ann_key="pragma_unroll_explicit", ann_val=1)
l175, l176, l177, l178, l179, l180, l181 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l175, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l175, ann_key="pragma_unroll_explicit", ann_val=1)
l182, l183, l184 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l182, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l182, ann_key="pragma_unroll_explicit", ann_val=1)
b185 = sch.get_block(name="conv2d_nchw", func_name="main")
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b185)
b206 = sch.decompose_reduction(block=b185, loop=l189)
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #19: GFLOPs: 1553.4289. Time: 0.0577 ms. Best GFLOPs: 2728.7975
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #20: GFLOPs: 48.7419. Time: 1.8391 ms. Best GFLOPs: 2728.7975
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #21: GFLOPs: 2.6678. Time: 33.6013 ms. Best GFLOPs: 2728.7975
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #22: GFLOPs: 621.1516. Time: 0.1443 ms. Best GFLOPs: 2728.7975
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #23: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 52, 52), "float32"], placeholder_1: T.Buffer[(128, 128, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 128, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 128, 52, 52], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 52, 52], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([128, 128, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(4, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(64, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(52, thread="threadIdx.x"):
                    for i3_3_init, i2_4_init in T.grid(2, 13):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 2 * 4 + i0_2_i1_2_i2_2_i3_2_fused // 13)
                            yy = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 13 + i2_4_init)
                            xx = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 2 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 13 * 2 + i3_3_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [128, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(64, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(7):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(128, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 676)
                                        v2 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 13 + (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 676 // 52)
                                        v3 = T.axis.spatial(52, (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 52)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) * 4 + ax0_ax1_ax2_ax3_fused_2 < 1352)
                                        T.reads(placeholder[v0, v1, v2, v3])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(5):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(128, (ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) // 2)
                                    v1 = T.axis.spatial(128, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) % 2)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1 < 256)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 13, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 2 * 4 + i0_2_i1_2_i2_2_i3_2_fused // 13)
                                yy = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 13 + i2_4)
                                xx = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 2 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 13 * 2 + i3_3)
                                rc = T.axis.reduce(128, i4_0 * 2 + i4_2)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [128, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 1, 13, 2):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 2 * 4 + i0_2_i1_2_i2_2_i3_2_fused // 13 + ax1)
                            v2 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 13 + ax2)
                            v3 = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 2 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 13 * 2 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(2):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(128, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 2704)
                        ax2 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 2704 // 52)
                        ax3 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 52)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 346112)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 32, 4, 1, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 13])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 2, 13, 2, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[64, 1, 2])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112, l113 = sch.split(loop=l110, factors=[None, 52, 4])
sch.vectorize(loop=l113)
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b90)
l121, l122 = sch.split(loop=l120, factors=[None, 52])
sch.bind(loop=l122, thread_axis="threadIdx.x")
b123 = sch.get_block(name="T_multiply", func_name="main")
l124, l125, l126, l127 = sch.get_loops(block=b123)
l128 = sch.fuse(l124, l125, l126, l127)
l129, l130, l131 = sch.split(loop=l128, factors=[None, 256, 1024])
sch.reorder(l130, l131, l129)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
b132 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b132, ann_key="meta_schedule.unroll_explicit")
b133, b134, b135, b136, b137 = sch.get_child_blocks(b132)
l138, l139, l140, l141, l142, l143, l144, l145, l146 = sch.get_loops(block=b133)
sch.annotate(block_or_loop=l138, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l138, ann_key="pragma_unroll_explicit", ann_val=1)
l147, l148, l149, l150, l151, l152, l153, l154 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l147, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l147, ann_key="pragma_unroll_explicit", ann_val=1)
l155, l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l155, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l155, ann_key="pragma_unroll_explicit", ann_val=1)
l175, l176, l177, l178, l179, l180, l181 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l175, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l175, ann_key="pragma_unroll_explicit", ann_val=1)
l182, l183, l184 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l182, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l182, ann_key="pragma_unroll_explicit", ann_val=1)
b185 = sch.get_block(name="conv2d_nchw", func_name="main")
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b185)
b206 = sch.decompose_reduction(block=b185, loop=l189)
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #24: GFLOPs: 946.8726. Time: 0.0947 ms. Best GFLOPs: 2728.7975
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #25: GFLOPs: 1750.7530. Time: 0.0512 ms. Best GFLOPs: 2728.7975
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #26: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 52, 52), "float32"], placeholder_1: T.Buffer[(128, 128, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 128, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 128, 52, 52], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 52, 52], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([128, 128, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(4, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(169, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(64, thread="threadIdx.x"):
                    for i1_3_init, i2_4_init, i3_4_init in T.grid(2, 2, 2):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 2 * 64 + i0_2_i1_2_i2_2_i3_2_fused // 2 * 2 + i1_3_init)
                            yy = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused // 13 * 4 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 2 + i2_4_init)
                            xx = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 2 * 26 + i0_1_i1_1_i2_1_i3_1_fused % 13 * 2 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [128, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(32, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(85):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(64, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(128, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1) // 1352)
                                    v2 = T.axis.spatial(52, (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1) % 1352 // 26)
                                    v3 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 2 * 26 + (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1) % 26)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1 < 5408)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(1):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(64, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 2 * 64 + (ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 4)
                                        v1 = T.axis.spatial(128, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 4)
                                        v2 = T.axis.spatial(1, 0)
                                        v3 = T.axis.spatial(1, 0)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 2 * 64 + i0_2_i1_2_i2_2_i3_2_fused // 2 * 2 + i1_3)
                                yy = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused // 13 * 4 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 2 + i2_4)
                                xx = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 2 * 26 + i0_1_i1_1_i2_1_i3_1_fused % 13 * 2 + i3_4)
                                rc = T.axis.reduce(128, i4_0 * 4 + i4_1 * 2 + i4_2)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [128, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 2, 2, 2):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused // 2 * 64 + i0_2_i1_2_i2_2_i3_2_fused // 2 * 2 + ax1)
                            v2 = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused // 13 * 4 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 2 + ax2)
                            v3 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 2 * 26 + i0_1_i1_1_i2_1_i3_1_fused % 13 * 2 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(2):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(128, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 2704)
                        ax2 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 2704 // 52)
                        ax3 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 52)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 346112)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[2, 1, 32, 2, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 13, 2, 1, 2])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[2, 13, 1, 1, 2])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[32, 2, 2])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112 = sch.split(loop=l110, factors=[None, 64])
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b90)
l120, l121, l122 = sch.split(loop=l119, factors=[None, 64, 4])
sch.vectorize(loop=l122)
sch.bind(loop=l121, thread_axis="threadIdx.x")
b123 = sch.get_block(name="T_multiply", func_name="main")
l124, l125, l126, l127 = sch.get_loops(block=b123)
l128 = sch.fuse(l124, l125, l126, l127)
l129, l130, l131 = sch.split(loop=l128, factors=[None, 256, 1024])
sch.reorder(l130, l131, l129)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
b132 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b132, ann_key="meta_schedule.unroll_explicit")
b133, b134, b135, b136, b137 = sch.get_child_blocks(b132)
l138, l139, l140, l141, l142, l143, l144, l145 = sch.get_loops(block=b133)
sch.annotate(block_or_loop=l138, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l138, ann_key="pragma_unroll_explicit", ann_val=1)
l146, l147, l148, l149, l150, l151, l152, l153, l154 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l146, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l146, ann_key="pragma_unroll_explicit", ann_val=1)
l155, l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l155, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l155, ann_key="pragma_unroll_explicit", ann_val=1)
l175, l176, l177, l178, l179, l180, l181 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l175, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l175, ann_key="pragma_unroll_explicit", ann_val=1)
l182, l183, l184 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l182, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l182, ann_key="pragma_unroll_explicit", ann_val=1)
b185 = sch.get_block(name="conv2d_nchw", func_name="main")
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b185)
b206 = sch.decompose_reduction(block=b185, loop=l189)
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #27: GFLOPs: 1553.1881. Time: 0.0577 ms. Best GFLOPs: 2728.7975
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #28: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 52, 52), "float32"], placeholder_1: T.Buffer[(128, 128, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 128, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 128, 52, 52], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 128, 52, 52], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 52, 52], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([128, 128, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(2, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(2, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(104, thread="threadIdx.x"):
                    for i2_3_init, i1_4_init, i2_4_init, i3_4_init in T.grid(2, 16, 13, 2):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused // 26 * 16 + i1_4_init)
                            yy = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 26 + i2_3_init * 13 + i2_4_init)
                            xx = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 26 * 2 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [128, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(16, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(104):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(104, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(128, i4_0 * 8 + (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1) // 1352)
                                    v2 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 26 + (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1) % 1352 // 52)
                                    v3 = T.axis.spatial(52, (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1) % 52)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(10):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(104, thread="threadIdx.x"):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(128, (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1) // 8)
                                    v1 = T.axis.spatial(128, i4_0 * 8 + (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1) % 8)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1 < 1024)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(8, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 16, 13, 2):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused // 26 * 16 + i1_4)
                                yy = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 26 + i2_3 * 13 + i2_4)
                                xx = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 26 * 2 + i3_4)
                                rc = T.axis.reduce(128, i4_0 * 8 + i4_1)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [128, 128, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 16, 26, 2):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused // 26 * 16 + ax1)
                            v2 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 26 + ax2)
                            v3 = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 26 * 2 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(2):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(128, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 2704)
                        ax2 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 2704 // 52)
                        ax3 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 52)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 346112)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 2, 4, 1, 16])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[2, 1, 1, 2, 13])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 1, 26, 1, 2])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[16, 8, 1])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112 = sch.split(loop=l110, factors=[None, 104])
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b90)
l120, l121 = sch.split(loop=l119, factors=[None, 104])
sch.bind(loop=l121, thread_axis="threadIdx.x")
b122 = sch.get_block(name="T_multiply", func_name="main")
l123, l124, l125, l126 = sch.get_loops(block=b122)
l127 = sch.fuse(l123, l124, l125, l126)
l128, l129, l130 = sch.split(loop=l127, factors=[None, 256, 1024])
sch.reorder(l129, l130, l128)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
b131 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b131, ann_key="meta_schedule.unroll_explicit")
b132, b133, b134, b135, b136 = sch.get_child_blocks(b131)
l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b132)
sch.annotate(block_or_loop=l137, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l137, ann_key="pragma_unroll_explicit", ann_val=1)
l145, l146, l147, l148, l149, l150, l151, l152 = sch.get_loops(block=b133)
sch.annotate(block_or_loop=l145, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l145, ann_key="pragma_unroll_explicit", ann_val=1)
l153, l154, l155, l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l153, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l153, ann_key="pragma_unroll_explicit", ann_val=1)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l173, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l173, ann_key="pragma_unroll_explicit", ann_val=1)
l180, l181, l182 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l180, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l180, ann_key="pragma_unroll_explicit", ann_val=1)
b183 = sch.get_block(name="conv2d_nchw", func_name="main")
l184, l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203 = sch.get_loops(block=b183)
b204 = sch.decompose_reduction(block=b183, loop=l187)
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #29: GFLOPs: 85.9323. Time: 1.0432 ms. Best GFLOPs: 2728.7975
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #30: GFLOPs: 931.4164. Time: 0.0962 ms. Best GFLOPs: 2728.7975
[14:03:34] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"] Trial #31: GFLOPs: 1358.6814. Time: 0.0660 ms. Best GFLOPs: 2728.7975
[14:03:35] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 832
Total latency (us): 5730.18

[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #0: GFLOPs: 0.0000. Time: 0.0148 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #1: GFLOPs: 0.0000. Time: 0.0148 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #2: GFLOPs: 0.0000. Time: 0.0147 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #3: GFLOPs: 0.0000. Time: 0.0148 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #4: GFLOPs: 0.0000. Time: 0.0147 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #5: GFLOPs: 0.0000. Time: 0.0150 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #6: GFLOPs: 0.0000. Time: 0.0146 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #7: GFLOPs: 0.0000. Time: 0.0165 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #8: GFLOPs: 0.0000. Time: 0.0206 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #9: GFLOPs: 0.0000. Time: 0.0202 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #10: GFLOPs: 0.0000. Time: 0.0207 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #11: GFLOPs: 0.0000. Time: 0.0158 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #12: GFLOPs: 0.0000. Time: 0.0158 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #13: GFLOPs: 0.0000. Time: 0.0158 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #14: GFLOPs: 0.0000. Time: 0.0156 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #15: GFLOPs: 0.0000. Time: 0.0155 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #16: GFLOPs: 0.0000. Time: 0.0157 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #17: GFLOPs: 0.0000. Time: 0.0159 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #18: GFLOPs: 0.0000. Time: 0.0155 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #19: GFLOPs: 0.0000. Time: 0.0154 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #20: GFLOPs: 0.0000. Time: 0.0156 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #21: GFLOPs: 0.0000. Time: 0.0152 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #22: GFLOPs: 0.0000. Time: 0.0159 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #23: GFLOPs: 0.0000. Time: 0.0156 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #24: GFLOPs: 0.0000. Time: 0.0160 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #25: GFLOPs: 0.0000. Time: 0.0153 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #26: GFLOPs: 0.0000. Time: 0.0159 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #27: GFLOPs: 0.0000. Time: 0.0159 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #28: GFLOPs: 0.0000. Time: 0.0159 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #29: GFLOPs: 0.0000. Time: 0.0154 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #30: GFLOPs: 0.0000. Time: 0.0157 ms. Best GFLOPs: 0.0000
[14:03:35] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #26: "fused_concatenate_2"] Trial #31: GFLOPs: 0.0000. Time: 0.0151 ms. Best GFLOPs: 0.0000
[14:03:37] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #26: "fused_concatenate_2"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 864
Total latency (us): 5744.81

[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #0: GFLOPs: 117.5683. Time: 3.0322 ms. Best GFLOPs: 117.5683
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #1: GFLOPs: 1490.9097. Time: 0.2391 ms. Best GFLOPs: 1490.9097
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #2: GFLOPs: 850.2218. Time: 0.4193 ms. Best GFLOPs: 1490.9097
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #3: GFLOPs: 765.3852. Time: 0.4658 ms. Best GFLOPs: 1490.9097
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #4: GFLOPs: 2669.9975. Time: 0.1335 ms. Best GFLOPs: 2669.9975
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #5: GFLOPs: 33.8451. Time: 10.5332 ms. Best GFLOPs: 2669.9975
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #6: GFLOPs: 244.9767. Time: 1.4552 ms. Best GFLOPs: 2669.9975
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #7: GFLOPs: 1357.5935. Time: 0.2626 ms. Best GFLOPs: 2669.9975
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #8: GFLOPs: 1466.0759. Time: 0.2432 ms. Best GFLOPs: 2669.9975
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #9: GFLOPs: 199.2345. Time: 1.7893 ms. Best GFLOPs: 2669.9975
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #10: GFLOPs: 22.2718. Time: 16.0066 ms. Best GFLOPs: 2669.9975
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #11: GFLOPs: 1608.0732. Time: 0.2217 ms. Best GFLOPs: 2669.9975
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #12: GFLOPs: 46.3133. Time: 7.6975 ms. Best GFLOPs: 2669.9975
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #13: GFLOPs: 1512.3062. Time: 0.2357 ms. Best GFLOPs: 2669.9975
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #14: GFLOPs: 3307.7699. Time: 0.1078 ms. Best GFLOPs: 3307.7699
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #15: GFLOPs: 2269.5220. Time: 0.1571 ms. Best GFLOPs: 3307.7699
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #16: GFLOPs: 1808.1638. Time: 0.1972 ms. Best GFLOPs: 3307.7699
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #17: GFLOPs: 1839.7887. Time: 0.1938 ms. Best GFLOPs: 3307.7699
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #18: GFLOPs: 39.4759. Time: 9.0307 ms. Best GFLOPs: 3307.7699
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #19: GFLOPs: 1154.0775. Time: 0.3089 ms. Best GFLOPs: 3307.7699
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #20: GFLOPs: 330.2424. Time: 1.0795 ms. Best GFLOPs: 3307.7699
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #21: GFLOPs: 1801.3879. Time: 0.1979 ms. Best GFLOPs: 3307.7699
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #22: GFLOPs: 2269.7878. Time: 0.1571 ms. Best GFLOPs: 3307.7699
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #23: GFLOPs: 2522.9995. Time: 0.1413 ms. Best GFLOPs: 3307.7699
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #24: GFLOPs: 39.0760. Time: 9.1231 ms. Best GFLOPs: 3307.7699
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #25: GFLOPs: 689.0492. Time: 0.5174 ms. Best GFLOPs: 3307.7699
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #26: GFLOPs: 2138.8259. Time: 0.1667 ms. Best GFLOPs: 3307.7699
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #27: GFLOPs: 58.5815. Time: 6.0855 ms. Best GFLOPs: 3307.7699
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #28: GFLOPs: 28.4575. Time: 12.5273 ms. Best GFLOPs: 3307.7699
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #29: GFLOPs: 15.8905. Time: 22.4345 ms. Best GFLOPs: 3307.7699
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #30: GFLOPs: 1964.8994. Time: 0.1814 ms. Best GFLOPs: 3307.7699
[14:03:37] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"] Trial #31: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 52, 52), "float32"], placeholder_1: T.Buffer[(256, 256, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 256, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 256, 52, 52], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 256, 52, 52], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 256, 52, 52], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([256, 256, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(1, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(104, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(416, thread="threadIdx.x"):
                    for i1_3_init, i1_4_init, i3_4_init in T.grid(4, 2, 2):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(256, i0_1_i1_1_i2_1_i3_1_fused // 26 * 64 + i0_2_i1_2_i2_2_i3_2_fused // 52 * 8 + i1_3_init * 2 + i1_4_init)
                            yy = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 26 * 2 + i0_2_i1_2_i2_2_i3_2_fused % 52 // 26)
                            xx = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 26 * 2 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [256, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(128, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(4):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(416, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(256, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 1664 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 2704)
                                        v2 = T.axis.spatial(52, (ax0_ax1_ax2_ax3_fused_0 * 1664 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 2704 // 52)
                                        v3 = T.axis.spatial(52, (ax0_ax1_ax2_ax3_fused_0 * 1664 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 52)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 416 + ax0_ax1_ax2_ax3_fused_1) * 4 + ax0_ax1_ax2_ax3_fused_2 < 5408)
                                        T.reads(placeholder[v0, v1, v2, v3])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(1):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(416, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(256, (ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 2)
                                        v1 = T.axis.spatial(256, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 2)
                                        v2 = T.axis.spatial(1, 0)
                                        v3 = T.axis.spatial(1, 0)
                                        T.where(ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2 < 512)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 4, 1, 1, 2, 1, 1, 1, 2, 1, 2):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(256, i0_1_i1_1_i2_1_i3_1_fused // 26 * 64 + i0_2_i1_2_i2_2_i3_2_fused // 52 * 8 + i1_3 * 2 + i1_4)
                                yy = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 26 * 2 + i0_2_i1_2_i2_2_i3_2_fused % 52 // 26)
                                xx = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 26 * 2 + i3_4)
                                rc = T.axis.reduce(256, i4_0 * 2 + i4_2)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [256, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 8, 1, 2):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(256, i0_1_i1_1_i2_1_i3_1_fused // 26 * 64 + i0_2_i1_2_i2_2_i3_2_fused // 52 * 8 + ax1)
                            v2 = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 26 * 2 + i0_2_i1_2_i2_2_i3_2_fused % 52 // 26 + ax2)
                            v3 = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 26 * 2 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(3):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(256, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 2704)
                        ax2 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 2704 // 52)
                        ax3 = T.axis.spatial(52, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 52)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 692224)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 4, 8, 4, 2])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 26, 2, 1, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 1, 26, 1, 2])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[128, 1, 2])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112, l113 = sch.split(loop=l110, factors=[None, 416, 4])
sch.vectorize(loop=l113)
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b90)
l121, l122, l123 = sch.split(loop=l120, factors=[None, 416, 4])
sch.vectorize(loop=l123)
sch.bind(loop=l122, thread_axis="threadIdx.x")
b124 = sch.get_block(name="T_multiply", func_name="main")
l125, l126, l127, l128 = sch.get_loops(block=b124)
l129 = sch.fuse(l125, l126, l127, l128)
l130, l131, l132 = sch.split(loop=l129, factors=[None, 256, 1024])
sch.reorder(l131, l132, l130)
sch.bind(loop=l131, thread_axis="blockIdx.x")
sch.bind(loop=l132, thread_axis="threadIdx.x")
b133 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b133, ann_key="meta_schedule.unroll_explicit")
b134, b135, b136, b137, b138 = sch.get_child_blocks(b133)
l139, l140, l141, l142, l143, l144, l145, l146, l147 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l139, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l139, ann_key="pragma_unroll_explicit", ann_val=1)
l148, l149, l150, l151, l152, l153, l154, l155, l156 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l148, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l148, ann_key="pragma_unroll_explicit", ann_val=1)
l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174, l175, l176 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l157, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l157, ann_key="pragma_unroll_explicit", ann_val=1)
l177, l178, l179, l180, l181, l182, l183 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l177, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l177, ann_key="pragma_unroll_explicit", ann_val=1)
l184, l185, l186 = sch.get_loops(block=b138)
sch.annotate(block_or_loop=l184, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l184, ann_key="pragma_unroll_explicit", ann_val=1)
b187 = sch.get_block(name="conv2d_nchw", func_name="main")
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b187)
b208 = sch.decompose_reduction(block=b187, loop=l191)
[14:03:39] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |            N/A |          N/A |                   N/A |      0 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 896
Total latency (us): 5852.58

[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #0: Error in building: LocalRunner: An exception occurred
Subprocess terminated
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 52, 52), "float32"], placeholder_1: T.Buffer[(512, 256, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 512, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 512, 26, 26], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 512, 26, 26], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 256, 53, 53], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([512, 256, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(52, thread="blockIdx.x"):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(4, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i1_4_init, i2_4_init in T.grid(4, 13):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused // 26 * 256 + i0_1_i1_1_i2_1_i3_1_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused // 2 * 4 + i1_4_init)
                            yy = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused % 2 * 13 + i2_4_init)
                            xx = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused % 26)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [512, 256, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(256, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(2):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(3):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(256, i4_0 + 0)
                                        v2 = T.axis.spatial(53, ((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 3 + ax0_ax1_ax2_ax3_fused_2) % 159 // 3)
                                        v3 = T.axis.spatial(53, i0_0_i1_0_i2_0_i3_0_fused % 26 * 2 + ((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 3 + ax0_ax1_ax2_ax3_fused_2) % 3)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 3 + ax0_ax1_ax2_ax3_fused_2 < 159)
                                        T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 53 and 1 <= v3 and v3 < 53, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(36):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(2):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused // 26 * 256 + (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) // 9)
                                        v1 = T.axis.spatial(256, i4_0)
                                        v2 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 9 // 3)
                                        v3 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 3)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 1, 4, 13, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused // 26 * 256 + i0_1_i1_1_i2_1_i3_1_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused // 2 * 4 + i1_4)
                                yy = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused % 2 * 13 + i2_4)
                                xx = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused % 26)
                                rc, ry, rx = T.axis.remap("RRR", [i4_0, i5_2, i6_2])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [512, 256, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 4, 13, 1):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused // 26 * 256 + i0_1_i1_1_i2_1_i3_1_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused // 2 * 4 + ax1)
                            v2 = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused % 2 * 13 + ax2)
                            v3 = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused % 26 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(2):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(512, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 676)
                        ax2 = T.axis.spatial(26, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 676 // 26)
                        ax3 = T.axis.spatial(26, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 26)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 346112)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[2, 4, 16, 1, 4])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 1, 2, 1, 13])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[26, 1, 1, 1, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[256, 1, 1])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112, l113 = sch.split(loop=l110, factors=[None, 32, 3])
sch.vectorize(loop=l113)
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b90)
l121, l122, l123 = sch.split(loop=l120, factors=[None, 32, 2])
sch.vectorize(loop=l123)
sch.bind(loop=l122, thread_axis="threadIdx.x")
b124 = sch.get_block(name="T_multiply", func_name="main")
l125, l126, l127, l128 = sch.get_loops(block=b124)
l129 = sch.fuse(l125, l126, l127, l128)
l130, l131, l132 = sch.split(loop=l129, factors=[None, 256, 1024])
sch.reorder(l131, l132, l130)
sch.bind(loop=l131, thread_axis="blockIdx.x")
sch.bind(loop=l132, thread_axis="threadIdx.x")
b133 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b133, ann_key="meta_schedule.unroll_explicit")
b134, b135, b136, b137, b138 = sch.get_child_blocks(b133)
l139, l140, l141, l142, l143, l144, l145, l146, l147 = sch.get_loops(block=b134)
l148, l149, l150, l151, l152, l153, l154, l155, l156 = sch.get_loops(block=b135)
l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174, l175, l176 = sch.get_loops(block=b136)
l177, l178, l179, l180, l181, l182, l183 = sch.get_loops(block=b137)
l184, l185, l186 = sch.get_loops(block=b138)
b187 = sch.get_block(name="conv2d_nchw", func_name="main")
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b187)
b208 = sch.decompose_reduction(block=b187, loop=l191)
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #1: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 52, 52), "float32"], placeholder_1: T.Buffer[(512, 256, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 512, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 512, 26, 26], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 512, 26, 26], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 256, 53, 53], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([512, 256, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(1, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(512, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(52, thread="threadIdx.x"):
                    for i2_4_init in T.serial(13):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(512, i0_1_i1_1_i2_1_i3_1_fused // 2 * 2 + i0_2_i1_2_i2_2_i3_2_fused // 26)
                            yy = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused % 2 * 13 + i2_4_init)
                            xx = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused % 26)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [512, 256, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(256, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(55):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(256, i4_0)
                                    v2 = T.axis.spatial(53, (ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) // 53)
                                    v3 = T.axis.spatial(53, (ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) % 53)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1 < 2809)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 53 and 1 <= v3 and v3 < 53, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(30):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(3):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(512, (ax0_ax1_ax2_ax3_fused_0 * 156 + ax0_ax1_ax2_ax3_fused_1 * 3 + ax0_ax1_ax2_ax3_fused_2) // 9)
                                        v1 = T.axis.spatial(256, i4_0)
                                        v2 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 156 + ax0_ax1_ax2_ax3_fused_1 * 3 + ax0_ax1_ax2_ax3_fused_2) % 9 // 3)
                                        v3 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 156 + ax0_ax1_ax2_ax3_fused_1 * 3 + ax0_ax1_ax2_ax3_fused_2) % 3)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) * 3 + ax0_ax1_ax2_ax3_fused_2 < 4608)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 1, 1, 13, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(512, i0_1_i1_1_i2_1_i3_1_fused // 2 * 2 + i0_2_i1_2_i2_2_i3_2_fused // 26)
                                yy = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused % 2 * 13 + i2_4)
                                xx = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused % 26)
                                rc, ry, rx = T.axis.remap("RRR", [i4_0, i5_2, i6_2])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [512, 256, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 1, 13, 1):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(512, i0_1_i1_1_i2_1_i3_1_fused // 2 * 2 + i0_2_i1_2_i2_2_i3_2_fused // 26 + ax1)
                            v2 = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused % 2 * 13 + ax2)
                            v3 = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused % 26 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(2):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(512, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 676)
                        ax2 = T.axis.spatial(26, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 676 // 26)
                        ax3 = T.axis.spatial(26, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 26)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 346112)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 256, 2, 1, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 2, 1, 1, 13])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 1, 26, 1, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[256, 1, 1])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112 = sch.split(loop=l110, factors=[None, 52])
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b90)
l120, l121, l122 = sch.split(loop=l119, factors=[None, 52, 3])
sch.vectorize(loop=l122)
sch.bind(loop=l121, thread_axis="threadIdx.x")
b123 = sch.get_block(name="T_multiply", func_name="main")
l124, l125, l126, l127 = sch.get_loops(block=b123)
l128 = sch.fuse(l124, l125, l126, l127)
l129, l130, l131 = sch.split(loop=l128, factors=[None, 256, 1024])
sch.reorder(l130, l131, l129)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
b132 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b132, ann_key="meta_schedule.unroll_explicit")
b133, b134, b135, b136, b137 = sch.get_child_blocks(b132)
l138, l139, l140, l141, l142, l143, l144, l145 = sch.get_loops(block=b133)
sch.annotate(block_or_loop=l138, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l138, ann_key="pragma_unroll_explicit", ann_val=1)
l146, l147, l148, l149, l150, l151, l152, l153, l154 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l146, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l146, ann_key="pragma_unroll_explicit", ann_val=1)
l155, l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l155, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l155, ann_key="pragma_unroll_explicit", ann_val=1)
l175, l176, l177, l178, l179, l180, l181 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l175, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l175, ann_key="pragma_unroll_explicit", ann_val=1)
l182, l183, l184 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l182, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l182, ann_key="pragma_unroll_explicit", ann_val=1)
b185 = sch.get_block(name="conv2d_nchw", func_name="main")
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b185)
b206 = sch.decompose_reduction(block=b185, loop=l189)
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #2: GFLOPs: 1659.2490. Time: 0.9618 ms. Best GFLOPs: 1659.2490
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #3: GFLOPs: 52.0913. Time: 30.6370 ms. Best GFLOPs: 1659.2490
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #4: GFLOPs: 261.3583. Time: 6.1063 ms. Best GFLOPs: 1659.2490
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #5: GFLOPs: 1095.6719. Time: 1.4566 ms. Best GFLOPs: 1659.2490
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #6: GFLOPs: 29.3927. Time: 54.2965 ms. Best GFLOPs: 1659.2490
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #7: GFLOPs: 3333.8786. Time: 0.4787 ms. Best GFLOPs: 3333.8786
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #8: GFLOPs: 2909.5783. Time: 0.5485 ms. Best GFLOPs: 3333.8786
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #9: GFLOPs: 1839.6618. Time: 0.8675 ms. Best GFLOPs: 3333.8786
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #10: GFLOPs: 1321.8406. Time: 1.2073 ms. Best GFLOPs: 3333.8786
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #11: GFLOPs: 2347.2956. Time: 0.6799 ms. Best GFLOPs: 3333.8786
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #12: GFLOPs: 2225.5379. Time: 0.7171 ms. Best GFLOPs: 3333.8786
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #13: GFLOPs: 1463.3881. Time: 1.0906 ms. Best GFLOPs: 3333.8786
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #14: GFLOPs: 848.1521. Time: 1.8816 ms. Best GFLOPs: 3333.8786
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #15: GFLOPs: 13.1797. Time: 121.0892 ms. Best GFLOPs: 3333.8786
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #16: GFLOPs: 834.9627. Time: 1.9114 ms. Best GFLOPs: 3333.8786
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #17: GFLOPs: 1728.0694. Time: 0.9235 ms. Best GFLOPs: 3333.8786
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #18: GFLOPs: 17.1793. Time: 92.8980 ms. Best GFLOPs: 3333.8786
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #19: GFLOPs: 2317.7936. Time: 0.6886 ms. Best GFLOPs: 3333.8786
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #20: GFLOPs: 349.7059. Time: 4.5636 ms. Best GFLOPs: 3333.8786
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #21: GFLOPs: 2187.9652. Time: 0.7294 ms. Best GFLOPs: 3333.8786
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #22: GFLOPs: 71.7085. Time: 22.2557 ms. Best GFLOPs: 3333.8786
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #23: GFLOPs: 164.2599. Time: 9.7158 ms. Best GFLOPs: 3333.8786
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #24: GFLOPs: 495.5561. Time: 3.2205 ms. Best GFLOPs: 3333.8786
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #25: GFLOPs: 528.7863. Time: 3.0181 ms. Best GFLOPs: 3333.8786
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #26: GFLOPs: 1216.1633. Time: 1.3123 ms. Best GFLOPs: 3333.8786
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #27: GFLOPs: 218.4039. Time: 7.3072 ms. Best GFLOPs: 3333.8786
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #28: GFLOPs: 34.9482. Time: 45.6654 ms. Best GFLOPs: 3333.8786
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #29: GFLOPs: 1380.0111. Time: 1.1565 ms. Best GFLOPs: 3333.8786
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #30: GFLOPs: 221.6106. Time: 7.2015 ms. Best GFLOPs: 3333.8786
[14:03:39] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"] Trial #31: GFLOPs: 239.4264. Time: 6.6656 ms. Best GFLOPs: 3333.8786
[14:03:41] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |      3333.8786 |     478.6984 |              478.6984 |     32 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |            N/A |          N/A |                   N/A |      0 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 928
Total latency (us): 6331.28

[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #0: GFLOPs: 1873.7379. Time: 0.0949 ms. Best GFLOPs: 1873.7379
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #1: GFLOPs: 637.3390. Time: 0.2789 ms. Best GFLOPs: 1873.7379
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #2: GFLOPs: 1057.7256. Time: 0.1680 ms. Best GFLOPs: 1873.7379
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #3: GFLOPs: 110.7785. Time: 1.6044 ms. Best GFLOPs: 1873.7379
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #4: GFLOPs: 2504.9907. Time: 0.0709 ms. Best GFLOPs: 2504.9907
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #5: GFLOPs: 205.4803. Time: 0.8649 ms. Best GFLOPs: 2504.9907
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #6: GFLOPs: 804.4123. Time: 0.2209 ms. Best GFLOPs: 2504.9907
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #7: GFLOPs: 2955.9997. Time: 0.0601 ms. Best GFLOPs: 2955.9997
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #8: GFLOPs: 659.7959. Time: 0.2694 ms. Best GFLOPs: 2955.9997
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #9: GFLOPs: 2041.9834. Time: 0.0870 ms. Best GFLOPs: 2955.9997
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #10: GFLOPs: 1489.6178. Time: 0.1193 ms. Best GFLOPs: 2955.9997
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #11: GFLOPs: 1248.9026. Time: 0.1423 ms. Best GFLOPs: 2955.9997
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #12: GFLOPs: 74.7064. Time: 2.3790 ms. Best GFLOPs: 2955.9997
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #13: GFLOPs: 35.0330. Time: 5.0732 ms. Best GFLOPs: 2955.9997
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #14: GFLOPs: 2960.8178. Time: 0.0600 ms. Best GFLOPs: 2960.8178
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #15: GFLOPs: 149.7966. Time: 1.1865 ms. Best GFLOPs: 2960.8178
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #16: GFLOPs: 1247.0970. Time: 0.1425 ms. Best GFLOPs: 2960.8178
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #17: GFLOPs: 1094.1456. Time: 0.1624 ms. Best GFLOPs: 2960.8178
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #18: GFLOPs: 850.5290. Time: 0.2090 ms. Best GFLOPs: 2960.8178
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #19: GFLOPs: 26.8463. Time: 6.6202 ms. Best GFLOPs: 2960.8178
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #20: GFLOPs: 1780.2755. Time: 0.0998 ms. Best GFLOPs: 2960.8178
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #21: GFLOPs: 24.0723. Time: 7.3831 ms. Best GFLOPs: 2960.8178
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #22: GFLOPs: 550.6860. Time: 0.3227 ms. Best GFLOPs: 2960.8178
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #23: GFLOPs: 17.4947. Time: 10.1590 ms. Best GFLOPs: 2960.8178
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #24: GFLOPs: 701.8134. Time: 0.2532 ms. Best GFLOPs: 2960.8178
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #25: GFLOPs: 2131.9947. Time: 0.0834 ms. Best GFLOPs: 2960.8178
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #26: GFLOPs: 93.8586. Time: 1.8936 ms. Best GFLOPs: 2960.8178
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #27: GFLOPs: 2152.6261. Time: 0.0826 ms. Best GFLOPs: 2960.8178
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #28: GFLOPs: 1796.4352. Time: 0.0989 ms. Best GFLOPs: 2960.8178
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #29: GFLOPs: 58.0327. Time: 3.0626 ms. Best GFLOPs: 2960.8178
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #30: GFLOPs: 1234.6031. Time: 0.1440 ms. Best GFLOPs: 2960.8178
[14:03:41] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"] Trial #31: GFLOPs: 92.3414. Time: 1.9247 ms. Best GFLOPs: 2960.8178
[14:03:43] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |      3333.8786 |     478.6984 |              478.6984 |     32 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |      2960.8178 |      60.0268 |              120.0537 |     32 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |            N/A |          N/A |                   N/A |      0 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 960
Total latency (us): 6451.33

[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #0: GFLOPs: 36.5755. Time: 21.8215 ms. Best GFLOPs: 36.5755
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #1: GFLOPs: 34.7250. Time: 22.9845 ms. Best GFLOPs: 36.5755
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #2: GFLOPs: 266.8998. Time: 2.9904 ms. Best GFLOPs: 266.8998
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #3: GFLOPs: 3729.7200. Time: 0.2140 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #4: GFLOPs: 1872.7678. Time: 0.4262 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #5: GFLOPs: 1020.4601. Time: 0.7821 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #6: GFLOPs: 679.9156. Time: 1.1739 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #7: GFLOPs: 1501.2989. Time: 0.5316 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #8: GFLOPs: 372.3113. Time: 2.1437 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #9: GFLOPs: 1664.9221. Time: 0.4794 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #10: GFLOPs: 13.7035. Time: 58.2429 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #11: GFLOPs: 1616.9095. Time: 0.4936 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #12: GFLOPs: 6.0630. Time: 131.6402 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #13: GFLOPs: 175.2684. Time: 4.5538 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #14: GFLOPs: 1401.0493. Time: 0.5697 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #15: GFLOPs: 43.2649. Time: 18.4476 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #16: GFLOPs: 457.7331. Time: 1.7437 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #17: GFLOPs: 985.4482. Time: 0.8099 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #18: GFLOPs: 1319.7610. Time: 0.6048 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #19: GFLOPs: 60.5583. Time: 13.1796 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #20: GFLOPs: 360.1083. Time: 2.2164 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #21: GFLOPs: 653.4893. Time: 1.2213 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #22: GFLOPs: 1285.5555. Time: 0.6208 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #23: GFLOPs: 682.2491. Time: 1.1699 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #24: GFLOPs: 1765.3176. Time: 0.4521 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #25: GFLOPs: 26.7185. Time: 29.8720 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #26: GFLOPs: 46.2993. Time: 17.2386 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #27: GFLOPs: 655.7308. Time: 1.2172 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #28: GFLOPs: 374.2553. Time: 2.1326 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #29: GFLOPs: 787.8550. Time: 1.0130 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #30: GFLOPs: 24.2411. Time: 32.9248 ms. Best GFLOPs: 3729.7200
[14:03:43] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"] Trial #31: GFLOPs: 1155.9657. Time: 0.6904 ms. Best GFLOPs: 3729.7200
[14:03:45] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |      3333.8786 |     478.6984 |              478.6984 |     32 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |      2960.8178 |      60.0268 |              120.0537 |     32 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |      3729.7200 |     213.9931 |             1711.9447 |     32 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |            N/A |          N/A |                   N/A |      0 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 992
Total latency (us): 8163.28

[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #0: GFLOPs: 2050.6776. Time: 0.0435 ms. Best GFLOPs: 2050.6776
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #1: GFLOPs: 1152.0254. Time: 0.0774 ms. Best GFLOPs: 2050.6776
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #2: GFLOPs: 820.5006. Time: 0.1086 ms. Best GFLOPs: 2050.6776
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #3: GFLOPs: 46.4908. Time: 1.9170 ms. Best GFLOPs: 2050.6776
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #4: GFLOPs: 754.6253. Time: 0.1181 ms. Best GFLOPs: 2050.6776
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #5: GFLOPs: 26.8423. Time: 3.3203 ms. Best GFLOPs: 2050.6776
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #6: GFLOPs: 1288.6650. Time: 0.0692 ms. Best GFLOPs: 2050.6776
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #7: GFLOPs: 19.7917. Time: 4.5031 ms. Best GFLOPs: 2050.6776
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #8: GFLOPs: 25.6538. Time: 3.4741 ms. Best GFLOPs: 2050.6776
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #9: GFLOPs: 30.1686. Time: 2.9542 ms. Best GFLOPs: 2050.6776
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #10: GFLOPs: 24.1242. Time: 3.6944 ms. Best GFLOPs: 2050.6776
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #11: GFLOPs: 95.6046. Time: 0.9322 ms. Best GFLOPs: 2050.6776
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #12: GFLOPs: 910.3398. Time: 0.0979 ms. Best GFLOPs: 2050.6776
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #13: GFLOPs: 23.9536. Time: 3.7207 ms. Best GFLOPs: 2050.6776
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #14: GFLOPs: 125.2864. Time: 0.7114 ms. Best GFLOPs: 2050.6776
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #15: GFLOPs: 25.2031. Time: 3.5362 ms. Best GFLOPs: 2050.6776
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #16: GFLOPs: 1285.8693. Time: 0.0693 ms. Best GFLOPs: 2050.6776
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #17: GFLOPs: 1933.7117. Time: 0.0461 ms. Best GFLOPs: 2050.6776
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #18: GFLOPs: 6.1897. Time: 14.3987 ms. Best GFLOPs: 2050.6776
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #19: GFLOPs: 1049.3362. Time: 0.0849 ms. Best GFLOPs: 2050.6776
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #20: GFLOPs: 219.0837. Time: 0.4068 ms. Best GFLOPs: 2050.6776
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #21: GFLOPs: 106.0824. Time: 0.8401 ms. Best GFLOPs: 2050.6776
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #22: GFLOPs: 57.4703. Time: 1.5508 ms. Best GFLOPs: 2050.6776
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #23: GFLOPs: 2624.8168. Time: 0.0340 ms. Best GFLOPs: 2624.8168
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #24: GFLOPs: 1823.8587. Time: 0.0489 ms. Best GFLOPs: 2624.8168
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #25: GFLOPs: 789.7047. Time: 0.1129 ms. Best GFLOPs: 2624.8168
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #26: GFLOPs: 1854.3908. Time: 0.0481 ms. Best GFLOPs: 2624.8168
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #27: GFLOPs: 673.4868. Time: 0.1323 ms. Best GFLOPs: 2624.8168
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #28: GFLOPs: 1139.6328. Time: 0.0782 ms. Best GFLOPs: 2624.8168
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #29: GFLOPs: 1506.4408. Time: 0.0592 ms. Best GFLOPs: 2624.8168
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #30: GFLOPs: 2831.4273. Time: 0.0315 ms. Best GFLOPs: 2831.4273
[14:03:45] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"] Trial #31: GFLOPs: 57.7461. Time: 1.5434 ms. Best GFLOPs: 2831.4273
[14:03:46] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |      3333.8786 |     478.6984 |              478.6984 |     32 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |      2960.8178 |      60.0268 |              120.0537 |     32 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |      3729.7200 |     213.9931 |             1711.9447 |     32 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |      2831.4273 |      31.4766 |              283.2898 |     32 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1024
Total latency (us): 8446.57

[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #0: GFLOPs: 0.0000. Time: 0.0043 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #1: GFLOPs: 0.0000. Time: 0.0041 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #2: GFLOPs: 0.0000. Time: 0.0041 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #3: GFLOPs: 0.0000. Time: 0.0041 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #4: GFLOPs: 0.0000. Time: 0.0041 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #5: GFLOPs: 0.0000. Time: 0.0042 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #6: GFLOPs: 0.0000. Time: 0.0043 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #7: GFLOPs: 0.0000. Time: 0.0041 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #8: GFLOPs: 0.0000. Time: 0.0041 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #9: GFLOPs: 0.0000. Time: 0.0040 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #10: GFLOPs: 0.0000. Time: 0.0041 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #11: GFLOPs: 0.0000. Time: 0.0040 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #12: GFLOPs: 0.0000. Time: 0.0041 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #13: GFLOPs: 0.0000. Time: 0.0041 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #14: GFLOPs: 0.0000. Time: 0.0041 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #15: GFLOPs: 0.0000. Time: 0.0041 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #16: GFLOPs: 0.0000. Time: 0.0041 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #17: GFLOPs: 0.0000. Time: 0.0042 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #18: GFLOPs: 0.0000. Time: 0.0043 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #19: GFLOPs: 0.0000. Time: 0.0042 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #20: GFLOPs: 0.0000. Time: 0.0041 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #21: GFLOPs: 0.0000. Time: 0.0042 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #22: GFLOPs: 0.0000. Time: 0.0041 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #23: GFLOPs: 0.0000. Time: 0.0040 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #24: GFLOPs: 0.0000. Time: 0.0040 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #25: GFLOPs: 0.0000. Time: 0.0040 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #26: GFLOPs: 0.0000. Time: 0.0041 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #27: GFLOPs: 0.0000. Time: 0.0042 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #28: GFLOPs: 0.0000. Time: 0.0041 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #29: GFLOPs: 0.0000. Time: 0.0045 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #30: GFLOPs: 0.0000. Time: 0.0042 ms. Best GFLOPs: 0.0000
[14:03:46] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #32: "fused_concatenate_3"] Trial #31: GFLOPs: 0.0000. Time: 0.0041 ms. Best GFLOPs: 0.0000
[14:03:48] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #32: "fused_concatenate_3"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |      3333.8786 |     478.6984 |              478.6984 |     32 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |      2960.8178 |      60.0268 |              120.0537 |     32 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |      3729.7200 |     213.9931 |             1711.9447 |     32 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |      2831.4273 |      31.4766 |              283.2898 |     32 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |         0.0002 |       4.0251 |                8.0501 |     32 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |            N/A |          N/A |                   N/A |      0 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1056
Total latency (us): 8454.62

[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #0: GFLOPs: 216.3085. Time: 1.6433 ms. Best GFLOPs: 216.3085
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #1: GFLOPs: 146.8942. Time: 2.4198 ms. Best GFLOPs: 216.3085
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #2: GFLOPs: 41.2443. Time: 8.6183 ms. Best GFLOPs: 216.3085
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #3: GFLOPs: 3258.1899. Time: 0.1091 ms. Best GFLOPs: 3258.1899
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #4: GFLOPs: 1069.3788. Time: 0.3324 ms. Best GFLOPs: 3258.1899
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #5: GFLOPs: 183.9489. Time: 1.9324 ms. Best GFLOPs: 3258.1899
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #6: GFLOPs: 112.6201. Time: 3.1562 ms. Best GFLOPs: 3258.1899
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #7: GFLOPs: 87.4622. Time: 4.0641 ms. Best GFLOPs: 3258.1899
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #8: GFLOPs: 627.1297. Time: 0.5668 ms. Best GFLOPs: 3258.1899
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #9: GFLOPs: 2356.2041. Time: 0.1509 ms. Best GFLOPs: 3258.1899
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #10: GFLOPs: 2203.7064. Time: 0.1613 ms. Best GFLOPs: 3258.1899
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #11: GFLOPs: 156.1964. Time: 2.2757 ms. Best GFLOPs: 3258.1899
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #12: GFLOPs: 1049.0828. Time: 0.3388 ms. Best GFLOPs: 3258.1899
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #13: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 26, 26), "float32"], placeholder_1: T.Buffer[(512, 512, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 512, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 512, 26, 26], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 512, 26, 26], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 512, 26, 26], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([512, 512, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(2, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(1, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(256, thread="threadIdx.x"):
                    for i1_3_init, i2_3_init, i3_3_init, i3_4_init in T.grid(2, 13, 13, 2):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(512, i0_2_i1_2_i2_2_i3_2_fused * 2 + i1_3_init)
                            yy = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused * 13 + i2_3_init)
                            xx = T.axis.spatial(26, i3_3_init * 2 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 26, 26], "float32"], ["TENSOR", [512, 512, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(64, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(11):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(256, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(512, i4_0 * 8 + (ax0_ax1_ax2_ax3_fused_0 * 256 + ax0_ax1_ax2_ax3_fused_1) // 338)
                                    v2 = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused * 13 + (ax0_ax1_ax2_ax3_fused_0 * 256 + ax0_ax1_ax2_ax3_fused_1) % 338 // 26)
                                    v3 = T.axis.spatial(26, (ax0_ax1_ax2_ax3_fused_0 * 256 + ax0_ax1_ax2_ax3_fused_1) % 26)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 256 + ax0_ax1_ax2_ax3_fused_1 < 2704)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(16):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(256, thread="threadIdx.x"):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(512, (ax0_ax1_ax2_ax3_fused_0 * 256 + ax0_ax1_ax2_ax3_fused_1) // 8)
                                    v1 = T.axis.spatial(512, i4_0 * 8 + (ax0_ax1_ax2_ax3_fused_0 * 256 + ax0_ax1_ax2_ax3_fused_1) % 8)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(4, 1, 1, 1, 2, 13, 13, 2, 1, 1, 1, 1, 1, 2):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(512, i0_2_i1_2_i2_2_i3_2_fused * 2 + i1_3)
                                yy = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused * 13 + i2_3)
                                xx = T.axis.spatial(26, i3_3 * 2 + i3_4)
                                rc = T.axis.reduce(512, i4_0 * 8 + i4_1 * 2 + i4_2)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 26, 26], "float32"], ["TENSOR", [512, 512, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 2, 13, 26):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(512, i0_2_i1_2_i2_2_i3_2_fused * 2 + ax1)
                            v2 = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused * 13 + ax2)
                            v3 = T.axis.spatial(26, ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(256, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(1024, thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in T.serial(2):
                    with T.block("T_multiply"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(512, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) // 676)
                        ax2 = T.axis.spatial(26, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 676 // 26)
                        ax3 = T.axis.spatial(26, (i0_i1_i2_i3_fused_0 * 262144 + i0_i1_i2_i3_fused_1 * 1024 + i0_i1_i2_i3_fused_2) % 26)
                        T.where((i0_i1_i2_i3_fused_0 * 256 + i0_i1_i2_i3_fused_1) * 1024 + i0_i1_i2_i3_fused_2 < 346112)
                        T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                        T.writes(T_multiply[ax0, ax1, ax2, ax3])
                        T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 1, 256, 2, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[2, 1, 1, 13, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 1, 1, 13, 2])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[64, 4, 2])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112 = sch.split(loop=l110, factors=[None, 256])
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b90)
l120, l121 = sch.split(loop=l119, factors=[None, 256])
sch.bind(loop=l121, thread_axis="threadIdx.x")
b122 = sch.get_block(name="T_multiply", func_name="main")
l123, l124, l125, l126 = sch.get_loops(block=b122)
l127 = sch.fuse(l123, l124, l125, l126)
l128, l129, l130 = sch.split(loop=l127, factors=[None, 256, 1024])
sch.reorder(l129, l130, l128)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
b131 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b131, ann_key="meta_schedule.unroll_explicit")
b132, b133, b134, b135, b136 = sch.get_child_blocks(b131)
l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b132)
sch.annotate(block_or_loop=l137, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l137, ann_key="pragma_unroll_explicit", ann_val=1)
l145, l146, l147, l148, l149, l150, l151, l152 = sch.get_loops(block=b133)
sch.annotate(block_or_loop=l145, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l145, ann_key="pragma_unroll_explicit", ann_val=1)
l153, l154, l155, l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l153, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l153, ann_key="pragma_unroll_explicit", ann_val=1)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l173, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l173, ann_key="pragma_unroll_explicit", ann_val=1)
l180, l181, l182 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l180, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l180, ann_key="pragma_unroll_explicit", ann_val=1)
b183 = sch.get_block(name="conv2d_nchw", func_name="main")
l184, l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203 = sch.get_loops(block=b183)
b204 = sch.decompose_reduction(block=b183, loop=l187)
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #14: GFLOPs: 1991.1790. Time: 0.1785 ms. Best GFLOPs: 3258.1899
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #15: GFLOPs: 13.6453. Time: 26.0497 ms. Best GFLOPs: 3258.1899
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #16: GFLOPs: 1246.5388. Time: 0.2852 ms. Best GFLOPs: 3258.1899
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #17: GFLOPs: 35.8354. Time: 9.9192 ms. Best GFLOPs: 3258.1899
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #18: GFLOPs: 1893.4857. Time: 0.1877 ms. Best GFLOPs: 3258.1899
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #19: GFLOPs: 20.6734. Time: 17.1940 ms. Best GFLOPs: 3258.1899
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #20: GFLOPs: 357.3500. Time: 0.9947 ms. Best GFLOPs: 3258.1899
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #21: GFLOPs: 16.7465. Time: 21.2258 ms. Best GFLOPs: 3258.1899
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #22: GFLOPs: 1642.8614. Time: 0.2164 ms. Best GFLOPs: 3258.1899
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #23: GFLOPs: 96.4876. Time: 3.6840 ms. Best GFLOPs: 3258.1899
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #24: GFLOPs: 302.3554. Time: 1.1756 ms. Best GFLOPs: 3258.1899
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #25: GFLOPs: 12.5752. Time: 28.2666 ms. Best GFLOPs: 3258.1899
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #26: GFLOPs: 2211.4853. Time: 0.1607 ms. Best GFLOPs: 3258.1899
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #27: GFLOPs: 3577.2919. Time: 0.0994 ms. Best GFLOPs: 3577.2919
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #28: GFLOPs: 273.5782. Time: 1.2993 ms. Best GFLOPs: 3577.2919
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #29: GFLOPs: 120.6768. Time: 2.9455 ms. Best GFLOPs: 3577.2919
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #30: GFLOPs: 426.1838. Time: 0.8340 ms. Best GFLOPs: 3577.2919
[14:03:48] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"] Trial #31: GFLOPs: 285.0465. Time: 1.2470 ms. Best GFLOPs: 3577.2919
[14:03:50] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |      3333.8786 |     478.6984 |              478.6984 |     32 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |      2960.8178 |      60.0268 |              120.0537 |     32 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |      3729.7200 |     213.9931 |             1711.9447 |     32 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |      2831.4273 |      31.4766 |              283.2898 |     32 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |         0.0002 |       4.0251 |                8.0501 |     32 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |      3577.2919 |      99.3648 |               99.3648 |     32 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |            N/A |          N/A |                   N/A |      0 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1088
Total latency (us): 8553.98

[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #0: GFLOPs: 26.6608. Time: 59.8408 ms. Best GFLOPs: 26.6608
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #1: GFLOPs: 231.1383. Time: 6.9024 ms. Best GFLOPs: 231.1383
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #2: GFLOPs: 199.4125. Time: 8.0005 ms. Best GFLOPs: 231.1383
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #3: GFLOPs: 365.6276. Time: 4.3635 ms. Best GFLOPs: 365.6276
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #4: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 26, 26), "float32"], placeholder_1: T.Buffer[(1024, 512, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 1024, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 1024, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 1024, 13, 13], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 1024, 13, 13], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 512, 27, 27], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([1024, 512, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(2, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(4, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(64, thread="threadIdx.x"):
                    for i1_3_init, i3_3_init, i2_4_init in T.grid(2, 13, 13):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused * 512 + i0_1_i1_1_i2_1_i3_1_fused * 128 + i0_2_i1_2_i2_2_i3_2_fused * 2 + i1_3_init)
                            yy, xx = T.axis.remap("SS", [i2_4_init, i3_3_init])
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 26, 26], "float32"], ["TENSOR", [1024, 512, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(128, 1, 3):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(43):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(64, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(512, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1) % 2700 // 675)
                                    v2 = T.axis.spatial(27, (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1) % 675 // 25)
                                    v3 = T.axis.spatial(27, i6_0 + (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1) % 25)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1 < 2700)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 27 and 1 <= v3 and v3 < 27, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(48):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(64, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(2):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused * 512 + (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) // 12)
                                        v1 = T.axis.spatial(512, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 12 // 3)
                                        v2 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 3)
                                        v3 = T.axis.spatial(3, i6_0)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(4, 3, 1, 1, 2, 1, 13, 1, 1, 1, 1, 1, 13, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused * 512 + i0_1_i1_1_i2_1_i3_1_fused * 128 + i0_2_i1_2_i2_2_i3_2_fused * 2 + i1_3)
                                yy, xx = T.axis.remap("SS", [i2_4, i3_3])
                                rc = T.axis.reduce(512, i4_0 * 4 + i4_1)
                                ry, rx = T.axis.remap("RR", [i5_1, i6_0])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 26, 26], "float32"], ["TENSOR", [1024, 512, 3, 3], "float32"], [2, 2], [1, 1, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy * 2 + ry, xx * 2 + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 2, 13, 13):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused * 512 + i0_1_i1_1_i2_1_i3_1_fused * 128 + i0_2_i1_2_i2_2_i3_2_fused * 2 + ax1)
                            v2, v3 = T.axis.remap("SS", [ax2, ax3])
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_0 in T.thread_binding(169, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_1 in T.thread_binding(1024, thread="threadIdx.x"):
                with T.block("T_multiply"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(1024, (i0_i1_i2_i3_fused_0 * 1024 + i0_i1_i2_i3_fused_1) // 169)
                    ax2 = T.axis.spatial(13, (i0_i1_i2_i3_fused_0 * 1024 + i0_i1_i2_i3_fused_1) % 169 // 13)
                    ax3 = T.axis.spatial(13, (i0_i1_i2_i3_fused_0 * 1024 + i0_i1_i2_i3_fused_1) % 13)
                    T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_multiply[ax0, ax1, ax2, ax3])
                    T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[2, 4, 64, 2, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 13])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 1, 1, 13, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[128, 4, 1])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112 = sch.split(loop=l110, factors=[None, 64])
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b90)
l120, l121, l122 = sch.split(loop=l119, factors=[None, 64, 2])
sch.vectorize(loop=l122)
sch.bind(loop=l121, thread_axis="threadIdx.x")
b123 = sch.get_block(name="T_multiply", func_name="main")
l124, l125, l126, l127 = sch.get_loops(block=b123)
l128 = sch.fuse(l124, l125, l126, l127)
l129, l130 = sch.split(loop=l128, factors=[None, 1024])
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
b131 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b131, ann_key="meta_schedule.unroll_explicit")
b132, b133, b134, b135, b136 = sch.get_child_blocks(b131)
l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b132)
sch.annotate(block_or_loop=l137, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l137, ann_key="pragma_unroll_explicit", ann_val=1)
l145, l146, l147, l148, l149, l150, l151, l152, l153 = sch.get_loops(block=b133)
sch.annotate(block_or_loop=l145, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l145, ann_key="pragma_unroll_explicit", ann_val=1)
l154, l155, l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l154, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l154, ann_key="pragma_unroll_explicit", ann_val=1)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l174, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l174, ann_key="pragma_unroll_explicit", ann_val=1)
l181, l182 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l181, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l181, ann_key="pragma_unroll_explicit", ann_val=1)
b183 = sch.get_block(name="conv2d_nchw", func_name="main")
l184, l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203 = sch.get_loops(block=b183)
b204 = sch.decompose_reduction(block=b183, loop=l187)
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #5: GFLOPs: 140.6075. Time: 11.3465 ms. Best GFLOPs: 365.6276
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #6: GFLOPs: 134.7255. Time: 11.8419 ms. Best GFLOPs: 365.6276
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #7: GFLOPs: 898.3039. Time: 1.7760 ms. Best GFLOPs: 898.3039
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #8: GFLOPs: 70.2261. Time: 22.7181 ms. Best GFLOPs: 898.3039
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #9: GFLOPs: 1160.6787. Time: 1.3745 ms. Best GFLOPs: 1160.6787
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #10: GFLOPs: 711.3506. Time: 2.2428 ms. Best GFLOPs: 1160.6787
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #11: GFLOPs: 160.6102. Time: 9.9334 ms. Best GFLOPs: 1160.6787
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #12: GFLOPs: 7.8760. Time: 202.5646 ms. Best GFLOPs: 1160.6787
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #13: GFLOPs: 1429.3952. Time: 1.1161 ms. Best GFLOPs: 1429.3952
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #14: GFLOPs: 33.6628. Time: 47.3936 ms. Best GFLOPs: 1429.3952
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #15: GFLOPs: 724.4816. Time: 2.2021 ms. Best GFLOPs: 1429.3952
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #16: GFLOPs: 162.6434. Time: 9.8092 ms. Best GFLOPs: 1429.3952
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #17: GFLOPs: 61.8681. Time: 25.7872 ms. Best GFLOPs: 1429.3952
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #18: GFLOPs: 201.4912. Time: 7.9180 ms. Best GFLOPs: 1429.3952
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #19: GFLOPs: 32.1718. Time: 49.5902 ms. Best GFLOPs: 1429.3952
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #20: GFLOPs: 843.4053. Time: 1.8916 ms. Best GFLOPs: 1429.3952
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #21: GFLOPs: 948.0561. Time: 1.6828 ms. Best GFLOPs: 1429.3952
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #22: GFLOPs: 1424.7217. Time: 1.1198 ms. Best GFLOPs: 1429.3952
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #23: GFLOPs: 301.6129. Time: 5.2896 ms. Best GFLOPs: 1429.3952
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #24: GFLOPs: 1495.2581. Time: 1.0670 ms. Best GFLOPs: 1495.2581
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #25: GFLOPs: 79.0558. Time: 20.1807 ms. Best GFLOPs: 1495.2581
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #26: GFLOPs: 1511.4957. Time: 1.0555 ms. Best GFLOPs: 1511.4957
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #27: GFLOPs: 71.2207. Time: 22.4008 ms. Best GFLOPs: 1511.4957
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #28: GFLOPs: 1641.9450. Time: 0.9717 ms. Best GFLOPs: 1641.9450
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #29: GFLOPs: 7.2750. Time: 219.2982 ms. Best GFLOPs: 1641.9450
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #30: GFLOPs: 85.0905. Time: 18.7495 ms. Best GFLOPs: 1641.9450
[14:03:50] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"] Trial #31: GFLOPs: 141.8240. Time: 11.2492 ms. Best GFLOPs: 1641.9450
[14:03:52] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |      3333.8786 |     478.6984 |              478.6984 |     32 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |      2960.8178 |      60.0268 |              120.0537 |     32 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |      3729.7200 |     213.9931 |             1711.9447 |     32 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |      2831.4273 |      31.4766 |              283.2898 |     32 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |         0.0002 |       4.0251 |                8.0501 |     32 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |      3577.2919 |      99.3648 |               99.3648 |     32 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |      1641.9450 |     971.6545 |              971.6545 |     32 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |            N/A |          N/A |                   N/A |      0 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1120
Total latency (us): 9525.64

[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #0: GFLOPs: 178.0025. Time: 0.9970 ms. Best GFLOPs: 178.0025
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #1: GFLOPs: 1296.1218. Time: 0.1369 ms. Best GFLOPs: 1296.1218
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #2: GFLOPs: 693.0276. Time: 0.2561 ms. Best GFLOPs: 1296.1218
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #3: GFLOPs: 1187.9526. Time: 0.1494 ms. Best GFLOPs: 1296.1218
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #4: GFLOPs: 757.5626. Time: 0.2343 ms. Best GFLOPs: 1296.1218
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #5: GFLOPs: 38.9278. Time: 4.5589 ms. Best GFLOPs: 1296.1218
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #6: GFLOPs: 2242.5252. Time: 0.0791 ms. Best GFLOPs: 2242.5252
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #7: GFLOPs: 865.0472. Time: 0.2052 ms. Best GFLOPs: 2242.5252
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #8: GFLOPs: 20.6905. Time: 8.5773 ms. Best GFLOPs: 2242.5252
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #9: GFLOPs: 69.1474. Time: 2.5665 ms. Best GFLOPs: 2242.5252
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #10: GFLOPs: 84.2641. Time: 2.1061 ms. Best GFLOPs: 2242.5252
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #11: GFLOPs: 243.2792. Time: 0.7295 ms. Best GFLOPs: 2242.5252
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #12: GFLOPs: 61.8542. Time: 2.8692 ms. Best GFLOPs: 2242.5252
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #13: GFLOPs: 302.1699. Time: 0.5873 ms. Best GFLOPs: 2242.5252
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #14: GFLOPs: 418.9699. Time: 0.4236 ms. Best GFLOPs: 2242.5252
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #15: GFLOPs: 110.8809. Time: 1.6005 ms. Best GFLOPs: 2242.5252
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #16: GFLOPs: 591.9498. Time: 0.2998 ms. Best GFLOPs: 2242.5252
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #17: GFLOPs: 1742.4811. Time: 0.1018 ms. Best GFLOPs: 2242.5252
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #18: GFLOPs: 168.3548. Time: 1.0541 ms. Best GFLOPs: 2242.5252
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #19: GFLOPs: 241.0111. Time: 0.7364 ms. Best GFLOPs: 2242.5252
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #20: GFLOPs: 915.9061. Time: 0.1938 ms. Best GFLOPs: 2242.5252
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #21: GFLOPs: 1235.0393. Time: 0.1437 ms. Best GFLOPs: 2242.5252
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #22: GFLOPs: 10.1664. Time: 17.4565 ms. Best GFLOPs: 2242.5252
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #23: GFLOPs: 1070.0278. Time: 0.1659 ms. Best GFLOPs: 2242.5252
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #24: GFLOPs: 1672.7253. Time: 0.1061 ms. Best GFLOPs: 2242.5252
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #25: GFLOPs: 142.5799. Time: 1.2447 ms. Best GFLOPs: 2242.5252
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #26: GFLOPs: 824.4008. Time: 0.2153 ms. Best GFLOPs: 2242.5252
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #27: GFLOPs: 13.3461. Time: 13.2975 ms. Best GFLOPs: 2242.5252
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #28: GFLOPs: 680.5158. Time: 0.2608 ms. Best GFLOPs: 2242.5252
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #29: GFLOPs: 604.1996. Time: 0.2937 ms. Best GFLOPs: 2242.5252
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #30: GFLOPs: 527.6243. Time: 0.3364 ms. Best GFLOPs: 2242.5252
[14:03:52] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"] Trial #31: GFLOPs: 155.3874. Time: 1.1421 ms. Best GFLOPs: 2242.5252
[14:03:54] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |      3333.8786 |     478.6984 |              478.6984 |     32 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |      2960.8178 |      60.0268 |              120.0537 |     32 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |      3729.7200 |     213.9931 |             1711.9447 |     32 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |      2831.4273 |      31.4766 |              283.2898 |     32 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |         0.0002 |       4.0251 |                8.0501 |     32 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |      3577.2919 |      99.3648 |               99.3648 |     32 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |      1641.9450 |     971.6545 |              971.6545 |     32 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |      2242.5252 |      79.1380 |              158.2760 |     32 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |            N/A |          N/A |                   N/A |      0 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1152
Total latency (us): 9683.91

[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #0: GFLOPs: 19.0221. Time: 41.9400 ms. Best GFLOPs: 19.0221
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #1: GFLOPs: 3.3362. Time: 239.1288 ms. Best GFLOPs: 19.0221
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #2: GFLOPs: 228.3680. Time: 3.4934 ms. Best GFLOPs: 228.3680
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #3: GFLOPs: 926.5978. Time: 0.8610 ms. Best GFLOPs: 926.5978
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #4: Error in building: LocalRunner: An exception occurred
Subprocess terminated
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 13, 13), "float32"], placeholder_1: T.Buffer[(512, 512, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], placeholder_4: T.Buffer[(1, 512, 13, 13), "float32"], T_add: T.Buffer[(1, 512, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 512, 13, 13], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 512, 15, 15], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([512, 512, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(52, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(1, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(64, thread="threadIdx.x"):
                    for i3_3_init, i1_4_init in T.grid(13, 2):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused // 13 * 128 + i0_2_i1_2_i2_2_i3_2_fused * 2 + i1_4_init)
                            yy = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_fused % 13)
                            xx = T.axis.spatial(13, i3_3_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 13, 13], "float32"], ["TENSOR", [512, 512, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(256, 1, 3):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(1):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(64, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(3):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(512, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_1 * 3 + ax0_ax1_ax2_ax3_fused_2) % 78 // 39)
                                        v2 = T.axis.spatial(15, i0_0_i1_0_i2_0_i3_0_fused % 13 + (ax0_ax1_ax2_ax3_fused_1 * 3 + ax0_ax1_ax2_ax3_fused_2) % 39 // 13)
                                        v3 = T.axis.spatial(15, i6_0 + (ax0_ax1_ax2_ax3_fused_1 * 3 + ax0_ax1_ax2_ax3_fused_2) % 13)
                                        T.where(ax0_ax1_ax2_ax3_fused_1 * 3 + ax0_ax1_ax2_ax3_fused_2 < 78)
                                        T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 14 and 1 <= v3 and v3 < 14, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(3):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(64, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused // 13 * 128 + (ax0_ax1_ax2_ax3_fused_0 * 256 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 6)
                                        v1 = T.axis.spatial(512, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 256 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 6 // 3)
                                        v2 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 256 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 3)
                                        v3 = T.axis.spatial(3, i6_0)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(2, 3, 1, 1, 1, 1, 13, 1, 1, 1, 1, 2, 1, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused // 13 * 128 + i0_2_i1_2_i2_2_i3_2_fused * 2 + i1_4)
                                yy = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_fused % 13)
                                xx = T.axis.spatial(13, i3_3)
                                rc = T.axis.reduce(512, i4_0 * 2 + i4_1)
                                ry, rx = T.axis.remap("RR", [i5_1, i6_0])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 13, 13], "float32"], ["TENSOR", [512, 512, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 2, 1, 13):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused // 13 * 128 + i0_2_i1_2_i2_2_i3_2_fused * 2 + ax1)
                            v2 = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_fused % 13 + ax2)
                            v3 = T.axis.spatial(13, ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_0 in T.thread_binding(85, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_1 in T.thread_binding(1024, thread="threadIdx.x"):
                with T.block("T_multiply"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(512, (i0_i1_i2_i3_fused_0 * 1024 + i0_i1_i2_i3_fused_1) // 169)
                    ax2 = T.axis.spatial(13, (i0_i1_i2_i3_fused_0 * 1024 + i0_i1_i2_i3_fused_1) % 169 // 13)
                    ax3 = T.axis.spatial(13, (i0_i1_i2_i3_fused_0 * 1024 + i0_i1_i2_i3_fused_1) % 13)
                    T.where(i0_i1_i2_i3_fused_0 * 1024 + i0_i1_i2_i3_fused_1 < 86528)
                    T.reads(placeholder_4[ax0, ax1, ax2, ax3], conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_add[ax0, ax1, ax2, ax3])
                    T_add[ax0, ax1, ax2, ax3] = placeholder_4[ax0, ax1, ax2, ax3] + (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="T_add_2", func_name="main")
b8 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l9, l10, l11, l12, l13, l14, l15 = sch.get_loops(block=b1)
v16, v17, v18, v19, v20 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l21, l22, l23, l24, l25 = sch.split(loop=l9, factors=[v16, v17, v18, v19, v20])
v26, v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[4, 1, 64, 1, 2])
l31, l32, l33, l34, l35 = sch.split(loop=l10, factors=[v26, v27, v28, v29, v30])
v36, v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[13, 1, 1, 1, 1])
l41, l42, l43, l44, l45 = sch.split(loop=l11, factors=[v36, v37, v38, v39, v40])
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l12, n=5, max_innermost_factor=64, decision=[1, 1, 1, 13, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l12, factors=[v46, v47, v48, v49, v50])
v56, v57, v58 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[256, 2, 1])
l59, l60, l61 = sch.split(loop=l13, factors=[v56, v57, v58])
v62, v63, v64 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l65, l66, l67 = sch.split(loop=l14, factors=[v62, v63, v64])
v68, v69, v70 = sch.sample_perfect_tile(loop=l15, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l71, l72, l73 = sch.split(loop=l15, factors=[v68, v69, v70])
sch.reorder(l21, l31, l41, l51, l22, l32, l42, l52, l23, l33, l43, l53, l59, l65, l71, l60, l66, l72, l24, l34, l44, l54, l61, l67, l73, l25, l35, l45, l55)
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="blockIdx.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="vthread.x")
l76 = sch.fuse(l23, l33, l43, l53)
sch.bind(loop=l76, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b77 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b77, loop=l76, preserve_unit_loops=True)
b78 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b78, loop=l71, preserve_unit_loops=True)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b78)
l89 = sch.fuse(l85, l86, l87, l88)
v90 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b78, ann_key="meta_schedule.cooperative_fetch", ann_val=v90)
b91 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b91, loop=l71, preserve_unit_loops=True)
l92, l93, l94, l95, l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b91)
l102 = sch.fuse(l98, l99, l100, l101)
v103 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b91, ann_key="meta_schedule.cooperative_fetch", ann_val=v103)
sch.reverse_compute_inline(block=b7)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v104 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b8, ann_key="meta_schedule.unroll_explicit", ann_val=v104)
sch.enter_postproc()
sch.unannotate(block_or_loop=b78, ann_key="meta_schedule.cooperative_fetch")
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b78)
l112, l113, l114 = sch.split(loop=l111, factors=[None, 64, 3])
sch.vectorize(loop=l114)
sch.bind(loop=l113, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b91, ann_key="meta_schedule.cooperative_fetch")
l115, l116, l117, l118, l119, l120, l121 = sch.get_loops(block=b91)
l122, l123, l124 = sch.split(loop=l121, factors=[None, 64, 4])
sch.vectorize(loop=l124)
sch.bind(loop=l123, thread_axis="threadIdx.x")
b125 = sch.get_block(name="T_multiply", func_name="main")
l126, l127, l128, l129 = sch.get_loops(block=b125)
l130 = sch.fuse(l126, l127, l128, l129)
l131, l132 = sch.split(loop=l130, factors=[None, 1024])
sch.bind(loop=l131, thread_axis="blockIdx.x")
sch.bind(loop=l132, thread_axis="threadIdx.x")
b133 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b133, ann_key="meta_schedule.unroll_explicit")
b134, b135, b136, b137, b138 = sch.get_child_blocks(b133)
l139, l140, l141, l142, l143, l144, l145, l146, l147 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l139, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l139, ann_key="pragma_unroll_explicit", ann_val=1)
l148, l149, l150, l151, l152, l153, l154, l155, l156 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l148, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l148, ann_key="pragma_unroll_explicit", ann_val=1)
l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174, l175, l176 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l157, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l157, ann_key="pragma_unroll_explicit", ann_val=1)
l177, l178, l179, l180, l181, l182, l183 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l177, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l177, ann_key="pragma_unroll_explicit", ann_val=1)
l184, l185 = sch.get_loops(block=b138)
sch.annotate(block_or_loop=l184, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l184, ann_key="pragma_unroll_explicit", ann_val=1)
b186 = sch.get_block(name="conv2d_nchw", func_name="main")
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b186)
b207 = sch.decompose_reduction(block=b186, loop=l190)
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #5: GFLOPs: 2059.1342. Time: 0.3874 ms. Best GFLOPs: 2059.1342
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #6: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 13, 13), "float32"], placeholder_1: T.Buffer[(512, 512, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], placeholder_4: T.Buffer[(1, 512, 13, 13), "float32"], T_add: T.Buffer[(1, 512, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 512, 13, 13], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 512, 15, 15], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([512, 512, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(2, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(26, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i1_4_init, i2_4_init in T.grid(4, 13):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused * 256 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 128 + i0_2_i1_2_i2_2_i3_2_fused * 4 + i1_4_init)
                            yy = T.axis.spatial(13, i2_4_init)
                            xx = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 13)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 13, 13], "float32"], ["TENSOR", [512, 512, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(64, 3, 3):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(43):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(512, i4_0 * 8 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 1352 // 169)
                                    v2 = T.axis.spatial(15, i5_0 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 169 // 13)
                                    v3 = T.axis.spatial(15, i6_0 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 13)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1 < 1352)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 14 and 1 <= v3 and v3 < 14, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(64):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused * 256 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) // 8)
                                    v1 = T.axis.spatial(512, i4_0 * 8 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 8)
                                    v2, v3 = T.axis.remap("SS", [i5_0, i6_0])
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 1, 1, 1, 8, 1, 1, 1, 4, 13, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused * 256 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 128 + i0_2_i1_2_i2_2_i3_2_fused * 4 + i1_4)
                                yy = T.axis.spatial(13, i2_4)
                                xx = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 13)
                                rc = T.axis.reduce(512, i4_0 * 8 + i4_2)
                                ry, rx = T.axis.remap("RR", [i5_0, i6_0])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 13, 13], "float32"], ["TENSOR", [512, 512, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 4, 13, 1):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused * 256 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 128 + i0_2_i1_2_i2_2_i3_2_fused * 4 + ax1)
                            v2 = T.axis.spatial(13, ax2)
                            v3 = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 13 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_0 in T.thread_binding(85, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_1 in T.thread_binding(1024, thread="threadIdx.x"):
                with T.block("T_multiply"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(512, (i0_i1_i2_i3_fused_0 * 1024 + i0_i1_i2_i3_fused_1) // 169)
                    ax2 = T.axis.spatial(13, (i0_i1_i2_i3_fused_0 * 1024 + i0_i1_i2_i3_fused_1) % 169 // 13)
                    ax3 = T.axis.spatial(13, (i0_i1_i2_i3_fused_0 * 1024 + i0_i1_i2_i3_fused_1) % 13)
                    T.where(i0_i1_i2_i3_fused_0 * 1024 + i0_i1_i2_i3_fused_1 < 86528)
                    T.reads(placeholder_4[ax0, ax1, ax2, ax3], conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_add[ax0, ax1, ax2, ax3])
                    T_add[ax0, ax1, ax2, ax3] = placeholder_4[ax0, ax1, ax2, ax3] + (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="T_add_2", func_name="main")
b8 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l9, l10, l11, l12, l13, l14, l15 = sch.get_loops(block=b1)
v16, v17, v18, v19, v20 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l21, l22, l23, l24, l25 = sch.split(loop=l9, factors=[v16, v17, v18, v19, v20])
v26, v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[2, 2, 32, 1, 4])
l31, l32, l33, l34, l35 = sch.split(loop=l10, factors=[v26, v27, v28, v29, v30])
v36, v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 13])
l41, l42, l43, l44, l45 = sch.split(loop=l11, factors=[v36, v37, v38, v39, v40])
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l12, n=5, max_innermost_factor=64, decision=[1, 13, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l12, factors=[v46, v47, v48, v49, v50])
v56, v57, v58 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[64, 1, 8])
l59, l60, l61 = sch.split(loop=l13, factors=[v56, v57, v58])
v62, v63, v64 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l65, l66, l67 = sch.split(loop=l14, factors=[v62, v63, v64])
v68, v69, v70 = sch.sample_perfect_tile(loop=l15, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l71, l72, l73 = sch.split(loop=l15, factors=[v68, v69, v70])
sch.reorder(l21, l31, l41, l51, l22, l32, l42, l52, l23, l33, l43, l53, l59, l65, l71, l60, l66, l72, l24, l34, l44, l54, l61, l67, l73, l25, l35, l45, l55)
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="blockIdx.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="vthread.x")
l76 = sch.fuse(l23, l33, l43, l53)
sch.bind(loop=l76, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b77 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b77, loop=l76, preserve_unit_loops=True)
b78 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b78, loop=l71, preserve_unit_loops=True)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b78)
l89 = sch.fuse(l85, l86, l87, l88)
v90 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b78, ann_key="meta_schedule.cooperative_fetch", ann_val=v90)
b91 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b91, loop=l71, preserve_unit_loops=True)
l92, l93, l94, l95, l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b91)
l102 = sch.fuse(l98, l99, l100, l101)
v103 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b91, ann_key="meta_schedule.cooperative_fetch", ann_val=v103)
sch.reverse_compute_inline(block=b7)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v104 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b8, ann_key="meta_schedule.unroll_explicit", ann_val=v104)
sch.enter_postproc()
sch.unannotate(block_or_loop=b78, ann_key="meta_schedule.cooperative_fetch")
l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b78)
l112, l113 = sch.split(loop=l111, factors=[None, 32])
sch.bind(loop=l113, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b91, ann_key="meta_schedule.cooperative_fetch")
l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b91)
l121, l122 = sch.split(loop=l120, factors=[None, 32])
sch.bind(loop=l122, thread_axis="threadIdx.x")
b123 = sch.get_block(name="T_multiply", func_name="main")
l124, l125, l126, l127 = sch.get_loops(block=b123)
l128 = sch.fuse(l124, l125, l126, l127)
l129, l130 = sch.split(loop=l128, factors=[None, 1024])
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
b131 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b131, ann_key="meta_schedule.unroll_explicit")
b132, b133, b134, b135, b136 = sch.get_child_blocks(b131)
l137, l138, l139, l140, l141, l142, l143, l144 = sch.get_loops(block=b132)
sch.annotate(block_or_loop=l137, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l137, ann_key="pragma_unroll_explicit", ann_val=1)
l145, l146, l147, l148, l149, l150, l151, l152 = sch.get_loops(block=b133)
sch.annotate(block_or_loop=l145, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l145, ann_key="pragma_unroll_explicit", ann_val=1)
l153, l154, l155, l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l153, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l153, ann_key="pragma_unroll_explicit", ann_val=1)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l173, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l173, ann_key="pragma_unroll_explicit", ann_val=1)
l180, l181 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l180, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l180, ann_key="pragma_unroll_explicit", ann_val=1)
b182 = sch.get_block(name="conv2d_nchw", func_name="main")
l183, l184, l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202 = sch.get_loops(block=b182)
b203 = sch.decompose_reduction(block=b182, loop=l186)
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #7: GFLOPs: 231.8208. Time: 3.4414 ms. Best GFLOPs: 2059.1342
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #8: GFLOPs: 34.5168. Time: 23.1131 ms. Best GFLOPs: 2059.1342
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #9: GFLOPs: 394.2144. Time: 2.0237 ms. Best GFLOPs: 2059.1342
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #10: GFLOPs: 1506.5567. Time: 0.5295 ms. Best GFLOPs: 2059.1342
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #11: GFLOPs: 290.1013. Time: 2.7500 ms. Best GFLOPs: 2059.1342
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #12: GFLOPs: 158.2576. Time: 5.0411 ms. Best GFLOPs: 2059.1342
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #13: GFLOPs: 1633.3505. Time: 0.4884 ms. Best GFLOPs: 2059.1342
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #14: GFLOPs: 197.1902. Time: 4.0458 ms. Best GFLOPs: 2059.1342
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #15: GFLOPs: 368.6132. Time: 2.1643 ms. Best GFLOPs: 2059.1342
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #16: GFLOPs: 565.7091. Time: 1.4102 ms. Best GFLOPs: 2059.1342
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #17: GFLOPs: 1822.4777. Time: 0.4377 ms. Best GFLOPs: 2059.1342
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #18: GFLOPs: 1706.4206. Time: 0.4675 ms. Best GFLOPs: 2059.1342
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #19: GFLOPs: 25.3644. Time: 31.4531 ms. Best GFLOPs: 2059.1342
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #20: GFLOPs: 89.3279. Time: 8.9310 ms. Best GFLOPs: 2059.1342
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #21: GFLOPs: 2992.4470. Time: 0.2666 ms. Best GFLOPs: 2992.4470
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #22: GFLOPs: 17.5538. Time: 45.4481 ms. Best GFLOPs: 2992.4470
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #23: GFLOPs: 49.7130. Time: 16.0479 ms. Best GFLOPs: 2992.4470
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #24: GFLOPs: 329.1734. Time: 2.4236 ms. Best GFLOPs: 2992.4470
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #25: GFLOPs: 106.9472. Time: 7.4596 ms. Best GFLOPs: 2992.4470
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #26: GFLOPs: 2149.9939. Time: 0.3711 ms. Best GFLOPs: 2992.4470
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #27: GFLOPs: 41.5243. Time: 19.2126 ms. Best GFLOPs: 2992.4470
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #28: GFLOPs: 866.7978. Time: 0.9204 ms. Best GFLOPs: 2992.4470
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #29: GFLOPs: 29.7156. Time: 26.8475 ms. Best GFLOPs: 2992.4470
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #30: GFLOPs: 63.6696. Time: 12.5301 ms. Best GFLOPs: 2992.4470
[14:03:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"] Trial #31: GFLOPs: 203.0261. Time: 3.9295 ms. Best GFLOPs: 2992.4470
[14:03:56] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |      3333.8786 |     478.6984 |              478.6984 |     32 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |      2960.8178 |      60.0268 |              120.0537 |     32 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |      3729.7200 |     213.9931 |             1711.9447 |     32 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |      2831.4273 |      31.4766 |              283.2898 |     32 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |         0.0002 |       4.0251 |                8.0501 |     32 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |      3577.2919 |      99.3648 |               99.3648 |     32 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |      1641.9450 |     971.6545 |              971.6545 |     32 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |      2242.5252 |      79.1380 |              158.2760 |     32 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |      2992.4470 |     266.6006 |             1066.4024 |     32 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |            N/A |          N/A |                   N/A |      0 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1184
Total latency (us): 10750.3

[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #0: GFLOPs: 851.7126. Time: 0.1043 ms. Best GFLOPs: 851.7126
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #1: GFLOPs: 18.8500. Time: 4.7143 ms. Best GFLOPs: 851.7126
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #2: GFLOPs: 545.3413. Time: 0.1630 ms. Best GFLOPs: 851.7126
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #3: GFLOPs: 68.2986. Time: 1.3011 ms. Best GFLOPs: 851.7126
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #4: GFLOPs: 12.8713. Time: 6.9041 ms. Best GFLOPs: 851.7126
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #5: GFLOPs: 1443.5559. Time: 0.0616 ms. Best GFLOPs: 1443.5559
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #6: GFLOPs: 468.9210. Time: 0.1895 ms. Best GFLOPs: 1443.5559
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #7: GFLOPs: 20.9982. Time: 4.2320 ms. Best GFLOPs: 1443.5559
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #8: GFLOPs: 1500.1992. Time: 0.0592 ms. Best GFLOPs: 1500.1992
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #9: GFLOPs: 53.4106. Time: 1.6638 ms. Best GFLOPs: 1500.1992
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #10: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 13, 13), "float32"], placeholder_1: T.Buffer[(512, 512, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 512, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 512, 13, 13], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 512, 13, 13], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 512, 13, 13], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([512, 512, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(1, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(52, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i1_3_init, i1_4_init, i2_4_init in T.grid(2, 2, 13):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(512, i0_1_i1_1_i2_1_i3_1_fused // 13 * 128 + i0_2_i1_2_i2_2_i3_2_fused * 4 + i1_3_init * 2 + i1_4_init)
                            yy = T.axis.spatial(13, i2_4_init)
                            xx = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 13)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 13, 13], "float32"], ["TENSOR", [512, 512, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(64, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(11):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(512, i4_0 * 8 + (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 169)
                                        v2 = T.axis.spatial(13, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 169 // 13)
                                        v3 = T.axis.spatial(13, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 13)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 4 + ax0_ax1_ax2_ax3_fused_2 < 1352)
                                        T.reads(placeholder[v0, v1, v2, v3])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(128):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(512, (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) // 8)
                                    v1 = T.axis.spatial(512, i4_0 * 8 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 8)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(4, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 13, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(512, i0_1_i1_1_i2_1_i3_1_fused // 13 * 128 + i0_2_i1_2_i2_2_i3_2_fused * 4 + i1_3 * 2 + i1_4)
                                yy = T.axis.spatial(13, i2_4)
                                xx = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 13)
                                rc = T.axis.reduce(512, i4_0 * 8 + i4_1 * 2 + i4_2)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 13, 13], "float32"], ["TENSOR", [512, 512, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 4, 13, 1):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(512, i0_1_i1_1_i2_1_i3_1_fused // 13 * 128 + i0_2_i1_2_i2_2_i3_2_fused * 4 + ax1)
                            v2 = T.axis.spatial(13, ax2)
                            v3 = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 13 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_0 in T.thread_binding(85, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_1 in T.thread_binding(1024, thread="threadIdx.x"):
                with T.block("T_multiply"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(512, (i0_i1_i2_i3_fused_0 * 1024 + i0_i1_i2_i3_fused_1) // 169)
                    ax2 = T.axis.spatial(13, (i0_i1_i2_i3_fused_0 * 1024 + i0_i1_i2_i3_fused_1) % 169 // 13)
                    ax3 = T.axis.spatial(13, (i0_i1_i2_i3_fused_0 * 1024 + i0_i1_i2_i3_fused_1) % 13)
                    T.where(i0_i1_i2_i3_fused_0 * 1024 + i0_i1_i2_i3_fused_1 < 86528)
                    T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_multiply[ax0, ax1, ax2, ax3])
                    T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 4, 32, 2, 2])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 13])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 13, 1, 1, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[64, 4, 2])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112, l113 = sch.split(loop=l110, factors=[None, 32, 4])
sch.vectorize(loop=l113)
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b90)
l121, l122 = sch.split(loop=l120, factors=[None, 32])
sch.bind(loop=l122, thread_axis="threadIdx.x")
b123 = sch.get_block(name="T_multiply", func_name="main")
l124, l125, l126, l127 = sch.get_loops(block=b123)
l128 = sch.fuse(l124, l125, l126, l127)
l129, l130 = sch.split(loop=l128, factors=[None, 1024])
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
b131 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b131, ann_key="meta_schedule.unroll_explicit")
b132, b133, b134, b135, b136 = sch.get_child_blocks(b131)
l137, l138, l139, l140, l141, l142, l143, l144, l145 = sch.get_loops(block=b132)
sch.annotate(block_or_loop=l137, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l137, ann_key="pragma_unroll_explicit", ann_val=1)
l146, l147, l148, l149, l150, l151, l152, l153 = sch.get_loops(block=b133)
sch.annotate(block_or_loop=l146, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l146, ann_key="pragma_unroll_explicit", ann_val=1)
l154, l155, l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l154, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l154, ann_key="pragma_unroll_explicit", ann_val=1)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l174, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l174, ann_key="pragma_unroll_explicit", ann_val=1)
l181, l182 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l181, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l181, ann_key="pragma_unroll_explicit", ann_val=1)
b183 = sch.get_block(name="conv2d_nchw", func_name="main")
l184, l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203 = sch.get_loops(block=b183)
b204 = sch.decompose_reduction(block=b183, loop=l187)
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #11: GFLOPs: 541.3330. Time: 0.1642 ms. Best GFLOPs: 1500.1992
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #12: GFLOPs: 1411.9073. Time: 0.0629 ms. Best GFLOPs: 1500.1992
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #13: GFLOPs: 382.6381. Time: 0.2322 ms. Best GFLOPs: 1500.1992
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #14: GFLOPs: 376.2201. Time: 0.2362 ms. Best GFLOPs: 1500.1992
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #15: GFLOPs: 175.7479. Time: 0.5056 ms. Best GFLOPs: 1500.1992
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #16: GFLOPs: 677.2482. Time: 0.1312 ms. Best GFLOPs: 1500.1992
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #17: GFLOPs: 151.9826. Time: 0.5847 ms. Best GFLOPs: 1500.1992
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #18: GFLOPs: 518.2334. Time: 0.1715 ms. Best GFLOPs: 1500.1992
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #19: GFLOPs: 398.2190. Time: 0.2232 ms. Best GFLOPs: 1500.1992
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #20: GFLOPs: 1097.0492. Time: 0.0810 ms. Best GFLOPs: 1500.1992
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #21: GFLOPs: 55.4390. Time: 1.6029 ms. Best GFLOPs: 1500.1992
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #22: GFLOPs: 44.8619. Time: 1.9808 ms. Best GFLOPs: 1500.1992
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #23: GFLOPs: 29.2608. Time: 3.0370 ms. Best GFLOPs: 1500.1992
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #24: GFLOPs: 71.7509. Time: 1.2385 ms. Best GFLOPs: 1500.1992
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #25: GFLOPs: 15.1759. Time: 5.8556 ms. Best GFLOPs: 1500.1992
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #26: GFLOPs: 38.5182. Time: 2.3071 ms. Best GFLOPs: 1500.1992
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #27: GFLOPs: 1314.2027. Time: 0.0676 ms. Best GFLOPs: 1500.1992
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #28: GFLOPs: 826.0547. Time: 0.1076 ms. Best GFLOPs: 1500.1992
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #29: GFLOPs: 711.3417. Time: 0.1249 ms. Best GFLOPs: 1500.1992
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #30: GFLOPs: 301.5432. Time: 0.2947 ms. Best GFLOPs: 1500.1992
[14:03:57] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"] Trial #31: GFLOPs: 682.5741. Time: 0.1302 ms. Best GFLOPs: 1500.1992
[14:03:58] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |      3333.8786 |     478.6984 |              478.6984 |     32 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |      2960.8178 |      60.0268 |              120.0537 |     32 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |      3729.7200 |     213.9931 |             1711.9447 |     32 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |      2831.4273 |      31.4766 |              283.2898 |     32 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |         0.0002 |       4.0251 |                8.0501 |     32 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |      3577.2919 |      99.3648 |               99.3648 |     32 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |      1641.9450 |     971.6545 |              971.6545 |     32 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |      2242.5252 |      79.1380 |              158.2760 |     32 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |      2992.4470 |     266.6006 |             1066.4024 |     32 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |      1500.1992 |      59.2350 |              296.1749 |     32 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1216
Total latency (us): 11046.5

[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #0: GFLOPs: 0.0000. Time: 0.0029 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #1: GFLOPs: 0.0000. Time: 0.0029 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #2: GFLOPs: 0.0000. Time: 0.0029 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #3: GFLOPs: 0.0000. Time: 0.0029 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #4: GFLOPs: 0.0000. Time: 0.0029 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #5: GFLOPs: 0.0000. Time: 0.0029 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #6: GFLOPs: 0.0000. Time: 0.0029 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #7: GFLOPs: 0.0000. Time: 0.0029 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #8: GFLOPs: 0.0000. Time: 0.0029 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #9: GFLOPs: 0.0000. Time: 0.0028 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #10: GFLOPs: 0.0000. Time: 0.0029 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #11: GFLOPs: 0.0000. Time: 0.0029 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #12: GFLOPs: 0.0000. Time: 0.0029 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #13: GFLOPs: 0.0000. Time: 0.0029 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #14: GFLOPs: 0.0000. Time: 0.0028 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #15: GFLOPs: 0.0000. Time: 0.0030 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #16: GFLOPs: 0.0000. Time: 0.0029 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #17: GFLOPs: 0.0000. Time: 0.0029 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #18: GFLOPs: 0.0000. Time: 0.0029 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #19: GFLOPs: 0.0000. Time: 0.0029 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #20: GFLOPs: 0.0000. Time: 0.0029 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #21: GFLOPs: 0.0000. Time: 0.0029 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #22: GFLOPs: 0.0000. Time: 0.0028 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #23: GFLOPs: 0.0000. Time: 0.0028 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #24: GFLOPs: 0.0000. Time: 0.0029 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #25: GFLOPs: 0.0000. Time: 0.0029 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #26: GFLOPs: 0.0000. Time: 0.0029 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #27: GFLOPs: 0.0000. Time: 0.0029 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #28: GFLOPs: 0.0000. Time: 0.0029 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #29: GFLOPs: 0.0000. Time: 0.0029 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #30: GFLOPs: 0.0000. Time: 0.0029 ms. Best GFLOPs: 0.0000
[14:03:58] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #38: "fused_concatenate_4"] Trial #31: GFLOPs: 0.0000. Time: 0.0029 ms. Best GFLOPs: 0.0000
[14:04:00] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #38: "fused_concatenate_4"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |      3333.8786 |     478.6984 |              478.6984 |     32 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |      2960.8178 |      60.0268 |              120.0537 |     32 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |      3729.7200 |     213.9931 |             1711.9447 |     32 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |      2831.4273 |      31.4766 |              283.2898 |     32 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |         0.0002 |       4.0251 |                8.0501 |     32 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |      3577.2919 |      99.3648 |               99.3648 |     32 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |      1641.9450 |     971.6545 |              971.6545 |     32 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |      2242.5252 |      79.1380 |              158.2760 |     32 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |      2992.4470 |     266.6006 |             1066.4024 |     32 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |      1500.1992 |      59.2350 |              296.1749 |     32 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |         0.0004 |       2.8040 |                5.6080 |     32 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |            N/A |          N/A |                   N/A |      0 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1248
Total latency (us): 11052.1

[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #0: GFLOPs: 14.8760. Time: 23.8597 ms. Best GFLOPs: 14.8760
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #1: GFLOPs: 1357.7642. Time: 0.2614 ms. Best GFLOPs: 1357.7642
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #2: GFLOPs: 126.2551. Time: 2.8113 ms. Best GFLOPs: 1357.7642
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #3: GFLOPs: 10.8527. Time: 32.7051 ms. Best GFLOPs: 1357.7642
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #4: GFLOPs: 99.3827. Time: 3.5714 ms. Best GFLOPs: 1357.7642
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #5: GFLOPs: 28.9965. Time: 12.2407 ms. Best GFLOPs: 1357.7642
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #6: GFLOPs: 118.9418. Time: 2.9841 ms. Best GFLOPs: 1357.7642
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #7: GFLOPs: 1857.5204. Time: 0.1911 ms. Best GFLOPs: 1857.5204
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #8: GFLOPs: 1244.7850. Time: 0.2851 ms. Best GFLOPs: 1857.5204
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #9: GFLOPs: 722.5927. Time: 0.4912 ms. Best GFLOPs: 1857.5204
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #10: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1024, 13, 13), "float32"], placeholder_1: T.Buffer[(1024, 1024, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 1024, 1, 1), "float32"], placeholder_3: T.Buffer[(1, 1, 1, 1), "float32"], T_multiply: T.Buffer[(1, 1024, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw = T.alloc_buffer([1, 1024, 13, 13], dtype="float32")
        conv2d_nchw_local = T.alloc_buffer([1, 1024, 13, 13], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 1024, 13, 13], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([1024, 1024, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(4, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(416, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(52, thread="threadIdx.x"):
                    for i1_3_init in T.serial(2):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused * 256 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 8 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 2 + i1_3_init)
                            yy = T.axis.spatial(13, i0_2_i1_2_i2_2_i3_2_fused % 13)
                            xx = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 13)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 1024, 13, 13], "float32"], ["TENSOR", [1024, 1024, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(64, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(13):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(1024, i4_0 * 16 + (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 169)
                                        v2 = T.axis.spatial(13, (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 169 // 13)
                                        v3 = T.axis.spatial(13, (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 13)
                                        T.reads(placeholder[v0, v1, v2, v3])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(40):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(2):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused * 256 + (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) // 16)
                                        v1 = T.axis.spatial(1024, i4_0 * 16 + (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 16)
                                        v2 = T.axis.spatial(1, 0)
                                        v3 = T.axis.spatial(1, 0)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) * 2 + ax0_ax1_ax2_ax3_fused_2 < 4096)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(4, 1, 1, 1, 2, 1, 1, 4, 1, 1, 1, 1, 1, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused * 256 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 8 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 2 + i1_3)
                                yy = T.axis.spatial(13, i0_2_i1_2_i2_2_i3_2_fused % 13)
                                xx = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 13)
                                rc = T.axis.reduce(1024, i4_0 * 16 + i4_1 * 4 + i4_2)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 1024, 13, 13], "float32"], ["TENSOR", [1024, 1024, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 2, 1, 1):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused * 256 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 8 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 2 + ax1)
                            v2 = T.axis.spatial(13, i0_2_i1_2_i2_2_i3_2_fused % 13 + ax2)
                            v3 = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 13 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3])
                            T.writes(conv2d_nchw[v0, v1, v2, v3])
                            conv2d_nchw[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3]
        for i0_i1_i2_i3_fused_0 in T.thread_binding(169, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_i1_i2_i3_fused_1 in T.thread_binding(1024, thread="threadIdx.x"):
                with T.block("T_multiply"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(1024, (i0_i1_i2_i3_fused_0 * 1024 + i0_i1_i2_i3_fused_1) // 169)
                    ax2 = T.axis.spatial(13, (i0_i1_i2_i3_fused_0 * 1024 + i0_i1_i2_i3_fused_1) % 169 // 13)
                    ax3 = T.axis.spatial(13, (i0_i1_i2_i3_fused_0 * 1024 + i0_i1_i2_i3_fused_1) % 13)
                    T.reads(conv2d_nchw[ax0, ax1, ax2, ax3], placeholder_2[ax0, ax1, 0, 0], placeholder_3[ax0, 0, 0, 0])
                    T.writes(T_multiply[ax0, ax1, ax2, ax3])
                    T_multiply[ax0, ax1, ax2, ax3] = (conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0]) * T.tanh(T.log(placeholder_3[ax0, 0, 0, 0] + T.exp(conv2d_nchw[ax0, ax1, ax2, ax3] + placeholder_2[ax0, ax1, 0, 0], dtype="float32"), dtype="float32"), dtype="float32")
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_exp", func_name="main")
b4 = sch.get_block(name="T_add_1", func_name="main")
b5 = sch.get_block(name="T_log", func_name="main")
b6 = sch.get_block(name="T_tanh", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b1)
v15, v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l20, l21, l22, l23, l24 = sch.split(loop=l8, factors=[v15, v16, v17, v18, v19])
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[4, 32, 4, 2, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l9, factors=[v25, v26, v27, v28, v29])
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l10, n=5, max_innermost_factor=64, decision=[1, 1, 13, 1, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l10, factors=[v35, v36, v37, v38, v39])
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l11, n=5, max_innermost_factor=64, decision=[1, 13, 1, 1, 1])
l50, l51, l52, l53, l54 = sch.split(loop=l11, factors=[v45, v46, v47, v48, v49])
v55, v56, v57 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[64, 4, 4])
l58, l59, l60 = sch.split(loop=l12, factors=[v55, v56, v57])
v61, v62, v63 = sch.sample_perfect_tile(loop=l13, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l64, l65, l66 = sch.split(loop=l13, factors=[v61, v62, v63])
v67, v68, v69 = sch.sample_perfect_tile(loop=l14, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l70, l71, l72 = sch.split(loop=l14, factors=[v67, v68, v69])
sch.reorder(l20, l30, l40, l50, l21, l31, l41, l51, l22, l32, l42, l52, l58, l64, l70, l59, l65, l71, l23, l33, l43, l53, l60, l66, l72, l24, l34, l44, l54)
l73 = sch.fuse(l20, l30, l40, l50)
sch.bind(loop=l73, thread_axis="blockIdx.x")
l74 = sch.fuse(l21, l31, l41, l51)
sch.bind(loop=l74, thread_axis="vthread.x")
l75 = sch.fuse(l22, l32, l42, l52)
sch.bind(loop=l75, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b76 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b76, loop=l75, preserve_unit_loops=True)
b77 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b77, loop=l70, preserve_unit_loops=True)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b77)
l88 = sch.fuse(l84, l85, l86, l87)
v89 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b90, loop=l70, preserve_unit_loops=True)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b90)
l101 = sch.fuse(l97, l98, l99, l100)
v102 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v102)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b0)
v103 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v103)
sch.enter_postproc()
sch.unannotate(block_or_loop=b77, ann_key="meta_schedule.cooperative_fetch")
l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b77)
l111, l112, l113 = sch.split(loop=l110, factors=[None, 52, 4])
sch.vectorize(loop=l113)
sch.bind(loop=l112, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch")
l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b90)
l121, l122, l123 = sch.split(loop=l120, factors=[None, 52, 2])
sch.vectorize(loop=l123)
sch.bind(loop=l122, thread_axis="threadIdx.x")
b124 = sch.get_block(name="T_multiply", func_name="main")
l125, l126, l127, l128 = sch.get_loops(block=b124)
l129 = sch.fuse(l125, l126, l127, l128)
l130, l131 = sch.split(loop=l129, factors=[None, 1024])
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
b132 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b132, ann_key="meta_schedule.unroll_explicit")
b133, b134, b135, b136, b137 = sch.get_child_blocks(b132)
l138, l139, l140, l141, l142, l143, l144, l145, l146 = sch.get_loops(block=b133)
sch.annotate(block_or_loop=l138, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l138, ann_key="pragma_unroll_explicit", ann_val=1)
l147, l148, l149, l150, l151, l152, l153, l154, l155 = sch.get_loops(block=b134)
sch.annotate(block_or_loop=l147, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l147, ann_key="pragma_unroll_explicit", ann_val=1)
l156, l157, l158, l159, l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174, l175 = sch.get_loops(block=b135)
sch.annotate(block_or_loop=l156, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l156, ann_key="pragma_unroll_explicit", ann_val=1)
l176, l177, l178, l179, l180, l181, l182 = sch.get_loops(block=b136)
sch.annotate(block_or_loop=l176, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l176, ann_key="pragma_unroll_explicit", ann_val=1)
l183, l184 = sch.get_loops(block=b137)
sch.annotate(block_or_loop=l183, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l183, ann_key="pragma_unroll_explicit", ann_val=1)
b185 = sch.get_block(name="conv2d_nchw", func_name="main")
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b185)
b206 = sch.decompose_reduction(block=b185, loop=l189)
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #11: GFLOPs: 568.8929. Time: 0.6239 ms. Best GFLOPs: 1857.5204
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #12: GFLOPs: 2287.3502. Time: 0.1552 ms. Best GFLOPs: 2287.3502
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #13: GFLOPs: 548.0488. Time: 0.6476 ms. Best GFLOPs: 2287.3502
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #14: GFLOPs: 487.9830. Time: 0.7274 ms. Best GFLOPs: 2287.3502
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #15: GFLOPs: 1804.3717. Time: 0.1967 ms. Best GFLOPs: 2287.3502
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #16: GFLOPs: 149.3818. Time: 2.3760 ms. Best GFLOPs: 2287.3502
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #17: GFLOPs: 67.3849. Time: 5.2673 ms. Best GFLOPs: 2287.3502
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #18: GFLOPs: 319.3469. Time: 1.1114 ms. Best GFLOPs: 2287.3502
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #19: GFLOPs: 62.7637. Time: 5.6551 ms. Best GFLOPs: 2287.3502
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #20: GFLOPs: 1706.5344. Time: 0.2080 ms. Best GFLOPs: 2287.3502
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #21: GFLOPs: 1274.0452. Time: 0.2786 ms. Best GFLOPs: 2287.3502
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #22: GFLOPs: 66.6904. Time: 5.3222 ms. Best GFLOPs: 2287.3502
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #23: GFLOPs: 852.0916. Time: 0.4165 ms. Best GFLOPs: 2287.3502
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #24: GFLOPs: 968.6543. Time: 0.3664 ms. Best GFLOPs: 2287.3502
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #25: GFLOPs: 29.2794. Time: 12.1224 ms. Best GFLOPs: 2287.3502
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #26: GFLOPs: 2711.9545. Time: 0.1309 ms. Best GFLOPs: 2711.9545
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #27: GFLOPs: 104.8351. Time: 3.3857 ms. Best GFLOPs: 2711.9545
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #28: GFLOPs: 810.3447. Time: 0.4380 ms. Best GFLOPs: 2711.9545
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #29: GFLOPs: 1839.7425. Time: 0.1929 ms. Best GFLOPs: 2711.9545
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #30: GFLOPs: 304.1093. Time: 1.1671 ms. Best GFLOPs: 2711.9545
[14:04:00] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"] Trial #31: GFLOPs: 1792.7271. Time: 0.1980 ms. Best GFLOPs: 2711.9545
[14:04:01] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |      3333.8786 |     478.6984 |              478.6984 |     32 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |      2960.8178 |      60.0268 |              120.0537 |     32 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |      3729.7200 |     213.9931 |             1711.9447 |     32 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |      2831.4273 |      31.4766 |              283.2898 |     32 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |         0.0002 |       4.0251 |                8.0501 |     32 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |      3577.2919 |      99.3648 |               99.3648 |     32 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |      1641.9450 |     971.6545 |              971.6545 |     32 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |      2242.5252 |      79.1380 |              158.2760 |     32 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |      2992.4470 |     266.6006 |             1066.4024 |     32 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |      1500.1992 |      59.2350 |              296.1749 |     32 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |         0.0004 |       2.8040 |                5.6080 |     32 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |      2711.9545 |     130.8790 |              130.8790 |     32 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |            N/A |          N/A |                   N/A |      0 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1280
Total latency (us): 11183

[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #0: GFLOPs: 18.1666. Time: 0.8050 ms. Best GFLOPs: 18.1666
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #1: GFLOPs: 86.1231. Time: 0.1698 ms. Best GFLOPs: 86.1231
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #2: GFLOPs: 53.3310. Time: 0.2742 ms. Best GFLOPs: 86.1231
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #3: GFLOPs: 474.7986. Time: 0.0308 ms. Best GFLOPs: 474.7986
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #4: GFLOPs: 491.6898. Time: 0.0297 ms. Best GFLOPs: 491.6898
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #5: GFLOPs: 471.5892. Time: 0.0310 ms. Best GFLOPs: 491.6898
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #6: GFLOPs: 472.0941. Time: 0.0310 ms. Best GFLOPs: 491.6898
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #7: GFLOPs: 51.3040. Time: 0.2850 ms. Best GFLOPs: 491.6898
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #8: GFLOPs: 483.3786. Time: 0.0303 ms. Best GFLOPs: 491.6898
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #9: GFLOPs: 19.4602. Time: 0.7514 ms. Best GFLOPs: 491.6898
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #10: GFLOPs: 51.3048. Time: 0.2850 ms. Best GFLOPs: 491.6898
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #11: GFLOPs: 473.4484. Time: 0.0309 ms. Best GFLOPs: 491.6898
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #12: GFLOPs: 19.4963. Time: 0.7501 ms. Best GFLOPs: 491.6898
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #13: GFLOPs: 470.5490. Time: 0.0311 ms. Best GFLOPs: 491.6898
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #14: GFLOPs: 44.8086. Time: 0.3263 ms. Best GFLOPs: 491.6898
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #15: GFLOPs: 19.8217. Time: 0.7377 ms. Best GFLOPs: 491.6898
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #16: GFLOPs: 469.0304. Time: 0.0312 ms. Best GFLOPs: 491.6898
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #17: GFLOPs: 44.4940. Time: 0.3287 ms. Best GFLOPs: 491.6898
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #18: GFLOPs: 477.3127. Time: 0.0306 ms. Best GFLOPs: 491.6898
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #19: GFLOPs: 485.4486. Time: 0.0301 ms. Best GFLOPs: 491.6898
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #20: GFLOPs: 463.7728. Time: 0.0315 ms. Best GFLOPs: 491.6898
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #21: GFLOPs: 44.3435. Time: 0.3298 ms. Best GFLOPs: 491.6898
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #22: GFLOPs: 474.2916. Time: 0.0308 ms. Best GFLOPs: 491.6898
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #23: GFLOPs: 476.5097. Time: 0.0307 ms. Best GFLOPs: 491.6898
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #24: GFLOPs: 465.7856. Time: 0.0314 ms. Best GFLOPs: 491.6898
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #25: GFLOPs: 44.1668. Time: 0.3311 ms. Best GFLOPs: 491.6898
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #26: GFLOPs: 120.6689. Time: 0.1212 ms. Best GFLOPs: 491.6898
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #27: GFLOPs: 90.3272. Time: 0.1619 ms. Best GFLOPs: 491.6898
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #28: GFLOPs: 472.9564. Time: 0.0309 ms. Best GFLOPs: 491.6898
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #29: GFLOPs: 480.1010. Time: 0.0305 ms. Best GFLOPs: 491.6898
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #30: GFLOPs: 472.0531. Time: 0.0310 ms. Best GFLOPs: 491.6898
[14:04:02] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #40: "fused_nn_max_pool2d_2"] Trial #31: GFLOPs: 73.6181. Time: 0.1986 ms. Best GFLOPs: 491.6898
[14:04:03] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #40: "fused_nn_max_pool2d_2"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |      3333.8786 |     478.6984 |              478.6984 |     32 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |      2960.8178 |      60.0268 |              120.0537 |     32 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |      3729.7200 |     213.9931 |             1711.9447 |     32 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |      2831.4273 |      31.4766 |              283.2898 |     32 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |         0.0002 |       4.0251 |                8.0501 |     32 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |      3577.2919 |      99.3648 |               99.3648 |     32 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |      1641.9450 |     971.6545 |              971.6545 |     32 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |      2242.5252 |      79.1380 |              158.2760 |     32 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |      2992.4470 |     266.6006 |             1066.4024 |     32 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |      1500.1992 |      59.2350 |              296.1749 |     32 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |         0.0004 |       2.8040 |                5.6080 |     32 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |      2711.9545 |     130.8790 |              130.8790 |     32 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |       491.6898 |      29.7408 |               29.7408 |     32 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1312
Total latency (us): 11212.7

[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #0: GFLOPs: 0.0000. Time: 0.0042 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #1: GFLOPs: 0.0000. Time: 0.0043 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #2: GFLOPs: 0.0000. Time: 0.0052 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #3: GFLOPs: 0.0000. Time: 0.0043 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #4: GFLOPs: 0.0000. Time: 0.0043 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #5: GFLOPs: 0.0000. Time: 0.0043 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #6: GFLOPs: 0.0000. Time: 0.0043 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #7: GFLOPs: 0.0000. Time: 0.0044 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #8: GFLOPs: 0.0000. Time: 0.0043 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #9: GFLOPs: 0.0000. Time: 0.0043 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #10: GFLOPs: 0.0000. Time: 0.0043 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #11: GFLOPs: 0.0000. Time: 0.0042 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #12: GFLOPs: 0.0000. Time: 0.0043 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #13: GFLOPs: 0.0000. Time: 0.0042 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #14: GFLOPs: 0.0000. Time: 0.0043 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #15: GFLOPs: 0.0000. Time: 0.0043 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #16: GFLOPs: 0.0000. Time: 0.0044 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #17: GFLOPs: 0.0000. Time: 0.0043 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #18: GFLOPs: 0.0000. Time: 0.0043 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #19: GFLOPs: 0.0000. Time: 0.0043 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #20: GFLOPs: 0.0000. Time: 0.0043 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #21: GFLOPs: 0.0000. Time: 0.0043 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #22: GFLOPs: 0.0000. Time: 0.0043 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #23: GFLOPs: 0.0000. Time: 0.0043 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #24: GFLOPs: 0.0000. Time: 0.0044 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #25: GFLOPs: 0.0000. Time: 0.0043 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #26: GFLOPs: 0.0000. Time: 0.0042 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #27: GFLOPs: 0.0000. Time: 0.0042 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #28: GFLOPs: 0.0000. Time: 0.0043 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #29: GFLOPs: 0.0000. Time: 0.0043 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #30: GFLOPs: 0.0000. Time: 0.0043 ms. Best GFLOPs: 0.0000
[14:04:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #41: "fused_concatenate_5"] Trial #31: GFLOPs: 0.0000. Time: 0.0043 ms. Best GFLOPs: 0.0000
[14:04:04] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #41: "fused_concatenate_5"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |      3333.8786 |     478.6984 |              478.6984 |     32 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |      2960.8178 |      60.0268 |              120.0537 |     32 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |      3729.7200 |     213.9931 |             1711.9447 |     32 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |      2831.4273 |      31.4766 |              283.2898 |     32 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |         0.0002 |       4.0251 |                8.0501 |     32 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |      3577.2919 |      99.3648 |               99.3648 |     32 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |      1641.9450 |     971.6545 |              971.6545 |     32 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |      2242.5252 |      79.1380 |              158.2760 |     32 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |      2992.4470 |     266.6006 |             1066.4024 |     32 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |      1500.1992 |      59.2350 |              296.1749 |     32 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |         0.0004 |       2.8040 |                5.6080 |     32 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |      2711.9545 |     130.8790 |              130.8790 |     32 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |       491.6898 |      29.7408 |               29.7408 |     32 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |         0.0002 |       4.1701 |                4.1701 |     32 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |            N/A |          N/A |                   N/A |      0 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1344
Total latency (us): 11216.9

[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #0: GFLOPs: 165.2198. Time: 2.1462 ms. Best GFLOPs: 165.2198
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #1: GFLOPs: 82.9484. Time: 4.2748 ms. Best GFLOPs: 165.2198
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #2: GFLOPs: 161.7381. Time: 2.1924 ms. Best GFLOPs: 165.2198
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #3: GFLOPs: 1116.5671. Time: 0.3176 ms. Best GFLOPs: 1116.5671
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #4: GFLOPs: 1620.7721. Time: 0.2188 ms. Best GFLOPs: 1620.7721
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #5: GFLOPs: 877.7414. Time: 0.4040 ms. Best GFLOPs: 1620.7721
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #6: GFLOPs: 447.1467. Time: 0.7930 ms. Best GFLOPs: 1620.7721
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #7: GFLOPs: 766.3007. Time: 0.4627 ms. Best GFLOPs: 1620.7721
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #8: GFLOPs: 155.4915. Time: 2.2805 ms. Best GFLOPs: 1620.7721
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #9: GFLOPs: 637.3266. Time: 0.5564 ms. Best GFLOPs: 1620.7721
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #10: GFLOPs: 47.8105. Time: 7.4166 ms. Best GFLOPs: 1620.7721
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #11: GFLOPs: 14.8630. Time: 23.8574 ms. Best GFLOPs: 1620.7721
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #12: GFLOPs: 868.0918. Time: 0.4085 ms. Best GFLOPs: 1620.7721
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #13: GFLOPs: 16.9603. Time: 20.9071 ms. Best GFLOPs: 1620.7721
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #14: GFLOPs: 971.2767. Time: 0.3651 ms. Best GFLOPs: 1620.7721
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #15: GFLOPs: 139.3843. Time: 2.5440 ms. Best GFLOPs: 1620.7721
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #16: GFLOPs: 997.8344. Time: 0.3554 ms. Best GFLOPs: 1620.7721
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #17: GFLOPs: 240.7011. Time: 1.4732 ms. Best GFLOPs: 1620.7721
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #18: GFLOPs: 15.3608. Time: 23.0842 ms. Best GFLOPs: 1620.7721
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #19: GFLOPs: 18.8011. Time: 18.8602 ms. Best GFLOPs: 1620.7721
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #20: GFLOPs: 11.9130. Time: 29.7651 ms. Best GFLOPs: 1620.7721
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #21: GFLOPs: 26.1211. Time: 13.5749 ms. Best GFLOPs: 1620.7721
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #22: GFLOPs: 1750.6945. Time: 0.2025 ms. Best GFLOPs: 1750.6945
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #23: GFLOPs: 213.3550. Time: 1.6620 ms. Best GFLOPs: 1750.6945
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #24: GFLOPs: 181.6602. Time: 1.9520 ms. Best GFLOPs: 1750.6945
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #25: GFLOPs: 543.5703. Time: 0.6523 ms. Best GFLOPs: 1750.6945
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #26: GFLOPs: 855.3154. Time: 0.4146 ms. Best GFLOPs: 1750.6945
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #27: GFLOPs: 1232.9121. Time: 0.2876 ms. Best GFLOPs: 1750.6945
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #28: GFLOPs: 1399.1641. Time: 0.2534 ms. Best GFLOPs: 1750.6945
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #29: GFLOPs: 1421.0219. Time: 0.2495 ms. Best GFLOPs: 1750.6945
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #30: GFLOPs: 1066.6190. Time: 0.3324 ms. Best GFLOPs: 1750.6945
[14:04:05] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"] Trial #31: GFLOPs: 1136.7141. Time: 0.3119 ms. Best GFLOPs: 1750.6945
[14:04:07] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |      3333.8786 |     478.6984 |              478.6984 |     32 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |      2960.8178 |      60.0268 |              120.0537 |     32 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |      3729.7200 |     213.9931 |             1711.9447 |     32 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |      2831.4273 |      31.4766 |              283.2898 |     32 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |         0.0002 |       4.0251 |                8.0501 |     32 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |      3577.2919 |      99.3648 |               99.3648 |     32 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |      1641.9450 |     971.6545 |              971.6545 |     32 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |      2242.5252 |      79.1380 |              158.2760 |     32 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |      2992.4470 |     266.6006 |             1066.4024 |     32 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |      1500.1992 |      59.2350 |              296.1749 |     32 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |         0.0004 |       2.8040 |                5.6080 |     32 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |      2711.9545 |     130.8790 |              130.8790 |     32 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |       491.6898 |      29.7408 |               29.7408 |     32 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |         0.0002 |       4.1701 |                4.1701 |     32 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |      1750.6945 |     202.5435 |              202.5435 |     32 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |            N/A |          N/A |                   N/A |      0 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1376
Total latency (us): 11419.4

[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #0: GFLOPs: 15.8815. Time: 100.4455 ms. Best GFLOPs: 15.8815
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #1: GFLOPs: 624.6258. Time: 2.5539 ms. Best GFLOPs: 624.6258
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #2: GFLOPs: 110.0975. Time: 14.4892 ms. Best GFLOPs: 624.6258
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #3: GFLOPs: 1750.1363. Time: 0.9115 ms. Best GFLOPs: 1750.1363
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #4: GFLOPs: 542.6789. Time: 2.9395 ms. Best GFLOPs: 1750.1363
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #5: GFLOPs: 2731.9063. Time: 0.5839 ms. Best GFLOPs: 2731.9063
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #6: GFLOPs: 25.6590. Time: 62.1705 ms. Best GFLOPs: 2731.9063
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #7: Error in building: LocalRunner: An exception occurred
Subprocess terminated
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 13, 13), "float32"], placeholder_1: T.Buffer[(1024, 512, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 1024, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 1024, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw_local = T.alloc_buffer([1, 1024, 13, 13], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 512, 15, 15], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([1024, 512, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(26, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(2, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i1_3_init, i1_4_init, i2_4_init in T.grid(4, 2, 13):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused // 13 * 512 + i0_1_i1_1_i2_1_i3_1_fused * 256 + i0_2_i1_2_i2_2_i3_2_fused * 8 + i1_3_init * 2 + i1_4_init)
                            yy = T.axis.spatial(13, i2_4_init)
                            xx = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_fused % 13)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 13, 13], "float32"], ["TENSOR", [1024, 512, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(256, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(2):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(2):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(512, i4_0 * 2 + ((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 2 + ax0_ax1_ax2_ax3_fused_2) % 90 // 45)
                                        v2 = T.axis.spatial(15, ((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 2 + ax0_ax1_ax2_ax3_fused_2) % 45 // 3)
                                        v3 = T.axis.spatial(15, i0_0_i1_0_i2_0_i3_0_fused % 13 + ((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 2 + ax0_ax1_ax2_ax3_fused_2) % 3)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 2 + ax0_ax1_ax2_ax3_fused_2 < 90)
                                        T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 14 and 1 <= v3 and v3 < 14, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(72):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused // 13 * 512 + (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 18)
                                        v1 = T.axis.spatial(512, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 18 // 9)
                                        v2 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 9 // 3)
                                        v3 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 3)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 3, 3, 1, 4, 1, 1, 2, 1, 1, 1, 2, 13, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused // 13 * 512 + i0_1_i1_1_i2_1_i3_1_fused * 256 + i0_2_i1_2_i2_2_i3_2_fused * 8 + i1_3 * 2 + i1_4)
                                yy = T.axis.spatial(13, i2_4)
                                xx = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_fused % 13)
                                rc = T.axis.reduce(512, i4_0 * 2 + i4_2)
                                ry, rx = T.axis.remap("RR", [i5_1, i6_1])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 13, 13], "float32"], ["TENSOR", [1024, 512, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 8, 13, 1):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused // 13 * 512 + i0_1_i1_1_i2_1_i3_1_fused * 256 + i0_2_i1_2_i2_2_i3_2_fused * 8 + ax1)
                            v2 = T.axis.spatial(13, ax2)
                            v3 = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_fused % 13 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                            T.writes(T_leaky_relu[v0, v1, v2, v3])
                            T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[2, 2, 32, 4, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 13])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[13, 1, 1, 1, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[256, 1, 2])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109, l110 = sch.split(loop=l107, factors=[None, 32, 2])
sch.vectorize(loop=l110)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b87)
l118, l119, l120 = sch.split(loop=l117, factors=[None, 32, 4])
sch.vectorize(loop=l120)
sch.bind(loop=l119, thread_axis="threadIdx.x")
b121 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b121, ann_key="meta_schedule.unroll_explicit")
b122, b123, b124, b125 = sch.get_child_blocks(b121)
l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l126, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l126, ann_key="pragma_unroll_explicit", ann_val=1)
l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l135, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l135, ann_key="pragma_unroll_explicit", ann_val=1)
l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161, l162, l163 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l144, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l144, ann_key="pragma_unroll_explicit", ann_val=1)
l164, l165, l166, l167, l168, l169, l170 = sch.get_loops(block=b125)
sch.annotate(block_or_loop=l164, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l164, ann_key="pragma_unroll_explicit", ann_val=1)
b171 = sch.get_block(name="conv2d_nchw", func_name="main")
l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189, l190, l191 = sch.get_loops(block=b171)
b192 = sch.decompose_reduction(block=b171, loop=l175)
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #8: GFLOPs: 52.7925. Time: 30.2170 ms. Best GFLOPs: 2731.9063
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #9: GFLOPs: 915.8502. Time: 1.7418 ms. Best GFLOPs: 2731.9063
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #10: GFLOPs: 712.0040. Time: 2.2405 ms. Best GFLOPs: 2731.9063
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #11: GFLOPs: 923.9626. Time: 1.7265 ms. Best GFLOPs: 2731.9063
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #12: GFLOPs: 32.8884. Time: 48.5043 ms. Best GFLOPs: 2731.9063
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #13: GFLOPs: 9.1108. Time: 175.0924 ms. Best GFLOPs: 2731.9063
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #14: GFLOPs: 21.9089. Time: 72.8119 ms. Best GFLOPs: 2731.9063
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #15: GFLOPs: 2848.2262. Time: 0.5601 ms. Best GFLOPs: 2848.2262
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #16: GFLOPs: 211.6775. Time: 7.5361 ms. Best GFLOPs: 2848.2262
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #17: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 13, 13), "float32"], placeholder_1: T.Buffer[(1024, 512, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 1024, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 1024, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw_local = T.alloc_buffer([1, 1024, 13, 13], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 512, 15, 15], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([1024, 512, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(2, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(338, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i1_3_init in T.serial(8):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused * 512 + i0_1_i1_1_i2_1_i3_1_fused // 169 * 256 + i0_2_i1_2_i2_2_i3_2_fused * 8 + i1_3_init)
                            yy = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 169 // 13)
                            xx = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 13)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 13, 13], "float32"], ["TENSOR", [1024, 512, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(512, 3, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(7):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(512, i4_0 + 0)
                                    v2 = T.axis.spatial(15, i5_0 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 195 // 15)
                                    v3 = T.axis.spatial(15, (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 15)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1 < 195)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 14 and 1 <= v3 and v3 < 14, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(12):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused * 512 + (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 3)
                                        v1, v2 = T.axis.remap("SS", [i4_0, i5_0])
                                        v3 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 3)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 8, 1, 1, 1, 1, 3, 1, 1, 1, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused * 512 + i0_1_i1_1_i2_1_i3_1_fused // 169 * 256 + i0_2_i1_2_i2_2_i3_2_fused * 8 + i1_3)
                                yy = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 169 // 13)
                                xx = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 13)
                                rc, ry, rx = T.axis.remap("RRR", [i4_0, i5_0, i6_2])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 13, 13], "float32"], ["TENSOR", [1024, 512, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 8, 1, 1):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused * 512 + i0_1_i1_1_i2_1_i3_1_fused // 169 * 256 + i0_2_i1_2_i2_2_i3_2_fused * 8 + ax1)
                            v2 = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 169 // 13 + ax2)
                            v3 = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 13 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                            T.writes(T_leaky_relu[v0, v1, v2, v3])
                            T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[2, 2, 32, 8, 1])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 13, 1, 1, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 13, 1, 1, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[512, 1, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109 = sch.split(loop=l107, factors=[None, 32])
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b87)
l117, l118, l119 = sch.split(loop=l116, factors=[None, 32, 4])
sch.vectorize(loop=l119)
sch.bind(loop=l118, thread_axis="threadIdx.x")
b120 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b120, ann_key="meta_schedule.unroll_explicit")
b121, b122, b123, b124 = sch.get_child_blocks(b120)
l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b121)
sch.annotate(block_or_loop=l125, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l125, ann_key="pragma_unroll_explicit", ann_val=1)
l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l133, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l133, ann_key="pragma_unroll_explicit", ann_val=1)
l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l142, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l142, ann_key="pragma_unroll_explicit", ann_val=1)
l162, l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
b169 = sch.get_block(name="conv2d_nchw", func_name="main")
l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b169)
b190 = sch.decompose_reduction(block=b169, loop=l173)
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #18: Error in building: LocalRunner: An exception occurred
Subprocess terminated
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 13, 13), "float32"], placeholder_1: T.Buffer[(1024, 512, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 1024, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 1024, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw_local = T.alloc_buffer([1, 1024, 13, 13], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 512, 15, 15], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([1024, 512, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(26, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(1, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(128, thread="threadIdx.x"):
                    for i1_3_init, i1_4_init, i2_4_init in T.grid(2, 2, 13):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused // 13 * 512 + i0_2_i1_2_i2_2_i3_2_fused * 4 + i1_3_init * 2 + i1_4_init)
                            yy = T.axis.spatial(13, i2_4_init)
                            xx = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_fused % 13)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 13, 13], "float32"], ["TENSOR", [1024, 512, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(512, 1, 3):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(1):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(128, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(512, i4_0 + 0)
                                    v2 = T.axis.spatial(15, ax0_ax1_ax2_ax3_fused_1 % 15)
                                    v3 = T.axis.spatial(15, i6_0 + i0_0_i1_0_i2_0_i3_0_fused % 13 + 0)
                                    T.where(ax0_ax1_ax2_ax3_fused_1 < 15)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 14 and 1 <= v3 and v3 < 14, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(3):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(128, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused // 13 * 512 + (ax0_ax1_ax2_ax3_fused_0 * 512 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 3)
                                        v1 = T.axis.spatial(512, i4_0)
                                        v2 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 512 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 3)
                                        v3 = T.axis.spatial(3, i6_0)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 13, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused // 13 * 512 + i0_2_i1_2_i2_2_i3_2_fused * 4 + i1_3 * 2 + i1_4)
                                yy = T.axis.spatial(13, i2_4)
                                xx = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_fused % 13)
                                rc, ry, rx = T.axis.remap("RRR", [i4_0, i5_1, i6_0])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 13, 13], "float32"], ["TENSOR", [1024, 512, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 4, 13, 1):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused // 13 * 512 + i0_2_i1_2_i2_2_i3_2_fused * 4 + ax1)
                            v2 = T.axis.spatial(13, ax2)
                            v3 = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_fused % 13 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                            T.writes(T_leaky_relu[v0, v1, v2, v3])
                            T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[2, 1, 128, 2, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 13])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[13, 1, 1, 1, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[512, 1, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 3, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109 = sch.split(loop=l107, factors=[None, 128])
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b87)
l117, l118, l119 = sch.split(loop=l116, factors=[None, 128, 4])
sch.vectorize(loop=l119)
sch.bind(loop=l118, thread_axis="threadIdx.x")
b120 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b120, ann_key="meta_schedule.unroll_explicit")
b121, b122, b123, b124 = sch.get_child_blocks(b120)
l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b121)
sch.annotate(block_or_loop=l125, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l125, ann_key="pragma_unroll_explicit", ann_val=1)
l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l133, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l133, ann_key="pragma_unroll_explicit", ann_val=1)
l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l142, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l142, ann_key="pragma_unroll_explicit", ann_val=1)
l162, l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
b169 = sch.get_block(name="conv2d_nchw", func_name="main")
l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b169)
b190 = sch.decompose_reduction(block=b169, loop=l173)
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #19: GFLOPs: 209.4077. Time: 7.6178 ms. Best GFLOPs: 2848.2262
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #20: GFLOPs: 1506.9097. Time: 1.0586 ms. Best GFLOPs: 2848.2262
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #21: GFLOPs: 35.5017. Time: 44.9339 ms. Best GFLOPs: 2848.2262
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #22: GFLOPs: 2714.0641. Time: 0.5878 ms. Best GFLOPs: 2848.2262
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #23: GFLOPs: 343.0459. Time: 4.6502 ms. Best GFLOPs: 2848.2262
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #24: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 13, 13), "float32"], placeholder_1: T.Buffer[(1024, 512, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 1024, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 1024, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw_local = T.alloc_buffer([1, 1024, 13, 13], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 512, 15, 15], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([1024, 512, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(4, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(2, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(52, thread="threadIdx.x"):
                    for i1_3_init, i1_4_init, i3_4_init in T.grid(2, 16, 13):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused * 256 + i0_1_i1_1_i2_1_i3_1_fused * 128 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 32 + i1_3_init * 16 + i1_4_init)
                            yy = T.axis.spatial(13, i0_2_i1_2_i2_2_i3_2_fused % 13)
                            xx = T.axis.spatial(13, i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 13, 13], "float32"], ["TENSOR", [1024, 512, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(64, 3, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(30):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(512, i4_0 * 8 + (ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) % 1560 // 195)
                                    v2 = T.axis.spatial(15, i5_0 + (ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) % 195 // 15)
                                    v3 = T.axis.spatial(15, (ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) % 15)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 14 and 1 <= v3 and v3 < 14, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(30):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused * 256 + (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 24)
                                        v1 = T.axis.spatial(512, i4_0 * 8 + (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 24 // 3)
                                        v2 = T.axis.spatial(3, i5_0)
                                        v3 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 3)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) * 4 + ax0_ax1_ax2_ax3_fused_2 < 6144)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(2, 1, 1, 1, 2, 1, 1, 4, 1, 3, 1, 16, 1, 13):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused * 256 + i0_1_i1_1_i2_1_i3_1_fused * 128 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 32 + i1_3 * 16 + i1_4)
                                yy = T.axis.spatial(13, i0_2_i1_2_i2_2_i3_2_fused % 13)
                                xx = T.axis.spatial(13, i3_4)
                                rc = T.axis.reduce(512, i4_0 * 8 + i4_1 * 4 + i4_2)
                                ry, rx = T.axis.remap("RR", [i5_0, i6_2])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 13, 13], "float32"], ["TENSOR", [1024, 512, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 32, 1, 13):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused * 256 + i0_1_i1_1_i2_1_i3_1_fused * 128 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 32 + ax1)
                            v2 = T.axis.spatial(13, i0_2_i1_2_i2_2_i3_2_fused % 13 + ax2)
                            v3 = T.axis.spatial(13, ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                            T.writes(T_leaky_relu[v0, v1, v2, v3])
                            T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[4, 2, 4, 2, 16])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 1, 13, 1, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 13])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[64, 2, 4])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109 = sch.split(loop=l107, factors=[None, 52])
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b87)
l117, l118, l119 = sch.split(loop=l116, factors=[None, 52, 4])
sch.vectorize(loop=l119)
sch.bind(loop=l118, thread_axis="threadIdx.x")
b120 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b120, ann_key="meta_schedule.unroll_explicit")
b121, b122, b123, b124 = sch.get_child_blocks(b120)
l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b121)
sch.annotate(block_or_loop=l125, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l125, ann_key="pragma_unroll_explicit", ann_val=1)
l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l133, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l133, ann_key="pragma_unroll_explicit", ann_val=1)
l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l142, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l142, ann_key="pragma_unroll_explicit", ann_val=1)
l162, l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
b169 = sch.get_block(name="conv2d_nchw", func_name="main")
l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b169)
b190 = sch.decompose_reduction(block=b169, loop=l173)
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #25: GFLOPs: 53.6964. Time: 29.7083 ms. Best GFLOPs: 2848.2262
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #26: GFLOPs: 36.0607. Time: 44.2374 ms. Best GFLOPs: 2848.2262
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #27: GFLOPs: 2378.3024. Time: 0.6707 ms. Best GFLOPs: 2848.2262
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #28: GFLOPs: 645.9146. Time: 2.4697 ms. Best GFLOPs: 2848.2262
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #29: GFLOPs: 676.9311. Time: 2.3566 ms. Best GFLOPs: 2848.2262
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #30: GFLOPs: 563.6726. Time: 2.8301 ms. Best GFLOPs: 2848.2262
[14:04:07] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"] Trial #31: GFLOPs: 317.4553. Time: 5.0251 ms. Best GFLOPs: 2848.2262
[14:04:09] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |      3333.8786 |     478.6984 |              478.6984 |     32 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |      2960.8178 |      60.0268 |              120.0537 |     32 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |      3729.7200 |     213.9931 |             1711.9447 |     32 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |      2831.4273 |      31.4766 |              283.2898 |     32 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |         0.0002 |       4.0251 |                8.0501 |     32 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |      3577.2919 |      99.3648 |               99.3648 |     32 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |      1641.9450 |     971.6545 |              971.6545 |     32 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |      2242.5252 |      79.1380 |              158.2760 |     32 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |      2992.4470 |     266.6006 |             1066.4024 |     32 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |      1500.1992 |      59.2350 |              296.1749 |     32 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |         0.0004 |       2.8040 |                5.6080 |     32 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |      2711.9545 |     130.8790 |              130.8790 |     32 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |       491.6898 |      29.7408 |               29.7408 |     32 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |         0.0002 |       4.1701 |                4.1701 |     32 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |      1750.6945 |     202.5435 |              202.5435 |     32 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |      2848.2262 |     560.0785 |             2800.3924 |     32 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |            N/A |          N/A |                   N/A |      0 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1408
Total latency (us): 14219.8

[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #0: GFLOPs: 35.8250. Time: 4.9514 ms. Best GFLOPs: 35.8250
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #1: GFLOPs: 22.6732. Time: 7.8234 ms. Best GFLOPs: 35.8250
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #2: GFLOPs: 10.6973. Time: 16.5819 ms. Best GFLOPs: 35.8250
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #3: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1024, 13, 13), "float32"], placeholder_1: T.Buffer[(512, 1024, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 512, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw_local = T.alloc_buffer([1, 512, 13, 13], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 1024, 13, 13], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([512, 1024, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(1, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(52, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(64, thread="threadIdx.x"):
                    for i2_3_init, i1_4_init in T.grid(13, 2):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(512, i0_1_i1_1_i2_1_i3_1_fused // 13 * 128 + i0_2_i1_2_i2_2_i3_2_fused * 2 + i1_4_init)
                            yy = T.axis.spatial(13, i2_3_init)
                            xx = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 13)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 1024, 13, 13], "float32"], ["TENSOR", [512, 1024, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(64, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(11):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(64, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(1024, i4_0 * 16 + (ax0_ax1_ax2_ax3_fused_0 * 256 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 169)
                                        v2 = T.axis.spatial(13, (ax0_ax1_ax2_ax3_fused_0 * 256 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 169 // 13)
                                        v3 = T.axis.spatial(13, (ax0_ax1_ax2_ax3_fused_0 * 256 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 13)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1) * 4 + ax0_ax1_ax2_ax3_fused_2 < 2704)
                                        T.reads(placeholder[v0, v1, v2, v3])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(32):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(64, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(512, (ax0_ax1_ax2_ax3_fused_0 * 256 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 16)
                                        v1 = T.axis.spatial(1024, i4_0 * 16 + (ax0_ax1_ax2_ax3_fused_0 * 256 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 16)
                                        v2 = T.axis.spatial(1, 0)
                                        v3 = T.axis.spatial(1, 0)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(16, 1, 1, 1, 1, 13, 1, 1, 1, 1, 1, 2, 1, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(512, i0_1_i1_1_i2_1_i3_1_fused // 13 * 128 + i0_2_i1_2_i2_2_i3_2_fused * 2 + i1_4)
                                yy = T.axis.spatial(13, i2_3)
                                xx = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 13)
                                rc = T.axis.reduce(1024, i4_0 * 16 + i4_1)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 1024, 13, 13], "float32"], ["TENSOR", [512, 1024, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 2, 13, 1):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(512, i0_1_i1_1_i2_1_i3_1_fused // 13 * 128 + i0_2_i1_2_i2_2_i3_2_fused * 2 + ax1)
                            v2 = T.axis.spatial(13, ax2)
                            v3 = T.axis.spatial(13, i0_1_i1_1_i2_1_i3_1_fused % 13 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                            T.writes(T_leaky_relu[v0, v1, v2, v3])
                            T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 4, 64, 1, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 1, 1, 13, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 13, 1, 1, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[64, 16, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109, l110 = sch.split(loop=l107, factors=[None, 64, 4])
sch.vectorize(loop=l110)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b87)
l118, l119, l120 = sch.split(loop=l117, factors=[None, 64, 4])
sch.vectorize(loop=l120)
sch.bind(loop=l119, thread_axis="threadIdx.x")
b121 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b121, ann_key="meta_schedule.unroll_explicit")
b122, b123, b124, b125 = sch.get_child_blocks(b121)
l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l126, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l126, ann_key="pragma_unroll_explicit", ann_val=1)
l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l135, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l135, ann_key="pragma_unroll_explicit", ann_val=1)
l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161, l162, l163 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l144, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l144, ann_key="pragma_unroll_explicit", ann_val=1)
l164, l165, l166, l167, l168, l169, l170 = sch.get_loops(block=b125)
sch.annotate(block_or_loop=l164, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l164, ann_key="pragma_unroll_explicit", ann_val=1)
b171 = sch.get_block(name="conv2d_nchw", func_name="main")
l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189, l190, l191 = sch.get_loops(block=b171)
b192 = sch.decompose_reduction(block=b171, loop=l175)
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #4: GFLOPs: 8.4727. Time: 20.9358 ms. Best GFLOPs: 35.8250
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #5: GFLOPs: 128.2769. Time: 1.3828 ms. Best GFLOPs: 128.2769
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #6: GFLOPs: 24.6275. Time: 7.2026 ms. Best GFLOPs: 128.2769
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #7: GFLOPs: 494.0044. Time: 0.3591 ms. Best GFLOPs: 494.0044
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #8: GFLOPs: 47.7203. Time: 3.7171 ms. Best GFLOPs: 494.0044
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #9: GFLOPs: 366.6335. Time: 0.4838 ms. Best GFLOPs: 494.0044
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #10: GFLOPs: 40.6801. Time: 4.3604 ms. Best GFLOPs: 494.0044
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #11: GFLOPs: 12.5860. Time: 14.0937 ms. Best GFLOPs: 494.0044
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #12: GFLOPs: 7.9980. Time: 22.1783 ms. Best GFLOPs: 494.0044
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #13: Error in building: LocalRunner: An exception occurred
Subprocess terminated
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1024, 13, 13), "float32"], placeholder_1: T.Buffer[(512, 1024, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 512, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw_local = T.alloc_buffer([1, 512, 13, 13], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 1024, 13, 13], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([512, 1024, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(26, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(1, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(128, thread="threadIdx.x"):
                    for i1_4_init, i3_4_init in T.grid(2, 13):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused // 13 * 256 + i0_2_i1_2_i2_2_i3_2_fused * 2 + i1_4_init)
                            yy = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_fused % 13)
                            xx = T.axis.spatial(13, i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 1024, 13, 13], "float32"], ["TENSOR", [512, 1024, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(512, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(1):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(128, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(1024, i4_0 * 2 + ax0_ax1_ax2_ax3_fused_1 // 13)
                                    v2 = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_fused % 13)
                                    v3 = T.axis.spatial(13, ax0_ax1_ax2_ax3_fused_1 % 13)
                                    T.where(ax0_ax1_ax2_ax3_fused_1 < 26)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(1):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(128, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused // 13 * 256 + (ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 2)
                                        v1 = T.axis.spatial(1024, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 2)
                                        v2 = T.axis.spatial(1, 0)
                                        v3 = T.axis.spatial(1, 0)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 13):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused // 13 * 256 + i0_2_i1_2_i2_2_i3_2_fused * 2 + i1_4)
                                yy = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_fused % 13)
                                xx = T.axis.spatial(13, i3_4)
                                rc = T.axis.reduce(1024, i4_0 * 2 + i4_1)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 1024, 13, 13], "float32"], ["TENSOR", [512, 1024, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 2, 1, 13):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused // 13 * 256 + i0_2_i1_2_i2_2_i3_2_fused * 2 + ax1)
                            v2 = T.axis.spatial(13, i0_0_i1_0_i2_0_i3_0_fused % 13 + ax2)
                            v3 = T.axis.spatial(13, ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                            T.writes(T_leaky_relu[v0, v1, v2, v3])
                            T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[2, 1, 128, 1, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[13, 1, 1, 1, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 13])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[512, 2, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109 = sch.split(loop=l107, factors=[None, 128])
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b87)
l117, l118, l119 = sch.split(loop=l116, factors=[None, 128, 4])
sch.vectorize(loop=l119)
sch.bind(loop=l118, thread_axis="threadIdx.x")
b120 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b120, ann_key="meta_schedule.unroll_explicit")
b121, b122, b123, b124 = sch.get_child_blocks(b120)
l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b121)
sch.annotate(block_or_loop=l125, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l125, ann_key="pragma_unroll_explicit", ann_val=1)
l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l133, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l133, ann_key="pragma_unroll_explicit", ann_val=1)
l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l142, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l142, ann_key="pragma_unroll_explicit", ann_val=1)
l162, l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
b169 = sch.get_block(name="conv2d_nchw", func_name="main")
l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b169)
b190 = sch.decompose_reduction(block=b169, loop=l173)
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #14: GFLOPs: 2012.7442. Time: 0.0881 ms. Best GFLOPs: 2012.7442
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #15: GFLOPs: 87.6127. Time: 2.0246 ms. Best GFLOPs: 2012.7442
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #16: GFLOPs: 1203.9192. Time: 0.1473 ms. Best GFLOPs: 2012.7442
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #17: GFLOPs: 14.3074. Time: 12.3979 ms. Best GFLOPs: 2012.7442
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #18: GFLOPs: 78.9756. Time: 2.2460 ms. Best GFLOPs: 2012.7442
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #19: GFLOPs: 144.3081. Time: 1.2292 ms. Best GFLOPs: 2012.7442
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #20: GFLOPs: 1606.5607. Time: 0.1104 ms. Best GFLOPs: 2012.7442
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #21: GFLOPs: 583.7852. Time: 0.3038 ms. Best GFLOPs: 2012.7442
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #22: GFLOPs: 60.0767. Time: 2.9526 ms. Best GFLOPs: 2012.7442
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #23: GFLOPs: 975.5576. Time: 0.1818 ms. Best GFLOPs: 2012.7442
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #24: GFLOPs: 1600.7336. Time: 0.1108 ms. Best GFLOPs: 2012.7442
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #25: GFLOPs: 101.4977. Time: 1.7476 ms. Best GFLOPs: 2012.7442
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #26: GFLOPs: 4.5184. Time: 39.2582 ms. Best GFLOPs: 2012.7442
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #27: GFLOPs: 1473.0011. Time: 0.1204 ms. Best GFLOPs: 2012.7442
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #28: Error in building: LocalRunner: An exception occurred
Subprocess terminated
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1024, 13, 13), "float32"], placeholder_1: T.Buffer[(512, 1024, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 512, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw_local = T.alloc_buffer([1, 512, 13, 13], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 1024, 13, 13], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([512, 1024, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(1, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(8, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i1_3_init, i3_3_init, i2_4_init in T.grid(2, 13, 13):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(512, i0_1_i1_1_i2_1_i3_1_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused * 2 + i1_3_init)
                            yy, xx = T.axis.remap("SS", [i2_4_init, i3_3_init])
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 1024, 13, 13], "float32"], ["TENSOR", [512, 1024, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(512, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(6):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(2):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(1024, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) // 169)
                                        v2 = T.axis.spatial(13, (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 169 // 13)
                                        v3 = T.axis.spatial(13, (ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 13)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) * 2 + ax0_ax1_ax2_ax3_fused_2 < 338)
                                        T.reads(placeholder[v0, v1, v2, v3])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(8):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(512, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 2)
                                        v1 = T.axis.spatial(1024, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 2)
                                        v2 = T.axis.spatial(1, 0)
                                        v3 = T.axis.spatial(1, 0)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(2, 1, 1, 1, 2, 1, 13, 1, 1, 1, 1, 1, 13, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(512, i0_1_i1_1_i2_1_i3_1_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused * 2 + i1_3)
                                yy, xx = T.axis.remap("SS", [i2_4, i3_3])
                                rc = T.axis.reduce(1024, i4_0 * 2 + i4_1)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 1024, 13, 13], "float32"], ["TENSOR", [512, 1024, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 2, 13, 13):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(512, i0_1_i1_1_i2_1_i3_1_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused * 2 + ax1)
                            v2, v3 = T.axis.remap("SS", [ax2, ax3])
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                            T.writes(T_leaky_relu[v0, v1, v2, v3])
                            T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 8, 32, 2, 1])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 13])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 13, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[512, 2, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109, l110 = sch.split(loop=l107, factors=[None, 32, 2])
sch.vectorize(loop=l110)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b87)
l118, l119, l120 = sch.split(loop=l117, factors=[None, 32, 4])
sch.vectorize(loop=l120)
sch.bind(loop=l119, thread_axis="threadIdx.x")
b121 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b121, ann_key="meta_schedule.unroll_explicit")
b122, b123, b124, b125 = sch.get_child_blocks(b121)
l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l126, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l126, ann_key="pragma_unroll_explicit", ann_val=1)
l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l135, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l135, ann_key="pragma_unroll_explicit", ann_val=1)
l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161, l162, l163 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l144, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l144, ann_key="pragma_unroll_explicit", ann_val=1)
l164, l165, l166, l167, l168, l169, l170 = sch.get_loops(block=b125)
sch.annotate(block_or_loop=l164, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l164, ann_key="pragma_unroll_explicit", ann_val=1)
b171 = sch.get_block(name="conv2d_nchw", func_name="main")
l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189, l190, l191 = sch.get_loops(block=b171)
b192 = sch.decompose_reduction(block=b171, loop=l175)
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #29: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1024, 13, 13), "float32"], placeholder_1: T.Buffer[(512, 1024, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 512, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw_local = T.alloc_buffer([1, 512, 13, 13], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 1024, 13, 13], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([512, 1024, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(2, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(4, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(52, thread="threadIdx.x"):
                    for i1_3_init, i2_3_init, i1_4_init in T.grid(2, 13, 8):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused * 256 + i0_1_i1_1_i2_1_i3_1_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 16 + i1_3_init * 8 + i1_4_init)
                            yy = T.axis.spatial(13, i2_3_init)
                            xx = T.axis.spatial(13, i0_2_i1_2_i2_2_i3_2_fused % 13)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 1024, 13, 13], "float32"], ["TENSOR", [512, 1024, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(64, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(13):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(1024, i4_0 * 16 + (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 169)
                                        v2 = T.axis.spatial(13, (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 169 // 13)
                                        v3 = T.axis.spatial(13, (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 13)
                                        T.reads(placeholder[v0, v1, v2, v3])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(20):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused * 256 + (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 16)
                                        v1 = T.axis.spatial(1024, i4_0 * 16 + (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 16)
                                        v2 = T.axis.spatial(1, 0)
                                        v3 = T.axis.spatial(1, 0)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) * 4 + ax0_ax1_ax2_ax3_fused_2 < 4096)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(8, 1, 1, 1, 2, 13, 1, 2, 1, 1, 1, 8, 1, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused * 256 + i0_1_i1_1_i2_1_i3_1_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 16 + i1_3 * 8 + i1_4)
                                yy = T.axis.spatial(13, i2_3)
                                xx = T.axis.spatial(13, i0_2_i1_2_i2_2_i3_2_fused % 13)
                                rc = T.axis.reduce(1024, i4_0 * 16 + i4_1 * 2 + i4_2)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 1024, 13, 13], "float32"], ["TENSOR", [512, 1024, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 16, 13, 1):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_fused * 256 + i0_1_i1_1_i2_1_i3_1_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 16 + ax1)
                            v2 = T.axis.spatial(13, ax2)
                            v3 = T.axis.spatial(13, i0_2_i1_2_i2_2_i3_2_fused % 13 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                            T.writes(T_leaky_relu[v0, v1, v2, v3])
                            T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[2, 4, 4, 2, 8])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 1, 1, 13, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 13, 1, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[64, 8, 2])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109, l110 = sch.split(loop=l107, factors=[None, 52, 4])
sch.vectorize(loop=l110)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b87)
l118, l119, l120 = sch.split(loop=l117, factors=[None, 52, 4])
sch.vectorize(loop=l120)
sch.bind(loop=l119, thread_axis="threadIdx.x")
b121 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b121, ann_key="meta_schedule.unroll_explicit")
b122, b123, b124, b125 = sch.get_child_blocks(b121)
l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l126, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l126, ann_key="pragma_unroll_explicit", ann_val=1)
l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l135, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l135, ann_key="pragma_unroll_explicit", ann_val=1)
l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161, l162, l163 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l144, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l144, ann_key="pragma_unroll_explicit", ann_val=1)
l164, l165, l166, l167, l168, l169, l170 = sch.get_loops(block=b125)
sch.annotate(block_or_loop=l164, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l164, ann_key="pragma_unroll_explicit", ann_val=1)
b171 = sch.get_block(name="conv2d_nchw", func_name="main")
l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189, l190, l191 = sch.get_loops(block=b171)
b192 = sch.decompose_reduction(block=b171, loop=l175)
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #30: GFLOPs: 1086.1925. Time: 0.1633 ms. Best GFLOPs: 2012.7442
[14:04:10] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"] Trial #31: GFLOPs: 236.8558. Time: 0.7489 ms. Best GFLOPs: 2012.7442
[14:04:12] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |      3333.8786 |     478.6984 |              478.6984 |     32 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |      2960.8178 |      60.0268 |              120.0537 |     32 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |      3729.7200 |     213.9931 |             1711.9447 |     32 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |      2831.4273 |      31.4766 |              283.2898 |     32 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |         0.0002 |       4.0251 |                8.0501 |     32 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |      3577.2919 |      99.3648 |               99.3648 |     32 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |      1641.9450 |     971.6545 |              971.6545 |     32 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |      2242.5252 |      79.1380 |              158.2760 |     32 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |      2992.4470 |     266.6006 |             1066.4024 |     32 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |      1500.1992 |      59.2350 |              296.1749 |     32 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |         0.0004 |       2.8040 |                5.6080 |     32 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |      2711.9545 |     130.8790 |              130.8790 |     32 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |       491.6898 |      29.7408 |               29.7408 |     32 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |         0.0002 |       4.1701 |                4.1701 |     32 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |      1750.6945 |     202.5435 |              202.5435 |     32 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |      2848.2262 |     560.0785 |             2800.3924 |     32 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |      2012.7442 |      88.1296 |              528.7778 |     32 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1440
Total latency (us): 14748.6

[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #0: GFLOPs: 254.0904. Time: 0.1747 ms. Best GFLOPs: 254.0904
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #1: GFLOPs: 1321.5170. Time: 0.0336 ms. Best GFLOPs: 1321.5170
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #2: GFLOPs: 1385.0547. Time: 0.0320 ms. Best GFLOPs: 1385.0547
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #3: GFLOPs: 92.2310. Time: 0.4813 ms. Best GFLOPs: 1385.0547
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #4: GFLOPs: 102.2728. Time: 0.4340 ms. Best GFLOPs: 1385.0547
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #5: GFLOPs: 897.4015. Time: 0.0495 ms. Best GFLOPs: 1385.0547
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #6: GFLOPs: 1713.3262. Time: 0.0259 ms. Best GFLOPs: 1713.3262
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #7: GFLOPs: 10.4745. Time: 4.2378 ms. Best GFLOPs: 1713.3262
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #8: GFLOPs: 429.5666. Time: 0.1033 ms. Best GFLOPs: 1713.3262
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #9: GFLOPs: 200.4166. Time: 0.2215 ms. Best GFLOPs: 1713.3262
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #10: GFLOPs: 1359.9901. Time: 0.0326 ms. Best GFLOPs: 1713.3262
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #11: GFLOPs: 1.7078. Time: 25.9923 ms. Best GFLOPs: 1713.3262
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #12: GFLOPs: 1340.9429. Time: 0.0331 ms. Best GFLOPs: 1713.3262
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #13: GFLOPs: 214.0731. Time: 0.2074 ms. Best GFLOPs: 1713.3262
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #14: GFLOPs: 756.7143. Time: 0.0587 ms. Best GFLOPs: 1713.3262
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #15: GFLOPs: 115.9709. Time: 0.3828 ms. Best GFLOPs: 1713.3262
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #16: GFLOPs: 232.6720. Time: 0.1908 ms. Best GFLOPs: 1713.3262
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #17: GFLOPs: 327.5284. Time: 0.1355 ms. Best GFLOPs: 1713.3262
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #18: GFLOPs: 451.0816. Time: 0.0984 ms. Best GFLOPs: 1713.3262
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #19: GFLOPs: 1454.0402. Time: 0.0305 ms. Best GFLOPs: 1713.3262
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #20: GFLOPs: 953.0496. Time: 0.0466 ms. Best GFLOPs: 1713.3262
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #21: GFLOPs: 893.9383. Time: 0.0497 ms. Best GFLOPs: 1713.3262
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #22: GFLOPs: 638.1647. Time: 0.0696 ms. Best GFLOPs: 1713.3262
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #23: GFLOPs: 640.7839. Time: 0.0693 ms. Best GFLOPs: 1713.3262
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #24: GFLOPs: 661.7409. Time: 0.0671 ms. Best GFLOPs: 1713.3262
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #25: GFLOPs: 151.4506. Time: 0.2931 ms. Best GFLOPs: 1713.3262
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #26: GFLOPs: 859.3336. Time: 0.0517 ms. Best GFLOPs: 1713.3262
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #27: GFLOPs: 493.4584. Time: 0.0900 ms. Best GFLOPs: 1713.3262
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #28: GFLOPs: 614.4885. Time: 0.0722 ms. Best GFLOPs: 1713.3262
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #29: GFLOPs: 20.5576. Time: 2.1592 ms. Best GFLOPs: 1713.3262
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #30: GFLOPs: 543.5327. Time: 0.0817 ms. Best GFLOPs: 1713.3262
[14:04:12] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"] Trial #31: GFLOPs: 60.7755. Time: 0.7304 ms. Best GFLOPs: 1713.3262
[14:04:14] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |      3333.8786 |     478.6984 |              478.6984 |     32 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |      2960.8178 |      60.0268 |              120.0537 |     32 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |      3729.7200 |     213.9931 |             1711.9447 |     32 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |      2831.4273 |      31.4766 |              283.2898 |     32 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |         0.0002 |       4.0251 |                8.0501 |     32 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |      3577.2919 |      99.3648 |               99.3648 |     32 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |      1641.9450 |     971.6545 |              971.6545 |     32 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |      2242.5252 |      79.1380 |              158.2760 |     32 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |      2992.4470 |     266.6006 |             1066.4024 |     32 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |      1500.1992 |      59.2350 |              296.1749 |     32 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |         0.0004 |       2.8040 |                5.6080 |     32 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |      2711.9545 |     130.8790 |              130.8790 |     32 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |       491.6898 |      29.7408 |               29.7408 |     32 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |         0.0002 |       4.1701 |                4.1701 |     32 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |      1750.6945 |     202.5435 |              202.5435 |     32 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |      2848.2262 |     560.0785 |             2800.3924 |     32 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |      2012.7442 |      88.1296 |              528.7778 |     32 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |      1713.3262 |      25.9080 |               25.9080 |     32 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1472
Total latency (us): 14774.5

[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #0: GFLOPs: 0.0000. Time: 0.0046 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #1: GFLOPs: 0.0000. Time: 0.0045 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #2: GFLOPs: 0.0000. Time: 0.0047 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #3: GFLOPs: 0.0000. Time: 0.0049 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #4: GFLOPs: 0.0000. Time: 0.0046 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #5: GFLOPs: 0.0000. Time: 0.0046 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #6: GFLOPs: 0.0000. Time: 0.0049 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #7: GFLOPs: 0.0000. Time: 0.0047 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #8: GFLOPs: 0.0000. Time: 0.0046 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #9: GFLOPs: 0.0000. Time: 0.0046 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #10: GFLOPs: 0.0000. Time: 0.0046 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #11: GFLOPs: 0.0000. Time: 0.0049 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #12: GFLOPs: 0.0000. Time: 0.0047 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #13: GFLOPs: 0.0000. Time: 0.0046 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #14: GFLOPs: 0.0000. Time: 0.0046 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #15: GFLOPs: 0.0000. Time: 0.0045 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #16: GFLOPs: 0.0000. Time: 0.0046 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #17: GFLOPs: 0.0000. Time: 0.0046 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #18: GFLOPs: 0.0000. Time: 0.0047 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #19: GFLOPs: 0.0000. Time: 0.0046 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #20: GFLOPs: 0.0000. Time: 0.0045 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #21: GFLOPs: 0.0000. Time: 0.0045 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #22: GFLOPs: 0.0000. Time: 0.0046 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #23: GFLOPs: 0.0000. Time: 0.0046 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #24: GFLOPs: 0.0000. Time: 0.0046 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #25: GFLOPs: 0.0000. Time: 0.0045 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #26: GFLOPs: 0.0000. Time: 0.0047 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #27: GFLOPs: 0.0000. Time: 0.0046 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #28: GFLOPs: 0.0000. Time: 0.0045 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #29: GFLOPs: 0.0000. Time: 0.0048 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #30: GFLOPs: 0.0000. Time: 0.0046 ms. Best GFLOPs: 0.0000
[14:04:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #46: "fused_image_resize2d_concatenate"] Trial #31: GFLOPs: 0.0000. Time: 0.0045 ms. Best GFLOPs: 0.0000
[14:04:16] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #46: "fused_image_resize2d_concatenate"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |      3333.8786 |     478.6984 |              478.6984 |     32 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |      2960.8178 |      60.0268 |              120.0537 |     32 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |      3729.7200 |     213.9931 |             1711.9447 |     32 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |      2831.4273 |      31.4766 |              283.2898 |     32 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |         0.0002 |       4.0251 |                8.0501 |     32 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |      3577.2919 |      99.3648 |               99.3648 |     32 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |      1641.9450 |     971.6545 |              971.6545 |     32 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |      2242.5252 |      79.1380 |              158.2760 |     32 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |      2992.4470 |     266.6006 |             1066.4024 |     32 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |      1500.1992 |      59.2350 |              296.1749 |     32 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |         0.0004 |       2.8040 |                5.6080 |     32 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |      2711.9545 |     130.8790 |              130.8790 |     32 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |       491.6898 |      29.7408 |               29.7408 |     32 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |         0.0002 |       4.1701 |                4.1701 |     32 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |      1750.6945 |     202.5435 |              202.5435 |     32 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |      2848.2262 |     560.0785 |             2800.3924 |     32 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |      2012.7442 |      88.1296 |              528.7778 |     32 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |      1713.3262 |      25.9080 |               25.9080 |     32 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |         0.0002 |       4.4672 |                4.4672 |     32 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |            N/A |          N/A |                   N/A |      0 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1504
Total latency (us): 14779

[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #0: GFLOPs: 98.3162. Time: 16.2290 ms. Best GFLOPs: 98.3162
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #1: GFLOPs: 3286.9107. Time: 0.4854 ms. Best GFLOPs: 3286.9107
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #2: GFLOPs: 3770.5479. Time: 0.4232 ms. Best GFLOPs: 3770.5479
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #3: GFLOPs: 484.9527. Time: 3.2902 ms. Best GFLOPs: 3770.5479
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #4: GFLOPs: 1567.6373. Time: 1.0178 ms. Best GFLOPs: 3770.5479
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #5: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 26, 26), "float32"], placeholder_1: T.Buffer[(512, 256, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 512, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 512, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw_local = T.alloc_buffer([1, 512, 26, 26], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 256, 28, 28], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([512, 256, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(1, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(32, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(52, thread="threadIdx.x"):
                    for i2_3_init, i1_4_init, i3_4_init in T.grid(2, 8, 13):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(512, i0_1_i1_1_i2_1_i3_1_fused // 2 * 32 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 8 + i1_4_init)
                            yy = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused % 13 * 2 + i2_3_init)
                            xx = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused % 2 * 13 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 26, 26], "float32"], ["TENSOR", [512, 256, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(128, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(8):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(256, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 784)
                                        v2 = T.axis.spatial(28, (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 784 // 28)
                                        v3 = T.axis.spatial(28, (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 28)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) * 4 + ax0_ax1_ax2_ax3_fused_2 < 1568)
                                        T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 27 and 1 <= v3 and v3 < 27, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(178):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(512, (ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) // 18)
                                    v1 = T.axis.spatial(256, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) % 18 // 9)
                                    v2 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) % 9 // 3)
                                    v3 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) % 3)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1 < 9216)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(2, 1, 1, 1, 1, 2, 1, 1, 3, 3, 1, 8, 1, 13):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(512, i0_1_i1_1_i2_1_i3_1_fused // 2 * 32 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 8 + i1_4)
                                yy = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused % 13 * 2 + i2_3)
                                xx = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused % 2 * 13 + i3_4)
                                rc = T.axis.reduce(256, i4_0 * 2 + i4_1)
                                ry, rx = T.axis.remap("RR", [i5_2, i6_2])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 26, 26], "float32"], ["TENSOR", [512, 256, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 8, 2, 13):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(512, i0_1_i1_1_i2_1_i3_1_fused // 2 * 32 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 8 + ax1)
                            v2 = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused % 13 * 2 + ax2)
                            v3 = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused % 2 * 13 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                            T.writes(T_leaky_relu[v0, v1, v2, v3])
                            T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 16, 4, 1, 8])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 1, 13, 2, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 2, 1, 1, 13])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[128, 2, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109, l110 = sch.split(loop=l107, factors=[None, 52, 4])
sch.vectorize(loop=l110)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b87)
l118, l119 = sch.split(loop=l117, factors=[None, 52])
sch.bind(loop=l119, thread_axis="threadIdx.x")
b120 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b120, ann_key="meta_schedule.unroll_explicit")
b121, b122, b123, b124 = sch.get_child_blocks(b120)
l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b121)
sch.annotate(block_or_loop=l125, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l125, ann_key="pragma_unroll_explicit", ann_val=1)
l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l134, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l134, ann_key="pragma_unroll_explicit", ann_val=1)
l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l142, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l142, ann_key="pragma_unroll_explicit", ann_val=1)
l162, l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
b169 = sch.get_block(name="conv2d_nchw", func_name="main")
l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b169)
b190 = sch.decompose_reduction(block=b169, loop=l173)
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #6: GFLOPs: 1890.0580. Time: 0.8442 ms. Best GFLOPs: 3770.5479
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #7: GFLOPs: 278.2348. Time: 5.7346 ms. Best GFLOPs: 3770.5479
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #8: GFLOPs: 166.6526. Time: 9.5743 ms. Best GFLOPs: 3770.5479
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #9: GFLOPs: 212.8723. Time: 7.4955 ms. Best GFLOPs: 3770.5479
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #10: GFLOPs: 38.1789. Time: 41.7921 ms. Best GFLOPs: 3770.5479
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #11: GFLOPs: 4127.4777. Time: 0.3866 ms. Best GFLOPs: 4127.4777
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #12: GFLOPs: 421.1155. Time: 3.7889 ms. Best GFLOPs: 4127.4777
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #13: GFLOPs: 66.9687. Time: 23.8257 ms. Best GFLOPs: 4127.4777
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #14: GFLOPs: 2304.0600. Time: 0.6925 ms. Best GFLOPs: 4127.4777
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #15: GFLOPs: 3494.4464. Time: 0.4566 ms. Best GFLOPs: 4127.4777
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #16: GFLOPs: 324.7528. Time: 4.9132 ms. Best GFLOPs: 4127.4777
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #17: GFLOPs: 4783.3216. Time: 0.3336 ms. Best GFLOPs: 4783.3216
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #18: GFLOPs: 2827.8364. Time: 0.5642 ms. Best GFLOPs: 4783.3216
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #19: GFLOPs: 106.4357. Time: 14.9910 ms. Best GFLOPs: 4783.3216
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #20: GFLOPs: 2162.3602. Time: 0.7379 ms. Best GFLOPs: 4783.3216
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #21: GFLOPs: 1454.1641. Time: 1.0972 ms. Best GFLOPs: 4783.3216
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #22: GFLOPs: 19.9483. Time: 79.9855 ms. Best GFLOPs: 4783.3216
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #23: GFLOPs: 89.7742. Time: 17.7732 ms. Best GFLOPs: 4783.3216
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #24: GFLOPs: 143.6849. Time: 11.1047 ms. Best GFLOPs: 4783.3216
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #25: GFLOPs: 4947.1213. Time: 0.3225 ms. Best GFLOPs: 4947.1213
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #26: GFLOPs: 250.7798. Time: 6.3625 ms. Best GFLOPs: 4947.1213
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #27: GFLOPs: 492.7882. Time: 3.2379 ms. Best GFLOPs: 4947.1213
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #28: GFLOPs: 411.6011. Time: 3.8765 ms. Best GFLOPs: 4947.1213
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #29: GFLOPs: 242.3983. Time: 6.5825 ms. Best GFLOPs: 4947.1213
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #30: GFLOPs: 190.5176. Time: 8.3750 ms. Best GFLOPs: 4947.1213
[14:04:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"] Trial #31: GFLOPs: 512.0226. Time: 3.1162 ms. Best GFLOPs: 4947.1213
[14:04:18] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |      3333.8786 |     478.6984 |              478.6984 |     32 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |      2960.8178 |      60.0268 |              120.0537 |     32 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |      3729.7200 |     213.9931 |             1711.9447 |     32 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |      2831.4273 |      31.4766 |              283.2898 |     32 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |         0.0002 |       4.0251 |                8.0501 |     32 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |      3577.2919 |      99.3648 |               99.3648 |     32 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |      1641.9450 |     971.6545 |              971.6545 |     32 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |      2242.5252 |      79.1380 |              158.2760 |     32 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |      2992.4470 |     266.6006 |             1066.4024 |     32 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |      1500.1992 |      59.2350 |              296.1749 |     32 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |         0.0004 |       2.8040 |                5.6080 |     32 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |      2711.9545 |     130.8790 |              130.8790 |     32 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |       491.6898 |      29.7408 |               29.7408 |     32 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |         0.0002 |       4.1701 |                4.1701 |     32 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |      1750.6945 |     202.5435 |              202.5435 |     32 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |      2848.2262 |     560.0785 |             2800.3924 |     32 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |      2012.7442 |      88.1296 |              528.7778 |     32 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |      1713.3262 |      25.9080 |               25.9080 |     32 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |         0.0002 |       4.4672 |                4.4672 |     32 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |      4947.1213 |     322.5262 |             1612.6311 |     32 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |            N/A |          N/A |                   N/A |      0 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1536
Total latency (us): 16391.6

[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #0: GFLOPs: 2613.8669. Time: 0.0679 ms. Best GFLOPs: 2613.8669
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #1: GFLOPs: 6.4913. Time: 27.3527 ms. Best GFLOPs: 2613.8669
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #2: GFLOPs: 1270.5471. Time: 0.1397 ms. Best GFLOPs: 2613.8669
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #3: GFLOPs: 3325.7491. Time: 0.0534 ms. Best GFLOPs: 3325.7491
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #4: GFLOPs: 1978.1073. Time: 0.0898 ms. Best GFLOPs: 3325.7491
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #5: GFLOPs: 116.2196. Time: 1.5278 ms. Best GFLOPs: 3325.7491
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #6: GFLOPs: 1341.3954. Time: 0.1324 ms. Best GFLOPs: 3325.7491
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #7: GFLOPs: 124.7539. Time: 1.4232 ms. Best GFLOPs: 3325.7491
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #8: GFLOPs: 1808.5828. Time: 0.0982 ms. Best GFLOPs: 3325.7491
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #9: GFLOPs: 782.5082. Time: 0.2269 ms. Best GFLOPs: 3325.7491
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #10: GFLOPs: 998.6907. Time: 0.1778 ms. Best GFLOPs: 3325.7491
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #11: GFLOPs: 1003.8036. Time: 0.1769 ms. Best GFLOPs: 3325.7491
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #12: GFLOPs: 214.3549. Time: 0.8283 ms. Best GFLOPs: 3325.7491
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #13: GFLOPs: 1321.6142. Time: 0.1343 ms. Best GFLOPs: 3325.7491
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #14: GFLOPs: 1880.0371. Time: 0.0944 ms. Best GFLOPs: 3325.7491
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #15: GFLOPs: 509.1499. Time: 0.3487 ms. Best GFLOPs: 3325.7491
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #16: GFLOPs: 1420.0429. Time: 0.1250 ms. Best GFLOPs: 3325.7491
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #17: GFLOPs: 540.3618. Time: 0.3286 ms. Best GFLOPs: 3325.7491
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #18: GFLOPs: 1136.6793. Time: 0.1562 ms. Best GFLOPs: 3325.7491
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #19: GFLOPs: 1205.6475. Time: 0.1473 ms. Best GFLOPs: 3325.7491
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #20: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 26, 26), "float32"], placeholder_1: T.Buffer[(256, 512, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 256, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw_local = T.alloc_buffer([1, 256, 26, 26], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 512, 26, 26], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([256, 512, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(4, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(416, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(52, thread="threadIdx.x"):
                    for i2_3_init in T.serial(2):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused * 64 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 2 + i0_2_i1_2_i2_2_i3_2_fused // 26)
                            yy = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused % 13 * 2 + i2_3_init)
                            xx = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused % 26)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 26, 26], "float32"], ["TENSOR", [256, 512, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(32, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(104):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(2):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(512, i4_0 * 16 + (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) // 676)
                                        v2 = T.axis.spatial(26, (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 676 // 26)
                                        v3 = T.axis.spatial(26, (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 26)
                                        T.reads(placeholder[v0, v1, v2, v3])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(10):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(2):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused * 64 + (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) // 16)
                                        v1 = T.axis.spatial(512, i4_0 * 16 + (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 16)
                                        v2 = T.axis.spatial(1, 0)
                                        v3 = T.axis.spatial(1, 0)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) * 2 + ax0_ax1_ax2_ax3_fused_2 < 1024)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(2, 1, 1, 1, 1, 2, 1, 8, 1, 1, 1, 1, 1, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused * 64 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 2 + i0_2_i1_2_i2_2_i3_2_fused // 26)
                                yy = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused % 13 * 2 + i2_3)
                                xx = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused % 26)
                                rc = T.axis.reduce(512, i4_0 * 16 + i4_1 * 8 + i4_2)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 26, 26], "float32"], ["TENSOR", [256, 512, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 1, 2, 1):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused * 64 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 2 + i0_2_i1_2_i2_2_i3_2_fused // 26 + ax1)
                            v2 = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused % 13 * 2 + ax2)
                            v3 = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused % 26 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                            T.writes(T_leaky_relu[v0, v1, v2, v3])
                            T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[4, 32, 2, 1, 1])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 13, 1, 2, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 26, 1, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[32, 2, 8])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109, l110 = sch.split(loop=l107, factors=[None, 52, 2])
sch.vectorize(loop=l110)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b87)
l118, l119, l120 = sch.split(loop=l117, factors=[None, 52, 2])
sch.vectorize(loop=l120)
sch.bind(loop=l119, thread_axis="threadIdx.x")
b121 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b121, ann_key="meta_schedule.unroll_explicit")
b122, b123, b124, b125 = sch.get_child_blocks(b121)
l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l126, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l126, ann_key="pragma_unroll_explicit", ann_val=1)
l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l135, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l135, ann_key="pragma_unroll_explicit", ann_val=1)
l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161, l162, l163 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l144, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l144, ann_key="pragma_unroll_explicit", ann_val=1)
l164, l165, l166, l167, l168, l169, l170 = sch.get_loops(block=b125)
sch.annotate(block_or_loop=l164, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l164, ann_key="pragma_unroll_explicit", ann_val=1)
b171 = sch.get_block(name="conv2d_nchw", func_name="main")
l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189, l190, l191 = sch.get_loops(block=b171)
b192 = sch.decompose_reduction(block=b171, loop=l175)
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #21: GFLOPs: 1762.7855. Time: 0.1007 ms. Best GFLOPs: 3325.7491
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #22: GFLOPs: 348.3595. Time: 0.5097 ms. Best GFLOPs: 3325.7491
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #23: GFLOPs: 10.5814. Time: 16.7799 ms. Best GFLOPs: 3325.7491
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #24: GFLOPs: 221.8902. Time: 0.8002 ms. Best GFLOPs: 3325.7491
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #25: GFLOPs: 450.8530. Time: 0.3938 ms. Best GFLOPs: 3325.7491
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #26: GFLOPs: 1175.5314. Time: 0.1510 ms. Best GFLOPs: 3325.7491
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #27: GFLOPs: 1797.7168. Time: 0.0988 ms. Best GFLOPs: 3325.7491
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #28: GFLOPs: 240.0231. Time: 0.7397 ms. Best GFLOPs: 3325.7491
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #29: Error in building: LocalRunner: An exception occurred
Subprocess terminated
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 512, 26, 26), "float32"], placeholder_1: T.Buffer[(256, 512, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 256, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw_local = T.alloc_buffer([1, 256, 26, 26], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 512, 26, 26], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([256, 512, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(4, thread="blockIdx.x"):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(4, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i1_4_init, i2_4_init, i3_4_init in T.grid(2, 13, 13):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(256, i0_1_i1_1_i2_1_i3_1_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused * 2 + i1_4_init)
                            yy = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused // 2 * 13 + i2_4_init)
                            xx = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused % 2 * 13 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 26, 26], "float32"], ["TENSOR", [256, 512, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(512, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(6):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(512, i4_0)
                                    v2 = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused // 2 * 13 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) // 13)
                                    v3 = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused % 2 * 13 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 13)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1 < 169)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(4):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(2):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(256, ax0_ax1_ax2_ax3_fused_0 * 64 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2)
                                        v1 = T.axis.spatial(512, i4_0)
                                        v2 = T.axis.spatial(1, 0)
                                        v3 = T.axis.spatial(1, 0)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 13, 13):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(256, i0_1_i1_1_i2_1_i3_1_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused * 2 + i1_4)
                                yy = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused // 2 * 13 + i2_4)
                                xx = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused % 2 * 13 + i3_4)
                                rc = T.axis.reduce(512, i4_0)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 512, 26, 26], "float32"], ["TENSOR", [256, 512, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 2, 13, 13):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(256, i0_1_i1_1_i2_1_i3_1_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused * 2 + ax1)
                            v2 = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused // 2 * 13 + ax2)
                            v3 = T.axis.spatial(26, i0_0_i1_0_i2_0_i3_0_fused % 2 * 13 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                            T.writes(T_leaky_relu[v0, v1, v2, v3])
                            T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 4, 32, 1, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[2, 1, 1, 1, 13])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[2, 1, 1, 1, 13])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[512, 1, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109 = sch.split(loop=l107, factors=[None, 32])
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b87)
l117, l118, l119 = sch.split(loop=l116, factors=[None, 32, 2])
sch.vectorize(loop=l119)
sch.bind(loop=l118, thread_axis="threadIdx.x")
b120 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b120, ann_key="meta_schedule.unroll_explicit")
b121, b122, b123, b124 = sch.get_child_blocks(b120)
l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b121)
l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b122)
l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b123)
l162, l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b124)
b169 = sch.get_block(name="conv2d_nchw", func_name="main")
l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b169)
b190 = sch.decompose_reduction(block=b169, loop=l173)
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #30: GFLOPs: 123.2128. Time: 1.4410 ms. Best GFLOPs: 3325.7491
[14:04:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"] Trial #31: GFLOPs: 15.3494. Time: 11.5676 ms. Best GFLOPs: 3325.7491
[14:04:20] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |      3333.8786 |     478.6984 |              478.6984 |     32 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |      2960.8178 |      60.0268 |              120.0537 |     32 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |      3729.7200 |     213.9931 |             1711.9447 |     32 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |      2831.4273 |      31.4766 |              283.2898 |     32 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |         0.0002 |       4.0251 |                8.0501 |     32 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |      3577.2919 |      99.3648 |               99.3648 |     32 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |      1641.9450 |     971.6545 |              971.6545 |     32 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |      2242.5252 |      79.1380 |              158.2760 |     32 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |      2992.4470 |     266.6006 |             1066.4024 |     32 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |      1500.1992 |      59.2350 |              296.1749 |     32 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |         0.0004 |       2.8040 |                5.6080 |     32 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |      2711.9545 |     130.8790 |              130.8790 |     32 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |       491.6898 |      29.7408 |               29.7408 |     32 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |         0.0002 |       4.1701 |                4.1701 |     32 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |      1750.6945 |     202.5435 |              202.5435 |     32 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |      2848.2262 |     560.0785 |             2800.3924 |     32 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |      2012.7442 |      88.1296 |              528.7778 |     32 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |      1713.3262 |      25.9080 |               25.9080 |     32 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |         0.0002 |       4.4672 |                4.4672 |     32 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |      4947.1213 |     322.5262 |             1612.6311 |     32 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |      3325.7491 |      53.3881 |              373.7168 |     32 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |            N/A |          N/A |                   N/A |      0 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1568
Total latency (us): 16765.3

[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #0: GFLOPs: 440.0587. Time: 0.1011 ms. Best GFLOPs: 440.0587
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #1: GFLOPs: 193.6550. Time: 0.2297 ms. Best GFLOPs: 440.0587
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #2: GFLOPs: 74.2214. Time: 0.5992 ms. Best GFLOPs: 440.0587
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #3: GFLOPs: 37.8671. Time: 1.1745 ms. Best GFLOPs: 440.0587
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #4: GFLOPs: 639.0094. Time: 0.0696 ms. Best GFLOPs: 639.0094
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #5: GFLOPs: 517.2333. Time: 0.0860 ms. Best GFLOPs: 639.0094
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #6: GFLOPs: 1527.2596. Time: 0.0291 ms. Best GFLOPs: 1527.2596
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #7: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 26, 26), "float32"], placeholder_1: T.Buffer[(128, 256, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 128, 26, 26), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw_local = T.alloc_buffer([1, 128, 26, 26], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 256, 26, 26], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([128, 256, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(1, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(208, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(52, thread="threadIdx.x"):
                    for i1_4_init, i3_4_init in T.grid(4, 2):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 13 * 8 + i0_2_i1_2_i2_2_i3_2_fused // 26 * 4 + i1_4_init)
                            yy = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused % 26)
                            xx = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused % 13 * 2 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 26, 26], "float32"], ["TENSOR", [128, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(128, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(7):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(256, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 676)
                                        v2 = T.axis.spatial(26, (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 676 // 26)
                                        v3 = T.axis.spatial(26, (ax0_ax1_ax2_ax3_fused_0 * 208 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 26)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) * 4 + ax0_ax1_ax2_ax3_fused_2 < 1352)
                                        T.reads(placeholder[v0, v1, v2, v3])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(5):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(128, (ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) // 2)
                                    v1 = T.axis.spatial(256, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) % 2)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1 < 256)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 4, 1, 2):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 13 * 8 + i0_2_i1_2_i2_2_i3_2_fused // 26 * 4 + i1_4)
                                yy = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused % 26)
                                xx = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused % 13 * 2 + i3_4)
                                rc = T.axis.reduce(256, i4_0 * 2 + i4_2)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 26, 26], "float32"], ["TENSOR", [128, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 4, 1, 2):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 13 * 8 + i0_2_i1_2_i2_2_i3_2_fused // 26 * 4 + ax1)
                            v2 = T.axis.spatial(26, i0_2_i1_2_i2_2_i3_2_fused % 26 + ax2)
                            v3 = T.axis.spatial(26, i0_1_i1_1_i2_1_i3_1_fused % 13 * 2 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                            T.writes(T_leaky_relu[v0, v1, v2, v3])
                            T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 16, 2, 1, 4])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 1, 26, 1, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 13, 1, 1, 2])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[128, 1, 2])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109, l110 = sch.split(loop=l107, factors=[None, 52, 4])
sch.vectorize(loop=l110)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b87)
l118, l119 = sch.split(loop=l117, factors=[None, 52])
sch.bind(loop=l119, thread_axis="threadIdx.x")
b120 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b120, ann_key="meta_schedule.unroll_explicit")
b121, b122, b123, b124 = sch.get_child_blocks(b120)
l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b121)
sch.annotate(block_or_loop=l125, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l125, ann_key="pragma_unroll_explicit", ann_val=1)
l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l134, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l134, ann_key="pragma_unroll_explicit", ann_val=1)
l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l142, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l142, ann_key="pragma_unroll_explicit", ann_val=1)
l162, l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
b169 = sch.get_block(name="conv2d_nchw", func_name="main")
l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b169)
b190 = sch.decompose_reduction(block=b169, loop=l173)
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #8: GFLOPs: 841.0933. Time: 0.0529 ms. Best GFLOPs: 1527.2596
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #9: GFLOPs: 126.4658. Time: 0.3517 ms. Best GFLOPs: 1527.2596
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #10: GFLOPs: 65.8343. Time: 0.6756 ms. Best GFLOPs: 1527.2596
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #11: GFLOPs: 316.7545. Time: 0.1404 ms. Best GFLOPs: 1527.2596
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #12: GFLOPs: 1718.9146. Time: 0.0259 ms. Best GFLOPs: 1718.9146
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #13: GFLOPs: 1273.5246. Time: 0.0349 ms. Best GFLOPs: 1718.9146
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #14: GFLOPs: 1169.8344. Time: 0.0380 ms. Best GFLOPs: 1718.9146
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #15: GFLOPs: 29.2808. Time: 1.5189 ms. Best GFLOPs: 1718.9146
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #16: GFLOPs: 261.2139. Time: 0.1703 ms. Best GFLOPs: 1718.9146
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #17: GFLOPs: 752.0211. Time: 0.0591 ms. Best GFLOPs: 1718.9146
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #18: GFLOPs: 1927.9605. Time: 0.0231 ms. Best GFLOPs: 1927.9605
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #19: GFLOPs: 666.5779. Time: 0.0667 ms. Best GFLOPs: 1927.9605
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #20: GFLOPs: 26.9913. Time: 1.6478 ms. Best GFLOPs: 1927.9605
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #21: GFLOPs: 1387.8294. Time: 0.0320 ms. Best GFLOPs: 1927.9605
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #22: GFLOPs: 969.9013. Time: 0.0459 ms. Best GFLOPs: 1927.9605
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #23: GFLOPs: 372.9370. Time: 0.1193 ms. Best GFLOPs: 1927.9605
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #24: GFLOPs: 631.9157. Time: 0.0704 ms. Best GFLOPs: 1927.9605
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #25: GFLOPs: 1260.5221. Time: 0.0353 ms. Best GFLOPs: 1927.9605
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #26: GFLOPs: 550.9249. Time: 0.0807 ms. Best GFLOPs: 1927.9605
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #27: GFLOPs: 265.5110. Time: 0.1675 ms. Best GFLOPs: 1927.9605
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #28: GFLOPs: 245.2541. Time: 0.1813 ms. Best GFLOPs: 1927.9605
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #29: GFLOPs: 16.6750. Time: 2.6672 ms. Best GFLOPs: 1927.9605
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #30: GFLOPs: 186.7727. Time: 0.2381 ms. Best GFLOPs: 1927.9605
[14:04:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"] Trial #31: GFLOPs: 981.1624. Time: 0.0453 ms. Best GFLOPs: 1927.9605
[14:04:23] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |      3333.8786 |     478.6984 |              478.6984 |     32 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |      2960.8178 |      60.0268 |              120.0537 |     32 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |      3729.7200 |     213.9931 |             1711.9447 |     32 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |      2831.4273 |      31.4766 |              283.2898 |     32 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |         0.0002 |       4.0251 |                8.0501 |     32 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |      3577.2919 |      99.3648 |               99.3648 |     32 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |      1641.9450 |     971.6545 |              971.6545 |     32 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |      2242.5252 |      79.1380 |              158.2760 |     32 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |      2992.4470 |     266.6006 |             1066.4024 |     32 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |      1500.1992 |      59.2350 |              296.1749 |     32 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |         0.0004 |       2.8040 |                5.6080 |     32 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |      2711.9545 |     130.8790 |              130.8790 |     32 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |       491.6898 |      29.7408 |               29.7408 |     32 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |         0.0002 |       4.1701 |                4.1701 |     32 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |      1750.6945 |     202.5435 |              202.5435 |     32 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |      2848.2262 |     560.0785 |             2800.3924 |     32 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |      2012.7442 |      88.1296 |              528.7778 |     32 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |      1713.3262 |      25.9080 |               25.9080 |     32 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |         0.0002 |       4.4672 |                4.4672 |     32 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |      4947.1213 |     322.5262 |             1612.6311 |     32 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |      3325.7491 |      53.3881 |              373.7168 |     32 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |      1927.9605 |      23.0686 |               23.0686 |     32 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1600
Total latency (us): 16788.4

[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #0: GFLOPs: 0.0000. Time: 0.0137 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #1: GFLOPs: 0.0000. Time: 0.0133 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #2: GFLOPs: 0.0000. Time: 0.0136 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #3: GFLOPs: 0.0000. Time: 0.0136 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #4: GFLOPs: 0.0000. Time: 0.0137 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #5: GFLOPs: 0.0000. Time: 0.0141 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #6: GFLOPs: 0.0000. Time: 0.0136 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #7: GFLOPs: 0.0000. Time: 0.0138 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #8: GFLOPs: 0.0000. Time: 0.0138 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #9: GFLOPs: 0.0000. Time: 0.0138 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #10: GFLOPs: 0.0000. Time: 0.0137 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #11: GFLOPs: 0.0000. Time: 0.0135 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #12: GFLOPs: 0.0000. Time: 0.0140 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #13: GFLOPs: 0.0000. Time: 0.0133 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #14: GFLOPs: 0.0000. Time: 0.0138 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #15: GFLOPs: 0.0000. Time: 0.0137 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #16: GFLOPs: 0.0000. Time: 0.0139 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #17: GFLOPs: 0.0000. Time: 0.0140 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #18: GFLOPs: 0.0000. Time: 0.0137 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #19: GFLOPs: 0.0000. Time: 0.0137 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #20: GFLOPs: 0.0000. Time: 0.0137 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #21: GFLOPs: 0.0000. Time: 0.0138 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #22: GFLOPs: 0.0000. Time: 0.0137 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #23: GFLOPs: 0.0000. Time: 0.0133 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #24: GFLOPs: 0.0000. Time: 0.0137 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #25: GFLOPs: 0.0000. Time: 0.0137 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #26: GFLOPs: 0.0000. Time: 0.0138 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #27: GFLOPs: 0.0000. Time: 0.0137 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #28: GFLOPs: 0.0000. Time: 0.0138 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #29: GFLOPs: 0.0000. Time: 0.0137 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #30: GFLOPs: 0.0000. Time: 0.0139 ms. Best GFLOPs: 0.0000
[14:04:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #50: "fused_image_resize2d_concatenate_1"] Trial #31: GFLOPs: 0.0000. Time: 0.0137 ms. Best GFLOPs: 0.0000
[14:04:24] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #50: "fused_image_resize2d_concatenate_1"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |      3333.8786 |     478.6984 |              478.6984 |     32 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |      2960.8178 |      60.0268 |              120.0537 |     32 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |      3729.7200 |     213.9931 |             1711.9447 |     32 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |      2831.4273 |      31.4766 |              283.2898 |     32 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |         0.0002 |       4.0251 |                8.0501 |     32 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |      3577.2919 |      99.3648 |               99.3648 |     32 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |      1641.9450 |     971.6545 |              971.6545 |     32 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |      2242.5252 |      79.1380 |              158.2760 |     32 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |      2992.4470 |     266.6006 |             1066.4024 |     32 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |      1500.1992 |      59.2350 |              296.1749 |     32 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |         0.0004 |       2.8040 |                5.6080 |     32 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |      2711.9545 |     130.8790 |              130.8790 |     32 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |       491.6898 |      29.7408 |               29.7408 |     32 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |         0.0002 |       4.1701 |                4.1701 |     32 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |      1750.6945 |     202.5435 |              202.5435 |     32 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |      2848.2262 |     560.0785 |             2800.3924 |     32 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |      2012.7442 |      88.1296 |              528.7778 |     32 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |      1713.3262 |      25.9080 |               25.9080 |     32 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |         0.0002 |       4.4672 |                4.4672 |     32 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |      4947.1213 |     322.5262 |             1612.6311 |     32 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |      3325.7491 |      53.3881 |              373.7168 |     32 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |      1927.9605 |      23.0686 |               23.0686 |     32 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |         0.0001 |      13.3191 |               13.3191 |     32 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |            N/A |          N/A |                   N/A |      0 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1632
Total latency (us): 16801.7

[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #0: GFLOPs: 2147.3976. Time: 0.0828 ms. Best GFLOPs: 2147.3976
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #1: GFLOPs: 20.9325. Time: 8.4988 ms. Best GFLOPs: 2147.3976
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #2: GFLOPs: 10.3025. Time: 17.2678 ms. Best GFLOPs: 2147.3976
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #3: GFLOPs: 190.5697. Time: 0.9335 ms. Best GFLOPs: 2147.3976
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #4: GFLOPs: 3069.7393. Time: 0.0580 ms. Best GFLOPs: 3069.7393
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #5: GFLOPs: 3042.7936. Time: 0.0585 ms. Best GFLOPs: 3069.7393
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #6: GFLOPs: 818.4952. Time: 0.2174 ms. Best GFLOPs: 3069.7393
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #7: GFLOPs: 41.5482. Time: 4.2818 ms. Best GFLOPs: 3069.7393
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #8: GFLOPs: 125.8161. Time: 1.4140 ms. Best GFLOPs: 3069.7393
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #9: GFLOPs: 75.9014. Time: 2.3439 ms. Best GFLOPs: 3069.7393
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #10: GFLOPs: 1214.4133. Time: 0.1465 ms. Best GFLOPs: 3069.7393
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #11: GFLOPs: 2415.7769. Time: 0.0736 ms. Best GFLOPs: 3069.7393
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #12: GFLOPs: 56.7279. Time: 3.1361 ms. Best GFLOPs: 3069.7393
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #13: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 52, 52), "float32"], placeholder_1: T.Buffer[(128, 256, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 128, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw_local = T.alloc_buffer([1, 128, 52, 52], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 256, 52, 52], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([128, 256, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(1, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(16, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(416, thread="threadIdx.x"):
                    for i1_3_init, i2_4_init in T.grid(2, 26):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 2 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 52 * 2 + i1_3_init)
                            yy = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 52 // 26 * 26 + i2_4_init)
                            xx = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 2 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 26)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [128, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(64, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(7):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(416, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(256, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 1664 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 2704)
                                        v2 = T.axis.spatial(52, (ax0_ax1_ax2_ax3_fused_0 * 1664 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 2704 // 52)
                                        v3 = T.axis.spatial(52, (ax0_ax1_ax2_ax3_fused_0 * 1664 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 52)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 416 + ax0_ax1_ax2_ax3_fused_1) * 4 + ax0_ax1_ax2_ax3_fused_2 < 10816)
                                        T.reads(placeholder[v0, v1, v2, v3])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(2):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(416, thread="threadIdx.x"):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(128, (ax0_ax1_ax2_ax3_fused_0 * 416 + ax0_ax1_ax2_ax3_fused_1) // 4)
                                    v1 = T.axis.spatial(256, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 416 + ax0_ax1_ax2_ax3_fused_1) % 4)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 416 + ax0_ax1_ax2_ax3_fused_1 < 512)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 2, 1, 1, 4, 1, 1, 1, 1, 26, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 2 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 52 * 2 + i1_3)
                                yy = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 52 // 26 * 26 + i2_4)
                                xx = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 2 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 26)
                                rc = T.axis.reduce(256, i4_0 * 4 + i4_2)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [128, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 2, 26, 1):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(128, i0_1_i1_1_i2_1_i3_1_fused // 2 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 52 * 2 + ax1)
                            v2 = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 52 // 26 * 26 + ax2)
                            v3 = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 2 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 26 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                            T.writes(T_leaky_relu[v0, v1, v2, v3])
                            T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 8, 8, 2, 1])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 1, 2, 1, 26])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 2, 26, 1, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[64, 1, 4])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109, l110 = sch.split(loop=l107, factors=[None, 416, 4])
sch.vectorize(loop=l110)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b87)
l118, l119 = sch.split(loop=l117, factors=[None, 416])
sch.bind(loop=l119, thread_axis="threadIdx.x")
b120 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b120, ann_key="meta_schedule.unroll_explicit")
b121, b122, b123, b124 = sch.get_child_blocks(b120)
l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b121)
sch.annotate(block_or_loop=l125, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l125, ann_key="pragma_unroll_explicit", ann_val=1)
l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l134, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l134, ann_key="pragma_unroll_explicit", ann_val=1)
l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l142, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l142, ann_key="pragma_unroll_explicit", ann_val=1)
l162, l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
b169 = sch.get_block(name="conv2d_nchw", func_name="main")
l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b169)
b190 = sch.decompose_reduction(block=b169, loop=l173)
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #14: GFLOPs: 7.9497. Time: 22.3783 ms. Best GFLOPs: 3069.7393
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #15: GFLOPs: 22.1676. Time: 8.0253 ms. Best GFLOPs: 3069.7393
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #16: GFLOPs: 348.6178. Time: 0.5103 ms. Best GFLOPs: 3069.7393
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #17: GFLOPs: 89.6874. Time: 1.9836 ms. Best GFLOPs: 3069.7393
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #18: GFLOPs: 247.6338. Time: 0.7184 ms. Best GFLOPs: 3069.7393
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #19: GFLOPs: 2489.9933. Time: 0.0714 ms. Best GFLOPs: 3069.7393
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #20: GFLOPs: 1843.8494. Time: 0.0965 ms. Best GFLOPs: 3069.7393
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #21: GFLOPs: 1076.4200. Time: 0.1653 ms. Best GFLOPs: 3069.7393
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #22: GFLOPs: 266.8726. Time: 0.6666 ms. Best GFLOPs: 3069.7393
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #23: GFLOPs: 12.2763. Time: 14.4914 ms. Best GFLOPs: 3069.7393
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #24: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 52, 52), "float32"], placeholder_1: T.Buffer[(128, 256, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 128, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw_local = T.alloc_buffer([1, 128, 52, 52], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 256, 52, 52], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([128, 256, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(2, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(169, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(128, thread="threadIdx.x"):
                    for i1_4_init in T.serial(8):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(128, i0_2_i1_2_i2_2_i3_2_fused // 8 * 8 + i1_4_init)
                            yy = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 26 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 2 + i0_2_i1_2_i2_2_i3_2_fused % 8 // 4)
                            xx = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 13 * 4 + i0_2_i1_2_i2_2_i3_2_fused % 4)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [128, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(32, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(85):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(128, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(256, i4_0 * 8 + (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1) // 1352)
                                    v2 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 26 + (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1) % 1352 // 52)
                                    v3 = T.axis.spatial(52, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1) % 52)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1 < 10816)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(8):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(128, thread="threadIdx.x"):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(128, (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1) // 8)
                                    v1 = T.axis.spatial(256, i4_0 * 8 + (ax0_ax1_ax2_ax3_fused_0 * 128 + ax0_ax1_ax2_ax3_fused_1) % 8)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(4, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 8, 1, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(128, i0_2_i1_2_i2_2_i3_2_fused // 8 * 8 + i1_4)
                                yy = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 26 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 2 + i0_2_i1_2_i2_2_i3_2_fused % 8 // 4)
                                xx = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 13 * 4 + i0_2_i1_2_i2_2_i3_2_fused % 4)
                                rc = T.axis.reduce(256, i4_0 * 8 + i4_1 * 2 + i4_2)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [128, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 8, 1, 1):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(128, i0_2_i1_2_i2_2_i3_2_fused // 8 * 8 + ax1)
                            v2 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 26 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 2 + i0_2_i1_2_i2_2_i3_2_fused % 8 // 4 + ax2)
                            v3 = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 13 * 4 + i0_2_i1_2_i2_2_i3_2_fused % 4 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                            T.writes(T_leaky_relu[v0, v1, v2, v3])
                            T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 8])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[2, 13, 2, 1, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 13, 4, 1, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[32, 4, 2])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109 = sch.split(loop=l107, factors=[None, 128])
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b87)
l117, l118 = sch.split(loop=l116, factors=[None, 128])
sch.bind(loop=l118, thread_axis="threadIdx.x")
b119 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b119, ann_key="meta_schedule.unroll_explicit")
b120, b121, b122, b123 = sch.get_child_blocks(b119)
l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b120)
sch.annotate(block_or_loop=l124, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l124, ann_key="pragma_unroll_explicit", ann_val=1)
l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b121)
sch.annotate(block_or_loop=l132, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l132, ann_key="pragma_unroll_explicit", ann_val=1)
l140, l141, l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l140, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l140, ann_key="pragma_unroll_explicit", ann_val=1)
l160, l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l160, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l160, ann_key="pragma_unroll_explicit", ann_val=1)
b167 = sch.get_block(name="conv2d_nchw", func_name="main")
l168, l169, l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b167)
b188 = sch.decompose_reduction(block=b167, loop=l171)
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #25: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 52, 52), "float32"], placeholder_1: T.Buffer[(128, 256, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 128, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw_local = T.alloc_buffer([1, 128, 52, 52], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 256, 52, 52], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([128, 256, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(4, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(4, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(104, thread="threadIdx.x"):
                    for i2_3_init, i3_3_init, i1_4_init, i3_4_init in T.grid(2, 13, 2, 4):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused * 32 + i0_1_i1_1_i2_1_i3_1_fused // 2 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 2 + i1_4_init)
                            yy = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 2 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 13 * 2 + i2_3_init)
                            xx = T.axis.spatial(52, i3_3_init * 4 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [128, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(128, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(52):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(104, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(256, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1) // 2704)
                                    v2 = T.axis.spatial(52, (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1) % 2704 // 52)
                                    v3 = T.axis.spatial(52, (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1) % 52)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(1):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(104, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(2):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused * 32 + (ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) // 2)
                                        v1 = T.axis.spatial(256, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 2)
                                        v2 = T.axis.spatial(1, 0)
                                        v3 = T.axis.spatial(1, 0)
                                        T.where(ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2 < 64)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 1, 2, 13, 2, 1, 1, 1, 2, 1, 4):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused * 32 + i0_1_i1_1_i2_1_i3_1_fused // 2 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 2 + i1_4)
                                yy = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 2 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 13 * 2 + i2_3)
                                xx = T.axis.spatial(52, i3_3 * 4 + i3_4)
                                rc = T.axis.reduce(256, i4_0 * 2 + i4_2)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [128, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 2, 2, 52):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused * 32 + i0_1_i1_1_i2_1_i3_1_fused // 2 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 2 + ax1)
                            v2 = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 2 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 13 * 2 + ax2)
                            v3 = T.axis.spatial(52, ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                            T.writes(T_leaky_relu[v0, v1, v2, v3])
                            T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[4, 2, 8, 1, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 2, 13, 2, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 1, 13, 4])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[128, 1, 2])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109 = sch.split(loop=l107, factors=[None, 104])
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b87)
l117, l118, l119 = sch.split(loop=l116, factors=[None, 104, 2])
sch.vectorize(loop=l119)
sch.bind(loop=l118, thread_axis="threadIdx.x")
b120 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b120, ann_key="meta_schedule.unroll_explicit")
b121, b122, b123, b124 = sch.get_child_blocks(b120)
l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b121)
sch.annotate(block_or_loop=l125, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l125, ann_key="pragma_unroll_explicit", ann_val=1)
l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l133, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l133, ann_key="pragma_unroll_explicit", ann_val=1)
l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l142, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l142, ann_key="pragma_unroll_explicit", ann_val=1)
l162, l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
b169 = sch.get_block(name="conv2d_nchw", func_name="main")
l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b169)
b190 = sch.decompose_reduction(block=b169, loop=l173)
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #26: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 52, 52), "float32"], placeholder_1: T.Buffer[(128, 256, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 128, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 128, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw_local = T.alloc_buffer([1, 128, 52, 52], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 256, 52, 52], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([128, 256, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(2, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(1, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(32, thread="threadIdx.x"):
                    for i1_3_init, i3_3_init, i1_4_init, i2_4_init in T.grid(8, 26, 2, 13):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused // 8 * 16 + i1_3_init * 2 + i1_4_init)
                            yy = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 8 // 2 * 13 + i2_4_init)
                            xx = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 2 * 26 + i3_3_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [128, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(128, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(169):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(256, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) // 2704)
                                    v2 = T.axis.spatial(52, (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 2704 // 52)
                                    v3 = T.axis.spatial(52, (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 52)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(4):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(32, thread="threadIdx.x"):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused * 64 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) // 2)
                                    v1 = T.axis.spatial(256, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 32 + ax0_ax1_ax2_ax3_fused_1) % 2)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(2, 1, 1, 1, 8, 1, 26, 1, 1, 1, 1, 2, 13, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused // 8 * 16 + i1_3 * 2 + i1_4)
                                yy = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 8 // 2 * 13 + i2_4)
                                xx = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 2 * 26 + i3_3)
                                rc = T.axis.reduce(256, i4_0 * 2 + i4_1)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [128, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 16, 13, 26):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused * 64 + i0_2_i1_2_i2_2_i3_2_fused // 8 * 16 + ax1)
                            v2 = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 8 // 2 * 13 + ax2)
                            v3 = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 2 * 26 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                            T.writes(T_leaky_relu[v0, v1, v2, v3])
                            T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[2, 1, 4, 8, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 1, 4, 1, 13])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 2, 26, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[128, 2, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109 = sch.split(loop=l107, factors=[None, 32])
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b87)
l117, l118 = sch.split(loop=l116, factors=[None, 32])
sch.bind(loop=l118, thread_axis="threadIdx.x")
b119 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b119, ann_key="meta_schedule.unroll_explicit")
b120, b121, b122, b123 = sch.get_child_blocks(b119)
l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b120)
sch.annotate(block_or_loop=l124, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l124, ann_key="pragma_unroll_explicit", ann_val=1)
l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b121)
sch.annotate(block_or_loop=l132, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l132, ann_key="pragma_unroll_explicit", ann_val=1)
l140, l141, l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l140, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l140, ann_key="pragma_unroll_explicit", ann_val=1)
l160, l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l160, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l160, ann_key="pragma_unroll_explicit", ann_val=1)
b167 = sch.get_block(name="conv2d_nchw", func_name="main")
l168, l169, l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b167)
b188 = sch.decompose_reduction(block=b167, loop=l171)
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #27: GFLOPs: 184.5431. Time: 0.9640 ms. Best GFLOPs: 3069.7393
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #28: GFLOPs: 2831.2535. Time: 0.0628 ms. Best GFLOPs: 3069.7393
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #29: GFLOPs: 959.9828. Time: 0.1853 ms. Best GFLOPs: 3069.7393
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #30: GFLOPs: 3345.0504. Time: 0.0532 ms. Best GFLOPs: 3345.0504
[14:04:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"] Trial #31: GFLOPs: 1770.4234. Time: 0.1005 ms. Best GFLOPs: 3345.0504
[14:04:27] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |      3333.8786 |     478.6984 |              478.6984 |     32 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |      2960.8178 |      60.0268 |              120.0537 |     32 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |      3729.7200 |     213.9931 |             1711.9447 |     32 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |      2831.4273 |      31.4766 |              283.2898 |     32 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |         0.0002 |       4.0251 |                8.0501 |     32 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |      3577.2919 |      99.3648 |               99.3648 |     32 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |      1641.9450 |     971.6545 |              971.6545 |     32 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |      2242.5252 |      79.1380 |              158.2760 |     32 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |      2992.4470 |     266.6006 |             1066.4024 |     32 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |      1500.1992 |      59.2350 |              296.1749 |     32 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |         0.0004 |       2.8040 |                5.6080 |     32 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |      2711.9545 |     130.8790 |              130.8790 |     32 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |       491.6898 |      29.7408 |               29.7408 |     32 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |         0.0002 |       4.1701 |                4.1701 |     32 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |      1750.6945 |     202.5435 |              202.5435 |     32 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |      2848.2262 |     560.0785 |             2800.3924 |     32 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |      2012.7442 |      88.1296 |              528.7778 |     32 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |      1713.3262 |      25.9080 |               25.9080 |     32 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |         0.0002 |       4.4672 |                4.4672 |     32 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |      4947.1213 |     322.5262 |             1612.6311 |     32 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |      3325.7491 |      53.3881 |              373.7168 |     32 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |      1927.9605 |      23.0686 |               23.0686 |     32 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |         0.0001 |      13.3191 |               13.3191 |     32 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |      3345.0504 |      53.1835 |              212.7341 |     32 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |            N/A |          N/A |                   N/A |      0 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1664
Total latency (us): 17014.4

[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #0: GFLOPs: 22.8885. Time: 69.7412 ms. Best GFLOPs: 22.8885
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #1: GFLOPs: 106.4475. Time: 14.9958 ms. Best GFLOPs: 106.4475
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #2: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 52, 52), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 256, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw_local = T.alloc_buffer([1, 256, 52, 52], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 54, 54], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([256, 128, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(8, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(16, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(52, thread="threadIdx.x"):
                    for i3_3_init, i1_4_init in T.grid(13, 8):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 4 * 128 + i0_1_i1_1_i2_1_i3_1_fused // 2 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 26 * 8 + i1_4_init)
                            yy = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 2 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 26)
                            xx = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 4 * 13 + i3_3_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(64, 3, 3):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(7):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(128, i4_0 * 2 + ((ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) * 4 + ax0_ax1_ax2_ax3_fused_2) % 1352 // 676)
                                        v2 = T.axis.spatial(54, i5_0 + ((ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) * 4 + ax0_ax1_ax2_ax3_fused_2) % 676 // 13)
                                        v3 = T.axis.spatial(54, i0_0_i1_0_i2_0_i3_0_fused % 4 * 13 + i6_0 + ((ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) * 4 + ax0_ax1_ax2_ax3_fused_2) % 13)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) * 4 + ax0_ax1_ax2_ax3_fused_2 < 1352)
                                        T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 53 and 1 <= v3 and v3 < 53, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(3):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(2):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 4 * 128 + (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) // 2)
                                        v1 = T.axis.spatial(128, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 2)
                                        v2, v3 = T.axis.remap("SS", [i5_0, i6_0])
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) * 2 + ax0_ax1_ax2_ax3_fused_2 < 256)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(2, 1, 1, 1, 1, 1, 13, 1, 1, 1, 1, 8, 1, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 4 * 128 + i0_1_i1_1_i2_1_i3_1_fused // 2 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 26 * 8 + i1_4)
                                yy = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 2 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 26)
                                xx = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 4 * 13 + i3_3)
                                rc = T.axis.reduce(128, i4_0 * 2 + i4_1)
                                ry, rx = T.axis.remap("RR", [i5_0, i6_0])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 8, 1, 13):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused // 4 * 128 + i0_1_i1_1_i2_1_i3_1_fused // 2 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 26 * 8 + ax1)
                            v2 = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 2 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 26 + ax2)
                            v3 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 4 * 13 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                            T.writes(T_leaky_relu[v0, v1, v2, v3])
                            T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[2, 8, 2, 1, 8])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 2, 26, 1, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[4, 1, 1, 13, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[64, 2, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109, l110 = sch.split(loop=l107, factors=[None, 52, 4])
sch.vectorize(loop=l110)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b87)
l118, l119, l120 = sch.split(loop=l117, factors=[None, 52, 2])
sch.vectorize(loop=l120)
sch.bind(loop=l119, thread_axis="threadIdx.x")
b121 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b121, ann_key="meta_schedule.unroll_explicit")
b122, b123, b124, b125 = sch.get_child_blocks(b121)
l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l126, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l126, ann_key="pragma_unroll_explicit", ann_val=1)
l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l135, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l135, ann_key="pragma_unroll_explicit", ann_val=1)
l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161, l162, l163 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l144, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l144, ann_key="pragma_unroll_explicit", ann_val=1)
l164, l165, l166, l167, l168, l169, l170 = sch.get_loops(block=b125)
sch.annotate(block_or_loop=l164, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l164, ann_key="pragma_unroll_explicit", ann_val=1)
b171 = sch.get_block(name="conv2d_nchw", func_name="main")
l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189, l190, l191 = sch.get_loops(block=b171)
b192 = sch.decompose_reduction(block=b171, loop=l175)
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #3: GFLOPs: 603.4992. Time: 2.6450 ms. Best GFLOPs: 603.4992
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #4: GFLOPs: 4451.1613. Time: 0.3586 ms. Best GFLOPs: 4451.1613
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #5: GFLOPs: 8.6929. Time: 183.6282 ms. Best GFLOPs: 4451.1613
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #6: GFLOPs: 21.6800. Time: 73.6285 ms. Best GFLOPs: 4451.1613
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #7: GFLOPs: 1160.7005. Time: 1.3753 ms. Best GFLOPs: 4451.1613
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #8: GFLOPs: 65.9590. Time: 24.2009 ms. Best GFLOPs: 4451.1613
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #9: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 52, 52), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 256, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw_local = T.alloc_buffer([1, 256, 52, 52], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 54, 54], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([256, 128, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(4, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(32, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(104, thread="threadIdx.x"):
                    for i3_3_init, i1_4_init, i3_4_init in T.grid(2, 2, 13):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(256, i0_1_i1_1_i2_1_i3_1_fused // 2 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 2 + i1_4_init)
                            yy = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused // 2 * 26 + i0_1_i1_1_i2_1_i3_1_fused % 2 * 13 + i0_2_i1_2_i2_2_i3_2_fused % 13)
                            xx = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 2 * 26 + i3_3_init * 13 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(128, 3, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(7):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(104, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(128, i4_0 + 0)
                                    v2 = T.axis.spatial(54, i0_0_i1_0_i2_0_i3_0_fused // 2 * 26 + i5_0 + (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1) % 728 // 28)
                                    v3 = T.axis.spatial(54, i0_0_i1_0_i2_0_i3_0_fused % 2 * 26 + (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1) % 28)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 53 and 1 <= v3 and v3 < 53, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(2):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(104, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(256, (ax0_ax1_ax2_ax3_fused_0 * 416 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 3)
                                        v1, v2 = T.axis.remap("SS", [i4_0, i5_0])
                                        v3 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 416 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 3)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1) * 4 + ax0_ax1_ax2_ax3_fused_2 < 768)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 1, 1, 2, 1, 1, 3, 1, 2, 1, 13):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(256, i0_1_i1_1_i2_1_i3_1_fused // 2 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 2 + i1_4)
                                yy = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused // 2 * 26 + i0_1_i1_1_i2_1_i3_1_fused % 2 * 13 + i0_2_i1_2_i2_2_i3_2_fused % 13)
                                xx = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 2 * 26 + i3_3 * 13 + i3_4)
                                rc, ry, rx = T.axis.remap("RRR", [i4_0, i5_0, i6_2])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 2, 1, 26):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(256, i0_1_i1_1_i2_1_i3_1_fused // 2 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 13 * 2 + ax1)
                            v2 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused // 2 * 26 + i0_1_i1_1_i2_1_i3_1_fused % 2 * 13 + i0_2_i1_2_i2_2_i3_2_fused % 13 + ax2)
                            v3 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused % 2 * 26 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                            T.writes(T_leaky_relu[v0, v1, v2, v3])
                            T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 16, 8, 1, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[2, 2, 13, 1, 1])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[2, 1, 1, 2, 13])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[128, 1, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109 = sch.split(loop=l107, factors=[None, 104])
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b87)
l117, l118, l119 = sch.split(loop=l116, factors=[None, 104, 4])
sch.vectorize(loop=l119)
sch.bind(loop=l118, thread_axis="threadIdx.x")
b120 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b120, ann_key="meta_schedule.unroll_explicit")
b121, b122, b123, b124 = sch.get_child_blocks(b120)
l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b121)
sch.annotate(block_or_loop=l125, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l125, ann_key="pragma_unroll_explicit", ann_val=1)
l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l133, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l133, ann_key="pragma_unroll_explicit", ann_val=1)
l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l142, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l142, ann_key="pragma_unroll_explicit", ann_val=1)
l162, l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
b169 = sch.get_block(name="conv2d_nchw", func_name="main")
l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b169)
b190 = sch.decompose_reduction(block=b169, loop=l173)
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #10: GFLOPs: 1012.3283. Time: 1.5768 ms. Best GFLOPs: 4451.1613
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #11: GFLOPs: 105.9430. Time: 15.0672 ms. Best GFLOPs: 4451.1613
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #12: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 52, 52), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 256, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw_local = T.alloc_buffer([1, 256, 52, 52], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 54, 54], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([256, 128, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(16, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(52, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(52, thread="threadIdx.x"):
                    for i1_3_init, i3_3_init, i2_4_init, i3_4_init in T.grid(2, 2, 2, 2):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused * 16 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 4 + i0_2_i1_2_i2_2_i3_2_fused // 26 * 2 + i1_3_init)
                            yy = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 26 * 2 + i2_4_init)
                            xx = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 13 * 4 + i3_3_init * 2 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(64, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(113):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(128, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) // 2916)
                                    v2 = T.axis.spatial(54, (ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) % 2916 // 54)
                                    v3 = T.axis.spatial(54, (ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) % 54)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1 < 5832)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 53 and 1 <= v3 and v3 < 53, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(3):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(52, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(2):
                                    with T.block("placeholder_shared"):
                                        v0 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused * 16 + (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) // 18)
                                        v1 = T.axis.spatial(128, i4_0 * 2 + (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 18 // 9)
                                        v2 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 9 // 3)
                                        v3 = T.axis.spatial(3, (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1 * 2 + ax0_ax1_ax2_ax3_fused_2) % 3)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 52 + ax0_ax1_ax2_ax3_fused_1) * 2 + ax0_ax1_ax2_ax3_fused_2 < 288)
                                        T.reads(placeholder_1[v0, v1, v2, v3])
                                        T.writes(placeholder_shared[v0, v1, v2, v3])
                                        placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 2, 1, 2, 2, 3, 3, 1, 1, 2, 2):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused * 16 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 4 + i0_2_i1_2_i2_2_i3_2_fused // 26 * 2 + i1_3)
                                yy = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 26 * 2 + i2_4)
                                xx = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 13 * 4 + i3_3 * 2 + i3_4)
                                rc = T.axis.reduce(128, i4_0 * 2 + i4_2)
                                ry, rx = T.axis.remap("RR", [i5_2, i6_2])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 2, 2, 4):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused * 16 + i0_1_i1_1_i2_1_i3_1_fused // 13 * 4 + i0_2_i1_2_i2_2_i3_2_fused // 26 * 2 + ax1)
                            v2 = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 26 * 2 + ax2)
                            v3 = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 13 * 4 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                            T.writes(T_leaky_relu[v0, v1, v2, v3])
                            T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[16, 4, 2, 2, 1])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 1, 26, 1, 2])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 13, 1, 2, 2])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[64, 1, 2])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 3])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109 = sch.split(loop=l107, factors=[None, 52])
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b87)
l117, l118, l119 = sch.split(loop=l116, factors=[None, 52, 2])
sch.vectorize(loop=l119)
sch.bind(loop=l118, thread_axis="threadIdx.x")
b120 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b120, ann_key="meta_schedule.unroll_explicit")
b121, b122, b123, b124 = sch.get_child_blocks(b120)
l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b121)
sch.annotate(block_or_loop=l125, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l125, ann_key="pragma_unroll_explicit", ann_val=1)
l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l133, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l133, ann_key="pragma_unroll_explicit", ann_val=1)
l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l142, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l142, ann_key="pragma_unroll_explicit", ann_val=1)
l162, l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b124)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
b169 = sch.get_block(name="conv2d_nchw", func_name="main")
l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b169)
b190 = sch.decompose_reduction(block=b169, loop=l173)
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #13: GFLOPs: 10.5038. Time: 151.9706 ms. Best GFLOPs: 4451.1613
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #14: GFLOPs: 2785.0453. Time: 0.5732 ms. Best GFLOPs: 4451.1613
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #15: GFLOPs: 26.9285. Time: 59.2780 ms. Best GFLOPs: 4451.1613
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #16: GFLOPs: 4085.9511. Time: 0.3907 ms. Best GFLOPs: 4451.1613
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #17: GFLOPs: 84.6876. Time: 18.8489 ms. Best GFLOPs: 4451.1613
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #18: GFLOPs: 1520.2869. Time: 1.0500 ms. Best GFLOPs: 4451.1613
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #19: GFLOPs: 14.5935. Time: 109.3820 ms. Best GFLOPs: 4451.1613
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #20: GFLOPs: 1753.7264. Time: 0.9102 ms. Best GFLOPs: 4451.1613
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #21: GFLOPs: 2317.7019. Time: 0.6887 ms. Best GFLOPs: 4451.1613
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #22: GFLOPs: 120.8874. Time: 13.2046 ms. Best GFLOPs: 4451.1613
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #23: GFLOPs: 303.7402. Time: 5.2554 ms. Best GFLOPs: 4451.1613
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #24: GFLOPs: 2518.6950. Time: 0.6338 ms. Best GFLOPs: 4451.1613
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #25: GFLOPs: 1710.4748. Time: 0.9332 ms. Best GFLOPs: 4451.1613
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #26: GFLOPs: 1081.4056. Time: 1.4761 ms. Best GFLOPs: 4451.1613
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #27: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 128, 52, 52), "float32"], placeholder_1: T.Buffer[(256, 128, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], T_leaky_relu: T.Buffer[(1, 256, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw_local = T.alloc_buffer([1, 256, 52, 52], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 128, 54, 54], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([256, 128, 3, 3], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(2, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(16, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(104, thread="threadIdx.x"):
                    for i1_3_init, i1_4_init, i2_4_init in T.grid(2, 4, 26):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused * 128 + i0_1_i1_1_i2_1_i3_1_fused // 2 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 52 * 8 + i1_3_init * 4 + i1_4_init)
                            yy = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 52 // 26 * 26 + i2_4_init)
                            xx = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 2 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 26)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(32, 3, 3):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(104):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(104, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(128, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1) % 10816 // 2704)
                                    v2 = T.axis.spatial(54, i5_0 + (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1) % 2704 // 52)
                                    v3 = T.axis.spatial(54, i6_0 + (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1) % 52)
                                    T.reads(placeholder[v0, v1, v2 - 1, v3 - 1])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = T.if_then_else(1 <= v2 and v2 < 53 and 1 <= v3 and v3 < 53, placeholder[v0, v1, v2 - 1, v3 - 1], T.float32(0), dtype="float32")
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(5):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(104, thread="threadIdx.x"):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused * 128 + (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1) // 4)
                                    v1 = T.axis.spatial(128, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1) % 4)
                                    v2, v3 = T.axis.remap("SS", [i5_0, i6_0])
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 104 + ax0_ax1_ax2_ax3_fused_1 < 512)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(4, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 4, 26, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused * 128 + i0_1_i1_1_i2_1_i3_1_fused // 2 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 52 * 8 + i1_3 * 4 + i1_4)
                                yy = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 52 // 26 * 26 + i2_4)
                                xx = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 2 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 26)
                                rc = T.axis.reduce(128, i4_0 * 4 + i4_1)
                                ry, rx = T.axis.remap("RR", [i5_0, i6_0])
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 128, 52, 52], "float32"], ["TENSOR", [256, 128, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 8, 26, 1):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused * 128 + i0_1_i1_1_i2_1_i3_1_fused // 2 * 16 + i0_2_i1_2_i2_2_i3_2_fused // 52 * 8 + ax1)
                            v2 = T.axis.spatial(52, i0_2_i1_2_i2_2_i3_2_fused % 52 // 26 * 26 + ax2)
                            v3 = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 2 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 26 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                            T.writes(T_leaky_relu[v0, v1, v2, v3])
                            T_leaky_relu[v0, v1, v2, v3] = T.Select(T.float32(0) < conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0], (conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]) * T.float32(0.10000000149011612))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_leaky_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16])
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[2, 8, 2, 2, 4])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26])
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 1, 2, 1, 26])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36])
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 2, 26, 1, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46])
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[32, 4, 1])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54])
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60])
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[3, 1, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66])
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
sch.enter_postproc()
sch.unannotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch")
l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b74)
l108, l109 = sch.split(loop=l107, factors=[None, 104])
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch")
l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b87)
l117, l118 = sch.split(loop=l116, factors=[None, 104])
sch.bind(loop=l118, thread_axis="threadIdx.x")
b119 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b119, ann_key="meta_schedule.unroll_explicit")
b120, b121, b122, b123 = sch.get_child_blocks(b119)
l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b120)
sch.annotate(block_or_loop=l124, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l124, ann_key="pragma_unroll_explicit", ann_val=1)
l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b121)
sch.annotate(block_or_loop=l132, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l132, ann_key="pragma_unroll_explicit", ann_val=1)
l140, l141, l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l140, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l140, ann_key="pragma_unroll_explicit", ann_val=1)
l160, l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l160, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l160, ann_key="pragma_unroll_explicit", ann_val=1)
b167 = sch.get_block(name="conv2d_nchw", func_name="main")
l168, l169, l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b167)
b188 = sch.decompose_reduction(block=b167, loop=l171)
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #28: GFLOPs: 190.9375. Time: 8.3602 ms. Best GFLOPs: 4451.1613
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #29: GFLOPs: 160.0139. Time: 9.9758 ms. Best GFLOPs: 4451.1613
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #30: GFLOPs: 706.7120. Time: 2.2587 ms. Best GFLOPs: 4451.1613
[14:04:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"] Trial #31: GFLOPs: 1494.7010. Time: 1.0680 ms. Best GFLOPs: 4451.1613
[14:04:29] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |      3333.8786 |     478.6984 |              478.6984 |     32 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |      2960.8178 |      60.0268 |              120.0537 |     32 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |      3729.7200 |     213.9931 |             1711.9447 |     32 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |      2831.4273 |      31.4766 |              283.2898 |     32 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |         0.0002 |       4.0251 |                8.0501 |     32 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |      3577.2919 |      99.3648 |               99.3648 |     32 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |      1641.9450 |     971.6545 |              971.6545 |     32 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |      2242.5252 |      79.1380 |              158.2760 |     32 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |      2992.4470 |     266.6006 |             1066.4024 |     32 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |      1500.1992 |      59.2350 |              296.1749 |     32 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |         0.0004 |       2.8040 |                5.6080 |     32 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |      2711.9545 |     130.8790 |              130.8790 |     32 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |       491.6898 |      29.7408 |               29.7408 |     32 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |         0.0002 |       4.1701 |                4.1701 |     32 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |      1750.6945 |     202.5435 |              202.5435 |     32 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |      2848.2262 |     560.0785 |             2800.3924 |     32 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |      2012.7442 |      88.1296 |              528.7778 |     32 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |      1713.3262 |      25.9080 |               25.9080 |     32 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |         0.0002 |       4.4672 |                4.4672 |     32 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |      4947.1213 |     322.5262 |             1612.6311 |     32 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |      3325.7491 |      53.3881 |              373.7168 |     32 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |      1927.9605 |      23.0686 |               23.0686 |     32 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |         0.0001 |      13.3191 |               13.3191 |     32 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |      3345.0504 |      53.1835 |              212.7341 |     32 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |      4451.1613 |     358.6184 |             1075.8553 |     32 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |            N/A |          N/A |                   N/A |      0 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1696
Total latency (us): 18090.3

[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #0: GFLOPs: 82.6345. Time: 4.2806 ms. Best GFLOPs: 82.6345
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #53: "fused_nn_conv2d_add_2"] Trial #1: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 52, 52), "float32"], placeholder_1: T.Buffer[(255, 256, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 255, 1, 1), "float32"], T_add: T.Buffer[(1, 255, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw_local = T.alloc_buffer([1, 255, 52, 52], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 256, 52, 52], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([255, 256, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(2, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(169, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(40, thread="threadIdx.x"):
                    for i1_3_init, i1_4_init in T.grid(17, 3):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(255, i0_2_i1_2_i2_2_i3_2_fused // 8 * 51 + i1_3_init * 3 + i1_4_init)
                            yy = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused // 13 * 4 + i0_2_i1_2_i2_2_i3_2_fused % 8 // 2)
                            xx = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 26 + i0_1_i1_1_i2_1_i3_1_fused % 13 * 2 + i0_2_i1_2_i2_2_i3_2_fused % 2)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [255, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(64, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(136):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(40, thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(1, 0)
                                    v1 = T.axis.spatial(256, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 40 + ax0_ax1_ax2_ax3_fused_1) // 1352)
                                    v2 = T.axis.spatial(52, (ax0_ax1_ax2_ax3_fused_0 * 40 + ax0_ax1_ax2_ax3_fused_1) % 1352 // 26)
                                    v3 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 26 + (ax0_ax1_ax2_ax3_fused_0 * 40 + ax0_ax1_ax2_ax3_fused_1) % 26)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 40 + ax0_ax1_ax2_ax3_fused_1 < 5408)
                                    T.reads(placeholder[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(26):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(40, thread="threadIdx.x"):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(255, (ax0_ax1_ax2_ax3_fused_0 * 40 + ax0_ax1_ax2_ax3_fused_1) // 4)
                                    v1 = T.axis.spatial(256, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 40 + ax0_ax1_ax2_ax3_fused_1) % 4)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 40 + ax0_ax1_ax2_ax3_fused_1 < 1020)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(2, 1, 1, 1, 17, 1, 1, 2, 1, 1, 1, 3, 1, 1):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(255, i0_2_i1_2_i2_2_i3_2_fused // 8 * 51 + i1_3 * 3 + i1_4)
                                yy = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused // 13 * 4 + i0_2_i1_2_i2_2_i3_2_fused % 8 // 2)
                                xx = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 26 + i0_1_i1_1_i2_1_i3_1_fused % 13 * 2 + i0_2_i1_2_i2_2_i3_2_fused % 2)
                                rc = T.axis.reduce(256, i4_0 * 4 + i4_1 * 2 + i4_2)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [255, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 51, 1, 1):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(255, i0_2_i1_2_i2_2_i3_2_fused // 8 * 51 + ax1)
                            v2 = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused // 13 * 4 + i0_2_i1_2_i2_2_i3_2_fused % 8 // 2 + ax2)
                            v3 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 26 + i0_1_i1_1_i2_1_i3_1_fused % 13 * 2 + i0_2_i1_2_i2_2_i3_2_fused % 2 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                            T.writes(T_add[v0, v1, v2, v3])
                            T_add[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b1)
v11, v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l16, l17, l18, l19, l20 = sch.split(loop=l4, factors=[v11, v12, v13, v14, v15])
v21, v22, v23, v24, v25 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 5, 17, 3])
l26, l27, l28, l29, l30 = sch.split(loop=l5, factors=[v21, v22, v23, v24, v25])
v31, v32, v33, v34, v35 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 13, 4, 1, 1])
l36, l37, l38, l39, l40 = sch.split(loop=l6, factors=[v31, v32, v33, v34, v35])
v41, v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[2, 13, 2, 1, 1])
l46, l47, l48, l49, l50 = sch.split(loop=l7, factors=[v41, v42, v43, v44, v45])
v51, v52, v53 = sch.sample_perfect_tile(loop=l8, n=3, max_innermost_factor=64, decision=[64, 2, 2])
l54, l55, l56 = sch.split(loop=l8, factors=[v51, v52, v53])
v57, v58, v59 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l60, l61, l62 = sch.split(loop=l9, factors=[v57, v58, v59])
v63, v64, v65 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l66, l67, l68 = sch.split(loop=l10, factors=[v63, v64, v65])
sch.reorder(l16, l26, l36, l46, l17, l27, l37, l47, l18, l28, l38, l48, l54, l60, l66, l55, l61, l67, l19, l29, l39, l49, l56, l62, l68, l20, l30, l40, l50)
l69 = sch.fuse(l16, l26, l36, l46)
sch.bind(loop=l69, thread_axis="blockIdx.x")
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="vthread.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b72 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b72, loop=l71, preserve_unit_loops=True)
b73 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b73, loop=l66, preserve_unit_loops=True)
l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b73)
l84 = sch.fuse(l80, l81, l82, l83)
v85 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b73, ann_key="meta_schedule.cooperative_fetch", ann_val=v85)
b86 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b86, loop=l66, preserve_unit_loops=True)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96 = sch.get_loops(block=b86)
l97 = sch.fuse(l93, l94, l95, l96)
v98 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b86, ann_key="meta_schedule.cooperative_fetch", ann_val=v98)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v99 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v99)
sch.enter_postproc()
sch.unannotate(block_or_loop=b73, ann_key="meta_schedule.cooperative_fetch")
l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b73)
l107, l108 = sch.split(loop=l106, factors=[None, 40])
sch.bind(loop=l108, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b86, ann_key="meta_schedule.cooperative_fetch")
l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b86)
l116, l117 = sch.split(loop=l115, factors=[None, 40])
sch.bind(loop=l117, thread_axis="threadIdx.x")
b118 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b118, ann_key="meta_schedule.unroll_explicit")
b119, b120, b121, b122 = sch.get_child_blocks(b118)
l123, l124, l125, l126, l127, l128, l129, l130 = sch.get_loops(block=b119)
sch.annotate(block_or_loop=l123, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l123, ann_key="pragma_unroll_explicit", ann_val=1)
l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b120)
sch.annotate(block_or_loop=l131, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l131, ann_key="pragma_unroll_explicit", ann_val=1)
l139, l140, l141, l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158 = sch.get_loops(block=b121)
sch.annotate(block_or_loop=l139, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l139, ann_key="pragma_unroll_explicit", ann_val=1)
l159, l160, l161, l162, l163, l164, l165 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l159, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l159, ann_key="pragma_unroll_explicit", ann_val=1)
b166 = sch.get_block(name="conv2d_nchw", func_name="main")
l167, l168, l169, l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b166)
b187 = sch.decompose_reduction(block=b166, loop=l170)
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #2: GFLOPs: 182.2046. Time: 1.9414 ms. Best GFLOPs: 182.2046
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #3: GFLOPs: 1215.8063. Time: 0.2909 ms. Best GFLOPs: 1215.8063
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #4: GFLOPs: 1162.2875. Time: 0.3043 ms. Best GFLOPs: 1215.8063
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #5: GFLOPs: 5478.3527. Time: 0.0646 ms. Best GFLOPs: 5478.3527
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #6: GFLOPs: 592.6575. Time: 0.5968 ms. Best GFLOPs: 5478.3527
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #7: GFLOPs: 34.8167. Time: 10.1596 ms. Best GFLOPs: 5478.3527
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #8: GFLOPs: 9.5287. Time: 37.1220 ms. Best GFLOPs: 5478.3527
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #9: GFLOPs: 1079.7823. Time: 0.3276 ms. Best GFLOPs: 5478.3527
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #10: GFLOPs: 2292.9538. Time: 0.1543 ms. Best GFLOPs: 5478.3527
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #11: GFLOPs: 558.9186. Time: 0.6329 ms. Best GFLOPs: 5478.3527
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #12: GFLOPs: 235.7876. Time: 1.5002 ms. Best GFLOPs: 5478.3527
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #13: GFLOPs: 1868.3839. Time: 0.1893 ms. Best GFLOPs: 5478.3527
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #14: GFLOPs: 470.9783. Time: 0.7510 ms. Best GFLOPs: 5478.3527
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #15: GFLOPs: 57.2367. Time: 6.1800 ms. Best GFLOPs: 5478.3527
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #53: "fused_nn_conv2d_add_2"] Trial #16: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 52, 52), "float32"], placeholder_1: T.Buffer[(255, 256, 1, 1), "float32"], placeholder_2: T.Buffer[(1, 255, 1, 1), "float32"], T_add: T.Buffer[(1, 255, 52, 52), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        conv2d_nchw_local = T.alloc_buffer([1, 255, 52, 52], dtype="float32", scope="local")
        pad_temp_shared = T.alloc_buffer([1, 256, 52, 52], dtype="float32", scope="shared")
        placeholder_shared = T.alloc_buffer([255, 256, 1, 1], dtype="float32", scope="shared")
        for i0_0_i1_0_i2_0_i3_0_fused in T.thread_binding(2, thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step":1024, "pragma_unroll_explicit":1}):
            for i0_1_i1_1_i2_1_i3_1_fused in T.thread_binding(340, thread="vthread.x"):
                for i0_2_i1_2_i2_2_i3_2_fused in T.thread_binding(78, thread="threadIdx.x"):
                    for i3_4_init in T.serial(13):
                        with T.block("conv2d_nchw_init"):
                            nn = T.axis.spatial(1, 0)
                            ff = T.axis.spatial(255, i0_1_i1_1_i2_1_i3_1_fused // 4 * 3 + i0_2_i1_2_i2_2_i3_2_fused // 26)
                            yy = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 26 + i0_1_i1_1_i2_1_i3_1_fused % 4 // 2 * 13 + i0_2_i1_2_i2_2_i3_2_fused % 26 // 2)
                            xx = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 2 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 13 + i3_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [255, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                            conv2d_nchw_local[nn, ff, yy, xx] = T.float32(0)
                    for i4_0, i5_0, i6_0 in T.grid(64, 1, 1):
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(18):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(78, thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(4):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(1, 0)
                                        v1 = T.axis.spatial(256, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 312 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) // 1352)
                                        v2 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 26 + (ax0_ax1_ax2_ax3_fused_0 * 312 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 1352 // 52)
                                        v3 = T.axis.spatial(52, (ax0_ax1_ax2_ax3_fused_0 * 312 + ax0_ax1_ax2_ax3_fused_1 * 4 + ax0_ax1_ax2_ax3_fused_2) % 52)
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * 78 + ax0_ax1_ax2_ax3_fused_1) * 4 + ax0_ax1_ax2_ax3_fused_2 < 5408)
                                        T.reads(placeholder[v0, v1, v2, v3])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = placeholder[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in T.serial(14):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(78, thread="threadIdx.x"):
                                with T.block("placeholder_shared"):
                                    v0 = T.axis.spatial(255, (ax0_ax1_ax2_ax3_fused_0 * 78 + ax0_ax1_ax2_ax3_fused_1) // 4)
                                    v1 = T.axis.spatial(256, i4_0 * 4 + (ax0_ax1_ax2_ax3_fused_0 * 78 + ax0_ax1_ax2_ax3_fused_1) % 4)
                                    v2 = T.axis.spatial(1, 0)
                                    v3 = T.axis.spatial(1, 0)
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * 78 + ax0_ax1_ax2_ax3_fused_1 < 1020)
                                    T.reads(placeholder_1[v0, v1, v2, v3])
                                    T.writes(placeholder_shared[v0, v1, v2, v3])
                                    placeholder_shared[v0, v1, v2, v3] = placeholder_1[v0, v1, v2, v3]
                        for i4_1, i5_1, i6_1, i0_3, i1_3, i2_3, i3_3, i4_2, i5_2, i6_2, i0_4, i1_4, i2_4, i3_4 in T.grid(1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 13):
                            with T.block("conv2d_nchw_update"):
                                nn = T.axis.spatial(1, 0)
                                ff = T.axis.spatial(255, i0_1_i1_1_i2_1_i3_1_fused // 4 * 3 + i0_2_i1_2_i2_2_i3_2_fused // 26)
                                yy = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 26 + i0_1_i1_1_i2_1_i3_1_fused % 4 // 2 * 13 + i0_2_i1_2_i2_2_i3_2_fused % 26 // 2)
                                xx = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 2 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 13 + i3_4)
                                rc = T.axis.reduce(256, i4_0 * 4 + i4_2)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                T.reads(conv2d_nchw_local[nn, ff, yy, xx], pad_temp_shared[nn, rc, yy + ry, xx + rx], placeholder_shared[ff, rc, ry, rx])
                                T.writes(conv2d_nchw_local[nn, ff, yy, xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "meta_schedule.tiling_structure":"SSSRRSRS", "workload":["conv2d_nchw.cuda", ["TENSOR", [1, 256, 52, 52], "float32"], ["TENSOR", [255, 256, 1, 1], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "float32"]})
                                conv2d_nchw_local[nn, ff, yy, xx] = conv2d_nchw_local[nn, ff, yy, xx] + pad_temp_shared[nn, rc, yy + ry, xx + rx] * placeholder_shared[ff, rc, ry, rx]
                    for ax0, ax1, ax2, ax3 in T.grid(1, 1, 1, 13):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(1, ax0)
                            v1 = T.axis.spatial(255, i0_1_i1_1_i2_1_i3_1_fused // 4 * 3 + i0_2_i1_2_i2_2_i3_2_fused // 26 + ax1)
                            v2 = T.axis.spatial(52, i0_0_i1_0_i2_0_i3_0_fused * 26 + i0_1_i1_1_i2_1_i3_1_fused % 4 // 2 * 13 + i0_2_i1_2_i2_2_i3_2_fused % 26 // 2 + ax2)
                            v3 = T.axis.spatial(52, i0_1_i1_1_i2_1_i3_1_fused % 2 * 26 + i0_2_i1_2_i2_2_i3_2_fused % 2 * 13 + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], placeholder_2[v0, v1, 0, 0])
                            T.writes(T_add[v0, v1, v2, v3])
                            T_add[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3] + placeholder_2[v0, v1, 0, 0]
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b1)
v11, v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l16, l17, l18, l19, l20 = sch.split(loop=l4, factors=[v11, v12, v13, v14, v15])
v21, v22, v23, v24, v25 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 85, 3, 1, 1])
l26, l27, l28, l29, l30 = sch.split(loop=l5, factors=[v21, v22, v23, v24, v25])
v31, v32, v33, v34, v35 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[2, 2, 13, 1, 1])
l36, l37, l38, l39, l40 = sch.split(loop=l6, factors=[v31, v32, v33, v34, v35])
v41, v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 2, 2, 1, 13])
l46, l47, l48, l49, l50 = sch.split(loop=l7, factors=[v41, v42, v43, v44, v45])
v51, v52, v53 = sch.sample_perfect_tile(loop=l8, n=3, max_innermost_factor=64, decision=[64, 1, 4])
l54, l55, l56 = sch.split(loop=l8, factors=[v51, v52, v53])
v57, v58, v59 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l60, l61, l62 = sch.split(loop=l9, factors=[v57, v58, v59])
v63, v64, v65 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l66, l67, l68 = sch.split(loop=l10, factors=[v63, v64, v65])
sch.reorder(l16, l26, l36, l46, l17, l27, l37, l47, l18, l28, l38, l48, l54, l60, l66, l55, l61, l67, l19, l29, l39, l49, l56, l62, l68, l20, l30, l40, l50)
l69 = sch.fuse(l16, l26, l36, l46)
sch.bind(loop=l69, thread_axis="blockIdx.x")
l70 = sch.fuse(l17, l27, l37, l47)
sch.bind(loop=l70, thread_axis="vthread.x")
l71 = sch.fuse(l18, l28, l38, l48)
sch.bind(loop=l71, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b72 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b72, loop=l71, preserve_unit_loops=True)
b73 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared")
sch.compute_at(block=b73, loop=l66, preserve_unit_loops=True)
l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b73)
l84 = sch.fuse(l80, l81, l82, l83)
v85 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b73, ann_key="meta_schedule.cooperative_fetch", ann_val=v85)
b86 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared")
sch.compute_at(block=b86, loop=l66, preserve_unit_loops=True)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96 = sch.get_loops(block=b86)
l97 = sch.fuse(l93, l94, l95, l96)
v98 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b86, ann_key="meta_schedule.cooperative_fetch", ann_val=v98)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v99 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v99)
sch.enter_postproc()
sch.unannotate(block_or_loop=b73, ann_key="meta_schedule.cooperative_fetch")
l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b73)
l107, l108, l109 = sch.split(loop=l106, factors=[None, 78, 4])
sch.vectorize(loop=l109)
sch.bind(loop=l108, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b86, ann_key="meta_schedule.cooperative_fetch")
l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b86)
l117, l118 = sch.split(loop=l116, factors=[None, 78])
sch.bind(loop=l118, thread_axis="threadIdx.x")
b119 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b119, ann_key="meta_schedule.unroll_explicit")
b120, b121, b122, b123 = sch.get_child_blocks(b119)
l124, l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b120)
sch.annotate(block_or_loop=l124, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l124, ann_key="pragma_unroll_explicit", ann_val=1)
l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b121)
sch.annotate(block_or_loop=l133, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l133, ann_key="pragma_unroll_explicit", ann_val=1)
l141, l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l141, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l141, ann_key="pragma_unroll_explicit", ann_val=1)
l161, l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b123)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
b168 = sch.get_block(name="conv2d_nchw", func_name="main")
l169, l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188 = sch.get_loops(block=b168)
b189 = sch.decompose_reduction(block=b168, loop=l172)
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #17: GFLOPs: 3303.6164. Time: 0.1071 ms. Best GFLOPs: 5478.3527
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #18: GFLOPs: 50.5408. Time: 6.9988 ms. Best GFLOPs: 5478.3527
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #19: GFLOPs: 1943.8207. Time: 0.1820 ms. Best GFLOPs: 5478.3527
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #20: GFLOPs: 1592.6819. Time: 0.2221 ms. Best GFLOPs: 5478.3527
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #21: GFLOPs: 3209.7894. Time: 0.1102 ms. Best GFLOPs: 5478.3527
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #22: GFLOPs: 12.6094. Time: 28.0524 ms. Best GFLOPs: 5478.3527
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #23: GFLOPs: 768.2208. Time: 0.4604 ms. Best GFLOPs: 5478.3527
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #24: GFLOPs: 62.0308. Time: 5.7024 ms. Best GFLOPs: 5478.3527
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #25: GFLOPs: 2881.2304. Time: 0.1228 ms. Best GFLOPs: 5478.3527
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #26: GFLOPs: 3402.8593. Time: 0.1039 ms. Best GFLOPs: 5478.3527
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #27: GFLOPs: 64.8985. Time: 5.4504 ms. Best GFLOPs: 5478.3527
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #28: GFLOPs: 4.9348. Time: 71.6802 ms. Best GFLOPs: 5478.3527
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #29: GFLOPs: 2196.0631. Time: 0.1611 ms. Best GFLOPs: 5478.3527
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #30: GFLOPs: 1943.1907. Time: 0.1820 ms. Best GFLOPs: 5478.3527
[14:04:30] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #53: "fused_nn_conv2d_add_2"] Trial #31: GFLOPs: 65.5502. Time: 5.3962 ms. Best GFLOPs: 5478.3527
[14:04:31] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #53: "fused_nn_conv2d_add_2"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |      3333.8786 |     478.6984 |              478.6984 |     32 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |      2960.8178 |      60.0268 |              120.0537 |     32 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |      3729.7200 |     213.9931 |             1711.9447 |     32 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |      2831.4273 |      31.4766 |              283.2898 |     32 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |         0.0002 |       4.0251 |                8.0501 |     32 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |      3577.2919 |      99.3648 |               99.3648 |     32 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |      1641.9450 |     971.6545 |              971.6545 |     32 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |      2242.5252 |      79.1380 |              158.2760 |     32 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |      2992.4470 |     266.6006 |             1066.4024 |     32 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |      1500.1992 |      59.2350 |              296.1749 |     32 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |         0.0004 |       2.8040 |                5.6080 |     32 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |      2711.9545 |     130.8790 |              130.8790 |     32 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |       491.6898 |      29.7408 |               29.7408 |     32 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |         0.0002 |       4.1701 |                4.1701 |     32 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |      1750.6945 |     202.5435 |              202.5435 |     32 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |      2848.2262 |     560.0785 |             2800.3924 |     32 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |      2012.7442 |      88.1296 |              528.7778 |     32 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |      1713.3262 |      25.9080 |               25.9080 |     32 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |         0.0002 |       4.4672 |                4.4672 |     32 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |      4947.1213 |     322.5262 |             1612.6311 |     32 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |      3325.7491 |      53.3881 |              373.7168 |     32 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |      1927.9605 |      23.0686 |               23.0686 |     32 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |         0.0001 |      13.3191 |               13.3191 |     32 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |      3345.0504 |      53.1835 |              212.7341 |     32 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |      4451.1613 |     358.6184 |             1075.8553 |     32 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |      5478.3527 |      64.5675 |               64.5675 |     32 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1728
Total latency (us): 18154.9

[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #0: GFLOPs: 0.0000. Time: 0.0248 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #1: GFLOPs: 0.0000. Time: 0.0248 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #2: GFLOPs: 0.0000. Time: 0.0248 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #3: GFLOPs: 0.0000. Time: 0.0248 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #4: GFLOPs: 0.0000. Time: 0.0249 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #5: GFLOPs: 0.0000. Time: 0.0247 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #6: GFLOPs: 0.0000. Time: 0.0248 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #7: GFLOPs: 0.0000. Time: 0.0248 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #8: GFLOPs: 0.0000. Time: 0.0243 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #9: GFLOPs: 0.0000. Time: 0.0240 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #10: GFLOPs: 0.0000. Time: 0.0247 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #11: GFLOPs: 0.0000. Time: 0.0248 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #12: GFLOPs: 0.0000. Time: 0.0248 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #13: GFLOPs: 0.0000. Time: 0.0249 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #14: GFLOPs: 0.0000. Time: 0.0249 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #15: GFLOPs: 0.0000. Time: 0.0249 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #16: GFLOPs: 0.0000. Time: 0.0248 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #17: GFLOPs: 0.0000. Time: 0.0250 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #18: GFLOPs: 0.0000. Time: 0.0247 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #19: GFLOPs: 0.0000. Time: 0.0248 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #20: GFLOPs: 0.0000. Time: 0.0246 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #21: GFLOPs: 0.0000. Time: 0.0239 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #22: GFLOPs: 0.0000. Time: 0.0247 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #23: GFLOPs: 0.0000. Time: 0.0248 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #24: GFLOPs: 0.0000. Time: 0.0246 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #25: GFLOPs: 0.0000. Time: 0.0247 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #26: GFLOPs: 0.0000. Time: 0.0251 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #27: GFLOPs: 0.0000. Time: 0.0246 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #28: GFLOPs: 0.0000. Time: 0.0244 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #29: GFLOPs: 0.0000. Time: 0.0243 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #30: GFLOPs: 0.0000. Time: 0.0237 ms. Best GFLOPs: 0.0000
[14:04:32] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"] Trial #31: GFLOPs: 0.0000. Time: 0.0247 ms. Best GFLOPs: 0.0000
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"
 ID |                                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                           fused_nn_conv2d_add_nn_leaky_relu |  398894080 |      1 |      1883.1598 |     211.8217 |              211.8217 |     32 |            
  1 |                                         fused_nn_conv2d_add |   88301655 |      1 |       937.5241 |      94.1860 |               94.1860 |     32 |            
  2 |   fused_transpose_reshape_split_sigmoid_sigmoid_concatenate |          1 |      1 |         0.0004 |       2.2533 |                2.2533 |     32 |            
  3 |                         fused_nn_conv2d_add_nn_leaky_relu_1 |  399067136 |      1 |      2480.6822 |     160.8699 |              160.8699 |     32 |            
  4 |                                       fused_nn_conv2d_add_1 |  176689500 |      1 |      3140.4327 |      56.2628 |               56.2628 |     32 |            
  5 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1 |          1 |      1 |         0.0002 |       4.9375 |                4.9375 |     32 |            
  6 |                                         fused_nn_max_pool2d |    2163200 |      1 |       376.8213 |       5.7407 |                5.7407 |     32 |            
  7 |                                       fused_nn_max_pool2d_1 |    7008768 |      1 |       236.9291 |      29.5817 |               29.5817 |     32 |            
  8 |                                             fused_transpose |          1 |      1 |         0.0001 |       6.6774 |                6.6774 |     32 |            
  9 |               fused_nn_conv2d_add_exp_add_log_tanh_multiply |  315654144 |      1 |      1361.3116 |     231.8750 |              231.8750 |     32 |            
 10 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_1 | 1603190784 |      1 |      4858.9061 |     329.9489 |              329.9489 |     32 |            
 11 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_2 |  181362688 |      1 |      1670.6234 |     108.5599 |              108.5599 |     32 |            
 12 |           fused_nn_conv2d_add_exp_add_log_tanh_multiply_add | 1605959680 |      1 |      4564.6346 |     351.8266 |              351.8266 |     32 |            
 13 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_3 |  362725376 |      3 |      2302.5946 |     157.5290 |              472.5869 |     32 |            
 14 |                                           fused_concatenate |          1 |      1 |         0.0000 |     114.1015 |              114.1015 |     32 |            
 15 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_4 |  717144064 |      1 |      3367.8870 |     212.9359 |              212.9359 |     32 |            
 16 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_5 | 1599037440 |      1 |      4798.6985 |     333.2232 |              333.2232 |     32 |            
 17 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_6 |  179286016 |      2 |      1839.5593 |      97.4614 |              194.9228 |     32 |            
 18 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1 |  800210944 |      2 |      3620.0905 |     221.0472 |              442.0944 |     32 |            
 19 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_7 |   90681344 |      3 |      2166.6358 |      41.8535 |              125.5606 |     32 |            
 20 |                                         fused_concatenate_1 |          1 |      1 |         0.0000 |      30.4726 |               30.4726 |     32 |            
 21 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_8 |  358572032 |      1 |      3419.6236 |     104.8572 |              104.8572 |     32 |            
 22 |             fused_nn_conv2d_add_exp_add_log_tanh_multiply_9 | 1596960768 |      1 |      3722.3763 |     429.0165 |              429.0165 |     32 |            
 23 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_10 |  178247680 |      2 |      3402.7627 |      52.3832 |              104.7664 |     32 |            
 24 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2 |  798826496 |      8 |      5010.5072 |     159.4303 |             1275.4421 |     32 |            
 25 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_11 |   89643008 |      9 |      2728.7975 |      32.8507 |              295.6566 |     32 |            
 26 |                                         fused_concatenate_2 |          1 |      1 |         0.0001 |      14.6275 |               14.6275 |     32 |            
 27 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_12 |  356495360 |      1 |      3307.7699 |     107.7751 |              107.7751 |     32 |            
 28 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_13 | 1595922432 |      1 |      3333.8786 |     478.6984 |              478.6984 |     32 |            
 29 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_14 |  177728512 |      2 |      2960.8178 |      60.0268 |              120.0537 |     32 |            
 30 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3 |  798134272 |      8 |      3729.7200 |     213.9931 |             1711.9447 |     32 |            
 31 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_15 |   89123840 |      9 |      2831.4273 |      31.4766 |              283.2898 |     32 |            
 32 |                                         fused_concatenate_3 |          1 |      2 |         0.0002 |       4.0251 |                8.0501 |     32 |            
 33 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_16 |  355457024 |      1 |      3577.2919 |      99.3648 |               99.3648 |     32 |            
 34 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_17 | 1595403264 |      1 |      1641.9450 |     971.6545 |              971.6545 |     32 |            
 35 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_18 |  177468928 |      2 |      2242.5252 |      79.1380 |              158.2760 |     32 |            
 36 |         fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4 |  797788160 |      4 |      2992.4470 |     266.6006 |             1066.4024 |     32 |            
 37 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_19 |   88864256 |      5 |      1500.1992 |      59.2350 |              296.1749 |     32 |            
 38 |                                         fused_concatenate_4 |          1 |      2 |         0.0004 |       2.8040 |                5.6080 |     32 |            
 39 |            fused_nn_conv2d_add_exp_add_log_tanh_multiply_20 |  354937856 |      1 |      2711.9545 |     130.8790 |              130.8790 |     32 |            
 40 |                                       fused_nn_max_pool2d_2 |   14623232 |      1 |       491.6898 |      29.7408 |               29.7408 |     32 |            
 41 |                                         fused_concatenate_5 |          1 |      1 |         0.0002 |       4.1701 |                4.1701 |     32 |            
 42 |                         fused_nn_conv2d_add_nn_leaky_relu_2 |  354591744 |      1 |      1750.6945 |     202.5435 |              202.5435 |     32 |            
 43 |                         fused_nn_conv2d_add_nn_leaky_relu_3 | 1595230208 |      5 |      2848.2262 |     560.0785 |             2800.3924 |     32 |            
 44 |                         fused_nn_conv2d_add_nn_leaky_relu_4 |  177382400 |      6 |      2012.7442 |      88.1296 |              528.7778 |     32 |            
 45 |                         fused_nn_conv2d_add_nn_leaky_relu_5 |   44388864 |      1 |      1713.3262 |      25.9080 |               25.9080 |     32 |            
 46 |                            fused_image_resize2d_concatenate |          1 |      1 |         0.0002 |       4.4672 |                4.4672 |     32 |            
 47 |                         fused_nn_conv2d_add_nn_leaky_relu_6 | 1595576320 |      5 |      4947.1213 |     322.5262 |             1612.6311 |     32 |            
 48 |                         fused_nn_conv2d_add_nn_leaky_relu_7 |  177555456 |      7 |      3325.7491 |      53.3881 |              373.7168 |     32 |            
 49 |                         fused_nn_conv2d_add_nn_leaky_relu_8 |   44475392 |      1 |      1927.9605 |      23.0686 |               23.0686 |     32 |            
 50 |                          fused_image_resize2d_concatenate_1 |          1 |      1 |         0.0001 |      13.3191 |               13.3191 |     32 |            
 51 |                         fused_nn_conv2d_add_nn_leaky_relu_9 |  177901568 |      4 |      3345.0504 |      53.1835 |              212.7341 |     32 |            
 52 |                        fused_nn_conv2d_add_nn_leaky_relu_10 | 1596268544 |      3 |      4451.1613 |     358.6184 |             1075.8553 |     32 |            
 53 |                                       fused_nn_conv2d_add_2 |  353723760 |      1 |      5478.3527 |      64.5675 |               64.5675 |     32 |            
 54 | fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2 |          1 |      1 |         0.0000 |      23.7422 |               23.7422 |     32 |            
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1760
Total latency (us): 18178.6

[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #43: "fused_nn_conv2d_add_nn_leaky_relu_3"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #43 has finished. Remaining task(s): 54
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #30: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_3"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #30 has finished. Remaining task(s): 53
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #47: "fused_nn_conv2d_add_nn_leaky_relu_6"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #47 has finished. Remaining task(s): 52
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #24: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_2"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #24 has finished. Remaining task(s): 51
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #52: "fused_nn_conv2d_add_nn_leaky_relu_10"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #52 has finished. Remaining task(s): 50
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #36: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_4"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #36 has finished. Remaining task(s): 49
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #34: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_17"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #34 has finished. Remaining task(s): 48
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #44: "fused_nn_conv2d_add_nn_leaky_relu_4"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #44 has finished. Remaining task(s): 47
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #28: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_13"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #28 has finished. Remaining task(s): 46
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #13: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_3"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #13 has finished. Remaining task(s): 45
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #18: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add_1"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #18 has finished. Remaining task(s): 44
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #22: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_9"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #22 has finished. Remaining task(s): 43
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #48: "fused_nn_conv2d_add_nn_leaky_relu_7"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #48 has finished. Remaining task(s): 42
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #12: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_add"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #12 has finished. Remaining task(s): 41
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #16: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_5"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #16 has finished. Remaining task(s): 40
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #10: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_1"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #10 has finished. Remaining task(s): 39
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #37: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_19"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #37 has finished. Remaining task(s): 38
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #25: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_11"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #25 has finished. Remaining task(s): 37
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #31: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_15"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #31 has finished. Remaining task(s): 36
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #9: "fused_nn_conv2d_add_exp_add_log_tanh_multiply"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #9 has finished. Remaining task(s): 35
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #15: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_4"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #15 has finished. Remaining task(s): 34
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #51: "fused_nn_conv2d_add_nn_leaky_relu_9"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #51 has finished. Remaining task(s): 33
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #0: "fused_nn_conv2d_add_nn_leaky_relu"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #0 has finished. Remaining task(s): 32
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #42: "fused_nn_conv2d_add_nn_leaky_relu_2"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #42 has finished. Remaining task(s): 31
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #17: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_6"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #17 has finished. Remaining task(s): 30
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #3: "fused_nn_conv2d_add_nn_leaky_relu_1"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #3 has finished. Remaining task(s): 29
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #35: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_18"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #35 has finished. Remaining task(s): 28
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #39: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_20"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #39 has finished. Remaining task(s): 27
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #19: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_7"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #19 has finished. Remaining task(s): 26
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #29: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_14"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #29 has finished. Remaining task(s): 25
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #14: "fused_concatenate"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #14 has finished. Remaining task(s): 24
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #11: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_2"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #11 has finished. Remaining task(s): 23
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #27: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_12"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #27 has finished. Remaining task(s): 22
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #21: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_8"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #21 has finished. Remaining task(s): 21
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #23: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_10"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #23 has finished. Remaining task(s): 20
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #33: "fused_nn_conv2d_add_exp_add_log_tanh_multiply_16"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #33 has finished. Remaining task(s): 19
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #1: "fused_nn_conv2d_add"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #1 has finished. Remaining task(s): 18
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #53: "fused_nn_conv2d_add_2"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #53 has finished. Remaining task(s): 17
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #4: "fused_nn_conv2d_add_1"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #4 has finished. Remaining task(s): 16
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #20: "fused_concatenate_1"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #20 has finished. Remaining task(s): 15
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #40: "fused_nn_max_pool2d_2"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #40 has finished. Remaining task(s): 14
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #7: "fused_nn_max_pool2d_1"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #7 has finished. Remaining task(s): 13
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #45: "fused_nn_conv2d_add_nn_leaky_relu_5"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #45 has finished. Remaining task(s): 12
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #54: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_2"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #54 has finished. Remaining task(s): 11
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #49: "fused_nn_conv2d_add_nn_leaky_relu_8"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #49 has finished. Remaining task(s): 10
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #26: "fused_concatenate_2"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #26 has finished. Remaining task(s): 9
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #50: "fused_image_resize2d_concatenate_1"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #50 has finished. Remaining task(s): 8
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #32: "fused_concatenate_3"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #32 has finished. Remaining task(s): 7
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #8: "fused_transpose"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #8 has finished. Remaining task(s): 6
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #6: "fused_nn_max_pool2d"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #6 has finished. Remaining task(s): 5
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #38: "fused_concatenate_4"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #38 has finished. Remaining task(s): 4
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #5: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate_1"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #5 has finished. Remaining task(s): 3
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #46: "fused_image_resize2d_concatenate"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #46 has finished. Remaining task(s): 2
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #41: "fused_concatenate_5"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #41 has finished. Remaining task(s): 1
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #2: "fused_transpose_reshape_split_sigmoid_sigmoid_concatenate"
[14:04:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #2 has finished. Remaining task(s): 0
[[[[[-4.86105442e-01 -2.00283989e-01 -7.79895246e-01 ...
      2.89325486e-04  1.12400310e-04  2.29207581e-04]
    [ 5.09953618e-01  7.65358150e-01 -4.53122377e-01 ...
      4.54887748e-04  1.15363589e-04  2.14625485e-04]
    [ 1.50907922e+00  8.80363882e-01 -5.91196120e-01 ...
      5.65062859e-04  1.15374030e-04  1.52047985e-04]]

   [[-4.37694788e-03 -3.94869089e-01  6.39470816e-02 ...
      1.74226734e-04  8.17629407e-05  8.16552492e-05]
    [-3.90505105e-01  4.08649892e-01 -3.36041749e-02 ...
      1.78188857e-04  6.19241182e-05  7.54648063e-05]
    [-6.46185637e-01  5.18035591e-01 -3.44361842e-01 ...
      2.30309059e-04  5.32810845e-05  6.01856518e-05]]

   [[-4.20330167e-01 -4.79184866e-01 -2.60783076e-01 ...
      1.48503619e-04  7.63694479e-05  9.64000501e-05]
    [-2.90702432e-01  4.11876082e-01  1.42219365e-02 ...
      1.63666249e-04  5.68964315e-05  7.98202163e-05]
    [-6.23844676e-02  3.25317681e-01 -1.06053472e-01 ...
      2.12637984e-04  4.78235997e-05  5.70123848e-05]]

   ...

   [[-6.20844588e-02 -6.15576267e-01 -1.25265121e-01 ...
      1.33274312e-04  6.17339174e-05  6.16515026e-05]
    [-1.98380306e-01  3.65824789e-01  3.67471427e-02 ...
      1.40358054e-04  4.19239477e-05  5.06731158e-05]
    [-2.00380966e-01  3.42994899e-01 -3.98881733e-02 ...
      1.75568173e-04  3.40867628e-05  3.62041246e-05]]

   [[ 7.26918638e-01 -3.12197983e-01 -2.73338556e-01 ...
      1.55646499e-04  7.20088647e-05  8.18289045e-05]
    [ 3.03172559e-01  4.86959308e-01 -1.80681944e-02 ...
      1.90929626e-04  5.73574107e-05  7.00507953e-05]
    [-2.05824390e-01  5.07274926e-01 -5.78209162e-02 ...
      2.56305415e-04  5.05051503e-05  4.98450245e-05]]

   [[-1.86941445e-01 -9.15262103e-02 -4.46523786e-01 ...
      2.72112811e-04  8.92739117e-05  1.21394718e-04]
    [-9.42194283e-01  7.60005891e-01 -4.04015720e-01 ...
      3.88015411e-04  8.15036110e-05  1.04982370e-04]
    [-1.56652093e+00  8.76502037e-01 -5.70559680e-01 ...
      4.84884076e-04  8.15262465e-05  7.84855438e-05]]]


  [[[-2.34888881e-01  3.96261692e-01 -5.43906629e-01 ...
      1.80623829e-04  7.87272511e-05  6.90286397e-05]
    [ 5.12971222e-01 -4.86238897e-02 -5.94878018e-01 ...
      2.25163691e-04  4.94885244e-05  6.91689056e-05]
    [ 1.51505530e+00 -8.12689215e-02 -1.03182018e+00 ...
      2.26411343e-04  4.38986390e-05  5.49138749e-05]]

   [[-3.00787121e-01  2.34118298e-01  2.59220868e-01 ...
      8.07545366e-05  7.35118811e-05  2.73041387e-05]
    [-5.92374206e-01 -2.17203349e-02  3.57242674e-02 ...
      7.34200512e-05  3.45807348e-05  2.24785053e-05]
    [-6.78165376e-01 -3.00176330e-02 -6.31277919e-01 ...
      7.28700543e-05  2.61527857e-05  1.84459004e-05]]

   [[ 4.24199790e-01 -3.10710669e-02 -2.04767764e-01 ...
      5.25374671e-05  6.03934313e-05  3.40353581e-05]
    [-8.95073116e-02 -2.18208820e-01  1.28841370e-01 ...
      5.58600586e-05  2.86896357e-05  2.31008526e-05]
    [-5.94738424e-02 -6.53077364e-02 -1.94723159e-01 ...
      5.71365053e-05  2.13009353e-05  1.63790064e-05]]

   ...

   [[-4.62615997e-01  8.47672284e-01 -2.37926483e-01 ...
      5.88096373e-05  4.77408830e-05  2.20521706e-05]
    [-1.85262039e-01  2.50727713e-01  6.68769926e-02 ...
      6.20747669e-05  2.04434746e-05  1.46391667e-05]
    [ 1.33219242e-01  1.40652671e-01 -2.34468743e-01 ...
      6.09622803e-05  1.42233139e-05  9.94617312e-06]]

   [[ 3.61420363e-01  3.72828066e-01 -4.54502583e-01 ...
      6.96903298e-05  6.06407229e-05  3.46222914e-05]
    [ 2.76872903e-01  4.87953201e-02 -1.52789906e-01 ...
      8.38243286e-05  3.17082886e-05  2.35805310e-05]
    [-6.50019199e-03  7.18827844e-02 -3.29948306e-01 ...
      9.15330020e-05  2.44330186e-05  1.55973594e-05]]

   [[-1.06236875e-01 -3.15783024e-01 -3.10810387e-01 ...
      1.89898565e-04  9.33703996e-05  5.77324245e-05]
    [-6.09593213e-01 -2.24431485e-01 -5.36305666e-01 ...
      2.19896727e-04  6.31277580e-05  4.95201057e-05]
    [-1.32643855e+00 -1.65258907e-02 -1.01296365e+00 ...
      2.29086567e-04  5.71032797e-05  3.94726849e-05]]]


  [[[ 2.31507160e-02 -2.47905150e-01 -4.41916227e-01 ...
      1.31837660e-04  8.76137128e-05  8.09996418e-05]
    [ 5.29586256e-01 -1.63130850e-01 -5.24372518e-01 ...
      1.69148974e-04  6.37516350e-05  8.09596022e-05]
    [ 1.41189134e+00 -2.09713131e-02 -9.34969664e-01 ...
      1.85236204e-04  5.86204333e-05  6.42231826e-05]]

   [[-2.38986135e-01 -2.65301704e-01  2.03077197e-02 ...
      6.55443000e-05  6.05854366e-05  3.28622700e-05]
    [-4.80705559e-01 -2.51218498e-01  3.07405442e-02 ...
      7.47820523e-05  3.59444930e-05  2.53392936e-05]
    [-5.42755127e-01 -5.59494309e-02 -5.46555877e-01 ...
      8.25983807e-05  2.84893540e-05  1.89211751e-05]]

   [[ 2.07920805e-01  2.95126349e-01  2.62388289e-02 ...
      5.68432806e-05  5.45221737e-05  3.66143649e-05]
    [-1.36505172e-01  1.55932344e-02  5.05268276e-02 ...
      6.12546864e-05  2.88475476e-05  2.58623186e-05]
    [-1.51464701e-01  1.34702757e-01 -3.18161905e-01 ...
      6.65436601e-05  2.21842820e-05  1.85760819e-05]]

   ...

   [[-7.02234581e-02  1.67261466e-01 -2.91872203e-01 ...
      4.28078165e-05  4.82431169e-05  1.91906583e-05]
    [-1.84892744e-01 -2.32644230e-02 -1.20756999e-01 ...
      4.34395079e-05  2.10878588e-05  1.41546025e-05]
    [-6.12788238e-02  3.32591608e-02 -3.68388623e-01 ...
      4.36536357e-05  1.56739879e-05  9.46605633e-06]]

   [[ 1.16693936e-02  4.88077462e-01 -3.39360297e-01 ...
      5.45037547e-05  5.36347616e-05  2.46916243e-05]
    [ 2.20718488e-01  1.20364726e-01 -2.35551909e-01 ...
      6.07919828e-05  2.61604619e-05  1.91091131e-05]
    [ 2.22712055e-01  9.70081091e-02 -4.33420569e-01 ...
      6.52317613e-05  2.05432989e-05  1.29502923e-05]]

   [[-1.26503825e-01  1.10541627e-01 -3.52956176e-01 ...
      1.24256912e-04  9.24425840e-05  5.10492464e-05]
    [-7.37202704e-01  4.21128087e-02 -5.03006816e-01 ...
      1.42081044e-04  6.19354614e-05  4.32669331e-05]
    [-1.50130761e+00  3.05691436e-02 -1.01346207e+00 ...
      1.45558137e-04  5.64485599e-05  3.45990957e-05]]]


  ...


  [[[-1.67342767e-01  4.45116758e-01 -5.90339959e-01 ...
      1.73918743e-04  1.08137006e-04  9.36053984e-05]
    [ 4.13311750e-01 -1.34697407e-02 -5.15420973e-01 ...
      2.55279127e-04  8.64965041e-05  8.13230727e-05]
    [ 1.35782349e+00 -5.69995604e-02 -8.37206364e-01 ...
      2.61823181e-04  7.82176940e-05  6.25267203e-05]]

   [[-5.32356024e-01 -1.54542610e-01 -5.34565032e-01 ...
      6.13773300e-05  7.37887385e-05  4.42505116e-05]
    [-4.63996649e-01  1.64952576e-02 -5.86551428e-03 ...
      8.63652167e-05  5.00891365e-05  2.79736178e-05]
    [-4.83737797e-01  1.43804908e-01 -2.17960015e-01 ...
      9.49575478e-05  3.99384371e-05  1.78950759e-05]]

   [[-1.07978657e-01 -3.43225896e-01 -4.59368348e-01 ...
      5.14087296e-05  6.69921865e-05  3.79448065e-05]
    [-2.51516461e-01 -2.85081446e-01 -4.24598753e-02 ...
      6.40766375e-05  4.06068102e-05  2.24342239e-05]
    [-2.40832761e-01 -1.01863086e-01 -2.14517847e-01 ...
      6.82030222e-05  3.21362386e-05  1.47270639e-05]]

   ...

   [[-5.44772111e-02  1.83698773e-01 -3.70640457e-01 ...
      6.08257105e-05  1.08292581e-04  4.60094379e-05]
    [ 5.09344675e-02  1.85608417e-01  1.04245879e-01 ...
      7.58589522e-05  7.21885226e-05  2.53724957e-05]
    [ 3.85307632e-02  2.29334176e-01 -1.89663172e-02 ...
      8.00166235e-05  5.72485551e-05  1.61894059e-05]]

   [[ 2.97651052e-01 -2.51953304e-03 -5.06468356e-01 ...
      8.78430510e-05  1.25533290e-04  7.16296636e-05]
    [-5.89212924e-02 -1.58794522e-01 -1.12276122e-01 ...
      1.27648105e-04  9.54681818e-05  4.23623605e-05]
    [-4.25687015e-01 -7.79462755e-02 -2.67077327e-01 ...
      1.40869772e-04  8.20648420e-05  2.73001315e-05]]

   [[ 1.45783752e-01 -7.29505569e-02 -4.51846004e-01 ...
      2.98584404e-04  1.73051449e-04  1.23410937e-04]
    [-5.41277468e-01  5.40584661e-02 -5.12424707e-01 ...
      4.38958843e-04  1.51245258e-04  8.84032124e-05]
    [-1.30353129e+00  8.85054767e-02 -8.67135882e-01 ...
      4.46090795e-04  1.47298124e-04  6.65074258e-05]]]


  [[[-2.91842133e-01 -5.10510981e-01 -6.91951931e-01 ...
      2.14075277e-04  1.29977780e-04  1.07654065e-04]
    [ 3.80939335e-01  6.32972121e-02 -4.33369219e-01 ...
      3.43654858e-04  1.16263560e-04  8.37990083e-05]
    [ 1.32721186e+00  3.10090870e-01 -7.07343340e-01 ...
      3.62116349e-04  1.06994776e-04  6.16790567e-05]]

   [[ 4.04014081e-01  3.77508491e-01 -5.16354203e-01 ...
      9.27709771e-05  1.11223781e-04  5.73860816e-05]
    [-3.17473471e-01  4.02687520e-01  8.50135013e-02 ...
      1.36780320e-04  8.89082221e-05  3.12575394e-05]
    [-6.08238995e-01  3.35214436e-01 -5.48448265e-02 ...
      1.45335114e-04  7.13891204e-05  2.00151826e-05]]

   [[ 1.40851766e-01  1.14995666e-01 -4.51324821e-01 ...
      7.03401311e-05  9.58644669e-05  4.87843499e-05]
    [-1.70219168e-01  2.22884774e-01  4.02624935e-01 ...
      1.00008787e-04  7.27820079e-05  2.32087605e-05]
    [-1.96786031e-01  1.96722403e-01  2.58423716e-01 ...
      1.03821134e-04  5.69722652e-05  1.41933906e-05]]

   ...

   [[ 8.81891847e-02  3.25602368e-02 -2.97806561e-01 ...
      1.17436568e-04  1.36363029e-04  5.10358877e-05]
    [ 2.44340599e-02 -2.35546231e-02  1.86694205e-01 ...
      1.49791318e-04  9.48667730e-05  2.84295511e-05]
    [ 1.19950056e-01 -4.11216952e-02  1.17799133e-01 ...
      1.50112435e-04  7.51838015e-05  1.86673678e-05]]

   [[-2.85889149e-01  3.87556344e-01 -4.02990997e-01 ...
      1.38595016e-04  1.30635875e-04  8.13737788e-05]
    [-5.82030602e-02  3.19450378e-01  9.93965119e-02 ...
      2.04255615e-04  1.03807273e-04  4.58583236e-05]
    [-2.21789733e-01  2.38609388e-01 -4.62036729e-02 ...
      2.17463399e-04  8.63022215e-05  2.98385439e-05]]

   [[ 2.91285574e-01  2.90640324e-01 -5.24897158e-01 ...
      3.41210776e-04  1.52119348e-04  9.71664776e-05]
    [-4.10386860e-01  5.03371656e-01 -5.95467627e-01 ...
      5.38247288e-04  1.33269728e-04  7.20436583e-05]
    [-1.27352488e+00  4.60009187e-01 -8.82650733e-01 ...
      5.62158471e-04  1.27987456e-04  5.42167327e-05]]]


  [[[ 6.11788407e-03  1.97126836e-01 -5.48716366e-01 ...
      3.37123231e-04  1.62481330e-04  1.69606821e-04]
    [ 6.69881165e-01 -6.68027103e-01 -4.14906204e-01 ...
      4.95998538e-04  1.78754330e-04  1.46508362e-04]
    [ 1.30715990e+00 -7.61517167e-01 -5.22553861e-01 ...
      5.56907384e-04  1.68014391e-04  1.09733126e-04]]

   [[ 9.34578776e-01  7.39253089e-02 -7.13833988e-01 ...
      1.55821792e-04  1.52383000e-04  1.14124807e-04]
    [ 9.48702544e-02 -5.17417550e-01 -2.87649155e-01 ...
      2.32520222e-04  1.73641354e-04  9.14883567e-05]
    [-5.39272606e-01 -6.25986278e-01 -1.53842449e-01 ...
      2.91084085e-04  1.68383805e-04  6.24646709e-05]]

   [[ 2.59290010e-01  2.12984741e-01 -4.67449605e-01 ...
      1.25893566e-04  1.16876552e-04  8.26915639e-05]
    [-9.31788981e-02 -3.58985782e-01 -6.70264214e-02 ...
      1.63745353e-04  1.15541610e-04  6.14138917e-05]
    [-2.49689400e-01 -4.59676147e-01  3.58463824e-02 ...
      1.98656751e-04  1.04320054e-04  4.12337904e-05]]

   ...

   [[-4.28260654e-01  2.68040523e-02 -5.88449538e-01 ...
      1.82887685e-04  1.42419332e-04  9.47464505e-05]
    [-1.53016206e-02 -4.37721699e-01 -1.40044883e-01 ...
      2.66341813e-04  1.51549655e-04  7.00732999e-05]
    [ 2.62691945e-01 -5.20723164e-01 -1.31401718e-02 ...
      3.30528477e-04  1.37742987e-04  4.64473778e-05]]

   [[ 2.38847867e-01 -1.22099802e-01 -3.47842574e-01 ...
      1.98968701e-04  1.35125432e-04  8.48947311e-05]
    [ 2.06915617e-01 -4.35337335e-01 -2.46189162e-01 ...
      2.64654605e-04  1.36546732e-04  7.06446808e-05]
    [-2.27972437e-02 -5.20604312e-01 -2.16864124e-01 ...
      3.32083961e-04  1.30325920e-04  5.21668517e-05]]

   [[ 3.13777745e-01  8.49064142e-02 -5.23925543e-01 ...
      4.49419109e-04  1.40024102e-04  1.21154153e-04]
    [-7.43514359e-01 -4.29079473e-01 -5.00099719e-01 ...
      6.61452126e-04  1.51698056e-04  1.06134263e-04]
    [-1.55004728e+00 -5.80837786e-01 -6.21664524e-01 ...
      7.47385086e-04  1.53085799e-04  8.10679849e-05]]]]]
[[[[[-4.86105382e-01 -2.00283781e-01 -7.79895127e-01 ...
      2.89325486e-04  1.12400463e-04  2.29207581e-04]
    [ 5.09953678e-01  7.65358210e-01 -4.53122497e-01 ...
      4.54888068e-04  1.15363589e-04  2.14625630e-04]
    [ 1.50907910e+00  8.80363882e-01 -5.91195941e-01 ...
      5.65063208e-04  1.15374103e-04  1.52048087e-04]]

   [[-4.37660888e-03 -3.94869030e-01  6.39466047e-02 ...
      1.74226734e-04  8.17629407e-05  8.16553584e-05]
    [-3.90505314e-01  4.08649862e-01 -3.36041451e-02 ...
      1.78188857e-04  6.19241182e-05  7.54648063e-05]
    [-6.46186292e-01  5.18036127e-01 -3.44361871e-01 ...
      2.30309059e-04  5.32810191e-05  6.01856518e-05]]

   [[-4.20329809e-01 -4.79184151e-01 -2.60783672e-01 ...
      1.48503619e-04  7.63694479e-05  9.64000501e-05]
    [-2.90702194e-01  4.11876529e-01  1.42210573e-02 ...
      1.63666249e-04  5.68964315e-05  7.98202163e-05]
    [-6.23847768e-02  3.25318575e-01 -1.06054127e-01 ...
      2.12637853e-04  4.78235379e-05  5.70123084e-05]]

   ...

   [[-6.20854311e-02 -6.15576863e-01 -1.25265360e-01 ...
      1.33274312e-04  6.17339538e-05  6.16514226e-05]
    [-1.98380440e-01  3.65824819e-01  3.67473215e-02 ...
      1.40358054e-04  4.19239805e-05  5.06730794e-05]
    [-2.00380653e-01  3.42994958e-01 -3.98880839e-02 ...
      1.75568071e-04  3.40867628e-05  3.62040992e-05]]

   [[ 7.26918340e-01 -3.12198102e-01 -2.73338556e-01 ...
      1.55646499e-04  7.20088647e-05  8.18289045e-05]
    [ 3.03172350e-01  4.86960053e-01 -1.80680454e-02 ...
      1.90929873e-04  5.73574107e-05  7.00508463e-05]
    [-2.05824077e-01  5.07275581e-01 -5.78210354e-02 ...
      2.56305415e-04  5.05051503e-05  4.98450245e-05]]

   [[-1.86941519e-01 -9.15262997e-02 -4.46523905e-01 ...
      2.72112811e-04  8.92737953e-05  1.21394718e-04]
    [-9.42194045e-01  7.60005772e-01 -4.04015660e-01 ...
      3.88015673e-04  8.15035601e-05  1.04982370e-04]
    [-1.56652057e+00  8.76501918e-01 -5.70559561e-01 ...
      4.84884426e-04  8.15261956e-05  7.84855438e-05]]]


  [[[-2.34889552e-01  3.96261454e-01 -5.43906629e-01 ...
      1.80623931e-04  7.87272511e-05  6.90286397e-05]
    [ 5.12970805e-01 -4.86239195e-02 -5.94877958e-01 ...
      2.25164011e-04  4.94885899e-05  6.91689056e-05]
    [ 1.51505578e+00 -8.12691152e-02 -1.03181994e+00 ...
      2.26411343e-04  4.38986681e-05  5.49138749e-05]]

   [[-3.00787330e-01  2.34116524e-01  2.59221792e-01 ...
      8.07545366e-05  7.35117865e-05  2.73041387e-05]
    [-5.92374444e-01 -2.17210650e-02  3.57245207e-02 ...
      7.34199566e-05  3.45806911e-05  2.24785053e-05]
    [-6.78165853e-01 -3.00182290e-02 -6.31277859e-01 ...
      7.28699088e-05  2.61527330e-05  1.84459004e-05]]

   [[ 4.24200356e-01 -3.10718864e-02 -2.04768836e-01 ...
      5.25373580e-05  6.03933549e-05  3.40352926e-05]
    [-8.95070732e-02 -2.18209505e-01  1.28840119e-01 ...
      5.58599495e-05  2.86895774e-05  2.31008235e-05]
    [-5.94741553e-02 -6.53084368e-02 -1.94724560e-01 ...
      5.71364690e-05  2.13009062e-05  1.63789737e-05]]

   ...

   [[-4.62615907e-01  8.47672641e-01 -2.37925887e-01 ...
      5.88097137e-05  4.77408830e-05  2.20521706e-05]
    [-1.85261637e-01  2.50727892e-01  6.68768063e-02 ...
      6.20747669e-05  2.04435019e-05  1.46391667e-05]
    [ 1.33219928e-01  1.40652582e-01 -2.34469458e-01 ...
      6.09622803e-05  1.42233330e-05  9.94617312e-06]]

   [[ 3.61420363e-01  3.72828692e-01 -4.54502404e-01 ...
      6.96902353e-05  6.06407229e-05  3.46222696e-05]
    [ 2.76872814e-01  4.87959497e-02 -1.52790561e-01 ...
      8.38241613e-05  3.17082486e-05  2.35805310e-05]
    [-6.50004297e-03  7.18831867e-02 -3.29949111e-01 ...
      9.15330020e-05  2.44330186e-05  1.55974012e-05]]

   [[-1.06236607e-01 -3.15782607e-01 -3.10810387e-01 ...
      1.89898565e-04  9.33703996e-05  5.77324245e-05]
    [-6.09593213e-01 -2.24430948e-01 -5.36305785e-01 ...
      2.19896727e-04  6.31277580e-05  4.95200729e-05]
    [-1.32643843e+00 -1.65252909e-02 -1.01296341e+00 ...
      2.29086567e-04  5.71032797e-05  3.94726849e-05]]]


  [[[ 2.31508650e-02 -2.47905478e-01 -4.41916347e-01 ...
      1.31837573e-04  8.76136619e-05  8.09995327e-05]
    [ 5.29586315e-01 -1.63130701e-01 -5.24372160e-01 ...
      1.69148756e-04  6.37515914e-05  8.09594421e-05]
    [ 1.41189158e+00 -2.09708959e-02 -9.34969425e-01 ...
      1.85235971e-04  5.86203932e-05  6.42231462e-05]]

   [[-2.38985986e-01 -2.65300572e-01  2.03074515e-02 ...
      6.55442127e-05  6.05853929e-05  3.28622700e-05]
    [-4.80705589e-01 -2.51217812e-01  3.07403505e-02 ...
      7.47819577e-05  3.59444202e-05  2.53392773e-05]
    [-5.42755604e-01 -5.59494309e-02 -5.46555877e-01 ...
      8.25983807e-05  2.84892958e-05  1.89211623e-05]]

   [[ 2.07920387e-01  2.95126081e-01  2.62389481e-02 ...
      5.68432806e-05  5.45221374e-05  3.66142922e-05]
    [-1.36504501e-01  1.55930892e-02  5.05262613e-02 ...
      6.12546864e-05  2.88474912e-05  2.58623040e-05]
    [-1.51463911e-01  1.34702772e-01 -3.18162531e-01 ...
      6.65435291e-05  2.21842383e-05  1.85760564e-05]]

   ...

   [[-7.02236816e-02  1.67261288e-01 -2.91871667e-01 ...
      4.28078420e-05  4.82431169e-05  1.91906965e-05]
    [-1.84892863e-01 -2.32644677e-02 -1.20757326e-01 ...
      4.34395079e-05  2.10878588e-05  1.41546388e-05]
    [-6.12782761e-02  3.32593098e-02 -3.68389249e-01 ...
      4.36536648e-05  1.56739989e-05  9.46606906e-06]]

   [[ 1.16693713e-02  4.88075495e-01 -3.39359999e-01 ...
      5.45037547e-05  5.36347616e-05  2.46916406e-05]
    [ 2.20718920e-01  1.20363370e-01 -2.35551849e-01 ...
      6.07919465e-05  2.61604619e-05  1.91091385e-05]
    [ 2.22711936e-01  9.70074683e-02 -4.33420688e-01 ...
      6.52317613e-05  2.05432989e-05  1.29503260e-05]]

   [[-1.26503333e-01  1.10540763e-01 -3.52956235e-01 ...
      1.24256912e-04  9.24425840e-05  5.10492173e-05]
    [-7.37202764e-01  4.21127230e-02 -5.03006637e-01 ...
      1.42081044e-04  6.19354614e-05  4.32669913e-05]
    [-1.50130785e+00  3.05693895e-02 -1.01346207e+00 ...
      1.45558137e-04  5.64485599e-05  3.45991430e-05]]]


  ...


  [[[-1.67343572e-01  4.45117772e-01 -5.90340197e-01 ...
      1.73918510e-04  1.08137006e-04  9.36053984e-05]
    [ 4.13311124e-01 -1.34693533e-02 -5.15421033e-01 ...
      2.55279127e-04  8.64965041e-05  8.13231309e-05]
    [ 1.35782337e+00 -5.69993816e-02 -8.37206542e-01 ...
      2.61823181e-04  7.82176940e-05  6.25267203e-05]]

   [[-5.32355011e-01 -1.54542819e-01 -5.34564912e-01 ...
      6.13772063e-05  7.37886876e-05  4.42503951e-05]
    [-4.63995755e-01  1.64950788e-02 -5.86505234e-03 ...
      8.63650494e-05  5.00890710e-05  2.79735432e-05]
    [-4.83737051e-01  1.43804744e-01 -2.17959836e-01 ...
      9.49575478e-05  3.99383825e-05  1.78950177e-05]]

   [[-1.07978448e-01 -3.43226135e-01 -4.59367990e-01 ...
      5.14087296e-05  6.69921865e-05  3.79448065e-05]
    [-2.51515776e-01 -2.85082310e-01 -4.24602032e-02 ...
      6.40766375e-05  4.06068102e-05  2.24342239e-05]
    [-2.40832180e-01 -1.01864249e-01 -2.14518681e-01 ...
      6.82029277e-05  3.21362386e-05  1.47271030e-05]]

   ...

   [[-5.44763990e-02  1.83698148e-01 -3.70640755e-01 ...
      6.08257105e-05  1.08292581e-04  4.60094088e-05]
    [ 5.09351566e-02  1.85608625e-01  1.04246311e-01 ...
      7.58589522e-05  7.21884353e-05  2.53724447e-05]
    [ 3.85315455e-02  2.29334369e-01 -1.89657807e-02 ...
      8.00167254e-05  5.72485551e-05  1.61894059e-05]]

   [[ 2.97650635e-01 -2.51875818e-03 -5.06468058e-01 ...
      8.78430510e-05  1.25533290e-04  7.16296636e-05]
    [-5.89218885e-02 -1.58793956e-01 -1.12275645e-01 ...
      1.27648265e-04  9.54681818e-05  4.23623605e-05]
    [-4.25688207e-01 -7.79463649e-02 -2.67077208e-01 ...
      1.40869946e-04  8.20648420e-05  2.73001315e-05]]

   [[ 1.45782962e-01 -7.29496777e-02 -4.51845884e-01 ...
      2.98584404e-04  1.73051449e-04  1.23410937e-04]
    [-5.41277528e-01  5.40589429e-02 -5.12424946e-01 ...
      4.38958843e-04  1.51245258e-04  8.84030960e-05]
    [-1.30353093e+00  8.85057598e-02 -8.67136121e-01 ...
      4.46090795e-04  1.47298124e-04  6.65074258e-05]]]


  [[[-2.91842312e-01 -5.10511339e-01 -6.91951931e-01 ...
      2.14074986e-04  1.29977780e-04  1.07654138e-04]
    [ 3.80939156e-01  6.32972866e-02 -4.33368921e-01 ...
      3.43654392e-04  1.16263560e-04  8.37990665e-05]
    [ 1.32721186e+00  3.10091257e-01 -7.07343340e-01 ...
      3.62115854e-04  1.06994776e-04  6.16791367e-05]]

   [[ 4.04014856e-01  3.77508759e-01 -5.16354322e-01 ...
      9.27709771e-05  1.11223781e-04  5.73859652e-05]
    [-3.17472816e-01  4.02687848e-01  8.50139707e-02 ...
      1.36780232e-04  8.89082221e-05  3.12574994e-05]
    [-6.08238637e-01  3.35214794e-01 -5.48442900e-02 ...
      1.45335012e-04  7.13891204e-05  2.00151717e-05]]

   [[ 1.40851378e-01  1.14995882e-01 -4.51324284e-01 ...
      7.03399928e-05  9.58642777e-05  4.87842844e-05]
    [-1.70218870e-01  2.22883523e-01  4.02624846e-01 ...
      1.00008656e-04  7.27817678e-05  2.32087132e-05]
    [-1.96785718e-01  1.96721300e-01  2.58423358e-01 ...
      1.03820938e-04  5.69721124e-05  1.41933533e-05]]

   ...

   [[ 8.81896019e-02  3.25590298e-02 -2.97806025e-01 ...
      1.17436728e-04  1.36363029e-04  5.10358186e-05]
    [ 2.44342349e-02 -2.35553756e-02  1.86694592e-01 ...
      1.49791318e-04  9.48667730e-05  2.84295311e-05]
    [ 1.19949758e-01 -4.11220677e-02  1.17799193e-01 ...
      1.50112537e-04  7.51837506e-05  1.86673551e-05]]

   [[-2.85889208e-01  3.87555331e-01 -4.02990997e-01 ...
      1.38595016e-04  1.30635875e-04  8.13737788e-05]
    [-5.82029559e-02  3.19450378e-01  9.93969440e-02 ...
      2.04255746e-04  1.03807273e-04  4.58583236e-05]
    [-2.21789852e-01  2.38609552e-01 -4.62036431e-02 ...
      2.17463530e-04  8.63022215e-05  2.98385276e-05]]

   [[ 2.91285545e-01  2.90639430e-01 -5.24897158e-01 ...
      3.41211009e-04  1.52119348e-04  9.71665431e-05]
    [-4.10386801e-01  5.03372014e-01 -5.95467687e-01 ...
      5.38247696e-04  1.33269728e-04  7.20437602e-05]
    [-1.27352488e+00  4.60009485e-01 -8.82650554e-01 ...
      5.62158821e-04  1.27987543e-04  5.42167327e-05]]]


  [[[ 6.11744449e-03  1.97126597e-01 -5.48716486e-01 ...
      3.37122998e-04  1.62481534e-04  1.69606938e-04]
    [ 6.69880807e-01 -6.68027401e-01 -4.14906681e-01 ...
      4.95997549e-04  1.78754330e-04  1.46508566e-04]
    [ 1.30716038e+00 -7.61517525e-01 -5.22554159e-01 ...
      5.56906685e-04  1.68014274e-04  1.09733191e-04]]

   [[ 9.34578896e-01  7.39249438e-02 -7.13833869e-01 ...
      1.55821981e-04  1.52383000e-04  1.14124807e-04]
    [ 9.48705524e-02 -5.17417789e-01 -2.87648857e-01 ...
      2.32520222e-04  1.73641354e-04  9.14883567e-05]
    [-5.39272964e-01 -6.25986755e-01 -1.53842330e-01 ...
      2.91084085e-04  1.68383805e-04  6.24646709e-05]]

   [[ 2.59290159e-01  2.12984487e-01 -4.67448890e-01 ...
      1.25893566e-04  1.16876472e-04  8.26914620e-05]
    [-9.31784511e-02 -3.58985335e-01 -6.70271069e-02 ...
      1.63745353e-04  1.15541465e-04  6.14137680e-05]
    [-2.49689445e-01 -4.59675670e-01  3.58456969e-02 ...
      1.98656751e-04  1.04319915e-04  4.12337904e-05]]

   ...

   [[-4.28260207e-01  2.68047452e-02 -5.88449419e-01 ...
      1.82887816e-04  1.42419332e-04  9.47464505e-05]
    [-1.53017584e-02 -4.37720984e-01 -1.40045300e-01 ...
      2.66341987e-04  1.51549757e-04  7.00733508e-05]
    [ 2.62691677e-01 -5.20722866e-01 -1.31404400e-02 ...
      3.30528681e-04  1.37743249e-04  4.64474142e-05]]

   [[ 2.38847986e-01 -1.22099295e-01 -3.47842693e-01 ...
      1.98968846e-04  1.35125432e-04  8.48947311e-05]
    [ 2.06915274e-01 -4.35336858e-01 -2.46189192e-01 ...
      2.64654955e-04  1.36546820e-04  7.06446808e-05]
    [-2.27977373e-02 -5.20603776e-01 -2.16864273e-01 ...
      3.32084397e-04  1.30325920e-04  5.21668881e-05]]

   [[ 3.13778371e-01  8.49066898e-02 -5.23925543e-01 ...
      4.49419720e-04  1.40024204e-04  1.21154240e-04]
    [-7.43514657e-01 -4.29080158e-01 -5.00099540e-01 ...
      6.61453407e-04  1.51698259e-04  1.06134263e-04]
    [-1.55004764e+00 -5.80838323e-01 -6.21664524e-01 ...
      7.47386599e-04  1.53085901e-04  8.10680940e-05]]]]]
