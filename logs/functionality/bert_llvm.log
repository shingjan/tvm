nohup: ignoring input
Starting to build with relay.
One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.
[19:06:08] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #0: "fused_squeeze"
[19:06:08] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384, 1), "float32"], placeholder_1: T.Buffer[(1, 384, 1), "float32"], T_squeeze: T.Buffer[(1, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1 in T.grid(1, 384):
            with T.block("T_squeeze"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(placeholder_1[ax0, ax1, 0])
                T.writes(T_squeeze[ax0, ax1])
                T_squeeze[ax0, ax1] = placeholder_1[ax0, ax1, 0]
    

[19:06:08] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[19:06:08] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384, 1), "float32"], placeholder_1: T.Buffer[(1, 384, 1), "float32"], T_squeeze: T.Buffer[(1, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            for i0, i1 in T.grid(1, 384):
                with T.block("T_squeeze"):
                    ax0, ax1 = T.axis.remap("SS", [i0, i1])
                    T.reads(placeholder_1[ax0, ax1, 0])
                    T.writes(T_squeeze[ax0, ax1])
                    T_squeeze[ax0, ax1] = placeholder_1[ax0, ax1, 0]
    

b0 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.vectorize", ann_val=64)
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
[19:06:08] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"
[19:06:08] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 1024), "float32"], placeholder_1: T.Buffer[(1024,), "float32"], T_transpose: T.Buffer[(16, 64, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        T_reshape = T.alloc_buffer([1, 384, 1024], dtype="float32")
        T_add = T.alloc_buffer([1, 384, 1024], dtype="float32")
        T_reshape_1 = T.alloc_buffer([1, 384, 16, 64], dtype="float32")
        T_transpose_1 = T.alloc_buffer([1, 16, 384, 64], dtype="float32")
        T_reshape_2 = T.alloc_buffer([16, 384, 64], dtype="float32")
        for i0, i1, i2 in T.grid(1, 384, 1024):
            with T.block("T_reshape"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(placeholder[(ax2 // 1024 + ax1) % 384, ax2 % 1024])
                T.writes(T_reshape[ax0, ax1, ax2])
                T_reshape[ax0, ax1, ax2] = placeholder[(ax2 // 1024 + ax1) % 384, ax2 % 1024]
        for i0, i1, i2 in T.grid(1, 384, 1024):
            with T.block("T_add"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_reshape[ax0, ax1, ax2], placeholder_1[ax2])
                T.writes(T_add[ax0, ax1, ax2])
                T_add[ax0, ax1, ax2] = T_reshape[ax0, ax1, ax2] + placeholder_1[ax2]
        for i0, i1, i2, i3 in T.grid(1, 384, 16, 64):
            with T.block("T_reshape_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[0, ((ax2 * 64 + ax3) // 1024 + ax1) % 384, (ax2 * 64 + ax3) % 1024])
                T.writes(T_reshape_1[ax0, ax1, ax2, ax3])
                T_reshape_1[ax0, ax1, ax2, ax3] = T_add[0, ((ax2 * 64 + ax3) // 1024 + ax1) % 384, (ax2 * 64 + ax3) % 1024]
        for i0, i1, i2, i3 in T.grid(1, 16, 384, 64):
            with T.block("T_transpose"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_reshape_1[ax0, ax2, ax1, ax3])
                T.writes(T_transpose_1[ax0, ax1, ax2, ax3])
                T_transpose_1[ax0, ax1, ax2, ax3] = T_reshape_1[ax0, ax2, ax1, ax3]
        for i0, i1, i2 in T.grid(16, 384, 64):
            with T.block("T_reshape_2"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_transpose_1[0, ((ax2 // 64 + ax1) // 384 + ax0) % 16, (ax2 // 64 + ax1) % 384, ax2 % 64])
                T.writes(T_reshape_2[ax0, ax1, ax2])
                T_reshape_2[ax0, ax1, ax2] = T_transpose_1[0, ((ax2 // 64 + ax1) // 384 + ax0) % 16, (ax2 // 64 + ax1) % 384, ax2 % 64]
        for i0, i1, i2 in T.grid(16, 64, 384):
            with T.block("T_transpose_1"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_reshape_2[ax0, ax2, ax1])
                T.writes(T_transpose[ax0, ax1, ax2])
                T_transpose[ax0, ax1, ax2] = T_reshape_2[ax0, ax2, ax1]
    

[19:06:09] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[19:06:09] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 1024), "float32"], placeholder_1: T.Buffer[(1024,), "float32"], T_transpose: T.Buffer[(16, 64, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":64, "meta_schedule.vectorize":64})
            T_reshape = T.alloc_buffer([1, 384, 16, 64], dtype="float32")
            T_transpose_1 = T.alloc_buffer([1, 16, 384, 64], dtype="float32")
            T_reshape_1 = T.alloc_buffer([16, 384, 64], dtype="float32")
            for i0 in T.serial(16):
                for ax0, ax1, ax2 in T.grid(1, 1, 384):
                    for ax0_1, ax1_1, ax2_1, ax3 in T.grid(1, 1, 1, 64):
                        with T.block("T_reshape_1"):
                            ax0_2 = T.axis.spatial(1, ax0_1)
                            ax1_2 = T.axis.spatial(384, ax2 + ax1_1)
                            ax2_2 = T.axis.spatial(16, i0 + ax2_1)
                            ax3_1 = T.axis.spatial(64, ax3)
                            T.reads(placeholder[((ax2_2 * 64 + ax3_1) // 1024 + ax1_2) % 384, (ax2_2 * 64 + ax3_1) % 1024], placeholder_1[(ax2_2 * 64 + ax3_1) % 1024])
                            T.writes(T_reshape[ax0_2, ax1_2, ax2_2, ax3_1])
                            T_reshape[ax0_2, ax1_2, ax2_2, ax3_1] = placeholder[((ax2_2 * 64 + ax3_1) % 1024 // 1024 + ((ax2_2 * 64 + ax3_1) // 1024 + ax1_2) % 384) % 384, (ax2_2 * 64 + ax3_1) % 1024 % 1024] + placeholder_1[(ax2_2 * 64 + ax3_1) % 1024]
                    for ax3 in T.serial(64):
                        with T.block("T_transpose"):
                            ax0_3 = T.axis.spatial(1, ax0)
                            ax1_3 = T.axis.spatial(16, i0 + ax1)
                            ax2_3, ax3_2 = T.axis.remap("SS", [ax2, ax3])
                            T.reads(T_reshape[ax0_3, ax2_3, ax1_3, ax3_2])
                            T.writes(T_transpose_1[ax0_3, ax1_3, ax2_3, ax3_2])
                            T_transpose_1[ax0_3, ax1_3, ax2_3, ax3_2] = T_reshape[ax0_3, ax2_3, ax1_3, ax3_2]
                for i1, i2 in T.grid(64, 384):
                    for ax0_4, ax1_4, ax2_4 in T.grid(1, 1, 1):
                        with T.block("T_reshape_2"):
                            ax0_5 = T.axis.spatial(16, i0 + ax0_4)
                            ax1_5 = T.axis.spatial(384, i2 + ax1_4)
                            ax2_5 = T.axis.spatial(64, i1 + ax2_4)
                            T.reads(T_transpose_1[0, ((ax2_5 // 64 + ax1_5) // 384 + ax0_5) % 16, (ax2_5 // 64 + ax1_5) % 384, ax2_5 % 64])
                            T.writes(T_reshape_1[ax0_5, ax1_5, ax2_5])
                            T_reshape_1[ax0_5, ax1_5, ax2_5] = T_transpose_1[0, ((ax2_5 // 64 + ax1_5) // 384 + ax0_5) % 16, (ax2_5 // 64 + ax1_5) % 384, ax2_5 % 64]
                    with T.block("T_transpose_1"):
                        ax0_6, ax1_6, ax2_6 = T.axis.remap("SSS", [i0, i1, i2])
                        T.reads(T_reshape_1[ax0_6, ax2_6, ax1_6])
                        T.writes(T_transpose[ax0_6, ax1_6, ax2_6])
                        T_transpose[ax0_6, ax1_6, ax2_6] = T_reshape_1[ax0_6, ax2_6, ax1_6]
    

b0 = sch.get_block(name="T_reshape", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="T_reshape_1", func_name="main")
b3 = sch.get_block(name="T_transpose", func_name="main")
b4 = sch.get_block(name="T_reshape_2", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.vectorize", ann_val=64)
v6 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v6)
l7 = sch.sample_compute_location(block=b4, decision=2)
sch.compute_at(block=b4, loop=l7, preserve_unit_loops=True)
l8 = sch.sample_compute_location(block=b3, decision=0)
sch.compute_at(block=b3, loop=l8, preserve_unit_loops=True)
l9 = sch.sample_compute_location(block=b2, decision=3)
sch.compute_at(block=b2, loop=l9, preserve_unit_loops=True)
l10 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l10, preserve_unit_loops=True)
[19:06:09] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"
[19:06:09] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384), "int64"], T_multiply: T.Buffer[(1, 1, 1, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        compile_engine_const = T.alloc_buffer([], dtype="float32")
        T_expand_dims = T.alloc_buffer([1, 1, 384], dtype="int64")
        T_expand_dims_1 = T.alloc_buffer([1, 1, 1, 384], dtype="int64")
        T_cast = T.alloc_buffer([1, 1, 1, 384], dtype="float32")
        T_subtract = T.alloc_buffer([1, 1, 1, 384], dtype="float32")
        compile_engine_const_1 = T.alloc_buffer([], dtype="float32")
        with T.block("compile_engine_const"):
            T.reads()
            T.writes(compile_engine_const[()])
            compile_engine_const[()] = T.float32(1)
        for i0, i1, i2 in T.grid(1, 1, 384):
            with T.block("T_expand_dims"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(placeholder[ax0, ax2])
                T.writes(T_expand_dims[ax0, ax1, ax2])
                T_expand_dims[ax0, ax1, ax2] = placeholder[ax0, ax2]
        for i0, i1, i2, i3 in T.grid(1, 1, 1, 384):
            with T.block("T_expand_dims_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_expand_dims[ax0, ax1, ax3])
                T.writes(T_expand_dims_1[ax0, ax1, ax2, ax3])
                T_expand_dims_1[ax0, ax1, ax2, ax3] = T_expand_dims[ax0, ax1, ax3]
        for i0, i1, i2, i3 in T.grid(1, 1, 1, 384):
            with T.block("T_cast"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_expand_dims_1[ax0, ax1, ax2, ax3])
                T.writes(T_cast[ax0, ax1, ax2, ax3])
                T_cast[ax0, ax1, ax2, ax3] = T.cast(T_expand_dims_1[ax0, ax1, ax2, ax3], "float32")
        for i0, i1, i2, i3 in T.grid(1, 1, 1, 384):
            with T.block("T_subtract"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(compile_engine_const[()], T_cast[ax0, ax1, ax2, ax3])
                T.writes(T_subtract[ax0, ax1, ax2, ax3])
                T_subtract[ax0, ax1, ax2, ax3] = compile_engine_const[()] - T_cast[ax0, ax1, ax2, ax3]
        with T.block("compile_engine_const_1"):
            T.reads()
            T.writes(compile_engine_const_1[()])
            compile_engine_const_1[()] = T.float32(-10000)
        for i0, i1, i2, i3 in T.grid(1, 1, 1, 384):
            with T.block("T_multiply"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_subtract[ax0, ax1, ax2, ax3], compile_engine_const_1[()])
                T.writes(T_multiply[ax0, ax1, ax2, ax3])
                T_multiply[ax0, ax1, ax2, ax3] = T_subtract[ax0, ax1, ax2, ax3] * compile_engine_const_1[()]
    

[19:06:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[19:06:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384), "int64"], T_multiply: T.Buffer[(1, 1, 1, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":16, "meta_schedule.vectorize":64})
            for i0, i1, i2, i3 in T.grid(1, 1, 1, 384):
                with T.block("T_multiply"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(placeholder[ax0, ax3])
                    T.writes(T_multiply[ax0, ax1, ax2, ax3])
                    T_multiply[ax0, ax1, ax2, ax3] = (T.float32(1) - T.cast(placeholder[ax0, ax3], "float32")) * T.float32(-10000)
    

b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_expand_dims", func_name="main")
b2 = sch.get_block(name="T_expand_dims_1", func_name="main")
b3 = sch.get_block(name="T_cast", func_name="main")
b4 = sch.get_block(name="T_subtract", func_name="main")
b5 = sch.get_block(name="compile_engine_const_1", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.vectorize", ann_val=64)
v7 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v7)
[19:06:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"
[19:06:10] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 1024), "float32"], placeholder_1: T.Buffer[(1024,), "float32"], T_transpose: T.Buffer[(16, 384, 64), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        T_reshape = T.alloc_buffer([1, 384, 1024], dtype="float32")
        T_add = T.alloc_buffer([1, 384, 1024], dtype="float32")
        T_reshape_1 = T.alloc_buffer([1, 384, 16, 64], dtype="float32")
        T_transpose_1 = T.alloc_buffer([1, 16, 64, 384], dtype="float32")
        T_reshape_2 = T.alloc_buffer([16, 64, 384], dtype="float32")
        for i0, i1, i2 in T.grid(1, 384, 1024):
            with T.block("T_reshape"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(placeholder[(ax2 // 1024 + ax1) % 384, ax2 % 1024])
                T.writes(T_reshape[ax0, ax1, ax2])
                T_reshape[ax0, ax1, ax2] = placeholder[(ax2 // 1024 + ax1) % 384, ax2 % 1024]
        for i0, i1, i2 in T.grid(1, 384, 1024):
            with T.block("T_add"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_reshape[ax0, ax1, ax2], placeholder_1[ax2])
                T.writes(T_add[ax0, ax1, ax2])
                T_add[ax0, ax1, ax2] = T_reshape[ax0, ax1, ax2] + placeholder_1[ax2]
        for i0, i1, i2, i3 in T.grid(1, 384, 16, 64):
            with T.block("T_reshape_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[0, ((ax2 * 64 + ax3) // 1024 + ax1) % 384, (ax2 * 64 + ax3) % 1024])
                T.writes(T_reshape_1[ax0, ax1, ax2, ax3])
                T_reshape_1[ax0, ax1, ax2, ax3] = T_add[0, ((ax2 * 64 + ax3) // 1024 + ax1) % 384, (ax2 * 64 + ax3) % 1024]
        for i0, i1, i2, i3 in T.grid(1, 16, 64, 384):
            with T.block("T_transpose"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_reshape_1[ax0, ax3, ax1, ax2])
                T.writes(T_transpose_1[ax0, ax1, ax2, ax3])
                T_transpose_1[ax0, ax1, ax2, ax3] = T_reshape_1[ax0, ax3, ax1, ax2]
        for i0, i1, i2 in T.grid(16, 64, 384):
            with T.block("T_reshape_2"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_transpose_1[0, ((ax2 // 384 + ax1) // 64 + ax0) % 16, (ax2 // 384 + ax1) % 64, ax2 % 384])
                T.writes(T_reshape_2[ax0, ax1, ax2])
                T_reshape_2[ax0, ax1, ax2] = T_transpose_1[0, ((ax2 // 384 + ax1) // 64 + ax0) % 16, (ax2 // 384 + ax1) % 64, ax2 % 384]
        for i0, i1, i2 in T.grid(16, 384, 64):
            with T.block("T_transpose_1"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_reshape_2[ax0, ax2, ax1])
                T.writes(T_transpose[ax0, ax1, ax2])
                T_transpose[ax0, ax1, ax2] = T_reshape_2[ax0, ax2, ax1]
    

[19:06:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[19:06:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 1024), "float32"], placeholder_1: T.Buffer[(1024,), "float32"], T_transpose: T.Buffer[(16, 384, 64), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":64, "meta_schedule.vectorize":64})
            T_reshape = T.alloc_buffer([1, 384, 1024], dtype="float32")
            T_reshape_1 = T.alloc_buffer([1, 384, 16, 64], dtype="float32")
            T_transpose_1 = T.alloc_buffer([1, 16, 64, 384], dtype="float32")
            T_reshape_2 = T.alloc_buffer([16, 64, 384], dtype="float32")
            for i0, i1, i2 in T.grid(1, 384, 1024):
                with T.block("T_reshape"):
                    ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                    T.reads(placeholder[(ax2 // 1024 + ax1) % 384, ax2 % 1024])
                    T.writes(T_reshape[ax0, ax1, ax2])
                    T_reshape[ax0, ax1, ax2] = placeholder[(ax2 // 1024 + ax1) % 384, ax2 % 1024]
            for i0, i1, i2, i3 in T.grid(1, 384, 16, 64):
                with T.block("T_reshape_1"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(T_reshape[0, ((ax2 * 64 + ax3) // 1024 + ax1) % 384, (ax2 * 64 + ax3) % 1024], placeholder_1[(ax2 * 64 + ax3) % 1024])
                    T.writes(T_reshape_1[ax0, ax1, ax2, ax3])
                    T_reshape_1[ax0, ax1, ax2, ax3] = T_reshape[0, ((ax2 * 64 + ax3) // 1024 + ax1) % 384, (ax2 * 64 + ax3) % 1024] + placeholder_1[(ax2 * 64 + ax3) % 1024]
            for i0 in T.serial(16):
                for ax0, ax1, ax2, ax3 in T.grid(1, 1, 64, 384):
                    with T.block("T_transpose"):
                        ax0_1 = T.axis.spatial(1, ax0)
                        ax1_1 = T.axis.spatial(16, i0 + ax1)
                        ax2_1, ax3_1 = T.axis.remap("SS", [ax2, ax3])
                        T.reads(T_reshape_1[ax0_1, ax3_1, ax1_1, ax2_1])
                        T.writes(T_transpose_1[ax0_1, ax1_1, ax2_1, ax3_1])
                        T_transpose_1[ax0_1, ax1_1, ax2_1, ax3_1] = T_reshape_1[ax0_1, ax3_1, ax1_1, ax2_1]
                for i1, i2 in T.grid(384, 64):
                    for ax0, ax1, ax2 in T.grid(1, 1, 1):
                        with T.block("T_reshape_2"):
                            ax0_2 = T.axis.spatial(16, i0 + ax0)
                            ax1_2 = T.axis.spatial(64, i2 + ax1)
                            ax2_2 = T.axis.spatial(384, i1 + ax2)
                            T.reads(T_transpose_1[0, ((ax2_2 // 384 + ax1_2) // 64 + ax0_2) % 16, (ax2_2 // 384 + ax1_2) % 64, ax2_2 % 384])
                            T.writes(T_reshape_2[ax0_2, ax1_2, ax2_2])
                            T_reshape_2[ax0_2, ax1_2, ax2_2] = T_transpose_1[0, ((ax2_2 // 384 + ax1_2) // 64 + ax0_2) % 16, (ax2_2 // 384 + ax1_2) % 64, ax2_2 % 384]
                    with T.block("T_transpose_1"):
                        ax0_3, ax1_3, ax2_3 = T.axis.remap("SSS", [i0, i1, i2])
                        T.reads(T_reshape_2[ax0_3, ax2_3, ax1_3])
                        T.writes(T_transpose[ax0_3, ax1_3, ax2_3])
                        T_transpose[ax0_3, ax1_3, ax2_3] = T_reshape_2[ax0_3, ax2_3, ax1_3]
    

b0 = sch.get_block(name="T_reshape", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="T_reshape_1", func_name="main")
b3 = sch.get_block(name="T_transpose", func_name="main")
b4 = sch.get_block(name="T_reshape_2", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.vectorize", ann_val=64)
v6 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v6)
l7 = sch.sample_compute_location(block=b4, decision=2)
sch.compute_at(block=b4, loop=l7, preserve_unit_loops=True)
l8 = sch.sample_compute_location(block=b3, decision=0)
sch.compute_at(block=b3, loop=l8, preserve_unit_loops=True)
l9 = sch.sample_compute_location(block=b2, decision=-1)
sch.compute_at(block=b2, loop=l9, preserve_unit_loops=True)
l10 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l10, preserve_unit_loops=True)
[19:06:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #4: "fused_mean"
[19:06:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384, 1024), "float32"], T_divide: T.Buffer[(1, 384, 1), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        placeholder_red = T.alloc_buffer([1, 384, 1], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 384, 1, 1024):
            with T.block("placeholder_red"):
                ax0, ax1, ax2, k2 = T.axis.remap("SSSR", [i0, i1, i2, i3])
                T.reads(placeholder[ax0, ax1, k2])
                T.writes(placeholder_red[ax0, ax1, ax2])
                with T.init():
                    placeholder_red[ax0, ax1, ax2] = T.float32(0)
                placeholder_red[ax0, ax1, ax2] = placeholder_red[ax0, ax1, ax2] + placeholder[ax0, ax1, k2]
        for i0, i1, i2 in T.grid(1, 384, 1):
            with T.block("T_divide"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(placeholder_red[ax0, ax1, ax2])
                T.writes(T_divide[ax0, ax1, ax2])
                T_divide[ax0, ax1, ax2] = placeholder_red[ax0, ax1, ax2] * T.float32(0.0009765625)
    

[19:06:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 3 design space(s) generated
[19:06:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384, 1024), "float32"], T_divide: T.Buffer[(1, 384, 1), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            placeholder_red = T.alloc_buffer([1, 384, 1], dtype="float32")
            placeholder_red_rf = T.alloc_buffer([1, 384, 1, 512], dtype="float32")
            for i0, i1 in T.grid(1, 384):
                for ax0 in T.serial(512):
                    for ax0_1, ax1, ax2, ax3, ax4 in T.grid(1, 1, 1, 1, 2):
                        with T.block("placeholder_red_rf"):
                            vi3_0 = T.axis.spatial(512, ax0 + ax0_1)
                            ax0_2 = T.axis.spatial(1, ax1)
                            ax1_1 = T.axis.spatial(384, i1 + ax2)
                            ax2_1, vi3_1 = T.axis.remap("SR", [ax3, ax4])
                            T.reads(placeholder[ax0_2, ax1_1, vi3_0 * 2 + vi3_1])
                            T.writes(placeholder_red_rf[ax0_2, ax1_1, ax2_1, vi3_0])
                            with T.init():
                                placeholder_red_rf[ax0_2, ax1_1, ax2_1, vi3_0] = T.float32(0)
                            placeholder_red_rf[ax0_2, ax1_1, ax2_1, vi3_0] = placeholder_red_rf[ax0_2, ax1_1, ax2_1, vi3_0] + placeholder[ax0_2, ax1_1, vi3_0 * 2 + vi3_1]
                    for ax1, ax2, ax3 in T.grid(1, 1, 1):
                        with T.block("placeholder_red"):
                            vi3_0, ax0_3 = T.axis.remap("RS", [ax0, ax1])
                            ax1_2 = T.axis.spatial(384, i1 + ax2)
                            ax2_2 = T.axis.spatial(1, ax3)
                            T.reads(placeholder_red_rf[ax0_3, ax1_2, ax2_2, vi3_0])
                            T.writes(placeholder_red[ax0_3, ax1_2, ax2_2])
                            with T.init():
                                placeholder_red[ax0_3, ax1_2, ax2_2] = T.float32(0)
                            placeholder_red[ax0_3, ax1_2, ax2_2] = placeholder_red[ax0_3, ax1_2, ax2_2] + placeholder_red_rf[ax0_3, ax1_2, ax2_2, vi3_0]
                for i2 in T.serial(1):
                    with T.block("T_divide"):
                        ax0_4, ax1_3, ax2_3 = T.axis.remap("SSS", [i0, i1, i2])
                        T.reads(placeholder_red[ax0_4, ax1_3, ax2_3])
                        T.writes(T_divide[ax0_4, ax1_3, ax2_3])
                        T_divide[ax0_4, ax1_3, ax2_3] = placeholder_red[ax0_4, ax1_3, ax2_3] * T.float32(0.0009765625)
    

b0 = sch.get_block(name="placeholder_red", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
l2, l3, l4, l5 = sch.get_loops(block=b0)
v6, v7 = sch.sample_perfect_tile(loop=l5, n=2, max_innermost_factor=64, decision=[512, 2])
l8, l9 = sch.split(loop=l5, factors=[v6, v7])
b10 = sch.rfactor(loop=l8, factor_axis=3)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.random_compute_producer", ann_val=1)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v11 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v11)
b12, = sch.get_producers(block=b0)
sch.unannotate(block_or_loop=b0, ann_key="meta_schedule.random_compute_producer")
l13 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l13, preserve_unit_loops=True)
l14 = sch.sample_compute_location(block=b12, decision=2)
sch.compute_at(block=b12, loop=l14, preserve_unit_loops=True)
[19:06:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #1:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384, 1024), "float32"], T_divide: T.Buffer[(1, 384, 1), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            placeholder_red = T.alloc_buffer([1, 384, 1], dtype="float32")
            placeholder_red_rf = T.alloc_buffer([1, 384, 1, 2], dtype="float32")
            for i0, i1 in T.grid(1, 384):
                for ax0 in T.serial(2):
                    for ax0_1, ax1, ax2, ax3, ax4 in T.grid(1, 1, 1, 1, 512):
                        with T.block("placeholder_red_rf"):
                            vi3_1 = T.axis.spatial(2, ax0 + ax0_1)
                            ax0_2 = T.axis.spatial(1, ax1)
                            ax1_1 = T.axis.spatial(384, i1 + ax2)
                            ax2_1, vi3_0 = T.axis.remap("SR", [ax3, ax4])
                            T.reads(placeholder[ax0_2, ax1_1, vi3_0 * 2 + vi3_1])
                            T.writes(placeholder_red_rf[ax0_2, ax1_1, ax2_1, vi3_1])
                            with T.init():
                                placeholder_red_rf[ax0_2, ax1_1, ax2_1, vi3_1] = T.float32(0)
                            placeholder_red_rf[ax0_2, ax1_1, ax2_1, vi3_1] = placeholder_red_rf[ax0_2, ax1_1, ax2_1, vi3_1] + placeholder[ax0_2, ax1_1, vi3_0 * 2 + vi3_1]
                    for ax1, ax2, ax3 in T.grid(1, 1, 1):
                        with T.block("placeholder_red"):
                            vi3_1, ax0_3 = T.axis.remap("RS", [ax0, ax1])
                            ax1_2 = T.axis.spatial(384, i1 + ax2)
                            ax2_2 = T.axis.spatial(1, ax3)
                            T.reads(placeholder_red_rf[ax0_3, ax1_2, ax2_2, vi3_1])
                            T.writes(placeholder_red[ax0_3, ax1_2, ax2_2])
                            with T.init():
                                placeholder_red[ax0_3, ax1_2, ax2_2] = T.float32(0)
                            placeholder_red[ax0_3, ax1_2, ax2_2] = placeholder_red[ax0_3, ax1_2, ax2_2] + placeholder_red_rf[ax0_3, ax1_2, ax2_2, vi3_1]
                for i2 in T.serial(1):
                    with T.block("T_divide"):
                        ax0_4, ax1_3, ax2_3 = T.axis.remap("SSS", [i0, i1, i2])
                        T.reads(placeholder_red[ax0_4, ax1_3, ax2_3])
                        T.writes(T_divide[ax0_4, ax1_3, ax2_3])
                        T_divide[ax0_4, ax1_3, ax2_3] = placeholder_red[ax0_4, ax1_3, ax2_3] * T.float32(0.0009765625)
    

b0 = sch.get_block(name="placeholder_red", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
l2, l3, l4, l5 = sch.get_loops(block=b0)
v6, v7 = sch.sample_perfect_tile(loop=l5, n=2, max_innermost_factor=64, decision=[512, 2])
l8, l9 = sch.split(loop=l5, factors=[v6, v7])
b10 = sch.rfactor(loop=l9, factor_axis=3)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.random_compute_producer", ann_val=1)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v11 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v11)
b12, = sch.get_producers(block=b0)
sch.unannotate(block_or_loop=b0, ann_key="meta_schedule.random_compute_producer")
l13 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l13, preserve_unit_loops=True)
l14 = sch.sample_compute_location(block=b12, decision=2)
sch.compute_at(block=b12, loop=l14, preserve_unit_loops=True)
[19:06:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #2:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384, 1024), "float32"], T_divide: T.Buffer[(1, 384, 1), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":16, "meta_schedule.vectorize":64})
            placeholder_red = T.alloc_buffer([1, 384, 1], dtype="float32")
            for i0, i1 in T.grid(1, 384):
                for ax0, ax1, ax2, ax3 in T.grid(1, 1, 1, 1024):
                    with T.block("placeholder_red"):
                        ax0_1 = T.axis.spatial(1, ax0)
                        ax1_1 = T.axis.spatial(384, i1 + ax1)
                        ax2_1, k2 = T.axis.remap("SR", [ax2, ax3])
                        T.reads(placeholder[ax0_1, ax1_1, k2])
                        T.writes(placeholder_red[ax0_1, ax1_1, ax2_1])
                        with T.init():
                            placeholder_red[ax0_1, ax1_1, ax2_1] = T.float32(0)
                        placeholder_red[ax0_1, ax1_1, ax2_1] = placeholder_red[ax0_1, ax1_1, ax2_1] + placeholder[ax0_1, ax1_1, k2]
                for i2 in T.serial(1):
                    with T.block("T_divide"):
                        ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                        T.reads(placeholder_red[ax0, ax1, ax2])
                        T.writes(T_divide[ax0, ax1, ax2])
                        T_divide[ax0, ax1, ax2] = placeholder_red[ax0, ax1, ax2] * T.float32(0.0009765625)
    

b0 = sch.get_block(name="placeholder_red", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v2 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v2)
l3 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l3, preserve_unit_loops=True)
[19:06:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #5: "fused_less_add_where_take_add_less_add_where_take_add"
[19:06:11] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384), "int64"], placeholder_1: T.Buffer[(30522, 1024), "float32"], placeholder_2: T.Buffer[(1, 384, 1024), "float32"], placeholder_3: T.Buffer[(1, 384), "int64"], placeholder_4: T.Buffer[(2, 1024), "float32"], T_add: T.Buffer[(1, 384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        compile_engine_const = T.alloc_buffer([], dtype="int64")
        T_less = T.alloc_buffer([1, 384], dtype="bool")
        compile_engine_const_1 = T.alloc_buffer([], dtype="int64")
        T_add_1 = T.alloc_buffer([1, 384], dtype="int64")
        T_where = T.alloc_buffer([1, 384], dtype="int64")
        T_take = T.alloc_buffer([1, 384, 1024], dtype="float32")
        T_add_2 = T.alloc_buffer([1, 384, 1024], dtype="float32")
        compile_engine_const_2 = T.alloc_buffer([], dtype="int64")
        T_less_1 = T.alloc_buffer([1, 384], dtype="bool")
        compile_engine_const_3 = T.alloc_buffer([], dtype="int64")
        T_add_3 = T.alloc_buffer([1, 384], dtype="int64")
        T_where_1 = T.alloc_buffer([1, 384], dtype="int64")
        T_take_1 = T.alloc_buffer([1, 384, 1024], dtype="float32")
        with T.block("compile_engine_const"):
            T.reads()
            T.writes(compile_engine_const[()])
            compile_engine_const[()] = T.int64(0)
        for i0, i1 in T.grid(1, 384):
            with T.block("T_less"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(placeholder[ax0, ax1], compile_engine_const[()])
                T.writes(T_less[ax0, ax1])
                T_less[ax0, ax1] = placeholder[ax0, ax1] < compile_engine_const[()]
        with T.block("compile_engine_const_1"):
            T.reads()
            T.writes(compile_engine_const_1[()])
            compile_engine_const_1[()] = T.int64(30522)
        for i0, i1 in T.grid(1, 384):
            with T.block("T_add"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(placeholder[ax0, ax1], compile_engine_const_1[()])
                T.writes(T_add_1[ax0, ax1])
                T_add_1[ax0, ax1] = placeholder[ax0, ax1] + compile_engine_const_1[()]
        for i0, i1 in T.grid(1, 384):
            with T.block("T_where"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(T_less[ax0, ax1], T_add_1[ax0, ax1], placeholder[ax0, ax1])
                T.writes(T_where[ax0, ax1])
                T_where[ax0, ax1] = T.Select(T.cast(T_less[ax0, ax1], "int32") != 0, T_add_1[ax0, ax1], placeholder[ax0, ax1])
        for i0, i1, i2 in T.grid(1, 384, 1024):
            with T.block("T_take"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(placeholder_1[T.min(T.max(T.int64(0), T_where[ax0, ax1]), T.int64(30521)), ax2], T_where[ax0, ax1])
                T.writes(T_take[ax0, ax1, ax2])
                T_take[ax0, ax1, ax2] = placeholder_1[T.min(T.max(T.int64(0), T_where[ax0, ax1]), T.int64(30521)), ax2]
        for i0, i1, i2 in T.grid(1, 384, 1024):
            with T.block("T_add_1"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_take[ax0, ax1, ax2], placeholder_2[ax0, ax1, ax2])
                T.writes(T_add_2[ax0, ax1, ax2])
                T_add_2[ax0, ax1, ax2] = T_take[ax0, ax1, ax2] + placeholder_2[ax0, ax1, ax2]
        with T.block("compile_engine_const_2"):
            T.reads()
            T.writes(compile_engine_const_2[()])
            compile_engine_const_2[()] = T.int64(0)
        for i0, i1 in T.grid(1, 384):
            with T.block("T_less_1"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(placeholder_3[ax0, ax1], compile_engine_const_2[()])
                T.writes(T_less_1[ax0, ax1])
                T_less_1[ax0, ax1] = placeholder_3[ax0, ax1] < compile_engine_const_2[()]
        with T.block("compile_engine_const_3"):
            T.reads()
            T.writes(compile_engine_const_3[()])
            compile_engine_const_3[()] = T.int64(2)
        for i0, i1 in T.grid(1, 384):
            with T.block("T_add_2"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(placeholder_3[ax0, ax1], compile_engine_const_3[()])
                T.writes(T_add_3[ax0, ax1])
                T_add_3[ax0, ax1] = placeholder_3[ax0, ax1] + compile_engine_const_3[()]
        for i0, i1 in T.grid(1, 384):
            with T.block("T_where_1"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(T_less_1[ax0, ax1], T_add_3[ax0, ax1], placeholder_3[ax0, ax1])
                T.writes(T_where_1[ax0, ax1])
                T_where_1[ax0, ax1] = T.Select(T.cast(T_less_1[ax0, ax1], "int32") != 0, T_add_3[ax0, ax1], placeholder_3[ax0, ax1])
        for i0, i1, i2 in T.grid(1, 384, 1024):
            with T.block("T_take_1"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(placeholder_4[T.min(T.max(T.int64(0), T_where_1[ax0, ax1]), T.int64(1)), ax2], T_where_1[ax0, ax1])
                T.writes(T_take_1[ax0, ax1, ax2])
                T_take_1[ax0, ax1, ax2] = placeholder_4[T.min(T.max(T.int64(0), T_where_1[ax0, ax1]), T.int64(1)), ax2]
        for i0, i1, i2 in T.grid(1, 384, 1024):
            with T.block("T_add_3"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_add_2[ax0, ax1, ax2], T_take_1[ax0, ax1, ax2])
                T.writes(T_add[ax0, ax1, ax2])
                T_add[ax0, ax1, ax2] = T_add_2[ax0, ax1, ax2] + T_take_1[ax0, ax1, ax2]
    

[19:06:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[19:06:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384), "int64"], placeholder_1: T.Buffer[(30522, 1024), "float32"], placeholder_2: T.Buffer[(1, 384, 1024), "float32"], placeholder_3: T.Buffer[(1, 384), "int64"], placeholder_4: T.Buffer[(2, 1024), "float32"], T_add: T.Buffer[(1, 384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":16, "meta_schedule.vectorize":64})
            T_where = T.alloc_buffer([1, 384], dtype="int64")
            T_take = T.alloc_buffer([1, 384, 1024], dtype="float32")
            T_take_1 = T.alloc_buffer([1, 384, 1024], dtype="float32")
            for i0, i1 in T.grid(1, 384):
                with T.block("T_where"):
                    ax0, ax1 = T.axis.remap("SS", [i0, i1])
                    T.reads(placeholder[ax0, ax1])
                    T.writes(T_where[ax0, ax1])
                    T_where[ax0, ax1] = T.Select(T.cast(placeholder[ax0, ax1] < T.int64(0), "int32") != 0, placeholder[ax0, ax1] + T.int64(30522), placeholder[ax0, ax1])
            for i0, i1, i2 in T.grid(1, 384, 1024):
                for ax0, ax1, ax2 in T.grid(1, 1, 1):
                    with T.block("T_take_1"):
                        ax0_1 = T.axis.spatial(1, ax0)
                        ax1_1 = T.axis.spatial(384, i1 + ax1)
                        ax2_1 = T.axis.spatial(1024, i2 + ax2)
                        T.reads(placeholder_3[ax0_1, ax1_1], placeholder_4[T.min(T.max(T.int64(0), placeholder_3[ax0_1, ax1_1]), T.int64(1)) : T.min(T.max(T.int64(0), placeholder_3[ax0_1, ax1_1] + T.int64(2)), T.int64(1)) + T.int64(1), ax2_1])
                        T.writes(T_take_1[ax0_1, ax1_1, ax2_1])
                        T_take_1[ax0_1, ax1_1, ax2_1] = placeholder_4[T.min(T.max(T.int64(0), T.Select(T.cast(placeholder_3[ax0_1, ax1_1] < T.int64(0), "int32") != 0, placeholder_3[ax0_1, ax1_1] + T.int64(2), placeholder_3[ax0_1, ax1_1])), T.int64(1)), ax2_1]
                for ax0, ax1, ax2 in T.grid(1, 1, 1):
                    with T.block("T_take"):
                        ax0_2 = T.axis.spatial(1, ax0)
                        ax1_2 = T.axis.spatial(384, i1 + ax1)
                        ax2_2 = T.axis.spatial(1024, i2 + ax2)
                        T.reads(placeholder_1[T.min(T.max(T.int64(0), T_where[ax0_2, ax1_2]), T.int64(30521)), ax2_2], T_where[ax0_2, ax1_2])
                        T.writes(T_take[ax0_2, ax1_2, ax2_2])
                        T_take[ax0_2, ax1_2, ax2_2] = placeholder_1[T.min(T.max(T.int64(0), T_where[ax0_2, ax1_2]), T.int64(30521)), ax2_2]
                with T.block("T_add_3"):
                    ax0_3, ax1_3, ax2_3 = T.axis.remap("SSS", [i0, i1, i2])
                    T.reads(T_take[ax0_3, ax1_3, ax2_3], placeholder_2[ax0_3, ax1_3, ax2_3], T_take_1[ax0_3, ax1_3, ax2_3])
                    T.writes(T_add[ax0_3, ax1_3, ax2_3])
                    T_add[ax0_3, ax1_3, ax2_3] = T_take[ax0_3, ax1_3, ax2_3] + placeholder_2[ax0_3, ax1_3, ax2_3] + T_take_1[ax0_3, ax1_3, ax2_3]
    

b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_less", func_name="main")
b2 = sch.get_block(name="compile_engine_const_1", func_name="main")
b3 = sch.get_block(name="T_add", func_name="main")
b4 = sch.get_block(name="T_where", func_name="main")
b5 = sch.get_block(name="T_take", func_name="main")
b6 = sch.get_block(name="T_add_1", func_name="main")
b7 = sch.get_block(name="compile_engine_const_2", func_name="main")
b8 = sch.get_block(name="T_less_1", func_name="main")
b9 = sch.get_block(name="compile_engine_const_3", func_name="main")
b10 = sch.get_block(name="T_add_2", func_name="main")
b11 = sch.get_block(name="T_where_1", func_name="main")
b12 = sch.get_block(name="T_take_1", func_name="main")
b13 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b10)
sch.compute_inline(block=b9)
sch.compute_inline(block=b8)
sch.compute_inline(block=b7)
sch.compute_inline(block=b6)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
sch.annotate(block_or_loop=b13, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b13, ann_key="meta_schedule.vectorize", ann_val=64)
v14 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b13, ann_key="meta_schedule.unroll_explicit", ann_val=v14)
l15 = sch.sample_compute_location(block=b12, decision=2)
sch.compute_at(block=b12, loop=l15, preserve_unit_loops=True)
l16 = sch.sample_compute_location(block=b11, decision=-2)
sch.compute_at(block=b11, loop=l16, preserve_unit_loops=True)
l17 = sch.sample_compute_location(block=b5, decision=2)
sch.compute_at(block=b5, loop=l17, preserve_unit_loops=True)
l18 = sch.sample_compute_location(block=b4, decision=-1)
sch.compute_at(block=b4, loop=l18, preserve_unit_loops=True)
[19:06:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #6: "fused_reshape_add_reshape_transpose_reshape"
[19:06:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 1024), "float32"], placeholder_1: T.Buffer[(1024,), "float32"], T_reshape: T.Buffer[(16, 384, 64), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        T_reshape_1 = T.alloc_buffer([1, 384, 1024], dtype="float32")
        T_add = T.alloc_buffer([1, 384, 1024], dtype="float32")
        T_reshape_2 = T.alloc_buffer([1, 384, 16, 64], dtype="float32")
        T_transpose = T.alloc_buffer([1, 16, 384, 64], dtype="float32")
        for i0, i1, i2 in T.grid(1, 384, 1024):
            with T.block("T_reshape"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(placeholder[(ax2 // 1024 + ax1) % 384, ax2 % 1024])
                T.writes(T_reshape_1[ax0, ax1, ax2])
                T_reshape_1[ax0, ax1, ax2] = placeholder[(ax2 // 1024 + ax1) % 384, ax2 % 1024]
        for i0, i1, i2 in T.grid(1, 384, 1024):
            with T.block("T_add"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_reshape_1[ax0, ax1, ax2], placeholder_1[ax2])
                T.writes(T_add[ax0, ax1, ax2])
                T_add[ax0, ax1, ax2] = T_reshape_1[ax0, ax1, ax2] + placeholder_1[ax2]
        for i0, i1, i2, i3 in T.grid(1, 384, 16, 64):
            with T.block("T_reshape_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[0, ((ax2 * 64 + ax3) // 1024 + ax1) % 384, (ax2 * 64 + ax3) % 1024])
                T.writes(T_reshape_2[ax0, ax1, ax2, ax3])
                T_reshape_2[ax0, ax1, ax2, ax3] = T_add[0, ((ax2 * 64 + ax3) // 1024 + ax1) % 384, (ax2 * 64 + ax3) % 1024]
        for i0, i1, i2, i3 in T.grid(1, 16, 384, 64):
            with T.block("T_transpose"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_reshape_2[ax0, ax2, ax1, ax3])
                T.writes(T_transpose[ax0, ax1, ax2, ax3])
                T_transpose[ax0, ax1, ax2, ax3] = T_reshape_2[ax0, ax2, ax1, ax3]
        for i0, i1, i2 in T.grid(16, 384, 64):
            with T.block("T_reshape_2"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_transpose[0, ((ax2 // 64 + ax1) // 384 + ax0) % 16, (ax2 // 64 + ax1) % 384, ax2 % 64])
                T.writes(T_reshape[ax0, ax1, ax2])
                T_reshape[ax0, ax1, ax2] = T_transpose[0, ((ax2 // 64 + ax1) // 384 + ax0) % 16, (ax2 // 64 + ax1) % 384, ax2 % 64]
    

[19:06:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[19:06:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 1024), "float32"], placeholder_1: T.Buffer[(1024,), "float32"], T_reshape: T.Buffer[(16, 384, 64), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            T_reshape_1 = T.alloc_buffer([1, 384, 1024], dtype="float32")
            T_reshape_2 = T.alloc_buffer([1, 384, 16, 64], dtype="float32")
            T_transpose = T.alloc_buffer([1, 16, 384, 64], dtype="float32")
            for i0, i1, i2 in T.grid(1, 384, 1024):
                with T.block("T_reshape"):
                    ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                    T.reads(placeholder[(ax2 // 1024 + ax1) % 384, ax2 % 1024])
                    T.writes(T_reshape_1[ax0, ax1, ax2])
                    T_reshape_1[ax0, ax1, ax2] = placeholder[(ax2 // 1024 + ax1) % 384, ax2 % 1024]
            for i0 in T.serial(16):
                for ax0, ax1, ax2 in T.grid(1, 1, 384):
                    for ax0_1, ax1_1, ax2_1, ax3 in T.grid(1, 1, 1, 64):
                        with T.block("T_reshape_1"):
                            ax0_2 = T.axis.spatial(1, ax0_1)
                            ax1_2 = T.axis.spatial(384, ax2 + ax1_1)
                            ax2_2 = T.axis.spatial(16, i0 + ax2_1)
                            ax3_1 = T.axis.spatial(64, ax3)
                            T.reads(T_reshape_1[0, ((ax2_2 * 64 + ax3_1) // 1024 + ax1_2) % 384, (ax2_2 * 64 + ax3_1) % 1024], placeholder_1[(ax2_2 * 64 + ax3_1) % 1024])
                            T.writes(T_reshape_2[ax0_2, ax1_2, ax2_2, ax3_1])
                            T_reshape_2[ax0_2, ax1_2, ax2_2, ax3_1] = T_reshape_1[0, ((ax2_2 * 64 + ax3_1) // 1024 + ax1_2) % 384, (ax2_2 * 64 + ax3_1) % 1024] + placeholder_1[(ax2_2 * 64 + ax3_1) % 1024]
                    for ax3 in T.serial(64):
                        with T.block("T_transpose"):
                            ax0_3 = T.axis.spatial(1, ax0)
                            ax1_3 = T.axis.spatial(16, i0 + ax1)
                            ax2_3, ax3_2 = T.axis.remap("SS", [ax2, ax3])
                            T.reads(T_reshape_2[ax0_3, ax2_3, ax1_3, ax3_2])
                            T.writes(T_transpose[ax0_3, ax1_3, ax2_3, ax3_2])
                            T_transpose[ax0_3, ax1_3, ax2_3, ax3_2] = T_reshape_2[ax0_3, ax2_3, ax1_3, ax3_2]
                for i1, i2 in T.grid(384, 64):
                    with T.block("T_reshape_2"):
                        ax0_4, ax1_4, ax2_4 = T.axis.remap("SSS", [i0, i1, i2])
                        T.reads(T_transpose[0, ((ax2_4 // 64 + ax1_4) // 384 + ax0_4) % 16, (ax2_4 // 64 + ax1_4) % 384, ax2_4 % 64])
                        T.writes(T_reshape[ax0_4, ax1_4, ax2_4])
                        T_reshape[ax0_4, ax1_4, ax2_4] = T_transpose[0, ((ax2_4 // 64 + ax1_4) // 384 + ax0_4) % 16, (ax2_4 // 64 + ax1_4) % 384, ax2_4 % 64]
    

b0 = sch.get_block(name="T_reshape", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="T_reshape_1", func_name="main")
b3 = sch.get_block(name="T_transpose", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v5 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v5)
l6 = sch.sample_compute_location(block=b3, decision=0)
sch.compute_at(block=b3, loop=l6, preserve_unit_loops=True)
l7 = sch.sample_compute_location(block=b2, decision=3)
sch.compute_at(block=b2, loop=l7, preserve_unit_loops=True)
l8 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l8, preserve_unit_loops=True)
[19:06:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #7: "fused_nn_batch_matmul"
[19:06:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(16, 384, 64), "float32"], placeholder_1: T.Buffer[(16, 384, 64), "float32"], T_batch_matmul_NT: T.Buffer[(16, 384, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3 in T.grid(16, 384, 384, 64):
            with T.block("T_batch_matmul_NT"):
                b, i, j, k = T.axis.remap("SSSR", [i0, i1, i2, i3])
                T.reads(placeholder[b, i, k], placeholder_1[b, j, k])
                T.writes(T_batch_matmul_NT[b, i, j])
                T.block_attr({"layout_free_placeholders":[placeholder_1]})
                with T.init():
                    T_batch_matmul_NT[b, i, j] = T.float32(0)
                T_batch_matmul_NT[b, i, j] = T_batch_matmul_NT[b, i, j] + placeholder[b, i, k] * placeholder_1[b, j, k]
    

[19:06:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 3 design space(s) generated
[19:06:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(16, 384, 64), "float32"], placeholder_1: T.Buffer[(16, 384, 64), "float32"], T_batch_matmul_NT: T.Buffer[(16, 384, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":64, "meta_schedule.vectorize":64})
            T_batch_matmul_NT_global = T.alloc_buffer([16, 384, 384], dtype="float32")
            for i0_0, i1_0, i2_0, i0_1, i1_1, i2_1 in T.grid(1, 2, 4, 8, 12, 6):
                for i3_0, i0_2, i1_2, i2_2, i3_1, i0_3, i1_3, i2_3 in T.grid(64, 1, 2, 8, 1, 2, 8, 2):
                    with T.block("T_batch_matmul_NT"):
                        b = T.axis.spatial(16, i0_1 * 2 + i0_3)
                        i = T.axis.spatial(384, i1_0 * 192 + i1_1 * 16 + i1_2 * 8 + i1_3)
                        j = T.axis.spatial(384, i2_0 * 96 + i2_1 * 16 + i2_2 * 2 + i2_3)
                        k = T.axis.reduce(64, i3_0)
                        T.reads(placeholder[b, i, k], placeholder_1[b, j, k])
                        T.writes(T_batch_matmul_NT_global[b, i, j])
                        T.block_attr({"layout_free_placeholders":[placeholder_1], "meta_schedule.tiling_structure":"SSRSRS"})
                        with T.init():
                            T_batch_matmul_NT_global[b, i, j] = T.float32(0)
                        T_batch_matmul_NT_global[b, i, j] = T_batch_matmul_NT_global[b, i, j] + placeholder[b, i, k] * placeholder_1[b, j, k]
                for ax0, ax1, ax2 in T.grid(2, 16, 16):
                    with T.block("T_batch_matmul_NT_global"):
                        v0 = T.axis.spatial(16, i0_1 * 2 + ax0)
                        v1 = T.axis.spatial(384, i1_0 * 192 + i1_1 * 16 + ax1)
                        v2 = T.axis.spatial(384, i2_0 * 96 + i2_1 * 16 + ax2)
                        T.reads(T_batch_matmul_NT_global[v0, v1, v2])
                        T.writes(T_batch_matmul_NT[v0, v1, v2])
                        T_batch_matmul_NT[v0, v1, v2] = T_batch_matmul_NT_global[v0, v1, v2]
    

b0 = sch.get_block(name="T_batch_matmul_NT", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4, l5 = sch.get_loops(block=b0)
v6, v7, v8, v9 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 8, 1, 2])
l10, l11, l12, l13 = sch.split(loop=l2, factors=[v6, v7, v8, v9])
v14, v15, v16, v17 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[2, 12, 2, 8])
l18, l19, l20, l21 = sch.split(loop=l3, factors=[v14, v15, v16, v17])
v22, v23, v24, v25 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[4, 6, 8, 2])
l26, l27, l28, l29 = sch.split(loop=l4, factors=[v22, v23, v24, v25])
v30, v31 = sch.sample_perfect_tile(loop=l5, n=2, max_innermost_factor=64, decision=[64, 1])
l32, l33 = sch.split(loop=l5, factors=[v30, v31])
sch.reorder(l10, l18, l26, l11, l19, l27, l32, l12, l20, l28, l33, l13, l21, l29)
b34 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="global")
sch.reverse_compute_at(block=b34, loop=l27, preserve_unit_loops=True)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v35 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v35)
[19:06:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #1:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(16, 384, 64), "float32"], placeholder_1: T.Buffer[(16, 384, 64), "float32"], T_batch_matmul_NT: T.Buffer[(16, 384, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":16, "meta_schedule.vectorize":64})
            T_batch_matmul_NT_global = T.alloc_buffer([16, 384, 384], dtype="float32")
            for i0_0, i1_0, i2_0 in T.grid(1, 2, 4):
                for i0_1, i1_1, i2_1, i3_0, i0_2, i1_2, i2_2, i3_1, i0_3, i1_3, i2_3 in T.grid(8, 12, 6, 64, 1, 2, 8, 1, 2, 8, 2):
                    with T.block("T_batch_matmul_NT"):
                        b = T.axis.spatial(16, i0_1 * 2 + i0_3)
                        i = T.axis.spatial(384, i1_0 * 192 + i1_1 * 16 + i1_2 * 8 + i1_3)
                        j = T.axis.spatial(384, i2_0 * 96 + i2_1 * 16 + i2_2 * 2 + i2_3)
                        k = T.axis.reduce(64, i3_0)
                        T.reads(placeholder[b, i, k], placeholder_1[b, j, k])
                        T.writes(T_batch_matmul_NT_global[b, i, j])
                        T.block_attr({"layout_free_placeholders":[placeholder_1], "meta_schedule.tiling_structure":"SSRSRS"})
                        with T.init():
                            T_batch_matmul_NT_global[b, i, j] = T.float32(0)
                        T_batch_matmul_NT_global[b, i, j] = T_batch_matmul_NT_global[b, i, j] + placeholder[b, i, k] * placeholder_1[b, j, k]
                for ax0, ax1, ax2 in T.grid(16, 192, 96):
                    with T.block("T_batch_matmul_NT_global"):
                        v0 = T.axis.spatial(16, ax0)
                        v1 = T.axis.spatial(384, i1_0 * 192 + ax1)
                        v2 = T.axis.spatial(384, i2_0 * 96 + ax2)
                        T.reads(T_batch_matmul_NT_global[v0, v1, v2])
                        T.writes(T_batch_matmul_NT[v0, v1, v2])
                        T_batch_matmul_NT[v0, v1, v2] = T_batch_matmul_NT_global[v0, v1, v2]
    

b0 = sch.get_block(name="T_batch_matmul_NT", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4, l5 = sch.get_loops(block=b0)
v6, v7, v8, v9 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 8, 1, 2])
l10, l11, l12, l13 = sch.split(loop=l2, factors=[v6, v7, v8, v9])
v14, v15, v16, v17 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[2, 12, 2, 8])
l18, l19, l20, l21 = sch.split(loop=l3, factors=[v14, v15, v16, v17])
v22, v23, v24, v25 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[4, 6, 8, 2])
l26, l27, l28, l29 = sch.split(loop=l4, factors=[v22, v23, v24, v25])
v30, v31 = sch.sample_perfect_tile(loop=l5, n=2, max_innermost_factor=64, decision=[64, 1])
l32, l33 = sch.split(loop=l5, factors=[v30, v31])
sch.reorder(l10, l18, l26, l11, l19, l27, l32, l12, l20, l28, l33, l13, l21, l29)
b34 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="global")
sch.reverse_compute_at(block=b34, loop=l26, preserve_unit_loops=True)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v35 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v35)
[19:06:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #2:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(16, 384, 64), "float32"], placeholder_1: T.Buffer[(16, 384, 64), "float32"], T_batch_matmul_NT: T.Buffer[(16, 384, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            for i0_0, i1_0, i2_0, i0_1, i1_1, i2_1, i3_0, i0_2, i1_2, i2_2, i3_1, i0_3, i1_3, i2_3 in T.grid(1, 2, 4, 8, 12, 6, 64, 1, 2, 8, 1, 2, 8, 2):
                with T.block("T_batch_matmul_NT"):
                    b = T.axis.spatial(16, i0_1 * 2 + i0_3)
                    i = T.axis.spatial(384, i1_0 * 192 + i1_1 * 16 + i1_2 * 8 + i1_3)
                    j = T.axis.spatial(384, i2_0 * 96 + i2_1 * 16 + i2_2 * 2 + i2_3)
                    k = T.axis.reduce(64, i3_0)
                    T.reads(placeholder[b, i, k], placeholder_1[b, j, k])
                    T.writes(T_batch_matmul_NT[b, i, j])
                    T.block_attr({"layout_free_placeholders":[placeholder_1], "meta_schedule.tiling_structure":"SSRSRS"})
                    with T.init():
                        T_batch_matmul_NT[b, i, j] = T.float32(0)
                    T_batch_matmul_NT[b, i, j] = T_batch_matmul_NT[b, i, j] + placeholder[b, i, k] * placeholder_1[b, j, k]
    

b0 = sch.get_block(name="T_batch_matmul_NT", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4, l5 = sch.get_loops(block=b0)
v6, v7, v8, v9 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 8, 1, 2])
l10, l11, l12, l13 = sch.split(loop=l2, factors=[v6, v7, v8, v9])
v14, v15, v16, v17 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[2, 12, 2, 8])
l18, l19, l20, l21 = sch.split(loop=l3, factors=[v14, v15, v16, v17])
v22, v23, v24, v25 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[4, 6, 8, 2])
l26, l27, l28, l29 = sch.split(loop=l4, factors=[v22, v23, v24, v25])
v30, v31 = sch.sample_perfect_tile(loop=l5, n=2, max_innermost_factor=64, decision=[64, 1])
l32, l33 = sch.split(loop=l5, factors=[v30, v31])
sch.reorder(l10, l18, l26, l11, l19, l27, l32, l12, l20, l28, l33, l13, l21, l29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v34 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v34)
[19:06:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #8: "fused_reshape_divide_add"
[19:06:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(16, 384, 384), "float32"], placeholder_1: T.Buffer[(1, 1, 1, 384), "float32"], T_add: T.Buffer[(1, 16, 384, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        T_reshape = T.alloc_buffer([1, 16, 384, 384], dtype="float32")
        compile_engine_const = T.alloc_buffer([], dtype="float32")
        T_divide = T.alloc_buffer([1, 16, 384, 384], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 16, 384, 384):
            with T.block("T_reshape"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[((ax3 // 384 + ax2) // 384 + ax1) % 16, (ax3 // 384 + ax2) % 384, ax3 % 384])
                T.writes(T_reshape[ax0, ax1, ax2, ax3])
                T_reshape[ax0, ax1, ax2, ax3] = placeholder[((ax3 // 384 + ax2) // 384 + ax1) % 16, (ax3 // 384 + ax2) % 384, ax3 % 384]
        with T.block("compile_engine_const"):
            T.reads()
            T.writes(compile_engine_const[()])
            compile_engine_const[()] = T.float32(8)
        for i0, i1, i2, i3 in T.grid(1, 16, 384, 384):
            with T.block("T_divide"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_reshape[ax0, ax1, ax2, ax3], compile_engine_const[()])
                T.writes(T_divide[ax0, ax1, ax2, ax3])
                T_divide[ax0, ax1, ax2, ax3] = T_reshape[ax0, ax1, ax2, ax3] / compile_engine_const[()]
        for i0, i1, i2, i3 in T.grid(1, 16, 384, 384):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_divide[ax0, ax1, ax2, ax3], placeholder_1[ax0, 0, 0, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = T_divide[ax0, ax1, ax2, ax3] + placeholder_1[ax0, 0, 0, ax3]
    

[19:06:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[19:06:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(16, 384, 384), "float32"], placeholder_1: T.Buffer[(1, 1, 1, 384), "float32"], T_add: T.Buffer[(1, 16, 384, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":16, "meta_schedule.vectorize":64})
            for i0, i1, i2, i3 in T.grid(1, 16, 384, 384):
                with T.block("T_add"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(placeholder[((ax3 // 384 + ax2) // 384 + ax1) % 16, (ax3 // 384 + ax2) % 384, ax3 % 384], placeholder_1[ax0, 0, 0, ax3])
                    T.writes(T_add[ax0, ax1, ax2, ax3])
                    T_add[ax0, ax1, ax2, ax3] = placeholder[((ax3 // 384 + ax2) // 384 + ax1) % 16, (ax3 // 384 + ax2) % 384, ax3 % 384] / T.float32(8) + placeholder_1[ax0, 0, 0, ax3]
    

b0 = sch.get_block(name="T_reshape", func_name="main")
b1 = sch.get_block(name="compile_engine_const", func_name="main")
b2 = sch.get_block(name="T_divide", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v4 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v4)
l5 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l5, preserve_unit_loops=True)
[19:06:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #9: "fused_nn_softmax"
[19:06:13] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 384, 384), "float32"], T_softmax_norm: T.Buffer[(1, 16, 384, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        T_softmax_maxelem = T.alloc_buffer([1, 16, 384], dtype="float32")
        T_softmax_exp = T.alloc_buffer([1, 16, 384, 384], dtype="float32")
        T_softmax_expsum = T.alloc_buffer([1, 16, 384], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 16, 384, 384):
            with T.block("T_softmax_maxelem"):
                i0_1, i1_1, i2_1, k = T.axis.remap("SSSR", [i0, i1, i2, i3])
                T.reads(placeholder[i0_1, i1_1, i2_1, k])
                T.writes(T_softmax_maxelem[i0_1, i1_1, i2_1])
                with T.init():
                    T_softmax_maxelem[i0_1, i1_1, i2_1] = T.float32(-3.4028234663852886e+38)
                T_softmax_maxelem[i0_1, i1_1, i2_1] = T.max(T_softmax_maxelem[i0_1, i1_1, i2_1], placeholder[i0_1, i1_1, i2_1, k])
        for i0, i1, i2, i3 in T.grid(1, 16, 384, 384):
            with T.block("T_softmax_exp"):
                i0_2, i1_2, i2_2, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[i0_2, i1_2, i2_2, i3_1], T_softmax_maxelem[i0_2, i1_2, i2_2])
                T.writes(T_softmax_exp[i0_2, i1_2, i2_2, i3_1])
                T_softmax_exp[i0_2, i1_2, i2_2, i3_1] = T.exp(placeholder[i0_2, i1_2, i2_2, i3_1] - T_softmax_maxelem[i0_2, i1_2, i2_2], dtype="float32")
        for i0_3, i1_3, i2_3, i3 in T.grid(1, 16, 384, 384):
            with T.block("T_softmax_expsum"):
                i0_4, i1_4, i2_4, k = T.axis.remap("SSSR", [i0_3, i1_3, i2_3, i3])
                T.reads(T_softmax_exp[i0_4, i1_4, i2_4, k])
                T.writes(T_softmax_expsum[i0_4, i1_4, i2_4])
                with T.init():
                    T_softmax_expsum[i0_4, i1_4, i2_4] = T.float32(0)
                T_softmax_expsum[i0_4, i1_4, i2_4] = T_softmax_expsum[i0_4, i1_4, i2_4] + T_softmax_exp[i0_4, i1_4, i2_4, k]
        for i0_5, i1_5, i2_5, i3 in T.grid(1, 16, 384, 384):
            with T.block("T_softmax_norm"):
                i0_6, i1_6, i2_6, i3_2 = T.axis.remap("SSSS", [i0_5, i1_5, i2_5, i3])
                T.reads(T_softmax_exp[i0_6, i1_6, i2_6, i3_2], T_softmax_expsum[i0_6, i1_6, i2_6])
                T.writes(T_softmax_norm[i0_6, i1_6, i2_6, i3_2])
                T.block_attr({"axis":3})
                T_softmax_norm[i0_6, i1_6, i2_6, i3_2] = T_softmax_exp[i0_6, i1_6, i2_6, i3_2] / T_softmax_expsum[i0_6, i1_6, i2_6]
    

[19:06:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 9 design space(s) generated
[19:06:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 384, 384), "float32"], T_softmax_norm: T.Buffer[(1, 16, 384, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            T_softmax_maxelem = T.alloc_buffer([1, 16, 384], dtype="float32")
            T_softmax_exp = T.alloc_buffer([1, 16, 384, 384], dtype="float32")
            T_softmax_expsum = T.alloc_buffer([1, 16, 384], dtype="float32")
            T_softmax_expsum_rf = T.alloc_buffer([1, 16, 384, 64], dtype="float32")
            T_softmax_maxelem_rf = T.alloc_buffer([1, 16, 384, 96], dtype="float32")
            for i0, i1 in T.grid(1, 16):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(96, 1, 1, 384, 4):
                    with T.block("T_softmax_maxelem_rf"):
                        vi3_0, i0_1 = T.axis.remap("SS", [ax0, ax1])
                        i1_1 = T.axis.spatial(16, i1 + ax2)
                        i2, vi3_1 = T.axis.remap("SR", [ax3, ax4])
                        T.reads(placeholder[i0_1, i1_1, i2, vi3_0 * 4 + vi3_1])
                        T.writes(T_softmax_maxelem_rf[i0_1, i1_1, i2, vi3_0])
                        with T.init():
                            T_softmax_maxelem_rf[i0_1, i1_1, i2, vi3_0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem_rf[i0_1, i1_1, i2, vi3_0] = T.max(T_softmax_maxelem_rf[i0_1, i1_1, i2, vi3_0], placeholder[i0_1, i1_1, i2, vi3_0 * 4 + vi3_1])
                for i2, i3_0 in T.grid(384, 96):
                    with T.block("T_softmax_maxelem"):
                        vi3_0 = T.axis.reduce(96, i3_0)
                        i0_2 = T.axis.spatial(1, 0)
                        i1_2, i2_1 = T.axis.remap("SS", [i1, i2])
                        T.reads(T_softmax_maxelem_rf[i0_2, i1_2, i2_1, vi3_0])
                        T.writes(T_softmax_maxelem[i0_2, i1_2, i2_1])
                        with T.init():
                            T_softmax_maxelem[i0_2, i1_2, i2_1] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[i0_2, i1_2, i2_1] = T.max(T_softmax_maxelem[i0_2, i1_2, i2_1], T_softmax_maxelem_rf[i0_2, i1_2, i2_1, vi3_0])
            for i0_3, i1_3 in T.grid(1, 16):
                for ax0, ax1, ax2, ax3 in T.grid(1, 1, 384, 384):
                    with T.block("T_softmax_exp"):
                        i0_4 = T.axis.spatial(1, ax0)
                        i1_4 = T.axis.spatial(16, i1_3 + ax1)
                        i2, i3 = T.axis.remap("SS", [ax2, ax3])
                        T.reads(placeholder[i0_4, i1_4, i2, i3], T_softmax_maxelem[i0_4, i1_4, i2])
                        T.writes(T_softmax_exp[i0_4, i1_4, i2, i3])
                        T_softmax_exp[i0_4, i1_4, i2, i3] = T.exp(placeholder[i0_4, i1_4, i2, i3] - T_softmax_maxelem[i0_4, i1_4, i2], dtype="float32")
                for i2 in T.serial(384):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(64, 1, 1, 1, 6):
                        with T.block("T_softmax_expsum_rf"):
                            vi3_0, i0_5 = T.axis.remap("SS", [ax0, ax1])
                            i1_5 = T.axis.spatial(16, i1_3 + ax2)
                            i2_2 = T.axis.spatial(384, i2 + ax3)
                            vi3_1 = T.axis.reduce(6, ax4)
                            T.reads(T_softmax_exp[i0_5, i1_5, i2_2, vi3_0 * 6 + vi3_1])
                            T.writes(T_softmax_expsum_rf[i0_5, i1_5, i2_2, vi3_0])
                            with T.init():
                                T_softmax_expsum_rf[i0_5, i1_5, i2_2, vi3_0] = T.float32(0)
                            T_softmax_expsum_rf[i0_5, i1_5, i2_2, vi3_0] = T_softmax_expsum_rf[i0_5, i1_5, i2_2, vi3_0] + T_softmax_exp[i0_5, i1_5, i2_2, vi3_0 * 6 + vi3_1]
                    for i3 in T.serial(384):
                        for ax0, ax1, ax2, ax3 in T.grid(64, 1, 1, 1):
                            with T.block("T_softmax_expsum"):
                                vi3_0, i0_6 = T.axis.remap("RS", [ax0, ax1])
                                i1_6 = T.axis.spatial(16, i1_3 + ax2)
                                i2_3 = T.axis.spatial(384, i2 + ax3)
                                T.reads(T_softmax_expsum_rf[i0_6, i1_6, i2_3, vi3_0])
                                T.writes(T_softmax_expsum[i0_6, i1_6, i2_3])
                                with T.init():
                                    T_softmax_expsum[i0_6, i1_6, i2_3] = T.float32(0)
                                T_softmax_expsum[i0_6, i1_6, i2_3] = T_softmax_expsum[i0_6, i1_6, i2_3] + T_softmax_expsum_rf[i0_6, i1_6, i2_3, vi3_0]
                        with T.block("T_softmax_norm"):
                            i0_7, i1_7, i2_4, i3_1 = T.axis.remap("SSSS", [i0_3, i1_3, i2, i3])
                            T.reads(T_softmax_exp[i0_7, i1_7, i2_4, i3_1], T_softmax_expsum[i0_7, i1_7, i2_4])
                            T.writes(T_softmax_norm[i0_7, i1_7, i2_4, i3_1])
                            T.block_attr({"axis":3})
                            T_softmax_norm[i0_7, i1_7, i2_4, i3_1] = T_softmax_exp[i0_7, i1_7, i2_4, i3_1] / T_softmax_expsum[i0_7, i1_7, i2_4]
    

b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
l4, l5, l6, l7 = sch.get_loops(block=b2)
v8, v9 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[64, 6])
l10, l11 = sch.split(loop=l7, factors=[v8, v9])
b12 = sch.rfactor(loop=l10, factor_axis=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.random_compute_producer", ann_val=1)
l13, l14, l15, l16 = sch.get_loops(block=b0)
v17, v18 = sch.sample_perfect_tile(loop=l16, n=2, max_innermost_factor=64, decision=[96, 4])
l19, l20 = sch.split(loop=l16, factors=[v17, v18])
b21 = sch.rfactor(loop=l19, factor_axis=3)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.random_compute_producer", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v22 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v22)
b23, = sch.get_producers(block=b2)
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.random_compute_producer")
l24 = sch.sample_compute_location(block=b2, decision=3)
sch.compute_at(block=b2, loop=l24, preserve_unit_loops=True)
l25 = sch.sample_compute_location(block=b23, decision=2)
sch.compute_at(block=b23, loop=l25, preserve_unit_loops=True)
l26 = sch.sample_compute_location(block=b1, decision=1)
sch.compute_at(block=b1, loop=l26, preserve_unit_loops=True)
b27, = sch.get_producers(block=b0)
sch.unannotate(block_or_loop=b0, ann_key="meta_schedule.random_compute_producer")
l28 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l28, preserve_unit_loops=True)
l29 = sch.sample_compute_location(block=b27, decision=1)
sch.compute_at(block=b27, loop=l29, preserve_unit_loops=True)
[19:06:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #1:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 384, 384), "float32"], T_softmax_norm: T.Buffer[(1, 16, 384, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            T_softmax_maxelem = T.alloc_buffer([1, 16, 384], dtype="float32")
            T_softmax_exp = T.alloc_buffer([1, 16, 384, 384], dtype="float32")
            T_softmax_expsum = T.alloc_buffer([1, 16, 384], dtype="float32")
            T_softmax_expsum_rf = T.alloc_buffer([1, 16, 384, 64], dtype="float32")
            T_softmax_maxelem_rf = T.alloc_buffer([1, 16, 384, 4], dtype="float32")
            for i0, i1 in T.grid(1, 16):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(4, 1, 1, 384, 96):
                    with T.block("T_softmax_maxelem_rf"):
                        vi3_1, i0_1 = T.axis.remap("SS", [ax0, ax1])
                        i1_1 = T.axis.spatial(16, i1 + ax2)
                        i2, vi3_0 = T.axis.remap("SR", [ax3, ax4])
                        T.reads(placeholder[i0_1, i1_1, i2, vi3_0 * 4 + vi3_1])
                        T.writes(T_softmax_maxelem_rf[i0_1, i1_1, i2, vi3_1])
                        with T.init():
                            T_softmax_maxelem_rf[i0_1, i1_1, i2, vi3_1] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem_rf[i0_1, i1_1, i2, vi3_1] = T.max(T_softmax_maxelem_rf[i0_1, i1_1, i2, vi3_1], placeholder[i0_1, i1_1, i2, vi3_0 * 4 + vi3_1])
                for i2, i3_1 in T.grid(384, 4):
                    with T.block("T_softmax_maxelem"):
                        vi3_1 = T.axis.reduce(4, i3_1)
                        i0_2 = T.axis.spatial(1, 0)
                        i1_2, i2_1 = T.axis.remap("SS", [i1, i2])
                        T.reads(T_softmax_maxelem_rf[i0_2, i1_2, i2_1, vi3_1])
                        T.writes(T_softmax_maxelem[i0_2, i1_2, i2_1])
                        with T.init():
                            T_softmax_maxelem[i0_2, i1_2, i2_1] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[i0_2, i1_2, i2_1] = T.max(T_softmax_maxelem[i0_2, i1_2, i2_1], T_softmax_maxelem_rf[i0_2, i1_2, i2_1, vi3_1])
            for i0_3, i1_3, i2, i3 in T.grid(1, 16, 384, 384):
                with T.block("T_softmax_exp"):
                    i0_4, i1_4, i2_2, i3_2 = T.axis.remap("SSSS", [i0_3, i1_3, i2, i3])
                    T.reads(placeholder[i0_4, i1_4, i2_2, i3_2], T_softmax_maxelem[i0_4, i1_4, i2_2])
                    T.writes(T_softmax_exp[i0_4, i1_4, i2_2, i3_2])
                    T_softmax_exp[i0_4, i1_4, i2_2, i3_2] = T.exp(placeholder[i0_4, i1_4, i2_2, i3_2] - T_softmax_maxelem[i0_4, i1_4, i2_2], dtype="float32")
            for i0_5, i1_5, i2_3 in T.grid(1, 16, 384):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(64, 1, 1, 1, 6):
                    with T.block("T_softmax_expsum_rf"):
                        vi3_0, i0_6 = T.axis.remap("SS", [ax0, ax1])
                        i1_6 = T.axis.spatial(16, i1_5 + ax2)
                        i2_4 = T.axis.spatial(384, i2_3 + ax3)
                        vi3_1 = T.axis.reduce(6, ax4)
                        T.reads(T_softmax_exp[i0_6, i1_6, i2_4, vi3_0 * 6 + vi3_1])
                        T.writes(T_softmax_expsum_rf[i0_6, i1_6, i2_4, vi3_0])
                        with T.init():
                            T_softmax_expsum_rf[i0_6, i1_6, i2_4, vi3_0] = T.float32(0)
                        T_softmax_expsum_rf[i0_6, i1_6, i2_4, vi3_0] = T_softmax_expsum_rf[i0_6, i1_6, i2_4, vi3_0] + T_softmax_exp[i0_6, i1_6, i2_4, vi3_0 * 6 + vi3_1]
                for ax0, ax1, ax2, ax3 in T.grid(64, 1, 1, 1):
                    with T.block("T_softmax_expsum"):
                        vi3_0, i0_7 = T.axis.remap("RS", [ax0, ax1])
                        i1_7 = T.axis.spatial(16, i1_5 + ax2)
                        i2_5 = T.axis.spatial(384, i2_3 + ax3)
                        T.reads(T_softmax_expsum_rf[i0_7, i1_7, i2_5, vi3_0])
                        T.writes(T_softmax_expsum[i0_7, i1_7, i2_5])
                        with T.init():
                            T_softmax_expsum[i0_7, i1_7, i2_5] = T.float32(0)
                        T_softmax_expsum[i0_7, i1_7, i2_5] = T_softmax_expsum[i0_7, i1_7, i2_5] + T_softmax_expsum_rf[i0_7, i1_7, i2_5, vi3_0]
                for i3_3 in T.serial(384):
                    with T.block("T_softmax_norm"):
                        i0_8, i1_8, i2_6, i3_4 = T.axis.remap("SSSS", [i0_5, i1_5, i2_3, i3_3])
                        T.reads(T_softmax_exp[i0_8, i1_8, i2_6, i3_4], T_softmax_expsum[i0_8, i1_8, i2_6])
                        T.writes(T_softmax_norm[i0_8, i1_8, i2_6, i3_4])
                        T.block_attr({"axis":3})
                        T_softmax_norm[i0_8, i1_8, i2_6, i3_4] = T_softmax_exp[i0_8, i1_8, i2_6, i3_4] / T_softmax_expsum[i0_8, i1_8, i2_6]
    

b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
l4, l5, l6, l7 = sch.get_loops(block=b2)
v8, v9 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[64, 6])
l10, l11 = sch.split(loop=l7, factors=[v8, v9])
b12 = sch.rfactor(loop=l10, factor_axis=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.random_compute_producer", ann_val=1)
l13, l14, l15, l16 = sch.get_loops(block=b0)
v17, v18 = sch.sample_perfect_tile(loop=l16, n=2, max_innermost_factor=64, decision=[96, 4])
l19, l20 = sch.split(loop=l16, factors=[v17, v18])
b21 = sch.rfactor(loop=l20, factor_axis=3)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.random_compute_producer", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v22 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v22)
b23, = sch.get_producers(block=b2)
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.random_compute_producer")
l24 = sch.sample_compute_location(block=b2, decision=2)
sch.compute_at(block=b2, loop=l24, preserve_unit_loops=True)
l25 = sch.sample_compute_location(block=b23, decision=2)
sch.compute_at(block=b23, loop=l25, preserve_unit_loops=True)
l26 = sch.sample_compute_location(block=b1, decision=-1)
sch.compute_at(block=b1, loop=l26, preserve_unit_loops=True)
b27, = sch.get_producers(block=b0)
sch.unannotate(block_or_loop=b0, ann_key="meta_schedule.random_compute_producer")
l28 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l28, preserve_unit_loops=True)
l29 = sch.sample_compute_location(block=b27, decision=1)
sch.compute_at(block=b27, loop=l29, preserve_unit_loops=True)
[19:06:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #2:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 384, 384), "float32"], T_softmax_norm: T.Buffer[(1, 16, 384, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            T_softmax_maxelem = T.alloc_buffer([1, 16, 384], dtype="float32")
            T_softmax_expsum = T.alloc_buffer([1, 16, 384], dtype="float32")
            T_softmax_expsum_rf = T.alloc_buffer([1, 16, 384, 64], dtype="float32")
            for i0, i1, i2, i3 in T.grid(1, 16, 384, 384):
                with T.block("T_softmax_maxelem"):
                    i0_1, i1_1, i2_1, k = T.axis.remap("SSSR", [i0, i1, i2, i3])
                    T.reads(placeholder[i0_1, i1_1, i2_1, k])
                    T.writes(T_softmax_maxelem[i0_1, i1_1, i2_1])
                    with T.init():
                        T_softmax_maxelem[i0_1, i1_1, i2_1] = T.float32(-3.4028234663852886e+38)
                    T_softmax_maxelem[i0_1, i1_1, i2_1] = T.max(T_softmax_maxelem[i0_1, i1_1, i2_1], placeholder[i0_1, i1_1, i2_1, k])
            for i0, i1, i2, i3_0, i3_1 in T.grid(1, 16, 384, 64, 6):
                with T.block("T_softmax_expsum_rf"):
                    vi3_0 = T.axis.spatial(64, i3_0)
                    i0_2 = T.axis.spatial(1, 0)
                    i1_2, i2_2, vi3_1 = T.axis.remap("SSR", [i1, i2, i3_1])
                    T.reads(placeholder[i0_2, i1_2, i2_2, vi3_0 * 6 + vi3_1], T_softmax_maxelem[i0_2, i1_2, i2_2])
                    T.writes(T_softmax_expsum_rf[i0_2, i1_2, i2_2, vi3_0])
                    with T.init():
                        T_softmax_expsum_rf[i0_2, i1_2, i2_2, vi3_0] = T.float32(0)
                    T_softmax_expsum_rf[i0_2, i1_2, i2_2, vi3_0] = T_softmax_expsum_rf[i0_2, i1_2, i2_2, vi3_0] + T.exp(placeholder[i0_2, i1_2, i2_2, vi3_0 * 6 + vi3_1] - T_softmax_maxelem[i0_2, i1_2, i2_2], dtype="float32")
            for i0_3, i1_3, i2_3, i3_0 in T.grid(1, 16, 384, 64):
                with T.block("T_softmax_expsum"):
                    vi3_0 = T.axis.reduce(64, i3_0)
                    i0_4 = T.axis.spatial(1, 0)
                    i1_4, i2_4 = T.axis.remap("SS", [i1_3, i2_3])
                    T.reads(T_softmax_expsum_rf[i0_4, i1_4, i2_4, vi3_0])
                    T.writes(T_softmax_expsum[i0_4, i1_4, i2_4])
                    with T.init():
                        T_softmax_expsum[i0_4, i1_4, i2_4] = T.float32(0)
                    T_softmax_expsum[i0_4, i1_4, i2_4] = T_softmax_expsum[i0_4, i1_4, i2_4] + T_softmax_expsum_rf[i0_4, i1_4, i2_4, vi3_0]
            for i0_5, i1_5, i2_5, i3 in T.grid(1, 16, 384, 384):
                with T.block("T_softmax_norm"):
                    i0_6, i1_6, i2_6, i3_2 = T.axis.remap("SSSS", [i0_5, i1_5, i2_5, i3])
                    T.reads(placeholder[i0_6, i1_6, i2_6, i3_2], T_softmax_maxelem[i0_6, i1_6, i2_6], T_softmax_expsum[i0_6, i1_6, i2_6])
                    T.writes(T_softmax_norm[i0_6, i1_6, i2_6, i3_2])
                    T.block_attr({"axis":3})
                    T_softmax_norm[i0_6, i1_6, i2_6, i3_2] = T.exp(placeholder[i0_6, i1_6, i2_6, i3_2] - T_softmax_maxelem[i0_6, i1_6, i2_6], dtype="float32") / T_softmax_expsum[i0_6, i1_6, i2_6]
    

b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
l4, l5, l6, l7 = sch.get_loops(block=b2)
v8, v9 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[64, 6])
l10, l11 = sch.split(loop=l7, factors=[v8, v9])
b12 = sch.rfactor(loop=l10, factor_axis=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.random_compute_producer", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v13 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v13)
b14, = sch.get_producers(block=b2)
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.random_compute_producer")
l15 = sch.sample_compute_location(block=b2, decision=-1)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True)
l16 = sch.sample_compute_location(block=b14, decision=-1)
sch.compute_at(block=b14, loop=l16, preserve_unit_loops=True)
l17 = sch.sample_compute_location(block=b1, decision=-2)
sch.compute_at(block=b1, loop=l17, preserve_unit_loops=True)
l18 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l18, preserve_unit_loops=True)
[19:06:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #3:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 384, 384), "float32"], T_softmax_norm: T.Buffer[(1, 16, 384, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":16, "meta_schedule.vectorize":64})
            T_softmax_maxelem = T.alloc_buffer([1, 16, 384], dtype="float32")
            T_softmax_exp = T.alloc_buffer([1, 16, 384, 384], dtype="float32")
            T_softmax_expsum = T.alloc_buffer([1, 16, 384], dtype="float32")
            T_softmax_expsum_rf = T.alloc_buffer([1, 16, 384, 6], dtype="float32")
            T_softmax_maxelem_rf = T.alloc_buffer([1, 16, 384, 12], dtype="float32")
            for i0, i1 in T.grid(1, 16):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(12, 1, 1, 384, 32):
                    with T.block("T_softmax_maxelem_rf"):
                        vi3_0, i0_1 = T.axis.remap("SS", [ax0, ax1])
                        i1_1 = T.axis.spatial(16, i1 + ax2)
                        i2, vi3_1 = T.axis.remap("SR", [ax3, ax4])
                        T.reads(placeholder[i0_1, i1_1, i2, vi3_0 * 32 + vi3_1])
                        T.writes(T_softmax_maxelem_rf[i0_1, i1_1, i2, vi3_0])
                        with T.init():
                            T_softmax_maxelem_rf[i0_1, i1_1, i2, vi3_0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem_rf[i0_1, i1_1, i2, vi3_0] = T.max(T_softmax_maxelem_rf[i0_1, i1_1, i2, vi3_0], placeholder[i0_1, i1_1, i2, vi3_0 * 32 + vi3_1])
                for ax0, ax1, ax2, ax3 in T.grid(1, 1, 384, 384):
                    for ax0_1, ax1_1, ax2_1, ax3_1 in T.grid(12, 1, 1, 1):
                        with T.block("T_softmax_maxelem"):
                            vi3_0, i0_2 = T.axis.remap("RS", [ax0_1, ax1_1])
                            i1_2 = T.axis.spatial(16, i1 + ax2_1)
                            i2 = T.axis.spatial(384, ax2 + ax3_1)
                            T.reads(T_softmax_maxelem_rf[i0_2, i1_2, i2, vi3_0])
                            T.writes(T_softmax_maxelem[i0_2, i1_2, i2])
                            with T.init():
                                T_softmax_maxelem[i0_2, i1_2, i2] = T.float32(-3.4028234663852886e+38)
                            T_softmax_maxelem[i0_2, i1_2, i2] = T.max(T_softmax_maxelem[i0_2, i1_2, i2], T_softmax_maxelem_rf[i0_2, i1_2, i2, vi3_0])
                    with T.block("T_softmax_exp"):
                        i0_3 = T.axis.spatial(1, ax0)
                        i1_3 = T.axis.spatial(16, i1 + ax1)
                        i2, i3 = T.axis.remap("SS", [ax2, ax3])
                        T.reads(placeholder[i0_3, i1_3, i2, i3], T_softmax_maxelem[i0_3, i1_3, i2])
                        T.writes(T_softmax_exp[i0_3, i1_3, i2, i3])
                        T_softmax_exp[i0_3, i1_3, i2, i3] = T.exp(placeholder[i0_3, i1_3, i2, i3] - T_softmax_maxelem[i0_3, i1_3, i2], dtype="float32")
                for i2 in T.serial(384):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(6, 1, 1, 1, 64):
                        with T.block("T_softmax_expsum_rf"):
                            vi3_1, i0_4 = T.axis.remap("SS", [ax0, ax1])
                            i1_4 = T.axis.spatial(16, i1 + ax2)
                            i2_1 = T.axis.spatial(384, i2 + ax3)
                            vi3_0 = T.axis.reduce(64, ax4)
                            T.reads(T_softmax_exp[i0_4, i1_4, i2_1, vi3_0 * 6 + vi3_1])
                            T.writes(T_softmax_expsum_rf[i0_4, i1_4, i2_1, vi3_1])
                            with T.init():
                                T_softmax_expsum_rf[i0_4, i1_4, i2_1, vi3_1] = T.float32(0)
                            T_softmax_expsum_rf[i0_4, i1_4, i2_1, vi3_1] = T_softmax_expsum_rf[i0_4, i1_4, i2_1, vi3_1] + T_softmax_exp[i0_4, i1_4, i2_1, vi3_0 * 6 + vi3_1]
                    for ax0, ax1, ax2, ax3 in T.grid(6, 1, 1, 1):
                        with T.block("T_softmax_expsum"):
                            vi3_1, i0_5 = T.axis.remap("RS", [ax0, ax1])
                            i1_5 = T.axis.spatial(16, i1 + ax2)
                            i2_2 = T.axis.spatial(384, i2 + ax3)
                            T.reads(T_softmax_expsum_rf[i0_5, i1_5, i2_2, vi3_1])
                            T.writes(T_softmax_expsum[i0_5, i1_5, i2_2])
                            with T.init():
                                T_softmax_expsum[i0_5, i1_5, i2_2] = T.float32(0)
                            T_softmax_expsum[i0_5, i1_5, i2_2] = T_softmax_expsum[i0_5, i1_5, i2_2] + T_softmax_expsum_rf[i0_5, i1_5, i2_2, vi3_1]
                    for i3 in T.serial(384):
                        with T.block("T_softmax_norm"):
                            i0_6, i1_6, i2_3, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                            T.reads(T_softmax_exp[i0_6, i1_6, i2_3, i3_1], T_softmax_expsum[i0_6, i1_6, i2_3])
                            T.writes(T_softmax_norm[i0_6, i1_6, i2_3, i3_1])
                            T.block_attr({"axis":3})
                            T_softmax_norm[i0_6, i1_6, i2_3, i3_1] = T_softmax_exp[i0_6, i1_6, i2_3, i3_1] / T_softmax_expsum[i0_6, i1_6, i2_3]
    

b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
l4, l5, l6, l7 = sch.get_loops(block=b2)
v8, v9 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[64, 6])
l10, l11 = sch.split(loop=l7, factors=[v8, v9])
b12 = sch.rfactor(loop=l11, factor_axis=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.random_compute_producer", ann_val=1)
l13, l14, l15, l16 = sch.get_loops(block=b0)
v17, v18 = sch.sample_perfect_tile(loop=l16, n=2, max_innermost_factor=64, decision=[12, 32])
l19, l20 = sch.split(loop=l16, factors=[v17, v18])
b21 = sch.rfactor(loop=l19, factor_axis=3)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.random_compute_producer", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v22 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v22)
b23, = sch.get_producers(block=b2)
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.random_compute_producer")
l24 = sch.sample_compute_location(block=b2, decision=2)
sch.compute_at(block=b2, loop=l24, preserve_unit_loops=True)
l25 = sch.sample_compute_location(block=b23, decision=2)
sch.compute_at(block=b23, loop=l25, preserve_unit_loops=True)
l26 = sch.sample_compute_location(block=b1, decision=1)
sch.compute_at(block=b1, loop=l26, preserve_unit_loops=True)
b27, = sch.get_producers(block=b0)
sch.unannotate(block_or_loop=b0, ann_key="meta_schedule.random_compute_producer")
l28 = sch.sample_compute_location(block=b0, decision=5)
sch.compute_at(block=b0, loop=l28, preserve_unit_loops=True)
l29 = sch.sample_compute_location(block=b27, decision=1)
sch.compute_at(block=b27, loop=l29, preserve_unit_loops=True)
[19:06:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #4:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 384, 384), "float32"], T_softmax_norm: T.Buffer[(1, 16, 384, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            T_softmax_maxelem = T.alloc_buffer([1, 16, 384], dtype="float32")
            T_softmax_exp = T.alloc_buffer([1, 16, 384, 384], dtype="float32")
            T_softmax_expsum = T.alloc_buffer([1, 16, 384], dtype="float32")
            T_softmax_expsum_rf = T.alloc_buffer([1, 16, 384, 6], dtype="float32")
            T_softmax_maxelem_rf = T.alloc_buffer([1, 16, 384, 32], dtype="float32")
            for i0, i1 in T.grid(1, 16):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(32, 1, 1, 384, 12):
                    with T.block("T_softmax_maxelem_rf"):
                        vi3_1, i0_1 = T.axis.remap("SS", [ax0, ax1])
                        i1_1 = T.axis.spatial(16, i1 + ax2)
                        i2, vi3_0 = T.axis.remap("SR", [ax3, ax4])
                        T.reads(placeholder[i0_1, i1_1, i2, vi3_0 * 32 + vi3_1])
                        T.writes(T_softmax_maxelem_rf[i0_1, i1_1, i2, vi3_1])
                        with T.init():
                            T_softmax_maxelem_rf[i0_1, i1_1, i2, vi3_1] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem_rf[i0_1, i1_1, i2, vi3_1] = T.max(T_softmax_maxelem_rf[i0_1, i1_1, i2, vi3_1], placeholder[i0_1, i1_1, i2, vi3_0 * 32 + vi3_1])
                for i2 in T.serial(384):
                    for ax0, ax1, ax2, ax3 in T.grid(32, 1, 1, 1):
                        with T.block("T_softmax_maxelem"):
                            vi3_1, i0_2 = T.axis.remap("RS", [ax0, ax1])
                            i1_2 = T.axis.spatial(16, i1 + ax2)
                            i2_1 = T.axis.spatial(384, i2 + ax3)
                            T.reads(T_softmax_maxelem_rf[i0_2, i1_2, i2_1, vi3_1])
                            T.writes(T_softmax_maxelem[i0_2, i1_2, i2_1])
                            with T.init():
                                T_softmax_maxelem[i0_2, i1_2, i2_1] = T.float32(-3.4028234663852886e+38)
                            T_softmax_maxelem[i0_2, i1_2, i2_1] = T.max(T_softmax_maxelem[i0_2, i1_2, i2_1], T_softmax_maxelem_rf[i0_2, i1_2, i2_1, vi3_1])
                    for i3 in T.serial(384):
                        with T.block("T_softmax_exp"):
                            i0_3, i1_3, i2_2, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                            T.reads(placeholder[i0_3, i1_3, i2_2, i3_1], T_softmax_maxelem[i0_3, i1_3, i2_2])
                            T.writes(T_softmax_exp[i0_3, i1_3, i2_2, i3_1])
                            T_softmax_exp[i0_3, i1_3, i2_2, i3_1] = T.exp(placeholder[i0_3, i1_3, i2_2, i3_1] - T_softmax_maxelem[i0_3, i1_3, i2_2], dtype="float32")
            for i0_4, i1_4 in T.grid(1, 16):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(6, 1, 1, 384, 64):
                    with T.block("T_softmax_expsum_rf"):
                        vi3_1, i0_5 = T.axis.remap("SS", [ax0, ax1])
                        i1_5 = T.axis.spatial(16, i1_4 + ax2)
                        i2_3, vi3_0 = T.axis.remap("SR", [ax3, ax4])
                        T.reads(T_softmax_exp[i0_5, i1_5, i2_3, vi3_0 * 6 + vi3_1])
                        T.writes(T_softmax_expsum_rf[i0_5, i1_5, i2_3, vi3_1])
                        with T.init():
                            T_softmax_expsum_rf[i0_5, i1_5, i2_3, vi3_1] = T.float32(0)
                        T_softmax_expsum_rf[i0_5, i1_5, i2_3, vi3_1] = T_softmax_expsum_rf[i0_5, i1_5, i2_3, vi3_1] + T_softmax_exp[i0_5, i1_5, i2_3, vi3_0 * 6 + vi3_1]
                for i2_4 in T.serial(384):
                    for ax0, ax1, ax2, ax3 in T.grid(6, 1, 1, 1):
                        with T.block("T_softmax_expsum"):
                            vi3_1, i0_6 = T.axis.remap("RS", [ax0, ax1])
                            i1_6 = T.axis.spatial(16, i1_4 + ax2)
                            i2_5 = T.axis.spatial(384, i2_4 + ax3)
                            T.reads(T_softmax_expsum_rf[i0_6, i1_6, i2_5, vi3_1])
                            T.writes(T_softmax_expsum[i0_6, i1_6, i2_5])
                            with T.init():
                                T_softmax_expsum[i0_6, i1_6, i2_5] = T.float32(0)
                            T_softmax_expsum[i0_6, i1_6, i2_5] = T_softmax_expsum[i0_6, i1_6, i2_5] + T_softmax_expsum_rf[i0_6, i1_6, i2_5, vi3_1]
                    for i3 in T.serial(384):
                        with T.block("T_softmax_norm"):
                            i0_7, i1_7, i2_6, i3_2 = T.axis.remap("SSSS", [i0_4, i1_4, i2_4, i3])
                            T.reads(T_softmax_exp[i0_7, i1_7, i2_6, i3_2], T_softmax_expsum[i0_7, i1_7, i2_6])
                            T.writes(T_softmax_norm[i0_7, i1_7, i2_6, i3_2])
                            T.block_attr({"axis":3})
                            T_softmax_norm[i0_7, i1_7, i2_6, i3_2] = T_softmax_exp[i0_7, i1_7, i2_6, i3_2] / T_softmax_expsum[i0_7, i1_7, i2_6]
    

b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
l4, l5, l6, l7 = sch.get_loops(block=b2)
v8, v9 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[64, 6])
l10, l11 = sch.split(loop=l7, factors=[v8, v9])
b12 = sch.rfactor(loop=l11, factor_axis=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.random_compute_producer", ann_val=1)
l13, l14, l15, l16 = sch.get_loops(block=b0)
v17, v18 = sch.sample_perfect_tile(loop=l16, n=2, max_innermost_factor=64, decision=[12, 32])
l19, l20 = sch.split(loop=l16, factors=[v17, v18])
b21 = sch.rfactor(loop=l20, factor_axis=3)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.random_compute_producer", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v22 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v22)
b23, = sch.get_producers(block=b2)
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.random_compute_producer")
l24 = sch.sample_compute_location(block=b2, decision=2)
sch.compute_at(block=b2, loop=l24, preserve_unit_loops=True)
l25 = sch.sample_compute_location(block=b23, decision=1)
sch.compute_at(block=b23, loop=l25, preserve_unit_loops=True)
l26 = sch.sample_compute_location(block=b1, decision=-1)
sch.compute_at(block=b1, loop=l26, preserve_unit_loops=True)
b27, = sch.get_producers(block=b0)
sch.unannotate(block_or_loop=b0, ann_key="meta_schedule.random_compute_producer")
l28 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l28, preserve_unit_loops=True)
l29 = sch.sample_compute_location(block=b27, decision=1)
sch.compute_at(block=b27, loop=l29, preserve_unit_loops=True)
[19:06:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #5:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 384, 384), "float32"], T_softmax_norm: T.Buffer[(1, 16, 384, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            T_softmax_maxelem = T.alloc_buffer([1, 16, 384], dtype="float32")
            T_softmax_exp = T.alloc_buffer([1, 16, 384, 384], dtype="float32")
            T_softmax_expsum = T.alloc_buffer([1, 16, 384], dtype="float32")
            T_softmax_expsum_rf = T.alloc_buffer([1, 16, 384, 6], dtype="float32")
            for i0, i1, i2 in T.grid(1, 16, 384):
                for ax0, ax1, ax2, ax3 in T.grid(1, 1, 1, 384):
                    for ax0_1, ax1_1, ax2_1, ax3_1 in T.grid(1, 1, 1, 384):
                        with T.block("T_softmax_maxelem"):
                            i0_1 = T.axis.spatial(1, ax0_1)
                            i1_1 = T.axis.spatial(16, i1 + ax1_1)
                            i2_1 = T.axis.spatial(384, i2 + ax2_1)
                            k = T.axis.reduce(384, ax3_1)
                            T.reads(placeholder[i0_1, i1_1, i2_1, k])
                            T.writes(T_softmax_maxelem[i0_1, i1_1, i2_1])
                            with T.init():
                                T_softmax_maxelem[i0_1, i1_1, i2_1] = T.float32(-3.4028234663852886e+38)
                            T_softmax_maxelem[i0_1, i1_1, i2_1] = T.max(T_softmax_maxelem[i0_1, i1_1, i2_1], placeholder[i0_1, i1_1, i2_1, k])
                    with T.block("T_softmax_exp"):
                        i0_2 = T.axis.spatial(1, ax0)
                        i1_2 = T.axis.spatial(16, i1 + ax1)
                        i2_2 = T.axis.spatial(384, i2 + ax2)
                        i3 = T.axis.spatial(384, ax3)
                        T.reads(placeholder[i0_2, i1_2, i2_2, i3], T_softmax_maxelem[i0_2, i1_2, i2_2])
                        T.writes(T_softmax_exp[i0_2, i1_2, i2_2, i3])
                        T_softmax_exp[i0_2, i1_2, i2_2, i3] = T.exp(placeholder[i0_2, i1_2, i2_2, i3] - T_softmax_maxelem[i0_2, i1_2, i2_2], dtype="float32")
                for i3 in T.serial(384):
                    for ax0 in T.serial(6):
                        for ax0_2, ax1, ax2, ax3, ax4 in T.grid(1, 1, 1, 1, 64):
                            with T.block("T_softmax_expsum_rf"):
                                vi3_1 = T.axis.spatial(6, ax0 + ax0_2)
                                i0_3 = T.axis.spatial(1, ax1)
                                i1_3 = T.axis.spatial(16, i1 + ax2)
                                i2_3 = T.axis.spatial(384, i2 + ax3)
                                vi3_0 = T.axis.reduce(64, ax4)
                                T.reads(T_softmax_exp[i0_3, i1_3, i2_3, vi3_0 * 6 + vi3_1])
                                T.writes(T_softmax_expsum_rf[i0_3, i1_3, i2_3, vi3_1])
                                with T.init():
                                    T_softmax_expsum_rf[i0_3, i1_3, i2_3, vi3_1] = T.float32(0)
                                T_softmax_expsum_rf[i0_3, i1_3, i2_3, vi3_1] = T_softmax_expsum_rf[i0_3, i1_3, i2_3, vi3_1] + T_softmax_exp[i0_3, i1_3, i2_3, vi3_0 * 6 + vi3_1]
                        for ax1, ax2, ax3 in T.grid(1, 1, 1):
                            with T.block("T_softmax_expsum"):
                                vi3_1, i0_4 = T.axis.remap("RS", [ax0, ax1])
                                i1_4 = T.axis.spatial(16, i1 + ax2)
                                i2_4 = T.axis.spatial(384, i2 + ax3)
                                T.reads(T_softmax_expsum_rf[i0_4, i1_4, i2_4, vi3_1])
                                T.writes(T_softmax_expsum[i0_4, i1_4, i2_4])
                                with T.init():
                                    T_softmax_expsum[i0_4, i1_4, i2_4] = T.float32(0)
                                T_softmax_expsum[i0_4, i1_4, i2_4] = T_softmax_expsum[i0_4, i1_4, i2_4] + T_softmax_expsum_rf[i0_4, i1_4, i2_4, vi3_1]
                    with T.block("T_softmax_norm"):
                        i0_5, i1_5, i2_5, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                        T.reads(T_softmax_exp[i0_5, i1_5, i2_5, i3_1], T_softmax_expsum[i0_5, i1_5, i2_5])
                        T.writes(T_softmax_norm[i0_5, i1_5, i2_5, i3_1])
                        T.block_attr({"axis":3})
                        T_softmax_norm[i0_5, i1_5, i2_5, i3_1] = T_softmax_exp[i0_5, i1_5, i2_5, i3_1] / T_softmax_expsum[i0_5, i1_5, i2_5]
    

b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
l4, l5, l6, l7 = sch.get_loops(block=b2)
v8, v9 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[64, 6])
l10, l11 = sch.split(loop=l7, factors=[v8, v9])
b12 = sch.rfactor(loop=l11, factor_axis=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.random_compute_producer", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v13 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v13)
b14, = sch.get_producers(block=b2)
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.random_compute_producer")
l15 = sch.sample_compute_location(block=b2, decision=3)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True)
l16 = sch.sample_compute_location(block=b14, decision=4)
sch.compute_at(block=b14, loop=l16, preserve_unit_loops=True)
l17 = sch.sample_compute_location(block=b1, decision=2)
sch.compute_at(block=b1, loop=l17, preserve_unit_loops=True)
l18 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l18, preserve_unit_loops=True)
[19:06:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #6:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 384, 384), "float32"], T_softmax_norm: T.Buffer[(1, 16, 384, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            T_softmax_maxelem = T.alloc_buffer([1, 16, 384], dtype="float32")
            T_softmax_exp = T.alloc_buffer([1, 16, 384, 384], dtype="float32")
            T_softmax_expsum = T.alloc_buffer([1, 16, 384], dtype="float32")
            T_softmax_maxelem_rf = T.alloc_buffer([1, 16, 384, 8], dtype="float32")
            for i0, i1, i2, i3_0, i3_1 in T.grid(1, 16, 384, 8, 48):
                with T.block("T_softmax_maxelem_rf"):
                    vi3_0 = T.axis.spatial(8, i3_0)
                    i0_1 = T.axis.spatial(1, 0)
                    i1_1, i2_1, vi3_1 = T.axis.remap("SSR", [i1, i2, i3_1])
                    T.reads(placeholder[i0_1, i1_1, i2_1, vi3_0 * 48 + vi3_1])
                    T.writes(T_softmax_maxelem_rf[i0_1, i1_1, i2_1, vi3_0])
                    with T.init():
                        T_softmax_maxelem_rf[i0_1, i1_1, i2_1, vi3_0] = T.float32(-3.4028234663852886e+38)
                    T_softmax_maxelem_rf[i0_1, i1_1, i2_1, vi3_0] = T.max(T_softmax_maxelem_rf[i0_1, i1_1, i2_1, vi3_0], placeholder[i0_1, i1_1, i2_1, vi3_0 * 48 + vi3_1])
            for i0, i1, i2 in T.grid(1, 16, 384):
                for ax0, ax1, ax2, ax3 in T.grid(1, 1, 1, 384):
                    for ax0_1, ax1_1, ax2_1, ax3_1 in T.grid(8, 1, 1, 1):
                        with T.block("T_softmax_maxelem"):
                            vi3_0, i0_2 = T.axis.remap("RS", [ax0_1, ax1_1])
                            i1_2 = T.axis.spatial(16, i1 + ax2_1)
                            i2_2 = T.axis.spatial(384, i2 + ax3_1)
                            T.reads(T_softmax_maxelem_rf[i0_2, i1_2, i2_2, vi3_0])
                            T.writes(T_softmax_maxelem[i0_2, i1_2, i2_2])
                            with T.init():
                                T_softmax_maxelem[i0_2, i1_2, i2_2] = T.float32(-3.4028234663852886e+38)
                            T_softmax_maxelem[i0_2, i1_2, i2_2] = T.max(T_softmax_maxelem[i0_2, i1_2, i2_2], T_softmax_maxelem_rf[i0_2, i1_2, i2_2, vi3_0])
                    with T.block("T_softmax_exp"):
                        i0_3 = T.axis.spatial(1, ax0)
                        i1_3 = T.axis.spatial(16, i1 + ax1)
                        i2_3 = T.axis.spatial(384, i2 + ax2)
                        i3 = T.axis.spatial(384, ax3)
                        T.reads(placeholder[i0_3, i1_3, i2_3, i3], T_softmax_maxelem[i0_3, i1_3, i2_3])
                        T.writes(T_softmax_exp[i0_3, i1_3, i2_3, i3])
                        T_softmax_exp[i0_3, i1_3, i2_3, i3] = T.exp(placeholder[i0_3, i1_3, i2_3, i3] - T_softmax_maxelem[i0_3, i1_3, i2_3], dtype="float32")
                for i3 in T.serial(384):
                    for ax0, ax1, ax2, ax3 in T.grid(1, 1, 1, 384):
                        with T.block("T_softmax_expsum"):
                            i0_4 = T.axis.spatial(1, ax0)
                            i1_4 = T.axis.spatial(16, i1 + ax1)
                            i2_4 = T.axis.spatial(384, i2 + ax2)
                            k = T.axis.reduce(384, ax3)
                            T.reads(T_softmax_exp[i0_4, i1_4, i2_4, k])
                            T.writes(T_softmax_expsum[i0_4, i1_4, i2_4])
                            with T.init():
                                T_softmax_expsum[i0_4, i1_4, i2_4] = T.float32(0)
                            T_softmax_expsum[i0_4, i1_4, i2_4] = T_softmax_expsum[i0_4, i1_4, i2_4] + T_softmax_exp[i0_4, i1_4, i2_4, k]
                    with T.block("T_softmax_norm"):
                        i0_5, i1_5, i2_5, i3_2 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                        T.reads(T_softmax_exp[i0_5, i1_5, i2_5, i3_2], T_softmax_expsum[i0_5, i1_5, i2_5])
                        T.writes(T_softmax_norm[i0_5, i1_5, i2_5, i3_2])
                        T.block_attr({"axis":3})
                        T_softmax_norm[i0_5, i1_5, i2_5, i3_2] = T_softmax_exp[i0_5, i1_5, i2_5, i3_2] / T_softmax_expsum[i0_5, i1_5, i2_5]
    

b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
l4, l5, l6, l7 = sch.get_loops(block=b0)
v8, v9 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[8, 48])
l10, l11 = sch.split(loop=l7, factors=[v8, v9])
b12 = sch.rfactor(loop=l10, factor_axis=3)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.random_compute_producer", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v13 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v13)
l14 = sch.sample_compute_location(block=b2, decision=3)
sch.compute_at(block=b2, loop=l14, preserve_unit_loops=True)
l15 = sch.sample_compute_location(block=b1, decision=2)
sch.compute_at(block=b1, loop=l15, preserve_unit_loops=True)
b16, = sch.get_producers(block=b0)
sch.unannotate(block_or_loop=b0, ann_key="meta_schedule.random_compute_producer")
l17 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l17, preserve_unit_loops=True)
l18 = sch.sample_compute_location(block=b16, decision=-1)
sch.compute_at(block=b16, loop=l18, preserve_unit_loops=True)
[19:06:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #7:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 384, 384), "float32"], T_softmax_norm: T.Buffer[(1, 16, 384, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":16, "meta_schedule.vectorize":64})
            T_softmax_maxelem = T.alloc_buffer([1, 16, 384], dtype="float32")
            T_softmax_exp = T.alloc_buffer([1, 16, 384, 384], dtype="float32")
            T_softmax_expsum = T.alloc_buffer([1, 16, 384], dtype="float32")
            T_softmax_maxelem_rf = T.alloc_buffer([1, 16, 384, 48], dtype="float32")
            for i0, i1, i2, i3_0, i3_1 in T.grid(1, 16, 384, 8, 48):
                with T.block("T_softmax_maxelem_rf"):
                    vi3_1 = T.axis.spatial(48, i3_1)
                    i0_1 = T.axis.spatial(1, 0)
                    i1_1, i2_1, vi3_0 = T.axis.remap("SSR", [i1, i2, i3_0])
                    T.reads(placeholder[i0_1, i1_1, i2_1, vi3_0 * 48 + vi3_1])
                    T.writes(T_softmax_maxelem_rf[i0_1, i1_1, i2_1, vi3_1])
                    with T.init():
                        T_softmax_maxelem_rf[i0_1, i1_1, i2_1, vi3_1] = T.float32(-3.4028234663852886e+38)
                    T_softmax_maxelem_rf[i0_1, i1_1, i2_1, vi3_1] = T.max(T_softmax_maxelem_rf[i0_1, i1_1, i2_1, vi3_1], placeholder[i0_1, i1_1, i2_1, vi3_0 * 48 + vi3_1])
            for i0, i1 in T.grid(1, 16):
                for ax0, ax1, ax2 in T.grid(1, 1, 384):
                    for ax0_1, ax1_1, ax2_1, ax3 in T.grid(48, 1, 1, 1):
                        with T.block("T_softmax_maxelem"):
                            vi3_1, i0_2 = T.axis.remap("RS", [ax0_1, ax1_1])
                            i1_2 = T.axis.spatial(16, i1 + ax2_1)
                            i2 = T.axis.spatial(384, ax2 + ax3)
                            T.reads(T_softmax_maxelem_rf[i0_2, i1_2, i2, vi3_1])
                            T.writes(T_softmax_maxelem[i0_2, i1_2, i2])
                            with T.init():
                                T_softmax_maxelem[i0_2, i1_2, i2] = T.float32(-3.4028234663852886e+38)
                            T_softmax_maxelem[i0_2, i1_2, i2] = T.max(T_softmax_maxelem[i0_2, i1_2, i2], T_softmax_maxelem_rf[i0_2, i1_2, i2, vi3_1])
                    for ax3 in T.serial(384):
                        with T.block("T_softmax_exp"):
                            i0_3 = T.axis.spatial(1, ax0)
                            i1_3 = T.axis.spatial(16, i1 + ax1)
                            i2, i3 = T.axis.remap("SS", [ax2, ax3])
                            T.reads(placeholder[i0_3, i1_3, i2, i3], T_softmax_maxelem[i0_3, i1_3, i2])
                            T.writes(T_softmax_exp[i0_3, i1_3, i2, i3])
                            T_softmax_exp[i0_3, i1_3, i2, i3] = T.exp(placeholder[i0_3, i1_3, i2, i3] - T_softmax_maxelem[i0_3, i1_3, i2], dtype="float32")
                for ax0, ax1, ax2, ax3 in T.grid(1, 1, 384, 384):
                    with T.block("T_softmax_expsum"):
                        i0_4 = T.axis.spatial(1, ax0)
                        i1_4 = T.axis.spatial(16, i1 + ax1)
                        i2, k = T.axis.remap("SR", [ax2, ax3])
                        T.reads(T_softmax_exp[i0_4, i1_4, i2, k])
                        T.writes(T_softmax_expsum[i0_4, i1_4, i2])
                        with T.init():
                            T_softmax_expsum[i0_4, i1_4, i2] = T.float32(0)
                        T_softmax_expsum[i0_4, i1_4, i2] = T_softmax_expsum[i0_4, i1_4, i2] + T_softmax_exp[i0_4, i1_4, i2, k]
                for i2, i3 in T.grid(384, 384):
                    with T.block("T_softmax_norm"):
                        i0_5, i1_5, i2_2, i3_2 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                        T.reads(T_softmax_exp[i0_5, i1_5, i2_2, i3_2], T_softmax_expsum[i0_5, i1_5, i2_2])
                        T.writes(T_softmax_norm[i0_5, i1_5, i2_2, i3_2])
                        T.block_attr({"axis":3})
                        T_softmax_norm[i0_5, i1_5, i2_2, i3_2] = T_softmax_exp[i0_5, i1_5, i2_2, i3_2] / T_softmax_expsum[i0_5, i1_5, i2_2]
    

b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
l4, l5, l6, l7 = sch.get_loops(block=b0)
v8, v9 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[8, 48])
l10, l11 = sch.split(loop=l7, factors=[v8, v9])
b12 = sch.rfactor(loop=l11, factor_axis=3)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.random_compute_producer", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v13 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v13)
l14 = sch.sample_compute_location(block=b2, decision=1)
sch.compute_at(block=b2, loop=l14, preserve_unit_loops=True)
l15 = sch.sample_compute_location(block=b1, decision=1)
sch.compute_at(block=b1, loop=l15, preserve_unit_loops=True)
b16, = sch.get_producers(block=b0)
sch.unannotate(block_or_loop=b0, ann_key="meta_schedule.random_compute_producer")
l17 = sch.sample_compute_location(block=b0, decision=4)
sch.compute_at(block=b0, loop=l17, preserve_unit_loops=True)
l18 = sch.sample_compute_location(block=b16, decision=-1)
sch.compute_at(block=b16, loop=l18, preserve_unit_loops=True)
[19:06:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #8:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 384, 384), "float32"], T_softmax_norm: T.Buffer[(1, 16, 384, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":64, "meta_schedule.vectorize":64})
            T_softmax_maxelem = T.alloc_buffer([1, 16, 384], dtype="float32")
            T_softmax_expsum = T.alloc_buffer([1, 16, 384], dtype="float32")
            for i0, i1, i2, i3 in T.grid(1, 16, 384, 384):
                with T.block("T_softmax_maxelem"):
                    i0_1, i1_1, i2_1, k = T.axis.remap("SSSR", [i0, i1, i2, i3])
                    T.reads(placeholder[i0_1, i1_1, i2_1, k])
                    T.writes(T_softmax_maxelem[i0_1, i1_1, i2_1])
                    with T.init():
                        T_softmax_maxelem[i0_1, i1_1, i2_1] = T.float32(-3.4028234663852886e+38)
                    T_softmax_maxelem[i0_1, i1_1, i2_1] = T.max(T_softmax_maxelem[i0_1, i1_1, i2_1], placeholder[i0_1, i1_1, i2_1, k])
            for i0, i1, i2, i3 in T.grid(1, 16, 384, 384):
                with T.block("T_softmax_expsum"):
                    i0_2, i1_2, i2_2, k = T.axis.remap("SSSR", [i0, i1, i2, i3])
                    T.reads(placeholder[i0_2, i1_2, i2_2, k], T_softmax_maxelem[i0_2, i1_2, i2_2])
                    T.writes(T_softmax_expsum[i0_2, i1_2, i2_2])
                    with T.init():
                        T_softmax_expsum[i0_2, i1_2, i2_2] = T.float32(0)
                    T_softmax_expsum[i0_2, i1_2, i2_2] = T_softmax_expsum[i0_2, i1_2, i2_2] + T.exp(placeholder[i0_2, i1_2, i2_2, k] - T_softmax_maxelem[i0_2, i1_2, i2_2], dtype="float32")
            for i0_3, i1_3, i2_3, i3 in T.grid(1, 16, 384, 384):
                with T.block("T_softmax_norm"):
                    i0_4, i1_4, i2_4, i3_1 = T.axis.remap("SSSS", [i0_3, i1_3, i2_3, i3])
                    T.reads(placeholder[i0_4, i1_4, i2_4, i3_1], T_softmax_maxelem[i0_4, i1_4, i2_4], T_softmax_expsum[i0_4, i1_4, i2_4])
                    T.writes(T_softmax_norm[i0_4, i1_4, i2_4, i3_1])
                    T.block_attr({"axis":3})
                    T_softmax_norm[i0_4, i1_4, i2_4, i3_1] = T.exp(placeholder[i0_4, i1_4, i2_4, i3_1] - T_softmax_maxelem[i0_4, i1_4, i2_4], dtype="float32") / T_softmax_expsum[i0_4, i1_4, i2_4]
    

b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v4 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v4)
l5 = sch.sample_compute_location(block=b2, decision=-1)
sch.compute_at(block=b2, loop=l5, preserve_unit_loops=True)
l6 = sch.sample_compute_location(block=b1, decision=-2)
sch.compute_at(block=b1, loop=l6, preserve_unit_loops=True)
l7 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l7, preserve_unit_loops=True)
[19:06:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #10: "fused_reshape"
[19:06:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 384, 384), "float32"], T_reshape: T.Buffer[(16, 384, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2 in T.grid(16, 384, 384):
            with T.block("T_reshape"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(placeholder[0, ((ax2 // 384 + ax1) // 384 + ax0) % 16, (ax2 // 384 + ax1) % 384, ax2 % 384])
                T.writes(T_reshape[ax0, ax1, ax2])
                T_reshape[ax0, ax1, ax2] = placeholder[0, ((ax2 // 384 + ax1) // 384 + ax0) % 16, (ax2 // 384 + ax1) % 384, ax2 % 384]
    

[19:06:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[19:06:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 384, 384), "float32"], T_reshape: T.Buffer[(16, 384, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            for i0, i1, i2 in T.grid(16, 384, 384):
                with T.block("T_reshape"):
                    ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                    T.reads(placeholder[0, ((ax2 // 384 + ax1) // 384 + ax0) % 16, (ax2 // 384 + ax1) % 384, ax2 % 384])
                    T.writes(T_reshape[ax0, ax1, ax2])
                    T_reshape[ax0, ax1, ax2] = placeholder[0, ((ax2 // 384 + ax1) // 384 + ax0) % 16, (ax2 // 384 + ax1) % 384, ax2 % 384]
    

b0 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.vectorize", ann_val=64)
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
[19:06:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #11: "fused_nn_batch_matmul_1"
[19:06:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(16, 384, 384), "float32"], placeholder_1: T.Buffer[(16, 64, 384), "float32"], T_batch_matmul_NT: T.Buffer[(16, 384, 64), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3 in T.grid(16, 384, 64, 384):
            with T.block("T_batch_matmul_NT"):
                b, i, j, k = T.axis.remap("SSSR", [i0, i1, i2, i3])
                T.reads(placeholder[b, i, k], placeholder_1[b, j, k])
                T.writes(T_batch_matmul_NT[b, i, j])
                T.block_attr({"layout_free_placeholders":[placeholder_1]})
                with T.init():
                    T_batch_matmul_NT[b, i, j] = T.float32(0)
                T_batch_matmul_NT[b, i, j] = T_batch_matmul_NT[b, i, j] + placeholder[b, i, k] * placeholder_1[b, j, k]
    

[19:06:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 3 design space(s) generated
[19:06:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(16, 384, 384), "float32"], placeholder_1: T.Buffer[(16, 64, 384), "float32"], T_batch_matmul_NT: T.Buffer[(16, 384, 64), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":64, "meta_schedule.vectorize":64})
            T_batch_matmul_NT_global = T.alloc_buffer([16, 384, 64], dtype="float32")
            for i0_0, i1_0, i2_0, i0_1, i1_1, i2_1 in T.grid(4, 32, 1, 2, 6, 4):
                for i3_0, i0_2, i1_2, i2_2, i3_1, i0_3, i1_3, i2_3 in T.grid(24, 1, 1, 16, 16, 2, 2, 1):
                    with T.block("T_batch_matmul_NT"):
                        b = T.axis.spatial(16, i0_0 * 4 + i0_1 * 2 + i0_3)
                        i = T.axis.spatial(384, i1_0 * 12 + i1_1 * 2 + i1_3)
                        j = T.axis.spatial(64, i2_1 * 16 + i2_2)
                        k = T.axis.reduce(384, i3_0 * 16 + i3_1)
                        T.reads(placeholder[b, i, k], placeholder_1[b, j, k])
                        T.writes(T_batch_matmul_NT_global[b, i, j])
                        T.block_attr({"layout_free_placeholders":[placeholder_1], "meta_schedule.tiling_structure":"SSRSRS"})
                        with T.init():
                            T_batch_matmul_NT_global[b, i, j] = T.float32(0)
                        T_batch_matmul_NT_global[b, i, j] = T_batch_matmul_NT_global[b, i, j] + placeholder[b, i, k] * placeholder_1[b, j, k]
                for ax0, ax1, ax2 in T.grid(2, 2, 16):
                    with T.block("T_batch_matmul_NT_global"):
                        v0 = T.axis.spatial(16, i0_0 * 4 + i0_1 * 2 + ax0)
                        v1 = T.axis.spatial(384, i1_0 * 12 + i1_1 * 2 + ax1)
                        v2 = T.axis.spatial(64, i2_1 * 16 + ax2)
                        T.reads(T_batch_matmul_NT_global[v0, v1, v2])
                        T.writes(T_batch_matmul_NT[v0, v1, v2])
                        T_batch_matmul_NT[v0, v1, v2] = T_batch_matmul_NT_global[v0, v1, v2]
    

b0 = sch.get_block(name="T_batch_matmul_NT", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4, l5 = sch.get_loops(block=b0)
v6, v7, v8, v9 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[4, 2, 1, 2])
l10, l11, l12, l13 = sch.split(loop=l2, factors=[v6, v7, v8, v9])
v14, v15, v16, v17 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[32, 6, 1, 2])
l18, l19, l20, l21 = sch.split(loop=l3, factors=[v14, v15, v16, v17])
v22, v23, v24, v25 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 4, 16, 1])
l26, l27, l28, l29 = sch.split(loop=l4, factors=[v22, v23, v24, v25])
v30, v31 = sch.sample_perfect_tile(loop=l5, n=2, max_innermost_factor=64, decision=[24, 16])
l32, l33 = sch.split(loop=l5, factors=[v30, v31])
sch.reorder(l10, l18, l26, l11, l19, l27, l32, l12, l20, l28, l33, l13, l21, l29)
b34 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="global")
sch.reverse_compute_at(block=b34, loop=l27, preserve_unit_loops=True)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v35 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v35)
[19:06:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #1:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(16, 384, 384), "float32"], placeholder_1: T.Buffer[(16, 64, 384), "float32"], T_batch_matmul_NT: T.Buffer[(16, 384, 64), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            T_batch_matmul_NT_global = T.alloc_buffer([16, 384, 64], dtype="float32")
            for i0_0, i1_0, i2_0 in T.grid(4, 32, 1):
                for i0_1, i1_1, i2_1, i3_0, i0_2, i1_2, i2_2, i3_1, i0_3, i1_3, i2_3 in T.grid(2, 6, 4, 24, 1, 1, 16, 16, 2, 2, 1):
                    with T.block("T_batch_matmul_NT"):
                        b = T.axis.spatial(16, i0_0 * 4 + i0_1 * 2 + i0_3)
                        i = T.axis.spatial(384, i1_0 * 12 + i1_1 * 2 + i1_3)
                        j = T.axis.spatial(64, i2_1 * 16 + i2_2)
                        k = T.axis.reduce(384, i3_0 * 16 + i3_1)
                        T.reads(placeholder[b, i, k], placeholder_1[b, j, k])
                        T.writes(T_batch_matmul_NT_global[b, i, j])
                        T.block_attr({"layout_free_placeholders":[placeholder_1], "meta_schedule.tiling_structure":"SSRSRS"})
                        with T.init():
                            T_batch_matmul_NT_global[b, i, j] = T.float32(0)
                        T_batch_matmul_NT_global[b, i, j] = T_batch_matmul_NT_global[b, i, j] + placeholder[b, i, k] * placeholder_1[b, j, k]
                for ax0, ax1, ax2 in T.grid(4, 12, 64):
                    with T.block("T_batch_matmul_NT_global"):
                        v0 = T.axis.spatial(16, i0_0 * 4 + ax0)
                        v1 = T.axis.spatial(384, i1_0 * 12 + ax1)
                        v2 = T.axis.spatial(64, ax2)
                        T.reads(T_batch_matmul_NT_global[v0, v1, v2])
                        T.writes(T_batch_matmul_NT[v0, v1, v2])
                        T_batch_matmul_NT[v0, v1, v2] = T_batch_matmul_NT_global[v0, v1, v2]
    

b0 = sch.get_block(name="T_batch_matmul_NT", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4, l5 = sch.get_loops(block=b0)
v6, v7, v8, v9 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[4, 2, 1, 2])
l10, l11, l12, l13 = sch.split(loop=l2, factors=[v6, v7, v8, v9])
v14, v15, v16, v17 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[32, 6, 1, 2])
l18, l19, l20, l21 = sch.split(loop=l3, factors=[v14, v15, v16, v17])
v22, v23, v24, v25 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 4, 16, 1])
l26, l27, l28, l29 = sch.split(loop=l4, factors=[v22, v23, v24, v25])
v30, v31 = sch.sample_perfect_tile(loop=l5, n=2, max_innermost_factor=64, decision=[24, 16])
l32, l33 = sch.split(loop=l5, factors=[v30, v31])
sch.reorder(l10, l18, l26, l11, l19, l27, l32, l12, l20, l28, l33, l13, l21, l29)
b34 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="global")
sch.reverse_compute_at(block=b34, loop=l26, preserve_unit_loops=True)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v35 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v35)
[19:06:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #2:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(16, 384, 384), "float32"], placeholder_1: T.Buffer[(16, 64, 384), "float32"], T_batch_matmul_NT: T.Buffer[(16, 384, 64), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            for i0_0, i1_0, i2_0, i0_1, i1_1, i2_1, i3_0, i0_2, i1_2, i2_2, i3_1, i0_3, i1_3, i2_3 in T.grid(4, 32, 1, 2, 6, 4, 24, 1, 1, 16, 16, 2, 2, 1):
                with T.block("T_batch_matmul_NT"):
                    b = T.axis.spatial(16, i0_0 * 4 + i0_1 * 2 + i0_3)
                    i = T.axis.spatial(384, i1_0 * 12 + i1_1 * 2 + i1_3)
                    j = T.axis.spatial(64, i2_1 * 16 + i2_2)
                    k = T.axis.reduce(384, i3_0 * 16 + i3_1)
                    T.reads(placeholder[b, i, k], placeholder_1[b, j, k])
                    T.writes(T_batch_matmul_NT[b, i, j])
                    T.block_attr({"layout_free_placeholders":[placeholder_1], "meta_schedule.tiling_structure":"SSRSRS"})
                    with T.init():
                        T_batch_matmul_NT[b, i, j] = T.float32(0)
                    T_batch_matmul_NT[b, i, j] = T_batch_matmul_NT[b, i, j] + placeholder[b, i, k] * placeholder_1[b, j, k]
    

b0 = sch.get_block(name="T_batch_matmul_NT", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4, l5 = sch.get_loops(block=b0)
v6, v7, v8, v9 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[4, 2, 1, 2])
l10, l11, l12, l13 = sch.split(loop=l2, factors=[v6, v7, v8, v9])
v14, v15, v16, v17 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[32, 6, 1, 2])
l18, l19, l20, l21 = sch.split(loop=l3, factors=[v14, v15, v16, v17])
v22, v23, v24, v25 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 4, 16, 1])
l26, l27, l28, l29 = sch.split(loop=l4, factors=[v22, v23, v24, v25])
v30, v31 = sch.sample_perfect_tile(loop=l5, n=2, max_innermost_factor=64, decision=[24, 16])
l32, l33 = sch.split(loop=l5, factors=[v30, v31])
sch.reorder(l10, l18, l26, l11, l19, l27, l32, l12, l20, l28, l33, l13, l21, l29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v34 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v34)
[19:06:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #12: "fused_reshape_transpose_reshape"
[19:06:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(16, 384, 64), "float32"], T_reshape: T.Buffer[(384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        T_reshape_1 = T.alloc_buffer([1, 16, 384, 64], dtype="float32")
        T_transpose = T.alloc_buffer([1, 384, 16, 64], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 16, 384, 64):
            with T.block("T_reshape"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[((ax3 // 64 + ax2) // 384 + ax1) % 16, (ax3 // 64 + ax2) % 384, ax3 % 64])
                T.writes(T_reshape_1[ax0, ax1, ax2, ax3])
                T_reshape_1[ax0, ax1, ax2, ax3] = placeholder[((ax3 // 64 + ax2) // 384 + ax1) % 16, (ax3 // 64 + ax2) % 384, ax3 % 64]
        for i0, i1, i2, i3 in T.grid(1, 384, 16, 64):
            with T.block("T_transpose"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_reshape_1[ax0, ax2, ax1, ax3])
                T.writes(T_transpose[ax0, ax1, ax2, ax3])
                T_transpose[ax0, ax1, ax2, ax3] = T_reshape_1[ax0, ax2, ax1, ax3]
        for i0, i1 in T.grid(384, 1024):
            with T.block("T_reshape_1"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(T_transpose[0, (ax1 // 1024 + ax0) % 384, ax1 % 1024 // 64, ax1 % 64])
                T.writes(T_reshape[ax0, ax1])
                T_reshape[ax0, ax1] = T_transpose[0, (ax1 // 1024 + ax0) % 384, ax1 % 1024 // 64, ax1 % 64]
    

[19:06:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[19:06:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(16, 384, 64), "float32"], T_reshape: T.Buffer[(384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":64, "meta_schedule.vectorize":64})
            T_transpose = T.alloc_buffer([1, 384, 16, 64], dtype="float32")
            for i0, i1, i2, i3 in T.grid(1, 384, 16, 64):
                with T.block("T_transpose"):
                    ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                    T.reads(placeholder[((ax3 // 64 + ax1) // 384 + ax2) % 16, (ax3 // 64 + ax1) % 384, ax3 % 64])
                    T.writes(T_transpose[ax0, ax1, ax2, ax3])
                    T_transpose[ax0, ax1, ax2, ax3] = placeholder[((ax3 // 64 + ax1) // 384 + ax2) % 16, (ax3 // 64 + ax1) % 384, ax3 % 64]
            for i0, i1 in T.grid(384, 1024):
                with T.block("T_reshape_1"):
                    ax0, ax1 = T.axis.remap("SS", [i0, i1])
                    T.reads(T_transpose[0, (ax1 // 1024 + ax0) % 384, ax1 % 1024 // 64, ax1 % 64])
                    T.writes(T_reshape[ax0, ax1])
                    T_reshape[ax0, ax1] = T_transpose[0, (ax1 // 1024 + ax0) % 384, ax1 % 1024 // 64, ax1 % 64]
    

b0 = sch.get_block(name="T_reshape", func_name="main")
b1 = sch.get_block(name="T_transpose", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v3 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v3)
l4 = sch.sample_compute_location(block=b1, decision=-1)
sch.compute_at(block=b1, loop=l4, preserve_unit_loops=True)
l5 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l5, preserve_unit_loops=True)
[19:06:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #13: "fused_nn_dense"
[19:06:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 1024), "float32"], placeholder_1: T.Buffer[(1024, 1024), "float32"], T_matmul_NT: T.Buffer[(384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2 in T.grid(384, 1024, 1024):
            with T.block("T_matmul_NT"):
                i, j, k = T.axis.remap("SSR", [i0, i1, i2])
                T.reads(placeholder[i, k], placeholder_1[j, k])
                T.writes(T_matmul_NT[i, j])
                T.block_attr({"layout_free_placeholders":[placeholder_1]})
                with T.init():
                    T_matmul_NT[i, j] = T.float32(0)
                T_matmul_NT[i, j] = T_matmul_NT[i, j] + placeholder[i, k] * placeholder_1[j, k]
    

[19:06:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 3 design space(s) generated
[19:06:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 1024), "float32"], placeholder_1: T.Buffer[(1024, 1024), "float32"], T_matmul_NT: T.Buffer[(384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            T_matmul_NT_global = T.alloc_buffer([384, 1024], dtype="float32")
            for i0_0, i1_0, i0_1, i1_1 in T.grid(24, 2, 4, 256):
                for i2_0, i0_2, i1_2, i2_1, i0_3, i1_3 in T.grid(64, 1, 2, 16, 4, 1):
                    with T.block("T_matmul_NT"):
                        i = T.axis.spatial(384, i0_0 * 16 + i0_1 * 4 + i0_3)
                        j = T.axis.spatial(1024, i1_0 * 512 + i1_1 * 2 + i1_2)
                        k = T.axis.reduce(1024, i2_0 * 16 + i2_1)
                        T.reads(placeholder[i, k], placeholder_1[j, k])
                        T.writes(T_matmul_NT_global[i, j])
                        T.block_attr({"layout_free_placeholders":[placeholder_1], "meta_schedule.tiling_structure":"SSRSRS"})
                        with T.init():
                            T_matmul_NT_global[i, j] = T.float32(0)
                        T_matmul_NT_global[i, j] = T_matmul_NT_global[i, j] + placeholder[i, k] * placeholder_1[j, k]
                for ax0, ax1 in T.grid(4, 2):
                    with T.block("T_matmul_NT_global"):
                        v0 = T.axis.spatial(384, i0_0 * 16 + i0_1 * 4 + ax0)
                        v1 = T.axis.spatial(1024, i1_0 * 512 + i1_1 * 2 + ax1)
                        T.reads(T_matmul_NT_global[v0, v1])
                        T.writes(T_matmul_NT[v0, v1])
                        T_matmul_NT[v0, v1] = T_matmul_NT_global[v0, v1]
    

b0 = sch.get_block(name="T_matmul_NT", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4 = sch.get_loops(block=b0)
v5, v6, v7, v8 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[24, 4, 1, 4])
l9, l10, l11, l12 = sch.split(loop=l2, factors=[v5, v6, v7, v8])
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[2, 256, 2, 1])
l17, l18, l19, l20 = sch.split(loop=l3, factors=[v13, v14, v15, v16])
v21, v22 = sch.sample_perfect_tile(loop=l4, n=2, max_innermost_factor=64, decision=[64, 16])
l23, l24 = sch.split(loop=l4, factors=[v21, v22])
sch.reorder(l9, l17, l10, l18, l23, l11, l19, l24, l12, l20)
b25 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="global")
sch.reverse_compute_at(block=b25, loop=l18, preserve_unit_loops=True)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v26 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v26)
[19:06:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #1:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 1024), "float32"], placeholder_1: T.Buffer[(1024, 1024), "float32"], T_matmul_NT: T.Buffer[(384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            T_matmul_NT_global = T.alloc_buffer([384, 1024], dtype="float32")
            for i0_0, i1_0 in T.grid(24, 2):
                for i0_1, i1_1, i2_0, i0_2, i1_2, i2_1, i0_3, i1_3 in T.grid(4, 256, 64, 1, 2, 16, 4, 1):
                    with T.block("T_matmul_NT"):
                        i = T.axis.spatial(384, i0_0 * 16 + i0_1 * 4 + i0_3)
                        j = T.axis.spatial(1024, i1_0 * 512 + i1_1 * 2 + i1_2)
                        k = T.axis.reduce(1024, i2_0 * 16 + i2_1)
                        T.reads(placeholder[i, k], placeholder_1[j, k])
                        T.writes(T_matmul_NT_global[i, j])
                        T.block_attr({"layout_free_placeholders":[placeholder_1], "meta_schedule.tiling_structure":"SSRSRS"})
                        with T.init():
                            T_matmul_NT_global[i, j] = T.float32(0)
                        T_matmul_NT_global[i, j] = T_matmul_NT_global[i, j] + placeholder[i, k] * placeholder_1[j, k]
                for ax0, ax1 in T.grid(16, 512):
                    with T.block("T_matmul_NT_global"):
                        v0 = T.axis.spatial(384, i0_0 * 16 + ax0)
                        v1 = T.axis.spatial(1024, i1_0 * 512 + ax1)
                        T.reads(T_matmul_NT_global[v0, v1])
                        T.writes(T_matmul_NT[v0, v1])
                        T_matmul_NT[v0, v1] = T_matmul_NT_global[v0, v1]
    

b0 = sch.get_block(name="T_matmul_NT", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4 = sch.get_loops(block=b0)
v5, v6, v7, v8 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[24, 4, 1, 4])
l9, l10, l11, l12 = sch.split(loop=l2, factors=[v5, v6, v7, v8])
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[2, 256, 2, 1])
l17, l18, l19, l20 = sch.split(loop=l3, factors=[v13, v14, v15, v16])
v21, v22 = sch.sample_perfect_tile(loop=l4, n=2, max_innermost_factor=64, decision=[64, 16])
l23, l24 = sch.split(loop=l4, factors=[v21, v22])
sch.reorder(l9, l17, l10, l18, l23, l11, l19, l24, l12, l20)
b25 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="global")
sch.reverse_compute_at(block=b25, loop=l17, preserve_unit_loops=True)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v26 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v26)
[19:06:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #2:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 1024), "float32"], placeholder_1: T.Buffer[(1024, 1024), "float32"], T_matmul_NT: T.Buffer[(384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            for i0_0, i1_0, i0_1, i1_1, i2_0, i0_2, i1_2, i2_1, i0_3, i1_3 in T.grid(24, 2, 4, 256, 64, 1, 2, 16, 4, 1):
                with T.block("T_matmul_NT"):
                    i = T.axis.spatial(384, i0_0 * 16 + i0_1 * 4 + i0_3)
                    j = T.axis.spatial(1024, i1_0 * 512 + i1_1 * 2 + i1_2)
                    k = T.axis.reduce(1024, i2_0 * 16 + i2_1)
                    T.reads(placeholder[i, k], placeholder_1[j, k])
                    T.writes(T_matmul_NT[i, j])
                    T.block_attr({"layout_free_placeholders":[placeholder_1], "meta_schedule.tiling_structure":"SSRSRS"})
                    with T.init():
                        T_matmul_NT[i, j] = T.float32(0)
                    T_matmul_NT[i, j] = T_matmul_NT[i, j] + placeholder[i, k] * placeholder_1[j, k]
    

b0 = sch.get_block(name="T_matmul_NT", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4 = sch.get_loops(block=b0)
v5, v6, v7, v8 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[24, 4, 1, 4])
l9, l10, l11, l12 = sch.split(loop=l2, factors=[v5, v6, v7, v8])
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[2, 256, 2, 1])
l17, l18, l19, l20 = sch.split(loop=l3, factors=[v13, v14, v15, v16])
v21, v22 = sch.sample_perfect_tile(loop=l4, n=2, max_innermost_factor=64, decision=[64, 16])
l23, l24 = sch.split(loop=l4, factors=[v21, v22])
sch.reorder(l9, l17, l10, l18, l23, l11, l19, l24, l12, l20)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v25 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v25)
[19:06:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #14: "fused_add_sqrt_divide_multiply_add"
[19:06:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384, 1), "float32"], placeholder_1: T.Buffer[(1, 384, 1024), "float32"], placeholder_2: T.Buffer[(1024,), "float32"], placeholder_3: T.Buffer[(1024,), "float32"], T_add: T.Buffer[(1, 384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        compile_engine_const = T.alloc_buffer([], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 384, 1], dtype="float32")
        T_sqrt = T.alloc_buffer([1, 384, 1], dtype="float32")
        T_divide = T.alloc_buffer([1, 384, 1024], dtype="float32")
        T_multiply = T.alloc_buffer([1, 384, 1024], dtype="float32")
        with T.block("compile_engine_const"):
            T.reads()
            T.writes(compile_engine_const[()])
            compile_engine_const[()] = T.float32(9.999999960041972e-13)
        for i0, i1, i2 in T.grid(1, 384, 1):
            with T.block("T_add"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(placeholder[ax0, ax1, ax2], compile_engine_const[()])
                T.writes(T_add_1[ax0, ax1, ax2])
                T_add_1[ax0, ax1, ax2] = placeholder[ax0, ax1, ax2] + compile_engine_const[()]
        for i0, i1, i2 in T.grid(1, 384, 1):
            with T.block("T_sqrt"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_add_1[ax0, ax1, ax2])
                T.writes(T_sqrt[ax0, ax1, ax2])
                T_sqrt[ax0, ax1, ax2] = T.sqrt(T_add_1[ax0, ax1, ax2], dtype="float32")
        for i0, i1, i2 in T.grid(1, 384, 1024):
            with T.block("T_divide"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(placeholder_1[ax0, ax1, ax2], T_sqrt[ax0, ax1, 0])
                T.writes(T_divide[ax0, ax1, ax2])
                T_divide[ax0, ax1, ax2] = placeholder_1[ax0, ax1, ax2] / T_sqrt[ax0, ax1, 0]
        for i0, i1, i2 in T.grid(1, 384, 1024):
            with T.block("T_multiply"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_divide[ax0, ax1, ax2], placeholder_2[ax2])
                T.writes(T_multiply[ax0, ax1, ax2])
                T_multiply[ax0, ax1, ax2] = T_divide[ax0, ax1, ax2] * placeholder_2[ax2]
        for i0, i1, i2 in T.grid(1, 384, 1024):
            with T.block("T_add_1"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_multiply[ax0, ax1, ax2], placeholder_3[ax2])
                T.writes(T_add[ax0, ax1, ax2])
                T_add[ax0, ax1, ax2] = T_multiply[ax0, ax1, ax2] + placeholder_3[ax2]
    

[19:06:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[19:06:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384, 1), "float32"], placeholder_1: T.Buffer[(1, 384, 1024), "float32"], placeholder_2: T.Buffer[(1024,), "float32"], placeholder_3: T.Buffer[(1024,), "float32"], T_add: T.Buffer[(1, 384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":16, "meta_schedule.vectorize":64})
            for i0, i1, i2 in T.grid(1, 384, 1024):
                with T.block("T_add_1"):
                    ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                    T.reads(placeholder_1[ax0, ax1, ax2], placeholder[ax0, ax1, 0], placeholder_2[ax2], placeholder_3[ax2])
                    T.writes(T_add[ax0, ax1, ax2])
                    T_add[ax0, ax1, ax2] = placeholder_1[ax0, ax1, ax2] / T.sqrt(placeholder[ax0, ax1, 0] + T.float32(9.999999960041972e-13), dtype="float32") * placeholder_2[ax2] + placeholder_3[ax2]
    

b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="T_sqrt", func_name="main")
b3 = sch.get_block(name="T_divide", func_name="main")
b4 = sch.get_block(name="T_multiply", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.vectorize", ann_val=64)
v6 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v6)
[19:06:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #15: "fused_reshape_1"
[19:06:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384, 1024), "float32"], T_reshape: T.Buffer[(384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1 in T.grid(384, 1024):
            with T.block("T_reshape"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(placeholder[0, (ax1 // 1024 + ax0) % 384, ax1 % 1024])
                T.writes(T_reshape[ax0, ax1])
                T_reshape[ax0, ax1] = placeholder[0, (ax1 // 1024 + ax0) % 384, ax1 % 1024]
    

[19:06:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[19:06:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384, 1024), "float32"], T_reshape: T.Buffer[(384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            for i0, i1 in T.grid(384, 1024):
                with T.block("T_reshape"):
                    ax0, ax1 = T.axis.remap("SS", [i0, i1])
                    T.reads(placeholder[0, (ax1 // 1024 + ax0) % 384, ax1 % 1024])
                    T.writes(T_reshape[ax0, ax1])
                    T_reshape[ax0, ax1] = placeholder[0, (ax1 // 1024 + ax0) % 384, ax1 % 1024]
    

b0 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.vectorize", ann_val=64)
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
[19:06:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #16: "fused_nn_dense_1"
[19:06:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 1024), "float32"], placeholder_1: T.Buffer[(4096, 1024), "float32"], T_matmul_NT: T.Buffer[(384, 4096), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2 in T.grid(384, 4096, 1024):
            with T.block("T_matmul_NT"):
                i, j, k = T.axis.remap("SSR", [i0, i1, i2])
                T.reads(placeholder[i, k], placeholder_1[j, k])
                T.writes(T_matmul_NT[i, j])
                T.block_attr({"layout_free_placeholders":[placeholder_1]})
                with T.init():
                    T_matmul_NT[i, j] = T.float32(0)
                T_matmul_NT[i, j] = T_matmul_NT[i, j] + placeholder[i, k] * placeholder_1[j, k]
    

[19:06:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 3 design space(s) generated
[19:06:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 1024), "float32"], placeholder_1: T.Buffer[(4096, 1024), "float32"], T_matmul_NT: T.Buffer[(384, 4096), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":64, "meta_schedule.vectorize":64})
            T_matmul_NT_global = T.alloc_buffer([384, 4096], dtype="float32")
            for i0_0, i1_0, i0_1, i1_1 in T.grid(2, 2, 1, 4):
                for i2_0, i0_2, i1_2, i2_1, i0_3, i1_3 in T.grid(1024, 96, 512, 1, 2, 1):
                    with T.block("T_matmul_NT"):
                        i = T.axis.spatial(384, i0_0 * 192 + i0_2 * 2 + i0_3)
                        j = T.axis.spatial(4096, i1_0 * 2048 + i1_1 * 512 + i1_2)
                        k = T.axis.reduce(1024, i2_0)
                        T.reads(placeholder[i, k], placeholder_1[j, k])
                        T.writes(T_matmul_NT_global[i, j])
                        T.block_attr({"layout_free_placeholders":[placeholder_1], "meta_schedule.tiling_structure":"SSRSRS"})
                        with T.init():
                            T_matmul_NT_global[i, j] = T.float32(0)
                        T_matmul_NT_global[i, j] = T_matmul_NT_global[i, j] + placeholder[i, k] * placeholder_1[j, k]
                for ax0, ax1 in T.grid(192, 512):
                    with T.block("T_matmul_NT_global"):
                        v0 = T.axis.spatial(384, i0_0 * 192 + ax0)
                        v1 = T.axis.spatial(4096, i1_0 * 2048 + i1_1 * 512 + ax1)
                        T.reads(T_matmul_NT_global[v0, v1])
                        T.writes(T_matmul_NT[v0, v1])
                        T_matmul_NT[v0, v1] = T_matmul_NT_global[v0, v1]
    

b0 = sch.get_block(name="T_matmul_NT", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4 = sch.get_loops(block=b0)
v5, v6, v7, v8 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[2, 1, 96, 2])
l9, l10, l11, l12 = sch.split(loop=l2, factors=[v5, v6, v7, v8])
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[2, 4, 512, 1])
l17, l18, l19, l20 = sch.split(loop=l3, factors=[v13, v14, v15, v16])
v21, v22 = sch.sample_perfect_tile(loop=l4, n=2, max_innermost_factor=64, decision=[1024, 1])
l23, l24 = sch.split(loop=l4, factors=[v21, v22])
sch.reorder(l9, l17, l10, l18, l23, l11, l19, l24, l12, l20)
b25 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="global")
sch.reverse_compute_at(block=b25, loop=l18, preserve_unit_loops=True)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v26 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v26)
[19:06:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #1:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 1024), "float32"], placeholder_1: T.Buffer[(4096, 1024), "float32"], T_matmul_NT: T.Buffer[(384, 4096), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":64, "meta_schedule.vectorize":64})
            T_matmul_NT_global = T.alloc_buffer([384, 4096], dtype="float32")
            for i0_0, i1_0 in T.grid(2, 2):
                for i0_1, i1_1, i2_0, i0_2, i1_2, i2_1, i0_3, i1_3 in T.grid(1, 4, 1024, 96, 512, 1, 2, 1):
                    with T.block("T_matmul_NT"):
                        i = T.axis.spatial(384, i0_0 * 192 + i0_2 * 2 + i0_3)
                        j = T.axis.spatial(4096, i1_0 * 2048 + i1_1 * 512 + i1_2)
                        k = T.axis.reduce(1024, i2_0)
                        T.reads(placeholder[i, k], placeholder_1[j, k])
                        T.writes(T_matmul_NT_global[i, j])
                        T.block_attr({"layout_free_placeholders":[placeholder_1], "meta_schedule.tiling_structure":"SSRSRS"})
                        with T.init():
                            T_matmul_NT_global[i, j] = T.float32(0)
                        T_matmul_NT_global[i, j] = T_matmul_NT_global[i, j] + placeholder[i, k] * placeholder_1[j, k]
                for ax0, ax1 in T.grid(192, 2048):
                    with T.block("T_matmul_NT_global"):
                        v0 = T.axis.spatial(384, i0_0 * 192 + ax0)
                        v1 = T.axis.spatial(4096, i1_0 * 2048 + ax1)
                        T.reads(T_matmul_NT_global[v0, v1])
                        T.writes(T_matmul_NT[v0, v1])
                        T_matmul_NT[v0, v1] = T_matmul_NT_global[v0, v1]
    

b0 = sch.get_block(name="T_matmul_NT", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4 = sch.get_loops(block=b0)
v5, v6, v7, v8 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[2, 1, 96, 2])
l9, l10, l11, l12 = sch.split(loop=l2, factors=[v5, v6, v7, v8])
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[2, 4, 512, 1])
l17, l18, l19, l20 = sch.split(loop=l3, factors=[v13, v14, v15, v16])
v21, v22 = sch.sample_perfect_tile(loop=l4, n=2, max_innermost_factor=64, decision=[1024, 1])
l23, l24 = sch.split(loop=l4, factors=[v21, v22])
sch.reorder(l9, l17, l10, l18, l23, l11, l19, l24, l12, l20)
b25 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="global")
sch.reverse_compute_at(block=b25, loop=l17, preserve_unit_loops=True)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v26 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v26)
[19:06:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #2:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 1024), "float32"], placeholder_1: T.Buffer[(4096, 1024), "float32"], T_matmul_NT: T.Buffer[(384, 4096), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":64, "meta_schedule.vectorize":64})
            for i0_0, i1_0, i0_1, i1_1, i2_0, i0_2, i1_2, i2_1, i0_3, i1_3 in T.grid(2, 2, 1, 4, 1024, 96, 512, 1, 2, 1):
                with T.block("T_matmul_NT"):
                    i = T.axis.spatial(384, i0_0 * 192 + i0_2 * 2 + i0_3)
                    j = T.axis.spatial(4096, i1_0 * 2048 + i1_1 * 512 + i1_2)
                    k = T.axis.reduce(1024, i2_0)
                    T.reads(placeholder[i, k], placeholder_1[j, k])
                    T.writes(T_matmul_NT[i, j])
                    T.block_attr({"layout_free_placeholders":[placeholder_1], "meta_schedule.tiling_structure":"SSRSRS"})
                    with T.init():
                        T_matmul_NT[i, j] = T.float32(0)
                    T_matmul_NT[i, j] = T_matmul_NT[i, j] + placeholder[i, k] * placeholder_1[j, k]
    

b0 = sch.get_block(name="T_matmul_NT", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4 = sch.get_loops(block=b0)
v5, v6, v7, v8 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[2, 1, 96, 2])
l9, l10, l11, l12 = sch.split(loop=l2, factors=[v5, v6, v7, v8])
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[2, 4, 512, 1])
l17, l18, l19, l20 = sch.split(loop=l3, factors=[v13, v14, v15, v16])
v21, v22 = sch.sample_perfect_tile(loop=l4, n=2, max_innermost_factor=64, decision=[1024, 1])
l23, l24 = sch.split(loop=l4, factors=[v21, v22])
sch.reorder(l9, l17, l10, l18, l23, l11, l19, l24, l12, l20)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v25 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v25)
[19:06:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"
[19:06:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 4096), "float32"], placeholder_1: T.Buffer[(4096,), "float32"], T_reshape: T.Buffer[(384, 4096), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        T_reshape_1 = T.alloc_buffer([1, 384, 4096], dtype="float32")
        T_add = T.alloc_buffer([1, 384, 4096], dtype="float32")
        compile_engine_const = T.alloc_buffer([], dtype="float32")
        T_multiply = T.alloc_buffer([1, 384, 4096], dtype="float32")
        compile_engine_const_1 = T.alloc_buffer([], dtype="float32")
        T_divide = T.alloc_buffer([1, 384, 4096], dtype="float32")
        T_erf = T.alloc_buffer([1, 384, 4096], dtype="float32")
        compile_engine_const_2 = T.alloc_buffer([], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 384, 4096], dtype="float32")
        T_multiply_1 = T.alloc_buffer([1, 384, 4096], dtype="float32")
        for i0, i1, i2 in T.grid(1, 384, 4096):
            with T.block("T_reshape"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(placeholder[(ax2 // 4096 + ax1) % 384, ax2 % 4096])
                T.writes(T_reshape_1[ax0, ax1, ax2])
                T_reshape_1[ax0, ax1, ax2] = placeholder[(ax2 // 4096 + ax1) % 384, ax2 % 4096]
        for i0, i1, i2 in T.grid(1, 384, 4096):
            with T.block("T_add"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_reshape_1[ax0, ax1, ax2], placeholder_1[ax2])
                T.writes(T_add[ax0, ax1, ax2])
                T_add[ax0, ax1, ax2] = T_reshape_1[ax0, ax1, ax2] + placeholder_1[ax2]
        with T.block("compile_engine_const"):
            T.reads()
            T.writes(compile_engine_const[()])
            compile_engine_const[()] = T.float32(0.5)
        for i0, i1, i2 in T.grid(1, 384, 4096):
            with T.block("T_multiply"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_add[ax0, ax1, ax2], compile_engine_const[()])
                T.writes(T_multiply[ax0, ax1, ax2])
                T_multiply[ax0, ax1, ax2] = T_add[ax0, ax1, ax2] * compile_engine_const[()]
        with T.block("compile_engine_const_1"):
            T.reads()
            T.writes(compile_engine_const_1[()])
            compile_engine_const_1[()] = T.float32(1.4142135381698608)
        for i0, i1, i2 in T.grid(1, 384, 4096):
            with T.block("T_divide"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_add[ax0, ax1, ax2], compile_engine_const_1[()])
                T.writes(T_divide[ax0, ax1, ax2])
                T_divide[ax0, ax1, ax2] = T_add[ax0, ax1, ax2] / compile_engine_const_1[()]
        for i0, i1, i2 in T.grid(1, 384, 4096):
            with T.block("T_erf"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_divide[ax0, ax1, ax2])
                T.writes(T_erf[ax0, ax1, ax2])
                T_erf[ax0, ax1, ax2] = T.erf(T_divide[ax0, ax1, ax2], dtype="float32")
        with T.block("compile_engine_const_2"):
            T.reads()
            T.writes(compile_engine_const_2[()])
            compile_engine_const_2[()] = T.float32(1)
        for i0, i1, i2 in T.grid(1, 384, 4096):
            with T.block("T_add_1"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_erf[ax0, ax1, ax2], compile_engine_const_2[()])
                T.writes(T_add_1[ax0, ax1, ax2])
                T_add_1[ax0, ax1, ax2] = T_erf[ax0, ax1, ax2] + compile_engine_const_2[()]
        for i0, i1, i2 in T.grid(1, 384, 4096):
            with T.block("T_multiply_1"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_multiply[ax0, ax1, ax2], T_add_1[ax0, ax1, ax2])
                T.writes(T_multiply_1[ax0, ax1, ax2])
                T_multiply_1[ax0, ax1, ax2] = T_multiply[ax0, ax1, ax2] * T_add_1[ax0, ax1, ax2]
        for i0, i1 in T.grid(384, 4096):
            with T.block("T_reshape_1"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(T_multiply_1[0, (ax1 // 4096 + ax0) % 384, ax1 % 4096])
                T.writes(T_reshape[ax0, ax1])
                T_reshape[ax0, ax1] = T_multiply_1[0, (ax1 // 4096 + ax0) % 384, ax1 % 4096]
    

[19:06:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[19:06:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 4096), "float32"], placeholder_1: T.Buffer[(4096,), "float32"], T_reshape: T.Buffer[(384, 4096), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            T_reshape_1 = T.alloc_buffer([1, 384, 4096], dtype="float32")
            for i0, i1, i2 in T.grid(1, 384, 4096):
                with T.block("T_reshape"):
                    ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                    T.reads(placeholder[(ax2 // 4096 + ax1) % 384, ax2 % 4096])
                    T.writes(T_reshape_1[ax0, ax1, ax2])
                    T_reshape_1[ax0, ax1, ax2] = placeholder[(ax2 // 4096 + ax1) % 384, ax2 % 4096]
            for i0, i1 in T.grid(384, 4096):
                with T.block("T_reshape_1"):
                    ax0, ax1 = T.axis.remap("SS", [i0, i1])
                    T.reads(T_reshape_1[0, (ax1 // 4096 + ax0) % 384, ax1 % 4096], placeholder_1[ax1 % 4096])
                    T.writes(T_reshape[ax0, ax1])
                    T_reshape[ax0, ax1] = (T_reshape_1[0, (ax1 // 4096 + ax0) % 384, ax1 % 4096] + placeholder_1[ax1 % 4096]) * T.float32(0.5) * (T.erf((T_reshape_1[0, (ax1 // 4096 + ax0) % 384, ax1 % 4096] + placeholder_1[ax1 % 4096]) / T.float32(1.4142135381698608), dtype="float32") + T.float32(1))
    

b0 = sch.get_block(name="T_reshape", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="compile_engine_const", func_name="main")
b3 = sch.get_block(name="T_multiply", func_name="main")
b4 = sch.get_block(name="compile_engine_const_1", func_name="main")
b5 = sch.get_block(name="T_divide", func_name="main")
b6 = sch.get_block(name="T_erf", func_name="main")
b7 = sch.get_block(name="compile_engine_const_2", func_name="main")
b8 = sch.get_block(name="T_add_1", func_name="main")
b9 = sch.get_block(name="T_multiply_1", func_name="main")
b10 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b9)
sch.compute_inline(block=b8)
sch.compute_inline(block=b7)
sch.compute_inline(block=b6)
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b10, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b10, ann_key="meta_schedule.vectorize", ann_val=64)
v11 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b10, ann_key="meta_schedule.unroll_explicit", ann_val=v11)
l12 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l12, preserve_unit_loops=True)
[19:06:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #18: "fused_nn_dense_2"
[19:06:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 4096), "float32"], placeholder_1: T.Buffer[(1024, 4096), "float32"], T_matmul_NT: T.Buffer[(384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2 in T.grid(384, 1024, 4096):
            with T.block("T_matmul_NT"):
                i, j, k = T.axis.remap("SSR", [i0, i1, i2])
                T.reads(placeholder[i, k], placeholder_1[j, k])
                T.writes(T_matmul_NT[i, j])
                T.block_attr({"layout_free_placeholders":[placeholder_1]})
                with T.init():
                    T_matmul_NT[i, j] = T.float32(0)
                T_matmul_NT[i, j] = T_matmul_NT[i, j] + placeholder[i, k] * placeholder_1[j, k]
    

[19:06:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 3 design space(s) generated
[19:06:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 4096), "float32"], placeholder_1: T.Buffer[(1024, 4096), "float32"], T_matmul_NT: T.Buffer[(384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            T_matmul_NT_global = T.alloc_buffer([384, 1024], dtype="float32")
            for i0_0, i1_0, i0_1, i1_1 in T.grid(1, 64, 2, 8):
                for i2_0, i0_2, i1_2, i2_1, i0_3, i1_3 in T.grid(1024, 32, 1, 4, 6, 2):
                    with T.block("T_matmul_NT"):
                        i = T.axis.spatial(384, i0_1 * 192 + i0_2 * 6 + i0_3)
                        j = T.axis.spatial(1024, i1_0 * 16 + i1_1 * 2 + i1_3)
                        k = T.axis.reduce(4096, i2_0 * 4 + i2_1)
                        T.reads(placeholder[i, k], placeholder_1[j, k])
                        T.writes(T_matmul_NT_global[i, j])
                        T.block_attr({"layout_free_placeholders":[placeholder_1], "meta_schedule.tiling_structure":"SSRSRS"})
                        with T.init():
                            T_matmul_NT_global[i, j] = T.float32(0)
                        T_matmul_NT_global[i, j] = T_matmul_NT_global[i, j] + placeholder[i, k] * placeholder_1[j, k]
                for ax0, ax1 in T.grid(192, 2):
                    with T.block("T_matmul_NT_global"):
                        v0 = T.axis.spatial(384, i0_1 * 192 + ax0)
                        v1 = T.axis.spatial(1024, i1_0 * 16 + i1_1 * 2 + ax1)
                        T.reads(T_matmul_NT_global[v0, v1])
                        T.writes(T_matmul_NT[v0, v1])
                        T_matmul_NT[v0, v1] = T_matmul_NT_global[v0, v1]
    

b0 = sch.get_block(name="T_matmul_NT", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4 = sch.get_loops(block=b0)
v5, v6, v7, v8 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 2, 32, 6])
l9, l10, l11, l12 = sch.split(loop=l2, factors=[v5, v6, v7, v8])
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[64, 8, 1, 2])
l17, l18, l19, l20 = sch.split(loop=l3, factors=[v13, v14, v15, v16])
v21, v22 = sch.sample_perfect_tile(loop=l4, n=2, max_innermost_factor=64, decision=[1024, 4])
l23, l24 = sch.split(loop=l4, factors=[v21, v22])
sch.reorder(l9, l17, l10, l18, l23, l11, l19, l24, l12, l20)
b25 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="global")
sch.reverse_compute_at(block=b25, loop=l18, preserve_unit_loops=True)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v26 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v26)
[19:06:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #1:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 4096), "float32"], placeholder_1: T.Buffer[(1024, 4096), "float32"], T_matmul_NT: T.Buffer[(384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":64, "meta_schedule.vectorize":64})
            T_matmul_NT_global = T.alloc_buffer([384, 1024], dtype="float32")
            for i0_0, i1_0 in T.grid(1, 64):
                for i0_1, i1_1, i2_0, i0_2, i1_2, i2_1, i0_3, i1_3 in T.grid(2, 8, 1024, 32, 1, 4, 6, 2):
                    with T.block("T_matmul_NT"):
                        i = T.axis.spatial(384, i0_1 * 192 + i0_2 * 6 + i0_3)
                        j = T.axis.spatial(1024, i1_0 * 16 + i1_1 * 2 + i1_3)
                        k = T.axis.reduce(4096, i2_0 * 4 + i2_1)
                        T.reads(placeholder[i, k], placeholder_1[j, k])
                        T.writes(T_matmul_NT_global[i, j])
                        T.block_attr({"layout_free_placeholders":[placeholder_1], "meta_schedule.tiling_structure":"SSRSRS"})
                        with T.init():
                            T_matmul_NT_global[i, j] = T.float32(0)
                        T_matmul_NT_global[i, j] = T_matmul_NT_global[i, j] + placeholder[i, k] * placeholder_1[j, k]
                for ax0, ax1 in T.grid(384, 16):
                    with T.block("T_matmul_NT_global"):
                        v0 = T.axis.spatial(384, ax0)
                        v1 = T.axis.spatial(1024, i1_0 * 16 + ax1)
                        T.reads(T_matmul_NT_global[v0, v1])
                        T.writes(T_matmul_NT[v0, v1])
                        T_matmul_NT[v0, v1] = T_matmul_NT_global[v0, v1]
    

b0 = sch.get_block(name="T_matmul_NT", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4 = sch.get_loops(block=b0)
v5, v6, v7, v8 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 2, 32, 6])
l9, l10, l11, l12 = sch.split(loop=l2, factors=[v5, v6, v7, v8])
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[64, 8, 1, 2])
l17, l18, l19, l20 = sch.split(loop=l3, factors=[v13, v14, v15, v16])
v21, v22 = sch.sample_perfect_tile(loop=l4, n=2, max_innermost_factor=64, decision=[1024, 4])
l23, l24 = sch.split(loop=l4, factors=[v21, v22])
sch.reorder(l9, l17, l10, l18, l23, l11, l19, l24, l12, l20)
b25 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="global")
sch.reverse_compute_at(block=b25, loop=l17, preserve_unit_loops=True)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v26 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v26)
[19:06:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #2:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 4096), "float32"], placeholder_1: T.Buffer[(1024, 4096), "float32"], T_matmul_NT: T.Buffer[(384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            for i0_0, i1_0, i0_1, i1_1, i2_0, i0_2, i1_2, i2_1, i0_3, i1_3 in T.grid(1, 64, 2, 8, 1024, 32, 1, 4, 6, 2):
                with T.block("T_matmul_NT"):
                    i = T.axis.spatial(384, i0_1 * 192 + i0_2 * 6 + i0_3)
                    j = T.axis.spatial(1024, i1_0 * 16 + i1_1 * 2 + i1_3)
                    k = T.axis.reduce(4096, i2_0 * 4 + i2_1)
                    T.reads(placeholder[i, k], placeholder_1[j, k])
                    T.writes(T_matmul_NT[i, j])
                    T.block_attr({"layout_free_placeholders":[placeholder_1], "meta_schedule.tiling_structure":"SSRSRS"})
                    with T.init():
                        T_matmul_NT[i, j] = T.float32(0)
                    T_matmul_NT[i, j] = T_matmul_NT[i, j] + placeholder[i, k] * placeholder_1[j, k]
    

b0 = sch.get_block(name="T_matmul_NT", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4 = sch.get_loops(block=b0)
v5, v6, v7, v8 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 2, 32, 6])
l9, l10, l11, l12 = sch.split(loop=l2, factors=[v5, v6, v7, v8])
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[64, 8, 1, 2])
l17, l18, l19, l20 = sch.split(loop=l3, factors=[v13, v14, v15, v16])
v21, v22 = sch.sample_perfect_tile(loop=l4, n=2, max_innermost_factor=64, decision=[1024, 4])
l23, l24 = sch.split(loop=l4, factors=[v21, v22])
sch.reorder(l9, l17, l10, l18, l23, l11, l19, l24, l12, l20)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v25 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v25)
[19:06:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #19: "fused_reshape_add_add"
[19:06:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 1024), "float32"], placeholder_1: T.Buffer[(1024,), "float32"], placeholder_2: T.Buffer[(1, 384, 1024), "float32"], T_add: T.Buffer[(1, 384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        T_reshape = T.alloc_buffer([1, 384, 1024], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 384, 1024], dtype="float32")
        for i0, i1, i2 in T.grid(1, 384, 1024):
            with T.block("T_reshape"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(placeholder[(ax2 // 1024 + ax1) % 384, ax2 % 1024])
                T.writes(T_reshape[ax0, ax1, ax2])
                T_reshape[ax0, ax1, ax2] = placeholder[(ax2 // 1024 + ax1) % 384, ax2 % 1024]
        for i0, i1, i2 in T.grid(1, 384, 1024):
            with T.block("T_add"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_reshape[ax0, ax1, ax2], placeholder_1[ax2])
                T.writes(T_add_1[ax0, ax1, ax2])
                T_add_1[ax0, ax1, ax2] = T_reshape[ax0, ax1, ax2] + placeholder_1[ax2]
        for i0, i1, i2 in T.grid(1, 384, 1024):
            with T.block("T_add_1"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_add_1[ax0, ax1, ax2], placeholder_2[ax0, ax1, ax2])
                T.writes(T_add[ax0, ax1, ax2])
                T_add[ax0, ax1, ax2] = T_add_1[ax0, ax1, ax2] + placeholder_2[ax0, ax1, ax2]
    

[19:06:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[19:06:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 1024), "float32"], placeholder_1: T.Buffer[(1024,), "float32"], placeholder_2: T.Buffer[(1, 384, 1024), "float32"], T_add: T.Buffer[(1, 384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            T_reshape = T.alloc_buffer([1, 384, 1024], dtype="float32")
            for i0, i1 in T.grid(1, 384):
                for ax0, ax1, ax2 in T.grid(1, 1, 1024):
                    with T.block("T_reshape"):
                        ax0_1 = T.axis.spatial(1, ax0)
                        ax1_1 = T.axis.spatial(384, i1 + ax1)
                        ax2_1 = T.axis.spatial(1024, ax2)
                        T.reads(placeholder[(ax2_1 // 1024 + ax1_1) % 384, ax2_1 % 1024])
                        T.writes(T_reshape[ax0_1, ax1_1, ax2_1])
                        T_reshape[ax0_1, ax1_1, ax2_1] = placeholder[(ax2_1 // 1024 + ax1_1) % 384, ax2_1 % 1024]
                for i2 in T.serial(1024):
                    with T.block("T_add_1"):
                        ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                        T.reads(T_reshape[ax0, ax1, ax2], placeholder_1[ax2], placeholder_2[ax0, ax1, ax2])
                        T.writes(T_add[ax0, ax1, ax2])
                        T_add[ax0, ax1, ax2] = T_reshape[ax0, ax1, ax2] + placeholder_1[ax2] + placeholder_2[ax0, ax1, ax2]
    

b0 = sch.get_block(name="T_reshape", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v3 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v3)
l4 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l4, preserve_unit_loops=True)
[19:06:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #20: "fused_subtract"
[19:06:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384, 1024), "float32"], placeholder_1: T.Buffer[(1, 384, 1), "float32"], T_subtract: T.Buffer[(1, 384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2 in T.grid(1, 384, 1024):
            with T.block("T_subtract"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(placeholder[ax0, ax1, ax2], placeholder_1[ax0, ax1, 0])
                T.writes(T_subtract[ax0, ax1, ax2])
                T_subtract[ax0, ax1, ax2] = placeholder[ax0, ax1, ax2] - placeholder_1[ax0, ax1, 0]
    

[19:06:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[19:06:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384, 1024), "float32"], placeholder_1: T.Buffer[(1, 384, 1), "float32"], T_subtract: T.Buffer[(1, 384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            for i0, i1, i2 in T.grid(1, 384, 1024):
                with T.block("T_subtract"):
                    ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                    T.reads(placeholder[ax0, ax1, ax2], placeholder_1[ax0, ax1, 0])
                    T.writes(T_subtract[ax0, ax1, ax2])
                    T_subtract[ax0, ax1, ax2] = placeholder[ax0, ax1, ax2] - placeholder_1[ax0, ax1, 0]
    

b0 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.vectorize", ann_val=64)
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
[19:06:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #21: "fused_power_mean"
[19:06:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384, 1024), "float32"], T_divide: T.Buffer[(1, 384, 1), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        compile_engine_const = T.alloc_buffer([], dtype="float32")
        T_power = T.alloc_buffer([1, 384, 1024], dtype="float32")
        T_power_red = T.alloc_buffer([1, 384, 1], dtype="float32")
        with T.block("compile_engine_const"):
            T.reads()
            T.writes(compile_engine_const[()])
            compile_engine_const[()] = T.float32(2)
        for i0, i1, i2 in T.grid(1, 384, 1024):
            with T.block("T_power"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(placeholder[ax0, ax1, ax2], compile_engine_const[()])
                T.writes(T_power[ax0, ax1, ax2])
                T_power[ax0, ax1, ax2] = T.pow(placeholder[ax0, ax1, ax2], compile_engine_const[()], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 384, 1, 1024):
            with T.block("T_power_red"):
                ax0, ax1, ax2, k2 = T.axis.remap("SSSR", [i0, i1, i2, i3])
                T.reads(T_power[ax0, ax1, k2])
                T.writes(T_power_red[ax0, ax1, ax2])
                with T.init():
                    T_power_red[ax0, ax1, ax2] = T.float32(0)
                T_power_red[ax0, ax1, ax2] = T_power_red[ax0, ax1, ax2] + T_power[ax0, ax1, k2]
        for i0, i1, i2 in T.grid(1, 384, 1):
            with T.block("T_divide"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_power_red[ax0, ax1, ax2])
                T.writes(T_divide[ax0, ax1, ax2])
                T_divide[ax0, ax1, ax2] = T_power_red[ax0, ax1, ax2] * T.float32(0.0009765625)
    

[19:06:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 3 design space(s) generated
[19:06:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384, 1024), "float32"], T_divide: T.Buffer[(1, 384, 1), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            T_power_red = T.alloc_buffer([1, 384, 1], dtype="float32")
            T_power_red_rf = T.alloc_buffer([1, 384, 1, 256], dtype="float32")
            for i0, i1 in T.grid(1, 384):
                for ax0 in T.serial(256):
                    for ax0_1, ax1, ax2, ax3, ax4 in T.grid(1, 1, 1, 1, 4):
                        with T.block("T_power_red_rf"):
                            vi3_0 = T.axis.spatial(256, ax0 + ax0_1)
                            ax0_2 = T.axis.spatial(1, ax1)
                            ax1_1 = T.axis.spatial(384, i1 + ax2)
                            ax2_1, vi3_1 = T.axis.remap("SR", [ax3, ax4])
                            T.reads(placeholder[ax0_2, ax1_1, vi3_0 * 4 + vi3_1])
                            T.writes(T_power_red_rf[ax0_2, ax1_1, ax2_1, vi3_0])
                            with T.init():
                                T_power_red_rf[ax0_2, ax1_1, ax2_1, vi3_0] = T.float32(0)
                            T_power_red_rf[ax0_2, ax1_1, ax2_1, vi3_0] = T_power_red_rf[ax0_2, ax1_1, ax2_1, vi3_0] + T.pow(placeholder[ax0_2, ax1_1, vi3_0 * 4 + vi3_1], T.float32(2), dtype="float32")
                    for ax1, ax2, ax3 in T.grid(1, 1, 1):
                        with T.block("T_power_red"):
                            vi3_0, ax0_3 = T.axis.remap("RS", [ax0, ax1])
                            ax1_2 = T.axis.spatial(384, i1 + ax2)
                            ax2_2 = T.axis.spatial(1, ax3)
                            T.reads(T_power_red_rf[ax0_3, ax1_2, ax2_2, vi3_0])
                            T.writes(T_power_red[ax0_3, ax1_2, ax2_2])
                            with T.init():
                                T_power_red[ax0_3, ax1_2, ax2_2] = T.float32(0)
                            T_power_red[ax0_3, ax1_2, ax2_2] = T_power_red[ax0_3, ax1_2, ax2_2] + T_power_red_rf[ax0_3, ax1_2, ax2_2, vi3_0]
                for i2 in T.serial(1):
                    with T.block("T_divide"):
                        ax0_4, ax1_3, ax2_3 = T.axis.remap("SSS", [i0, i1, i2])
                        T.reads(T_power_red[ax0_4, ax1_3, ax2_3])
                        T.writes(T_divide[ax0_4, ax1_3, ax2_3])
                        T_divide[ax0_4, ax1_3, ax2_3] = T_power_red[ax0_4, ax1_3, ax2_3] * T.float32(0.0009765625)
    

b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_power", func_name="main")
b2 = sch.get_block(name="T_power_red", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
l4, l5, l6, l7 = sch.get_loops(block=b2)
v8, v9 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[256, 4])
l10, l11 = sch.split(loop=l7, factors=[v8, v9])
b12 = sch.rfactor(loop=l10, factor_axis=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.random_compute_producer", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v13 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v13)
b14, = sch.get_producers(block=b2)
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.random_compute_producer")
l15 = sch.sample_compute_location(block=b2, decision=1)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True)
l16 = sch.sample_compute_location(block=b14, decision=2)
sch.compute_at(block=b14, loop=l16, preserve_unit_loops=True)
[19:06:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #1:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384, 1024), "float32"], T_divide: T.Buffer[(1, 384, 1), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":16, "meta_schedule.vectorize":64})
            T_power_red = T.alloc_buffer([1, 384, 1], dtype="float32")
            T_power_red_rf = T.alloc_buffer([1, 384, 1, 4], dtype="float32")
            for i0, i1 in T.grid(1, 384):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(4, 1, 1, 1, 256):
                    with T.block("T_power_red_rf"):
                        vi3_1, ax0_1 = T.axis.remap("SS", [ax0, ax1])
                        ax1_1 = T.axis.spatial(384, i1 + ax2)
                        ax2_1, vi3_0 = T.axis.remap("SR", [ax3, ax4])
                        T.reads(placeholder[ax0_1, ax1_1, vi3_0 * 4 + vi3_1])
                        T.writes(T_power_red_rf[ax0_1, ax1_1, ax2_1, vi3_1])
                        with T.init():
                            T_power_red_rf[ax0_1, ax1_1, ax2_1, vi3_1] = T.float32(0)
                        T_power_red_rf[ax0_1, ax1_1, ax2_1, vi3_1] = T_power_red_rf[ax0_1, ax1_1, ax2_1, vi3_1] + T.pow(placeholder[ax0_1, ax1_1, vi3_0 * 4 + vi3_1], T.float32(2), dtype="float32")
                for ax0, ax1, ax2, ax3 in T.grid(4, 1, 1, 1):
                    with T.block("T_power_red"):
                        vi3_1, ax0_2 = T.axis.remap("RS", [ax0, ax1])
                        ax1_2 = T.axis.spatial(384, i1 + ax2)
                        ax2_2 = T.axis.spatial(1, ax3)
                        T.reads(T_power_red_rf[ax0_2, ax1_2, ax2_2, vi3_1])
                        T.writes(T_power_red[ax0_2, ax1_2, ax2_2])
                        with T.init():
                            T_power_red[ax0_2, ax1_2, ax2_2] = T.float32(0)
                        T_power_red[ax0_2, ax1_2, ax2_2] = T_power_red[ax0_2, ax1_2, ax2_2] + T_power_red_rf[ax0_2, ax1_2, ax2_2, vi3_1]
                for i2 in T.serial(1):
                    with T.block("T_divide"):
                        ax0_3, ax1_3, ax2_3 = T.axis.remap("SSS", [i0, i1, i2])
                        T.reads(T_power_red[ax0_3, ax1_3, ax2_3])
                        T.writes(T_divide[ax0_3, ax1_3, ax2_3])
                        T_divide[ax0_3, ax1_3, ax2_3] = T_power_red[ax0_3, ax1_3, ax2_3] * T.float32(0.0009765625)
    

b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_power", func_name="main")
b2 = sch.get_block(name="T_power_red", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
l4, l5, l6, l7 = sch.get_loops(block=b2)
v8, v9 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[256, 4])
l10, l11 = sch.split(loop=l7, factors=[v8, v9])
b12 = sch.rfactor(loop=l11, factor_axis=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.random_compute_producer", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v13 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v13)
b14, = sch.get_producers(block=b2)
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.random_compute_producer")
l15 = sch.sample_compute_location(block=b2, decision=1)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True)
l16 = sch.sample_compute_location(block=b14, decision=1)
sch.compute_at(block=b14, loop=l16, preserve_unit_loops=True)
[19:06:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #2:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384, 1024), "float32"], T_divide: T.Buffer[(1, 384, 1), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            T_power_red = T.alloc_buffer([1, 384, 1], dtype="float32")
            for i0, i1, i2, i3 in T.grid(1, 384, 1, 1024):
                with T.block("T_power_red"):
                    ax0, ax1, ax2, k2 = T.axis.remap("SSSR", [i0, i1, i2, i3])
                    T.reads(placeholder[ax0, ax1, k2])
                    T.writes(T_power_red[ax0, ax1, ax2])
                    with T.init():
                        T_power_red[ax0, ax1, ax2] = T.float32(0)
                    T_power_red[ax0, ax1, ax2] = T_power_red[ax0, ax1, ax2] + T.pow(placeholder[ax0, ax1, k2], T.float32(2), dtype="float32")
            for i0, i1, i2 in T.grid(1, 384, 1):
                with T.block("T_divide"):
                    ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                    T.reads(T_power_red[ax0, ax1, ax2])
                    T.writes(T_divide[ax0, ax1, ax2])
                    T_divide[ax0, ax1, ax2] = T_power_red[ax0, ax1, ax2] * T.float32(0.0009765625)
    

b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_power", func_name="main")
b2 = sch.get_block(name="T_power_red", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v4 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v4)
l5 = sch.sample_compute_location(block=b2, decision=-1)
sch.compute_at(block=b2, loop=l5, preserve_unit_loops=True)
[19:06:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #22: "fused_add_sqrt_divide_multiply_add_reshape"
[19:06:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384, 1), "float32"], placeholder_1: T.Buffer[(1, 384, 1024), "float32"], placeholder_2: T.Buffer[(1024,), "float32"], placeholder_3: T.Buffer[(1024,), "float32"], T_reshape: T.Buffer[(384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        compile_engine_const = T.alloc_buffer([], dtype="float32")
        T_add = T.alloc_buffer([1, 384, 1], dtype="float32")
        T_sqrt = T.alloc_buffer([1, 384, 1], dtype="float32")
        T_divide = T.alloc_buffer([1, 384, 1024], dtype="float32")
        T_multiply = T.alloc_buffer([1, 384, 1024], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 384, 1024], dtype="float32")
        with T.block("compile_engine_const"):
            T.reads()
            T.writes(compile_engine_const[()])
            compile_engine_const[()] = T.float32(9.999999960041972e-13)
        for i0, i1, i2 in T.grid(1, 384, 1):
            with T.block("T_add"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(placeholder[ax0, ax1, ax2], compile_engine_const[()])
                T.writes(T_add[ax0, ax1, ax2])
                T_add[ax0, ax1, ax2] = placeholder[ax0, ax1, ax2] + compile_engine_const[()]
        for i0, i1, i2 in T.grid(1, 384, 1):
            with T.block("T_sqrt"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_add[ax0, ax1, ax2])
                T.writes(T_sqrt[ax0, ax1, ax2])
                T_sqrt[ax0, ax1, ax2] = T.sqrt(T_add[ax0, ax1, ax2], dtype="float32")
        for i0, i1, i2 in T.grid(1, 384, 1024):
            with T.block("T_divide"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(placeholder_1[ax0, ax1, ax2], T_sqrt[ax0, ax1, 0])
                T.writes(T_divide[ax0, ax1, ax2])
                T_divide[ax0, ax1, ax2] = placeholder_1[ax0, ax1, ax2] / T_sqrt[ax0, ax1, 0]
        for i0, i1, i2 in T.grid(1, 384, 1024):
            with T.block("T_multiply"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_divide[ax0, ax1, ax2], placeholder_2[ax2])
                T.writes(T_multiply[ax0, ax1, ax2])
                T_multiply[ax0, ax1, ax2] = T_divide[ax0, ax1, ax2] * placeholder_2[ax2]
        for i0, i1, i2 in T.grid(1, 384, 1024):
            with T.block("T_add_1"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_multiply[ax0, ax1, ax2], placeholder_3[ax2])
                T.writes(T_add_1[ax0, ax1, ax2])
                T_add_1[ax0, ax1, ax2] = T_multiply[ax0, ax1, ax2] + placeholder_3[ax2]
        for i0, i1 in T.grid(384, 1024):
            with T.block("T_reshape"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(T_add_1[0, (ax1 // 1024 + ax0) % 384, ax1 % 1024])
                T.writes(T_reshape[ax0, ax1])
                T_reshape[ax0, ax1] = T_add_1[0, (ax1 // 1024 + ax0) % 384, ax1 % 1024]
    

[19:06:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[19:06:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384, 1), "float32"], placeholder_1: T.Buffer[(1, 384, 1024), "float32"], placeholder_2: T.Buffer[(1024,), "float32"], placeholder_3: T.Buffer[(1024,), "float32"], T_reshape: T.Buffer[(384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":512, "meta_schedule.vectorize":64})
            for i0, i1 in T.grid(384, 1024):
                with T.block("T_reshape"):
                    ax0, ax1 = T.axis.remap("SS", [i0, i1])
                    T.reads(placeholder_1[0, (ax1 // 1024 + ax0) % 384, ax1 % 1024], placeholder[0, (ax1 // 1024 + ax0) % 384, 0], placeholder_2[ax1 % 1024], placeholder_3[ax1 % 1024])
                    T.writes(T_reshape[ax0, ax1])
                    T_reshape[ax0, ax1] = placeholder_1[0, (ax1 // 1024 + ax0) % 384, ax1 % 1024] / T.sqrt(placeholder[0, (ax1 // 1024 + ax0) % 384, 0] + T.float32(9.999999960041972e-13), dtype="float32") * placeholder_2[ax1 % 1024] + placeholder_3[ax1 % 1024]
    

b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="T_sqrt", func_name="main")
b3 = sch.get_block(name="T_divide", func_name="main")
b4 = sch.get_block(name="T_multiply", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b5)
sch.compute_inline(block=b4)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.vectorize", ann_val=64)
v7 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v7)
[19:06:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #23: "fused_nn_dense_3"
[19:06:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 1024), "float32"], placeholder_1: T.Buffer[(2, 1024), "float32"], T_matmul_NT: T.Buffer[(384, 2), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2 in T.grid(384, 2, 1024):
            with T.block("T_matmul_NT"):
                i, j, k = T.axis.remap("SSR", [i0, i1, i2])
                T.reads(placeholder[i, k], placeholder_1[j, k])
                T.writes(T_matmul_NT[i, j])
                T.block_attr({"layout_free_placeholders":[placeholder_1]})
                with T.init():
                    T_matmul_NT[i, j] = T.float32(0)
                T_matmul_NT[i, j] = T_matmul_NT[i, j] + placeholder[i, k] * placeholder_1[j, k]
    

[19:06:18] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 3 design space(s) generated
[19:06:18] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 1024), "float32"], placeholder_1: T.Buffer[(2, 1024), "float32"], T_matmul_NT: T.Buffer[(384, 2), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            T_matmul_NT_global = T.alloc_buffer([384, 2], dtype="float32")
            for i0_0, i1_0, i0_1, i1_1 in T.grid(6, 1, 1, 1):
                for i2_0, i0_2, i1_2, i2_1, i0_3, i1_3 in T.grid(128, 4, 1, 8, 16, 2):
                    with T.block("T_matmul_NT"):
                        i = T.axis.spatial(384, i0_0 * 64 + i0_2 * 16 + i0_3)
                        j = T.axis.spatial(2, i1_3)
                        k = T.axis.reduce(1024, i2_0 * 8 + i2_1)
                        T.reads(placeholder[i, k], placeholder_1[j, k])
                        T.writes(T_matmul_NT_global[i, j])
                        T.block_attr({"layout_free_placeholders":[placeholder_1], "meta_schedule.tiling_structure":"SSRSRS"})
                        with T.init():
                            T_matmul_NT_global[i, j] = T.float32(0)
                        T_matmul_NT_global[i, j] = T_matmul_NT_global[i, j] + placeholder[i, k] * placeholder_1[j, k]
                for ax0, ax1 in T.grid(64, 2):
                    with T.block("T_matmul_NT_global"):
                        v0 = T.axis.spatial(384, i0_0 * 64 + ax0)
                        v1 = T.axis.spatial(2, ax1)
                        T.reads(T_matmul_NT_global[v0, v1])
                        T.writes(T_matmul_NT[v0, v1])
                        T_matmul_NT[v0, v1] = T_matmul_NT_global[v0, v1]
    

b0 = sch.get_block(name="T_matmul_NT", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4 = sch.get_loops(block=b0)
v5, v6, v7, v8 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[6, 1, 4, 16])
l9, l10, l11, l12 = sch.split(loop=l2, factors=[v5, v6, v7, v8])
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 2])
l17, l18, l19, l20 = sch.split(loop=l3, factors=[v13, v14, v15, v16])
v21, v22 = sch.sample_perfect_tile(loop=l4, n=2, max_innermost_factor=64, decision=[128, 8])
l23, l24 = sch.split(loop=l4, factors=[v21, v22])
sch.reorder(l9, l17, l10, l18, l23, l11, l19, l24, l12, l20)
b25 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="global")
sch.reverse_compute_at(block=b25, loop=l18, preserve_unit_loops=True)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v26 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v26)
[19:06:18] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #1:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 1024), "float32"], placeholder_1: T.Buffer[(2, 1024), "float32"], T_matmul_NT: T.Buffer[(384, 2), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":64, "meta_schedule.vectorize":64})
            T_matmul_NT_global = T.alloc_buffer([384, 2], dtype="float32")
            for i0_0, i1_0 in T.grid(6, 1):
                for i0_1, i1_1, i2_0, i0_2, i1_2, i2_1, i0_3, i1_3 in T.grid(1, 1, 128, 4, 1, 8, 16, 2):
                    with T.block("T_matmul_NT"):
                        i = T.axis.spatial(384, i0_0 * 64 + i0_2 * 16 + i0_3)
                        j = T.axis.spatial(2, i1_3)
                        k = T.axis.reduce(1024, i2_0 * 8 + i2_1)
                        T.reads(placeholder[i, k], placeholder_1[j, k])
                        T.writes(T_matmul_NT_global[i, j])
                        T.block_attr({"layout_free_placeholders":[placeholder_1], "meta_schedule.tiling_structure":"SSRSRS"})
                        with T.init():
                            T_matmul_NT_global[i, j] = T.float32(0)
                        T_matmul_NT_global[i, j] = T_matmul_NT_global[i, j] + placeholder[i, k] * placeholder_1[j, k]
                for ax0, ax1 in T.grid(64, 2):
                    with T.block("T_matmul_NT_global"):
                        v0 = T.axis.spatial(384, i0_0 * 64 + ax0)
                        v1 = T.axis.spatial(2, ax1)
                        T.reads(T_matmul_NT_global[v0, v1])
                        T.writes(T_matmul_NT[v0, v1])
                        T_matmul_NT[v0, v1] = T_matmul_NT_global[v0, v1]
    

b0 = sch.get_block(name="T_matmul_NT", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4 = sch.get_loops(block=b0)
v5, v6, v7, v8 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[6, 1, 4, 16])
l9, l10, l11, l12 = sch.split(loop=l2, factors=[v5, v6, v7, v8])
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 2])
l17, l18, l19, l20 = sch.split(loop=l3, factors=[v13, v14, v15, v16])
v21, v22 = sch.sample_perfect_tile(loop=l4, n=2, max_innermost_factor=64, decision=[128, 8])
l23, l24 = sch.split(loop=l4, factors=[v21, v22])
sch.reorder(l9, l17, l10, l18, l23, l11, l19, l24, l12, l20)
b25 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="global")
sch.reverse_compute_at(block=b25, loop=l17, preserve_unit_loops=True)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v26 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v26)
[19:06:18] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #2:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 1024), "float32"], placeholder_1: T.Buffer[(2, 1024), "float32"], T_matmul_NT: T.Buffer[(384, 2), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":16, "meta_schedule.vectorize":64})
            for i0_0, i1_0, i0_1, i1_1, i2_0, i0_2, i1_2, i2_1, i0_3, i1_3 in T.grid(6, 1, 1, 1, 128, 4, 1, 8, 16, 2):
                with T.block("T_matmul_NT"):
                    i = T.axis.spatial(384, i0_0 * 64 + i0_2 * 16 + i0_3)
                    j = T.axis.spatial(2, i1_3)
                    k = T.axis.reduce(1024, i2_0 * 8 + i2_1)
                    T.reads(placeholder[i, k], placeholder_1[j, k])
                    T.writes(T_matmul_NT[i, j])
                    T.block_attr({"layout_free_placeholders":[placeholder_1], "meta_schedule.tiling_structure":"SSRSRS"})
                    with T.init():
                        T_matmul_NT[i, j] = T.float32(0)
                    T_matmul_NT[i, j] = T_matmul_NT[i, j] + placeholder[i, k] * placeholder_1[j, k]
    

b0 = sch.get_block(name="T_matmul_NT", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4 = sch.get_loops(block=b0)
v5, v6, v7, v8 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[6, 1, 4, 16])
l9, l10, l11, l12 = sch.split(loop=l2, factors=[v5, v6, v7, v8])
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 2])
l17, l18, l19, l20 = sch.split(loop=l3, factors=[v13, v14, v15, v16])
v21, v22 = sch.sample_perfect_tile(loop=l4, n=2, max_innermost_factor=64, decision=[128, 8])
l23, l24 = sch.split(loop=l4, factors=[v21, v22])
sch.reorder(l9, l17, l10, l18, l23, l11, l19, l24, l12, l20)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v25 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v25)
[19:06:18] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #24: "fused_reshape_add_split"
[19:06:18] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 2), "float32"], placeholder_1: T.Buffer[(2,), "float32"], T_split: T.Buffer[(1, 384, 1), "float32"], T_split_1: T.Buffer[(1, 384, 1), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        T_reshape = T.alloc_buffer([1, 384, 2], dtype="float32")
        T_add = T.alloc_buffer([1, 384, 2], dtype="float32")
        for i0, i1, i2 in T.grid(1, 384, 2):
            with T.block("T_reshape"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(placeholder[(ax2 // 2 + ax1) % 384, ax2 % 2])
                T.writes(T_reshape[ax0, ax1, ax2])
                T_reshape[ax0, ax1, ax2] = placeholder[(ax2 // 2 + ax1) % 384, ax2 % 2]
        for i0, i1, i2 in T.grid(1, 384, 2):
            with T.block("T_add"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_reshape[ax0, ax1, ax2], placeholder_1[ax2])
                T.writes(T_add[ax0, ax1, ax2])
                T_add[ax0, ax1, ax2] = T_reshape[ax0, ax1, ax2] + placeholder_1[ax2]
        for i0, i1, i2 in T.grid(1, 384, 1):
            with T.block("T_split"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_add[ax0, ax1, ax2])
                T.writes(T_split[ax0, ax1, ax2])
                T_split[ax0, ax1, ax2] = T_add[ax0, ax1, ax2]
        for i0, i1, i2 in T.grid(1, 384, 1):
            with T.block("T_split_1"):
                ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_add[ax0, ax1, ax2 + 1])
                T.writes(T_split_1[ax0, ax1, ax2])
                T_split_1[ax0, ax1, ax2] = T_add[ax0, ax1, ax2 + 1]
    

[19:06:18] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[19:06:18] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 2), "float32"], placeholder_1: T.Buffer[(2,), "float32"], T_split: T.Buffer[(1, 384, 1), "float32"], T_split_1: T.Buffer[(1, 384, 1), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":64, "meta_schedule.vectorize":64})
            T_reshape = T.alloc_buffer([1, 384, 2], dtype="float32")
            for i0, i1, i2 in T.grid(1, 384, 2):
                with T.block("T_reshape"):
                    ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                    T.reads(placeholder[(ax2 // 2 + ax1) % 384, ax2 % 2])
                    T.writes(T_reshape[ax0, ax1, ax2])
                    T_reshape[ax0, ax1, ax2] = placeholder[(ax2 // 2 + ax1) % 384, ax2 % 2]
            for i0, i1, i2 in T.grid(1, 384, 1):
                with T.block("T_split"):
                    ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                    T.reads(T_reshape[ax0, ax1, ax2], placeholder_1[ax2])
                    T.writes(T_split[ax0, ax1, ax2])
                    T_split[ax0, ax1, ax2] = T_reshape[ax0, ax1, ax2] + placeholder_1[ax2]
            for i0, i1, i2 in T.grid(1, 384, 1):
                with T.block("T_split_1"):
                    ax0, ax1, ax2 = T.axis.remap("SSS", [i0, i1, i2])
                    T.reads(T_reshape[ax0, ax1, ax2 + 1], placeholder_1[ax2 + 1])
                    T.writes(T_split_1[ax0, ax1, ax2])
                    T_split_1[ax0, ax1, ax2] = T_reshape[ax0, ax1, ax2 + 1] + placeholder_1[ax2 + 1]
    

b0 = sch.get_block(name="T_reshape", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v3 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v3)
l4 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l4, preserve_unit_loops=True)
[19:06:18] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:96: Initializing Task #25: "fused_squeeze_1"
[19:06:18] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:102: 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384, 1), "float32"], placeholder_1: T.Buffer[(1, 384, 1), "float32"], T_squeeze: T.Buffer[(1, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1 in T.grid(1, 384):
            with T.block("T_squeeze"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(placeholder[ax0, ax1, 0])
                T.writes(T_squeeze[ax0, ax1])
                T_squeeze[ax0, ax1] = placeholder[ax0, ax1, 0]
    

[19:06:18] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:106: Total 1 design space(s) generated
[19:06:18] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:111: Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384, 1), "float32"], placeholder_1: T.Buffer[(1, 384, 1), "float32"], T_squeeze: T.Buffer[(1, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel":128, "meta_schedule.unroll_explicit":0, "meta_schedule.vectorize":64})
            for i0, i1 in T.grid(1, 384):
                with T.block("T_squeeze"):
                    ax0, ax1 = T.axis.remap("SS", [i0, i1])
                    T.reads(placeholder[ax0, ax1, 0])
                    T.writes(T_squeeze[ax0, ax1])
                    T_squeeze[ax0, ax1] = placeholder[ax0, ax1, 0]
    

b0 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.vectorize", ann_val=64)
v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.unroll_explicit", ann_val=v1)
[19:06:18] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:111: 
 ID |                                                       Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                              fused_squeeze |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  1 |      fused_reshape_add_reshape_transpose_reshape_transpose |     393216 |     24 |            N/A |          N/A |                   N/A |      0 |            
  2 |       fused_expand_dims_expand_dims_cast_subtract_multiply |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
  3 |    fused_reshape_add_reshape_transpose_reshape_transpose_1 |     393216 |     24 |            N/A |          N/A |                   N/A |      0 |            
  4 |                                                 fused_mean |     393600 |     49 |            N/A |          N/A |                   N/A |      0 |            
  5 |      fused_less_add_where_take_add_less_add_where_take_add |     787200 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                fused_reshape_add_reshape_transpose_reshape |     393216 |     24 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                      fused_nn_batch_matmul |  301989888 |     24 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                   fused_reshape_divide_add |    4718592 |     24 |            N/A |          N/A |                   N/A |      0 |            
  9 |                                           fused_nn_softmax |    9437184 |     24 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                              fused_reshape |          1 |     24 |            N/A |          N/A |                   N/A |      0 |            
 11 |                                    fused_nn_batch_matmul_1 |  301989888 |     24 |            N/A |          N/A |                   N/A |      0 |            
 12 |                            fused_reshape_transpose_reshape |          1 |     24 |            N/A |          N/A |                   N/A |      0 |            
 13 |                                             fused_nn_dense |  805306368 |     96 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_add_sqrt_divide_multiply_add |    1180032 |     48 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                            fused_reshape_1 |          1 |     48 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_dense_1 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_reshape_add_multiply_divide_erf_add_multiply_reshape |    7864320 |     24 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_dense_2 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 19 |                                      fused_reshape_add_add |     786432 |     48 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                             fused_subtract |     393216 |     49 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                           fused_power_mean |     393600 |     49 |            N/A |          N/A |                   N/A |      0 |            
 22 |                 fused_add_sqrt_divide_multiply_add_reshape |    1180032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                           fused_nn_dense_3 |    1572864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                    fused_reshape_add_split |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                            fused_squeeze_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 0
Total latency (us): 0

[19:06:18] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #0: "fused_squeeze"
[19:06:18] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[19:06:21] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[19:06:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"
[19:06:36] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[19:06:56] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[19:07:07] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"
[19:07:08] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[19:07:08] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[19:07:24] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"
[19:07:25] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[19:07:55] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[19:08:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #4: "fused_mean"
[19:08:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[19:08:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[19:08:28] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #5: "fused_less_add_where_take_add_less_add_where_take_add"
[19:08:28] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[19:08:30] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[19:09:32] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #6: "fused_reshape_add_reshape_transpose_reshape"
[19:09:32] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[19:09:47] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[19:10:00] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #7: "fused_nn_batch_matmul"
[19:10:00] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[19:10:06] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[19:10:21] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #8: "fused_reshape_divide_add"
[19:10:22] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[19:10:52] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[19:11:08] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #9: "fused_nn_softmax"
[19:11:08] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[19:11:39] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[19:11:59] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #10: "fused_reshape"
[19:11:59] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[19:12:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[19:12:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #11: "fused_nn_batch_matmul_1"
[19:12:34] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[19:12:59] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[19:13:18] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #12: "fused_reshape_transpose_reshape"
[19:13:18] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[19:13:19] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[19:13:44] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #13: "fused_nn_dense"
[19:13:44] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[19:14:14] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[19:14:28] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #14: "fused_add_sqrt_divide_multiply_add"
[19:14:29] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[19:14:29] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[19:14:37] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #15: "fused_reshape_1"
[19:14:37] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[19:14:38] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[19:14:49] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #16: "fused_nn_dense_1"
[19:14:49] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[19:15:12] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[19:15:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"
[19:15:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[19:15:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[19:16:05] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #18: "fused_nn_dense_2"
[19:16:05] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[19:16:17] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[19:17:06] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #19: "fused_reshape_add_add"
[19:17:06] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[19:17:07] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[19:17:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #20: "fused_subtract"
[19:17:15] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[19:17:16] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[19:17:30] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #21: "fused_power_mean"
[19:17:30] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[19:17:30] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[19:17:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #22: "fused_add_sqrt_divide_multiply_add_reshape"
[19:17:51] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[19:17:52] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[19:18:01] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #23: "fused_nn_dense_3"
[19:18:01] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[19:18:04] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[19:18:19] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #24: "fused_reshape_add_split"
[19:18:19] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[19:18:19] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[19:18:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #25: "fused_squeeze_1"
[19:18:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:32: Sending 32 sample(s) to builder
[19:18:45] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:53: Sending 32 sample(s) to runner
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #0: GFLOPs: 0.0000. Time: 0.0250 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #1: GFLOPs: 0.0000. Time: 0.0222 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #2: GFLOPs: 0.0000. Time: 0.0199 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #3: GFLOPs: 0.0000. Time: 0.0199 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #4: GFLOPs: 0.0000. Time: 0.0191 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #5: GFLOPs: 0.0000. Time: 0.0200 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #6: GFLOPs: 0.0000. Time: 0.0197 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #7: GFLOPs: 0.0000. Time: 0.0208 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #8: GFLOPs: 0.0000. Time: 0.0565 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #9: GFLOPs: 0.0000. Time: 0.0167 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #10: GFLOPs: 0.0000. Time: 0.0150 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #11: GFLOPs: 0.0000. Time: 0.0154 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #12: GFLOPs: 0.0000. Time: 0.0127 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #13: GFLOPs: 0.0000. Time: 0.0156 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #14: GFLOPs: 0.0000. Time: 0.0130 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #15: GFLOPs: 0.0000. Time: 0.0135 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #16: GFLOPs: 0.0000. Time: 0.0156 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #17: GFLOPs: 0.0000. Time: 0.0147 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #18: GFLOPs: 0.0000. Time: 0.0155 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #19: GFLOPs: 0.0000. Time: 0.0162 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #20: GFLOPs: 0.0000. Time: 0.0147 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #21: GFLOPs: 0.0000. Time: 0.0160 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #22: GFLOPs: 0.0000. Time: 0.0172 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #23: GFLOPs: 0.0000. Time: 0.0140 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #24: GFLOPs: 0.0000. Time: 0.0167 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #25: GFLOPs: 0.0000. Time: 0.0161 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #26: GFLOPs: 0.0000. Time: 0.0161 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #27: GFLOPs: 0.0000. Time: 0.0173 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #28: GFLOPs: 0.0000. Time: 0.0139 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #29: GFLOPs: 0.0000. Time: 0.0141 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #30: GFLOPs: 0.0000. Time: 0.0142 ms. Best GFLOPs: 0.0000
[19:18:53] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #0: "fused_squeeze"] Trial #31: GFLOPs: 0.0000. Time: 0.0139 ms. Best GFLOPs: 0.0000
/home/yj/anaconda3/lib/python3.9/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html
  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)
[19:18:54] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #0: "fused_squeeze"
 ID |                                                       Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                              fused_squeeze |          1 |      1 |         0.0001 |      12.6516 |               12.6516 |     32 |            
  1 |      fused_reshape_add_reshape_transpose_reshape_transpose |     393216 |     24 |            N/A |          N/A |                   N/A |      0 |            
  2 |       fused_expand_dims_expand_dims_cast_subtract_multiply |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
  3 |    fused_reshape_add_reshape_transpose_reshape_transpose_1 |     393216 |     24 |            N/A |          N/A |                   N/A |      0 |            
  4 |                                                 fused_mean |     393600 |     49 |            N/A |          N/A |                   N/A |      0 |            
  5 |      fused_less_add_where_take_add_less_add_where_take_add |     787200 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                fused_reshape_add_reshape_transpose_reshape |     393216 |     24 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                      fused_nn_batch_matmul |  301989888 |     24 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                   fused_reshape_divide_add |    4718592 |     24 |            N/A |          N/A |                   N/A |      0 |            
  9 |                                           fused_nn_softmax |    9437184 |     24 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                              fused_reshape |          1 |     24 |            N/A |          N/A |                   N/A |      0 |            
 11 |                                    fused_nn_batch_matmul_1 |  301989888 |     24 |            N/A |          N/A |                   N/A |      0 |            
 12 |                            fused_reshape_transpose_reshape |          1 |     24 |            N/A |          N/A |                   N/A |      0 |            
 13 |                                             fused_nn_dense |  805306368 |     96 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_add_sqrt_divide_multiply_add |    1180032 |     48 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                            fused_reshape_1 |          1 |     48 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_dense_1 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_reshape_add_multiply_divide_erf_add_multiply_reshape |    7864320 |     24 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_dense_2 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 19 |                                      fused_reshape_add_add |     786432 |     48 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                             fused_subtract |     393216 |     49 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                           fused_power_mean |     393600 |     49 |            N/A |          N/A |                   N/A |      0 |            
 22 |                 fused_add_sqrt_divide_multiply_add_reshape |    1180032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                           fused_nn_dense_3 |    1572864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                    fused_reshape_add_split |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                            fused_squeeze_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 32
Total latency (us): 12.6516

[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #0: GFLOPs: 1.1135. Time: 0.3531 ms. Best GFLOPs: 1.1135
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #1: GFLOPs: 0.6486. Time: 0.6062 ms. Best GFLOPs: 1.1135
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #2: GFLOPs: 1.8046. Time: 0.2179 ms. Best GFLOPs: 1.8046
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #3: GFLOPs: 0.9707. Time: 0.4051 ms. Best GFLOPs: 1.8046
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #4: GFLOPs: 0.5299. Time: 0.7421 ms. Best GFLOPs: 1.8046
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #5: GFLOPs: 0.0468. Time: 8.4037 ms. Best GFLOPs: 1.8046
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #6: GFLOPs: 0.7585. Time: 0.5184 ms. Best GFLOPs: 1.8046
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #7: GFLOPs: 1.2176. Time: 0.3230 ms. Best GFLOPs: 1.8046
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #8: GFLOPs: 2.2386. Time: 0.1757 ms. Best GFLOPs: 2.2386
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #9: GFLOPs: 0.1210. Time: 3.2500 ms. Best GFLOPs: 2.2386
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #10: GFLOPs: 0.6422. Time: 0.6123 ms. Best GFLOPs: 2.2386
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #11: GFLOPs: 0.0659. Time: 5.9674 ms. Best GFLOPs: 2.2386
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #12: GFLOPs: 0.0966. Time: 4.0692 ms. Best GFLOPs: 2.2386
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #13: GFLOPs: 0.7516. Time: 0.5232 ms. Best GFLOPs: 2.2386
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #14: GFLOPs: 0.9829. Time: 0.4001 ms. Best GFLOPs: 2.2386
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #15: GFLOPs: 1.9483. Time: 0.2018 ms. Best GFLOPs: 2.2386
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #16: GFLOPs: 0.8564. Time: 0.4592 ms. Best GFLOPs: 2.2386
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #17: GFLOPs: 1.5785. Time: 0.2491 ms. Best GFLOPs: 2.2386
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #18: GFLOPs: 0.9025. Time: 0.4357 ms. Best GFLOPs: 2.2386
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #19: GFLOPs: 2.4269. Time: 0.1620 ms. Best GFLOPs: 2.4269
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #20: GFLOPs: 0.7462. Time: 0.5269 ms. Best GFLOPs: 2.4269
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #21: GFLOPs: 0.9715. Time: 0.4048 ms. Best GFLOPs: 2.4269
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #22: GFLOPs: 0.4529. Time: 0.8681 ms. Best GFLOPs: 2.4269
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #23: GFLOPs: 0.0460. Time: 8.5453 ms. Best GFLOPs: 2.4269
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #24: GFLOPs: 0.7780. Time: 0.5054 ms. Best GFLOPs: 2.4269
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #25: GFLOPs: 1.0651. Time: 0.3692 ms. Best GFLOPs: 2.4269
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #26: GFLOPs: 1.0141. Time: 0.3878 ms. Best GFLOPs: 2.4269
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #27: GFLOPs: 0.8478. Time: 0.4638 ms. Best GFLOPs: 2.4269
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #28: GFLOPs: 1.8179. Time: 0.2163 ms. Best GFLOPs: 2.4269
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #29: GFLOPs: 1.8366. Time: 0.2141 ms. Best GFLOPs: 2.4269
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #30: GFLOPs: 1.6713. Time: 0.2353 ms. Best GFLOPs: 2.4269
[19:18:54] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"] Trial #31: GFLOPs: 0.6559. Time: 0.5995 ms. Best GFLOPs: 2.4269
[19:18:55] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"
 ID |                                                       Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                              fused_squeeze |          1 |      1 |         0.0001 |      12.6516 |               12.6516 |     32 |            
  1 |      fused_reshape_add_reshape_transpose_reshape_transpose |     393216 |     24 |         2.4269 |     162.0252 |             3888.6041 |     32 |            
  2 |       fused_expand_dims_expand_dims_cast_subtract_multiply |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
  3 |    fused_reshape_add_reshape_transpose_reshape_transpose_1 |     393216 |     24 |            N/A |          N/A |                   N/A |      0 |            
  4 |                                                 fused_mean |     393600 |     49 |            N/A |          N/A |                   N/A |      0 |            
  5 |      fused_less_add_where_take_add_less_add_where_take_add |     787200 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                fused_reshape_add_reshape_transpose_reshape |     393216 |     24 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                      fused_nn_batch_matmul |  301989888 |     24 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                   fused_reshape_divide_add |    4718592 |     24 |            N/A |          N/A |                   N/A |      0 |            
  9 |                                           fused_nn_softmax |    9437184 |     24 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                              fused_reshape |          1 |     24 |            N/A |          N/A |                   N/A |      0 |            
 11 |                                    fused_nn_batch_matmul_1 |  301989888 |     24 |            N/A |          N/A |                   N/A |      0 |            
 12 |                            fused_reshape_transpose_reshape |          1 |     24 |            N/A |          N/A |                   N/A |      0 |            
 13 |                                             fused_nn_dense |  805306368 |     96 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_add_sqrt_divide_multiply_add |    1180032 |     48 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                            fused_reshape_1 |          1 |     48 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_dense_1 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_reshape_add_multiply_divide_erf_add_multiply_reshape |    7864320 |     24 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_dense_2 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 19 |                                      fused_reshape_add_add |     786432 |     48 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                             fused_subtract |     393216 |     49 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                           fused_power_mean |     393600 |     49 |            N/A |          N/A |                   N/A |      0 |            
 22 |                 fused_add_sqrt_divide_multiply_add_reshape |    1180032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                           fused_nn_dense_3 |    1572864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                    fused_reshape_add_split |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                            fused_squeeze_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 64
Total latency (us): 3901.26

[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #0: GFLOPs: 0.0382. Time: 0.0201 ms. Best GFLOPs: 0.0382
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #1: GFLOPs: 0.0366. Time: 0.0210 ms. Best GFLOPs: 0.0382
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #2: GFLOPs: 0.0367. Time: 0.0209 ms. Best GFLOPs: 0.0382
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #3: GFLOPs: 0.0362. Time: 0.0212 ms. Best GFLOPs: 0.0382
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #4: GFLOPs: 0.0334. Time: 0.0230 ms. Best GFLOPs: 0.0382
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #5: GFLOPs: 0.0304. Time: 0.0253 ms. Best GFLOPs: 0.0382
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #6: GFLOPs: 0.0392. Time: 0.0196 ms. Best GFLOPs: 0.0392
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #7: GFLOPs: 0.0400. Time: 0.0192 ms. Best GFLOPs: 0.0400
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #8: GFLOPs: 0.0354. Time: 0.0217 ms. Best GFLOPs: 0.0400
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #9: GFLOPs: 0.0315. Time: 0.0243 ms. Best GFLOPs: 0.0400
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #10: GFLOPs: 0.0353. Time: 0.0218 ms. Best GFLOPs: 0.0400
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #11: GFLOPs: 0.0382. Time: 0.0201 ms. Best GFLOPs: 0.0400
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #12: GFLOPs: 0.0460. Time: 0.0167 ms. Best GFLOPs: 0.0460
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #13: GFLOPs: 0.0418. Time: 0.0184 ms. Best GFLOPs: 0.0460
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #14: GFLOPs: 0.0434. Time: 0.0177 ms. Best GFLOPs: 0.0460
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #15: GFLOPs: 0.0332. Time: 0.0231 ms. Best GFLOPs: 0.0460
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #16: GFLOPs: 0.0512. Time: 0.0150 ms. Best GFLOPs: 0.0512
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #17: GFLOPs: 0.0434. Time: 0.0177 ms. Best GFLOPs: 0.0512
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #18: GFLOPs: 0.0289. Time: 0.0265 ms. Best GFLOPs: 0.0512
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #19: GFLOPs: 0.0329. Time: 0.0234 ms. Best GFLOPs: 0.0512
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #20: GFLOPs: 0.0489. Time: 0.0157 ms. Best GFLOPs: 0.0512
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #21: GFLOPs: 0.0184. Time: 0.0417 ms. Best GFLOPs: 0.0512
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #22: GFLOPs: 0.0323. Time: 0.0238 ms. Best GFLOPs: 0.0512
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #23: GFLOPs: 0.0378. Time: 0.0203 ms. Best GFLOPs: 0.0512
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #24: GFLOPs: 0.0343. Time: 0.0224 ms. Best GFLOPs: 0.0512
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #25: GFLOPs: 0.0387. Time: 0.0199 ms. Best GFLOPs: 0.0512
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #26: GFLOPs: 0.0269. Time: 0.0286 ms. Best GFLOPs: 0.0512
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #27: GFLOPs: 0.0206. Time: 0.0373 ms. Best GFLOPs: 0.0512
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #28: GFLOPs: 0.0206. Time: 0.0372 ms. Best GFLOPs: 0.0512
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #29: GFLOPs: 0.0345. Time: 0.0223 ms. Best GFLOPs: 0.0512
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #30: GFLOPs: 0.0282. Time: 0.0272 ms. Best GFLOPs: 0.0512
[19:18:55] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"] Trial #31: GFLOPs: 0.0376. Time: 0.0204 ms. Best GFLOPs: 0.0512
[19:19:02] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"
 ID |                                                       Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                              fused_squeeze |          1 |      1 |         0.0001 |      12.6516 |               12.6516 |     32 |            
  1 |      fused_reshape_add_reshape_transpose_reshape_transpose |     393216 |     24 |         2.4269 |     162.0252 |             3888.6041 |     32 |            
  2 |       fused_expand_dims_expand_dims_cast_subtract_multiply |        768 |      1 |         0.0512 |      15.0019 |               15.0019 |     32 |            
  3 |    fused_reshape_add_reshape_transpose_reshape_transpose_1 |     393216 |     24 |            N/A |          N/A |                   N/A |      0 |            
  4 |                                                 fused_mean |     393600 |     49 |            N/A |          N/A |                   N/A |      0 |            
  5 |      fused_less_add_where_take_add_less_add_where_take_add |     787200 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                fused_reshape_add_reshape_transpose_reshape |     393216 |     24 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                      fused_nn_batch_matmul |  301989888 |     24 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                   fused_reshape_divide_add |    4718592 |     24 |            N/A |          N/A |                   N/A |      0 |            
  9 |                                           fused_nn_softmax |    9437184 |     24 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                              fused_reshape |          1 |     24 |            N/A |          N/A |                   N/A |      0 |            
 11 |                                    fused_nn_batch_matmul_1 |  301989888 |     24 |            N/A |          N/A |                   N/A |      0 |            
 12 |                            fused_reshape_transpose_reshape |          1 |     24 |            N/A |          N/A |                   N/A |      0 |            
 13 |                                             fused_nn_dense |  805306368 |     96 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_add_sqrt_divide_multiply_add |    1180032 |     48 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                            fused_reshape_1 |          1 |     48 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_dense_1 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_reshape_add_multiply_divide_erf_add_multiply_reshape |    7864320 |     24 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_dense_2 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 19 |                                      fused_reshape_add_add |     786432 |     48 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                             fused_subtract |     393216 |     49 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                           fused_power_mean |     393600 |     49 |            N/A |          N/A |                   N/A |      0 |            
 22 |                 fused_add_sqrt_divide_multiply_add_reshape |    1180032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                           fused_nn_dense_3 |    1572864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                    fused_reshape_add_split |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                            fused_squeeze_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 96
Total latency (us): 3916.26

[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #0: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 1024), "float32"], placeholder_1: T.Buffer[(1024,), "float32"], T_transpose: T.Buffer[(16, 384, 64), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        T_reshape = T.alloc_buffer([1, 384, 1024], dtype="float32")
        T_reshape_1 = T.alloc_buffer([1, 384, 16, 64], dtype="float32")
        T_transpose_1 = T.alloc_buffer([1, 16, 64, 384], dtype="float32")
        for i0_fused in T.parallel(16, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for ax0, ax1 in T.grid(1, 384):
                for ax0_1, ax1_1 in T.grid(1, 1):
                    for ax2_fused in T.vectorized(64):
                        with T.block("T_reshape"):
                            ax0_2 = T.axis.spatial(1, 0)
                            ax1_2 = T.axis.spatial(384, ax1)
                            ax2 = T.axis.spatial(1024, i0_fused * 64 + ax2_fused)
                            T.reads(placeholder[(ax2 // 1024 + ax1_2) % 384, ax2 % 1024])
                            T.writes(T_reshape[ax0_2, ax1_2, ax2])
                            T_reshape[ax0_2, ax1_2, ax2] = placeholder[(ax2 // 1024 + ax1_2) % 384, ax2 % 1024]
                for ax2_ax3_fused in T.vectorized(64):
                    with T.block("T_reshape_1"):
                        ax0_3 = T.axis.spatial(1, 0)
                        ax1_3, ax2, ax3 = T.axis.remap("SSS", [ax1, i0_fused, ax2_ax3_fused])
                        T.reads(T_reshape[0, ((ax2 * 64 + ax3) // 1024 + ax1_3) % 384, (ax2 * 64 + ax3) % 1024], placeholder_1[(ax2 * 64 + ax3) % 1024])
                        T.writes(T_reshape_1[ax0_3, ax1_3, ax2, ax3])
                        T_reshape_1[ax0_3, ax1_3, ax2, ax3] = T_reshape[0, ((ax2 * 64 + ax3) // 1024 + ax1_3) % 384, (ax2 * 64 + ax3) % 1024] + placeholder_1[(ax2 * 64 + ax3) % 1024]
            for ax0_4, ax1_4, ax2, ax3 in T.grid(1, 1, 64, 384):
                with T.block("T_transpose"):
                    ax0_5 = T.axis.spatial(1, 0)
                    ax1_5, ax2_1, ax3_1 = T.axis.remap("SSS", [i0_fused, ax2, ax3])
                    T.reads(T_reshape_1[ax0_5, ax3_1, ax1_5, ax2_1])
                    T.writes(T_transpose_1[ax0_5, ax1_5, ax2_1, ax3_1])
                    T_transpose_1[ax0_5, ax1_5, ax2_1, ax3_1] = T_reshape_1[ax0_5, ax3_1, ax1_5, ax2_1]
            for i1 in T.serial(384):
                for i2_fused in T.vectorized(64):
                    with T.block("T_transpose_1"):
                        ax0_6, ax1_6, ax2 = T.axis.remap("SSS", [i0_fused, i1, i2_fused])
                        T.reads(T_transpose_1[0, ((ax1_6 // 384 + ax2) // 64 + ax0_6) % 16, (ax1_6 // 384 + ax2) % 64, ax1_6 % 384])
                        T.writes(T_transpose[ax0_6, ax1_6, ax2])
                        T_transpose[ax0_6, ax1_6, ax2] = T_transpose_1[0, ((ax1_6 // 384 + ax2) // 64 + ax0_6) % 16, (ax1_6 // 384 + ax2) % 64, ax1_6 % 384]
    

b0 = sch.get_block(name="T_reshape", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="T_reshape_1", func_name="main")
b3 = sch.get_block(name="T_transpose", func_name="main")
b4 = sch.get_block(name="T_reshape_2", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.vectorize", ann_val=64)
v6 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v6)
l7 = sch.sample_compute_location(block=b4, decision=-2)
sch.compute_at(block=b4, loop=l7, preserve_unit_loops=True)
l8 = sch.sample_compute_location(block=b3, decision=0)
sch.compute_at(block=b3, loop=l8, preserve_unit_loops=True)
l9 = sch.sample_compute_location(block=b2, decision=0)
sch.compute_at(block=b2, loop=l9, preserve_unit_loops=True)
l10 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l10, preserve_unit_loops=True)
sch.enter_postproc()
b11 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b11, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b11, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b11, ann_key="meta_schedule.unroll_explicit")
b12, b13, b14, b15 = sch.get_child_blocks(b11)
l16, l17, l18, l19, l20, l21 = sch.get_loops(block=b12)
l22 = sch.fuse(l16)
sch.parallel(loop=l22)
l23 = sch.fuse(l21)
sch.vectorize(loop=l23)
sch.annotate(block_or_loop=l22, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l22, ann_key="pragma_unroll_explicit", ann_val=1)
l24, l25, l26, l27, l28 = sch.get_loops(block=b13)
l29 = sch.fuse(l27, l28)
sch.vectorize(loop=l29)
sch.annotate(block_or_loop=l24, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l24, ann_key="pragma_unroll_explicit", ann_val=1)
l30, l31, l32, l33, l34 = sch.get_loops(block=b14)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l35, l36, l37 = sch.get_loops(block=b15)
l38 = sch.fuse(l37)
sch.vectorize(loop=l38)
sch.annotate(block_or_loop=l35, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l35, ann_key="pragma_unroll_explicit", ann_val=1)
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #1: GFLOPs: 0.3085. Time: 1.2745 ms. Best GFLOPs: 0.3085
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #2: GFLOPs: 0.3155. Time: 1.2464 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #3: GFLOPs: 0.0864. Time: 4.5508 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #4: GFLOPs: 0.1337. Time: 2.9400 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #5: GFLOPs: 0.0402. Time: 9.7700 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #6: GFLOPs: 0.0640. Time: 6.1426 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #7: GFLOPs: 0.0567. Time: 6.9392 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #8: GFLOPs: 0.0603. Time: 6.5195 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #9: GFLOPs: 0.0882. Time: 4.4600 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #10: GFLOPs: 0.0666. Time: 5.9047 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #11: GFLOPs: 0.0337. Time: 11.6524 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #12: GFLOPs: 0.0808. Time: 4.8675 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #13: GFLOPs: 0.0464. Time: 8.4693 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #14: GFLOPs: 0.0281. Time: 13.9971 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #15: GFLOPs: 0.0765. Time: 5.1421 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #16: GFLOPs: 0.0808. Time: 4.8660 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #17: GFLOPs: 0.0656. Time: 5.9937 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #18: GFLOPs: 0.0793. Time: 4.9583 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #19: GFLOPs: 0.0513. Time: 7.6620 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #20: GFLOPs: 0.0298. Time: 13.1930 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #21: GFLOPs: 0.0679. Time: 5.7941 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #22: GFLOPs: 0.0702. Time: 5.5991 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #23: GFLOPs: 0.0647. Time: 6.0785 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #24: GFLOPs: 0.0365. Time: 10.7633 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #25: GFLOPs: 0.0331. Time: 11.8672 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #26: GFLOPs: 0.0746. Time: 5.2705 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #27: GFLOPs: 0.0634. Time: 6.2064 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #28: GFLOPs: 0.1625. Time: 2.4199 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #29: GFLOPs: 0.1897. Time: 2.0734 ms. Best GFLOPs: 0.3155
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #30: GFLOPs: 0.6302. Time: 0.6240 ms. Best GFLOPs: 0.6302
[19:19:03] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"] Trial #31: GFLOPs: 0.8998. Time: 0.4370 ms. Best GFLOPs: 0.8998
[19:19:06] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"
 ID |                                                       Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                              fused_squeeze |          1 |      1 |         0.0001 |      12.6516 |               12.6516 |     32 |            
  1 |      fused_reshape_add_reshape_transpose_reshape_transpose |     393216 |     24 |         2.4269 |     162.0252 |             3888.6041 |     32 |            
  2 |       fused_expand_dims_expand_dims_cast_subtract_multiply |        768 |      1 |         0.0512 |      15.0019 |               15.0019 |     32 |            
  3 |    fused_reshape_add_reshape_transpose_reshape_transpose_1 |     393216 |     24 |         0.8998 |     437.0154 |            10488.3689 |     32 |            
  4 |                                                 fused_mean |     393600 |     49 |            N/A |          N/A |                   N/A |      0 |            
  5 |      fused_less_add_where_take_add_less_add_where_take_add |     787200 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                fused_reshape_add_reshape_transpose_reshape |     393216 |     24 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                      fused_nn_batch_matmul |  301989888 |     24 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                   fused_reshape_divide_add |    4718592 |     24 |            N/A |          N/A |                   N/A |      0 |            
  9 |                                           fused_nn_softmax |    9437184 |     24 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                              fused_reshape |          1 |     24 |            N/A |          N/A |                   N/A |      0 |            
 11 |                                    fused_nn_batch_matmul_1 |  301989888 |     24 |            N/A |          N/A |                   N/A |      0 |            
 12 |                            fused_reshape_transpose_reshape |          1 |     24 |            N/A |          N/A |                   N/A |      0 |            
 13 |                                             fused_nn_dense |  805306368 |     96 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_add_sqrt_divide_multiply_add |    1180032 |     48 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                            fused_reshape_1 |          1 |     48 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_dense_1 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_reshape_add_multiply_divide_erf_add_multiply_reshape |    7864320 |     24 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_dense_2 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 19 |                                      fused_reshape_add_add |     786432 |     48 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                             fused_subtract |     393216 |     49 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                           fused_power_mean |     393600 |     49 |            N/A |          N/A |                   N/A |      0 |            
 22 |                 fused_add_sqrt_divide_multiply_add_reshape |    1180032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                           fused_nn_dense_3 |    1572864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                    fused_reshape_add_split |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                            fused_squeeze_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 128
Total latency (us): 14404.6

[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #0: GFLOPs: 2.3481. Time: 0.1676 ms. Best GFLOPs: 2.3481
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #1: GFLOPs: 2.3494. Time: 0.1675 ms. Best GFLOPs: 2.3494
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #2: GFLOPs: 4.2522. Time: 0.0926 ms. Best GFLOPs: 4.2522
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #3: GFLOPs: 4.0666. Time: 0.0968 ms. Best GFLOPs: 4.2522
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #4: GFLOPs: 3.9584. Time: 0.0994 ms. Best GFLOPs: 4.2522
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #5: GFLOPs: 2.1896. Time: 0.1798 ms. Best GFLOPs: 4.2522
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #6: GFLOPs: 5.6202. Time: 0.0700 ms. Best GFLOPs: 5.6202
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #7: GFLOPs: 4.1352. Time: 0.0952 ms. Best GFLOPs: 5.6202
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #8: GFLOPs: 1.6118. Time: 0.2442 ms. Best GFLOPs: 5.6202
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #9: GFLOPs: 2.6750. Time: 0.1471 ms. Best GFLOPs: 5.6202
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #10: GFLOPs: 6.2279. Time: 0.0632 ms. Best GFLOPs: 6.2279
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #11: GFLOPs: 3.8905. Time: 0.1012 ms. Best GFLOPs: 6.2279
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #12: GFLOPs: 7.3710. Time: 0.0534 ms. Best GFLOPs: 7.3710
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #13: GFLOPs: 2.0110. Time: 0.1957 ms. Best GFLOPs: 7.3710
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #14: GFLOPs: 5.9982. Time: 0.0656 ms. Best GFLOPs: 7.3710
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #15: GFLOPs: 10.0733. Time: 0.0391 ms. Best GFLOPs: 10.0733
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #16: GFLOPs: 3.8173. Time: 0.1031 ms. Best GFLOPs: 10.0733
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #17: GFLOPs: 3.0657. Time: 0.1284 ms. Best GFLOPs: 10.0733
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #18: GFLOPs: 2.9708. Time: 0.1325 ms. Best GFLOPs: 10.0733
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #19: GFLOPs: 6.3568. Time: 0.0619 ms. Best GFLOPs: 10.0733
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #20: GFLOPs: 2.2129. Time: 0.1779 ms. Best GFLOPs: 10.0733
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #21: GFLOPs: 4.0187. Time: 0.0979 ms. Best GFLOPs: 10.0733
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #22: GFLOPs: 8.8786. Time: 0.0443 ms. Best GFLOPs: 10.0733
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #23: GFLOPs: 0.1186. Time: 3.3186 ms. Best GFLOPs: 10.0733
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #24: GFLOPs: 4.1890. Time: 0.0940 ms. Best GFLOPs: 10.0733
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #25: GFLOPs: 3.4869. Time: 0.1129 ms. Best GFLOPs: 10.0733
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #26: GFLOPs: 3.7695. Time: 0.1044 ms. Best GFLOPs: 10.0733
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #27: GFLOPs: 4.4031. Time: 0.0894 ms. Best GFLOPs: 10.0733
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #28: GFLOPs: 8.2230. Time: 0.0479 ms. Best GFLOPs: 10.0733
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #29: GFLOPs: 5.2504. Time: 0.0750 ms. Best GFLOPs: 10.0733
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #30: GFLOPs: 4.6252. Time: 0.0851 ms. Best GFLOPs: 10.0733
[19:19:06] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #4: "fused_mean"] Trial #31: GFLOPs: 3.7247. Time: 0.1057 ms. Best GFLOPs: 10.0733
[19:19:08] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #4: "fused_mean"
 ID |                                                       Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                              fused_squeeze |          1 |      1 |         0.0001 |      12.6516 |               12.6516 |     32 |            
  1 |      fused_reshape_add_reshape_transpose_reshape_transpose |     393216 |     24 |         2.4269 |     162.0252 |             3888.6041 |     32 |            
  2 |       fused_expand_dims_expand_dims_cast_subtract_multiply |        768 |      1 |         0.0512 |      15.0019 |               15.0019 |     32 |            
  3 |    fused_reshape_add_reshape_transpose_reshape_transpose_1 |     393216 |     24 |         0.8998 |     437.0154 |            10488.3689 |     32 |            
  4 |                                                 fused_mean |     393600 |     49 |        10.0733 |      39.0736 |             1914.6079 |     32 |            
  5 |      fused_less_add_where_take_add_less_add_where_take_add |     787200 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                fused_reshape_add_reshape_transpose_reshape |     393216 |     24 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                      fused_nn_batch_matmul |  301989888 |     24 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                   fused_reshape_divide_add |    4718592 |     24 |            N/A |          N/A |                   N/A |      0 |            
  9 |                                           fused_nn_softmax |    9437184 |     24 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                              fused_reshape |          1 |     24 |            N/A |          N/A |                   N/A |      0 |            
 11 |                                    fused_nn_batch_matmul_1 |  301989888 |     24 |            N/A |          N/A |                   N/A |      0 |            
 12 |                            fused_reshape_transpose_reshape |          1 |     24 |            N/A |          N/A |                   N/A |      0 |            
 13 |                                             fused_nn_dense |  805306368 |     96 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_add_sqrt_divide_multiply_add |    1180032 |     48 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                            fused_reshape_1 |          1 |     48 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_dense_1 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_reshape_add_multiply_divide_erf_add_multiply_reshape |    7864320 |     24 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_dense_2 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 19 |                                      fused_reshape_add_add |     786432 |     48 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                             fused_subtract |     393216 |     49 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                           fused_power_mean |     393600 |     49 |            N/A |          N/A |                   N/A |      0 |            
 22 |                 fused_add_sqrt_divide_multiply_add_reshape |    1180032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                           fused_nn_dense_3 |    1572864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                    fused_reshape_add_split |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                            fused_squeeze_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 160
Total latency (us): 16319.2

[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #0: GFLOPs: 19.3910. Time: 0.0406 ms. Best GFLOPs: 19.3910
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #1: GFLOPs: 9.3798. Time: 0.0839 ms. Best GFLOPs: 19.3910
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #2: GFLOPs: 8.8285. Time: 0.0892 ms. Best GFLOPs: 19.3910
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #3: GFLOPs: 1.9521. Time: 0.4033 ms. Best GFLOPs: 19.3910
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #4: Error in building: LocalBuilder: An exception occurred
Subprocess terminated
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384), "int64"], placeholder_1: T.Buffer[(30522, 1024), "float32"], placeholder_2: T.Buffer[(1, 384, 1024), "float32"], placeholder_3: T.Buffer[(1, 384), "int64"], placeholder_4: T.Buffer[(2, 1024), "float32"], T_add: T.Buffer[(1, 384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        T_where = T.alloc_buffer([1, 384], dtype="int64")
        T_take = T.alloc_buffer([1, 384, 1024], dtype="float32")
        T_where_1 = T.alloc_buffer([1, 384], dtype="int64")
        T_take_1 = T.alloc_buffer([1, 384, 1024], dtype="float32")
        for i0_i1_fused in T.parallel(384, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for ax0, ax1 in T.grid(1, 1):
                with T.block("T_where"):
                    ax0_1 = T.axis.spatial(1, 0)
                    ax1_1 = T.axis.spatial(384, i0_i1_fused)
                    T.reads(placeholder[ax0_1, ax1_1])
                    T.writes(T_where[ax0_1, ax1_1])
                    T_where[ax0_1, ax1_1] = T.Select(T.cast(placeholder[ax0_1, ax1_1] < T.int64(0), "int32") != 0, placeholder[ax0_1, ax1_1] + T.int64(30522), placeholder[ax0_1, ax1_1])
            for i2 in T.serial(1024):
                with T.block("T_take"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1, ax2 = T.axis.remap("SS", [i0_i1_fused, i2])
                    T.reads(placeholder_1[T.min(T.max(T.int64(0), T_where[ax0, ax1]), T.int64(30521)), ax2], T_where[ax0, ax1])
                    T.writes(T_take[ax0, ax1, ax2])
                    T_take[ax0, ax1, ax2] = placeholder_1[T.min(T.max(T.int64(0), T_where[ax0, ax1]), T.int64(30521)), ax2]
        for i0_i1_fused in T.parallel(384, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for ax0, ax1, ax2 in T.grid(1, 1, 1024):
                for ax0_2, ax1_2 in T.grid(1, 1):
                    with T.block("T_where_1"):
                        ax0_3 = T.axis.spatial(1, 0)
                        ax1_3 = T.axis.spatial(384, i0_i1_fused)
                        T.reads(placeholder_3[ax0_3, ax1_3])
                        T.writes(T_where_1[ax0_3, ax1_3])
                        T_where_1[ax0_3, ax1_3] = T.Select(T.cast(placeholder_3[ax0_3, ax1_3] < T.int64(0), "int32") != 0, placeholder_3[ax0_3, ax1_3] + T.int64(2), placeholder_3[ax0_3, ax1_3])
                with T.block("T_take_1"):
                    ax0_4 = T.axis.spatial(1, 0)
                    ax1_4, ax2_1 = T.axis.remap("SS", [i0_i1_fused, ax2])
                    T.reads(placeholder_4[T.min(T.max(T.int64(0), T_where_1[ax0_4, ax1_4]), T.int64(1)), ax2_1], T_where_1[ax0_4, ax1_4])
                    T.writes(T_take_1[ax0_4, ax1_4, ax2_1])
                    T_take_1[ax0_4, ax1_4, ax2_1] = placeholder_4[T.min(T.max(T.int64(0), T_where_1[ax0_4, ax1_4]), T.int64(1)), ax2_1]
            for i2 in T.serial(1024):
                with T.block("T_add_3"):
                    ax0_5 = T.axis.spatial(1, 0)
                    ax1_5, ax2 = T.axis.remap("SS", [i0_i1_fused, i2])
                    T.reads(T_take[ax0_5, ax1_5, ax2], placeholder_2[ax0_5, ax1_5, ax2], T_take_1[ax0_5, ax1_5, ax2])
                    T.writes(T_add[ax0_5, ax1_5, ax2])
                    T_add[ax0_5, ax1_5, ax2] = T_take[ax0_5, ax1_5, ax2] + placeholder_2[ax0_5, ax1_5, ax2] + T_take_1[ax0_5, ax1_5, ax2]
    

b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_less", func_name="main")
b2 = sch.get_block(name="compile_engine_const_1", func_name="main")
b3 = sch.get_block(name="T_add", func_name="main")
b4 = sch.get_block(name="T_where", func_name="main")
b5 = sch.get_block(name="T_take", func_name="main")
b6 = sch.get_block(name="T_add_1", func_name="main")
b7 = sch.get_block(name="compile_engine_const_2", func_name="main")
b8 = sch.get_block(name="T_less_1", func_name="main")
b9 = sch.get_block(name="compile_engine_const_3", func_name="main")
b10 = sch.get_block(name="T_add_2", func_name="main")
b11 = sch.get_block(name="T_where_1", func_name="main")
b12 = sch.get_block(name="T_take_1", func_name="main")
b13 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b10)
sch.compute_inline(block=b9)
sch.compute_inline(block=b8)
sch.compute_inline(block=b7)
sch.compute_inline(block=b6)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
sch.annotate(block_or_loop=b13, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b13, ann_key="meta_schedule.vectorize", ann_val=64)
v14 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b13, ann_key="meta_schedule.unroll_explicit", ann_val=v14)
l15 = sch.sample_compute_location(block=b12, decision=1)
sch.compute_at(block=b12, loop=l15, preserve_unit_loops=True)
l16 = sch.sample_compute_location(block=b11, decision=4)
sch.compute_at(block=b11, loop=l16, preserve_unit_loops=True)
l17 = sch.sample_compute_location(block=b5, decision=-1)
sch.compute_at(block=b5, loop=l17, preserve_unit_loops=True)
l18 = sch.sample_compute_location(block=b4, decision=1)
sch.compute_at(block=b4, loop=l18, preserve_unit_loops=True)
sch.enter_postproc()
b19 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b19, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b19, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b19, ann_key="meta_schedule.unroll_explicit")
b20, b21, b22, b23, b24 = sch.get_child_blocks(b19)
l25, l26, l27, l28 = sch.get_loops(block=b20)
l29 = sch.fuse(l25, l26)
sch.parallel(loop=l29)
sch.annotate(block_or_loop=l29, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l29, ann_key="pragma_unroll_explicit", ann_val=1)
l30, l31 = sch.get_loops(block=b21)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l32, l33, l34, l35, l36, l37, l38 = sch.get_loops(block=b22)
l39 = sch.fuse(l32, l33)
sch.parallel(loop=l39)
sch.annotate(block_or_loop=l39, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l39, ann_key="pragma_unroll_explicit", ann_val=1)
l40, l41, l42, l43 = sch.get_loops(block=b23)
sch.annotate(block_or_loop=l40, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l40, ann_key="pragma_unroll_explicit", ann_val=1)
l44, l45 = sch.get_loops(block=b24)
sch.annotate(block_or_loop=l44, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l44, ann_key="pragma_unroll_explicit", ann_val=1)
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #5: GFLOPs: 1.5433. Time: 0.5101 ms. Best GFLOPs: 19.3910
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #6: GFLOPs: 2.4367. Time: 0.3231 ms. Best GFLOPs: 19.3910
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #7: GFLOPs: 7.8110. Time: 0.1008 ms. Best GFLOPs: 19.3910
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #8: Error in building: LocalBuilder: An exception occurred
Subprocess terminated
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384), "int64"], placeholder_1: T.Buffer[(30522, 1024), "float32"], placeholder_2: T.Buffer[(1, 384, 1024), "float32"], placeholder_3: T.Buffer[(1, 384), "int64"], placeholder_4: T.Buffer[(2, 1024), "float32"], T_add: T.Buffer[(1, 384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        T_where = T.alloc_buffer([1, 384], dtype="int64")
        T_where_1 = T.alloc_buffer([1, 384], dtype="int64")
        T_take = T.alloc_buffer([1, 384, 1024], dtype="float32")
        for i0_i1_fused in T.parallel(384):
            with T.block("T_where"):
                ax0 = T.axis.spatial(1, 0)
                ax1 = T.axis.spatial(384, i0_i1_fused)
                T.reads(placeholder[ax0, ax1])
                T.writes(T_where[ax0, ax1])
                T_where[ax0, ax1] = T.Select(T.cast(placeholder[ax0, ax1] < T.int64(0), "int32") != 0, placeholder[ax0, ax1] + T.int64(30522), placeholder[ax0, ax1])
        for i0_i1_fused_fused_fused in T.parallel(384):
            for ax0, ax1, ax2 in T.grid(1, 1, 1024):
                for ax0_1, ax1_1 in T.grid(1, 1):
                    with T.block("T_where_1"):
                        ax0_2 = T.axis.spatial(1, 0)
                        ax1_2 = T.axis.spatial(384, i0_i1_fused_fused_fused)
                        T.reads(placeholder_3[ax0_2, ax1_2])
                        T.writes(T_where_1[ax0_2, ax1_2])
                        T_where_1[ax0_2, ax1_2] = T.Select(T.cast(placeholder_3[ax0_2, ax1_2] < T.int64(0), "int32") != 0, placeholder_3[ax0_2, ax1_2] + T.int64(2), placeholder_3[ax0_2, ax1_2])
                with T.block("T_take_1"):
                    ax0_3 = T.axis.spatial(1, 0)
                    ax1_3, ax2_1 = T.axis.remap("SS", [i0_i1_fused_fused_fused, ax2])
                    T.reads(placeholder_4[T.min(T.max(T.int64(0), T_where_1[ax0_3, ax1_3]), T.int64(1)), ax2_1], T_where_1[ax0_3, ax1_3])
                    T.writes(T_take[ax0_3, ax1_3, ax2_1])
                    T_take[ax0_3, ax1_3, ax2_1] = placeholder_4[T.min(T.max(T.int64(0), T_where_1[ax0_3, ax1_3]), T.int64(1)), ax2_1]
            for i2 in T.serial(1024):
                with T.block("T_add_3"):
                    ax0_4 = T.axis.spatial(1, 0)
                    ax1_4, ax2 = T.axis.remap("SS", [i0_i1_fused_fused_fused, i2])
                    T.reads(placeholder_1[T.min(T.max(T.int64(0), T_where[ax0_4, ax1_4]), T.int64(30521)), ax2], T_where[ax0_4, ax1_4], placeholder_2[ax0_4, ax1_4, ax2], T_take[ax0_4, ax1_4, ax2])
                    T.writes(T_add[ax0_4, ax1_4, ax2])
                    T_add[ax0_4, ax1_4, ax2] = placeholder_1[T.min(T.max(T.int64(0), T_where[ax0_4, ax1_4]), T.int64(30521)), ax2] + placeholder_2[ax0_4, ax1_4, ax2] + T_take[ax0_4, ax1_4, ax2]
    

b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_less", func_name="main")
b2 = sch.get_block(name="compile_engine_const_1", func_name="main")
b3 = sch.get_block(name="T_add", func_name="main")
b4 = sch.get_block(name="T_where", func_name="main")
b5 = sch.get_block(name="T_take", func_name="main")
b6 = sch.get_block(name="T_add_1", func_name="main")
b7 = sch.get_block(name="compile_engine_const_2", func_name="main")
b8 = sch.get_block(name="T_less_1", func_name="main")
b9 = sch.get_block(name="compile_engine_const_3", func_name="main")
b10 = sch.get_block(name="T_add_2", func_name="main")
b11 = sch.get_block(name="T_where_1", func_name="main")
b12 = sch.get_block(name="T_take_1", func_name="main")
b13 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b10)
sch.compute_inline(block=b9)
sch.compute_inline(block=b8)
sch.compute_inline(block=b7)
sch.compute_inline(block=b6)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
sch.annotate(block_or_loop=b13, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b13, ann_key="meta_schedule.vectorize", ann_val=64)
v14 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b13, ann_key="meta_schedule.unroll_explicit", ann_val=v14)
l15 = sch.sample_compute_location(block=b12, decision=1)
sch.compute_at(block=b12, loop=l15, preserve_unit_loops=True)
l16 = sch.sample_compute_location(block=b11, decision=4)
sch.compute_at(block=b11, loop=l16, preserve_unit_loops=True)
l17 = sch.sample_compute_location(block=b5, decision=-2)
sch.compute_at(block=b5, loop=l17, preserve_unit_loops=True)
l18 = sch.sample_compute_location(block=b4, decision=-1)
sch.compute_at(block=b4, loop=l18, preserve_unit_loops=True)
sch.enter_postproc()
b19 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b19, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b19, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b19, ann_key="meta_schedule.unroll_explicit")
b20, b21, b22, b23 = sch.get_child_blocks(b19)
l24, l25 = sch.get_loops(block=b20)
l26 = sch.fuse(l24, l25)
sch.parallel(loop=l26)
l27, l28, l29, l30, l31, l32, l33 = sch.get_loops(block=b21)
l34 = sch.fuse(l27, l28)
sch.parallel(loop=l34)
l35, l36, l37, l38 = sch.get_loops(block=b22)
l39 = sch.fuse(l35)
sch.parallel(loop=l39)
l40, l41 = sch.get_loops(block=b23)
l42 = sch.fuse(l40)
sch.parallel(loop=l42)
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #9: GFLOPs: 4.6446. Time: 0.1695 ms. Best GFLOPs: 19.3910
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #10: GFLOPs: 5.1020. Time: 0.1543 ms. Best GFLOPs: 19.3910
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #11: GFLOPs: 0.8739. Time: 0.9008 ms. Best GFLOPs: 19.3910
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #12: Error in building: LocalBuilder: An exception occurred
Subprocess terminated
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384), "int64"], placeholder_1: T.Buffer[(30522, 1024), "float32"], placeholder_2: T.Buffer[(1, 384, 1024), "float32"], placeholder_3: T.Buffer[(1, 384), "int64"], placeholder_4: T.Buffer[(2, 1024), "float32"], T_add: T.Buffer[(1, 384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        T_where = T.alloc_buffer([1, 384], dtype="int64")
        T_take = T.alloc_buffer([1, 384, 1024], dtype="float32")
        for i0_i1_fused in T.parallel(384, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for ax0, ax1, ax2 in T.grid(1, 1, 1024):
                for ax0_1, ax1_1 in T.grid(1, 1):
                    with T.block("T_where_1"):
                        ax0_2 = T.axis.spatial(1, 0)
                        ax1_2 = T.axis.spatial(384, i0_i1_fused)
                        T.reads(placeholder_3[ax0_2, ax1_2])
                        T.writes(T_where[ax0_2, ax1_2])
                        T_where[ax0_2, ax1_2] = T.Select(T.cast(placeholder_3[ax0_2, ax1_2] < T.int64(0), "int32") != 0, placeholder_3[ax0_2, ax1_2] + T.int64(2), placeholder_3[ax0_2, ax1_2])
                with T.block("T_take_1"):
                    ax0_3 = T.axis.spatial(1, 0)
                    ax1_3, ax2_1 = T.axis.remap("SS", [i0_i1_fused, ax2])
                    T.reads(placeholder_4[T.min(T.max(T.int64(0), T_where[ax0_3, ax1_3]), T.int64(1)), ax2_1], T_where[ax0_3, ax1_3])
                    T.writes(T_take[ax0_3, ax1_3, ax2_1])
                    T_take[ax0_3, ax1_3, ax2_1] = placeholder_4[T.min(T.max(T.int64(0), T_where[ax0_3, ax1_3]), T.int64(1)), ax2_1]
            for i2 in T.serial(1024):
                with T.block("T_add_3"):
                    ax0_4 = T.axis.spatial(1, 0)
                    ax1_4, ax2 = T.axis.remap("SS", [i0_i1_fused, i2])
                    T.reads(placeholder[ax0_4, ax1_4], placeholder_1[T.min(T.max(T.int64(0), placeholder[ax0_4, ax1_4]), T.int64(30521)) : T.min(T.max(T.int64(0), placeholder[ax0_4, ax1_4] + T.int64(30522)), T.int64(30521)) + T.int64(1), ax2], placeholder_2[ax0_4, ax1_4, ax2], T_take[ax0_4, ax1_4, ax2])
                    T.writes(T_add[ax0_4, ax1_4, ax2])
                    T_add[ax0_4, ax1_4, ax2] = placeholder_1[T.min(T.max(T.int64(0), T.Select(T.cast(placeholder[ax0_4, ax1_4] < T.int64(0), "int32") != 0, placeholder[ax0_4, ax1_4] + T.int64(30522), placeholder[ax0_4, ax1_4])), T.int64(30521)), ax2] + placeholder_2[ax0_4, ax1_4, ax2] + T_take[ax0_4, ax1_4, ax2]
    

b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_less", func_name="main")
b2 = sch.get_block(name="compile_engine_const_1", func_name="main")
b3 = sch.get_block(name="T_add", func_name="main")
b4 = sch.get_block(name="T_where", func_name="main")
b5 = sch.get_block(name="T_take", func_name="main")
b6 = sch.get_block(name="T_add_1", func_name="main")
b7 = sch.get_block(name="compile_engine_const_2", func_name="main")
b8 = sch.get_block(name="T_less_1", func_name="main")
b9 = sch.get_block(name="compile_engine_const_3", func_name="main")
b10 = sch.get_block(name="T_add_2", func_name="main")
b11 = sch.get_block(name="T_where_1", func_name="main")
b12 = sch.get_block(name="T_take_1", func_name="main")
b13 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b10)
sch.compute_inline(block=b9)
sch.compute_inline(block=b8)
sch.compute_inline(block=b7)
sch.compute_inline(block=b6)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
sch.annotate(block_or_loop=b13, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b13, ann_key="meta_schedule.vectorize", ann_val=64)
v14 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b13, ann_key="meta_schedule.unroll_explicit", ann_val=v14)
l15 = sch.sample_compute_location(block=b12, decision=1)
sch.compute_at(block=b12, loop=l15, preserve_unit_loops=True)
l16 = sch.sample_compute_location(block=b11, decision=4)
sch.compute_at(block=b11, loop=l16, preserve_unit_loops=True)
l17 = sch.sample_compute_location(block=b5, decision=-2)
sch.compute_at(block=b5, loop=l17, preserve_unit_loops=True)
l18 = sch.sample_compute_location(block=b4, decision=-2)
sch.compute_at(block=b4, loop=l18, preserve_unit_loops=True)
sch.enter_postproc()
b19 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b19, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b19, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b19, ann_key="meta_schedule.unroll_explicit")
b20, b21, b22 = sch.get_child_blocks(b19)
l23, l24, l25, l26, l27, l28, l29 = sch.get_loops(block=b20)
l30 = sch.fuse(l23, l24)
sch.parallel(loop=l30)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l31, l32, l33, l34 = sch.get_loops(block=b21)
sch.annotate(block_or_loop=l31, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l31, ann_key="pragma_unroll_explicit", ann_val=1)
l35, l36 = sch.get_loops(block=b22)
sch.annotate(block_or_loop=l35, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l35, ann_key="pragma_unroll_explicit", ann_val=1)
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #13: GFLOPs: 7.9728. Time: 0.0987 ms. Best GFLOPs: 19.3910
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #14: GFLOPs: 0.6845. Time: 1.1501 ms. Best GFLOPs: 19.3910
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #15: GFLOPs: 8.3530. Time: 0.0942 ms. Best GFLOPs: 19.3910
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #16: GFLOPs: 6.7720. Time: 0.1162 ms. Best GFLOPs: 19.3910
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #17: GFLOPs: 7.3776. Time: 0.1067 ms. Best GFLOPs: 19.3910
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #18: Error in building: LocalBuilder: An exception occurred
Subprocess terminated
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384), "int64"], placeholder_1: T.Buffer[(30522, 1024), "float32"], placeholder_2: T.Buffer[(1, 384, 1024), "float32"], placeholder_3: T.Buffer[(1, 384), "int64"], placeholder_4: T.Buffer[(2, 1024), "float32"], T_add: T.Buffer[(1, 384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        T_where = T.alloc_buffer([1, 384], dtype="int64")
        T_take = T.alloc_buffer([1, 384, 1024], dtype="float32")
        T_where_1 = T.alloc_buffer([1, 384], dtype="int64")
        T_take_1 = T.alloc_buffer([1, 384, 1024], dtype="float32")
        for i0_i1_fused_fused_fused_fused_fused in T.parallel(384):
            for ax0, ax1 in T.grid(1, 1):
                with T.block("T_where_1"):
                    ax0_1 = T.axis.spatial(1, 0)
                    ax1_1 = T.axis.spatial(384, i0_i1_fused_fused_fused_fused_fused)
                    T.reads(placeholder_3[ax0_1, ax1_1])
                    T.writes(T_where_1[ax0_1, ax1_1])
                    T_where_1[ax0_1, ax1_1] = T.Select(T.cast(placeholder_3[ax0_1, ax1_1] < T.int64(0), "int32") != 0, placeholder_3[ax0_1, ax1_1] + T.int64(2), placeholder_3[ax0_1, ax1_1])
            for i2 in T.serial(1024):
                for ax0, ax1, ax2 in T.grid(1, 1, 1):
                    with T.block("T_take_1"):
                        ax0_2 = T.axis.spatial(1, 0)
                        ax1_2, ax2_1 = T.axis.remap("SS", [i0_i1_fused_fused_fused_fused_fused, i2])
                        T.reads(placeholder_4[T.min(T.max(T.int64(0), T_where_1[ax0_2, ax1_2]), T.int64(1)), ax2_1], T_where_1[ax0_2, ax1_2])
                        T.writes(T_take_1[ax0_2, ax1_2, ax2_1])
                        T_take_1[ax0_2, ax1_2, ax2_1] = placeholder_4[T.min(T.max(T.int64(0), T_where_1[ax0_2, ax1_2]), T.int64(1)), ax2_1]
                for ax0_3, ax1_3 in T.grid(1, 1):
                    with T.block("T_where"):
                        ax0_4 = T.axis.spatial(1, 0)
                        ax1_4 = T.axis.spatial(384, i0_i1_fused_fused_fused_fused_fused)
                        T.reads(placeholder[ax0_4, ax1_4])
                        T.writes(T_where[ax0_4, ax1_4])
                        T_where[ax0_4, ax1_4] = T.Select(T.cast(placeholder[ax0_4, ax1_4] < T.int64(0), "int32") != 0, placeholder[ax0_4, ax1_4] + T.int64(30522), placeholder[ax0_4, ax1_4])
                for ax0_5, ax1_5, ax2 in T.grid(1, 1, 1):
                    with T.block("T_take"):
                        ax0_6 = T.axis.spatial(1, 0)
                        ax1_6, ax2_2 = T.axis.remap("SS", [i0_i1_fused_fused_fused_fused_fused, i2])
                        T.reads(placeholder_1[T.min(T.max(T.int64(0), T_where[ax0_6, ax1_6]), T.int64(30521)), ax2_2], T_where[ax0_6, ax1_6])
                        T.writes(T_take[ax0_6, ax1_6, ax2_2])
                        T_take[ax0_6, ax1_6, ax2_2] = placeholder_1[T.min(T.max(T.int64(0), T_where[ax0_6, ax1_6]), T.int64(30521)), ax2_2]
                with T.block("T_add_3"):
                    ax0_7 = T.axis.spatial(1, 0)
                    ax1_7, ax2_3 = T.axis.remap("SS", [i0_i1_fused_fused_fused_fused_fused, i2])
                    T.reads(T_take[ax0_7, ax1_7, ax2_3], placeholder_2[ax0_7, ax1_7, ax2_3], T_take_1[ax0_7, ax1_7, ax2_3])
                    T.writes(T_add[ax0_7, ax1_7, ax2_3])
                    T_add[ax0_7, ax1_7, ax2_3] = T_take[ax0_7, ax1_7, ax2_3] + placeholder_2[ax0_7, ax1_7, ax2_3] + T_take_1[ax0_7, ax1_7, ax2_3]
    

b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_less", func_name="main")
b2 = sch.get_block(name="compile_engine_const_1", func_name="main")
b3 = sch.get_block(name="T_add", func_name="main")
b4 = sch.get_block(name="T_where", func_name="main")
b5 = sch.get_block(name="T_take", func_name="main")
b6 = sch.get_block(name="T_add_1", func_name="main")
b7 = sch.get_block(name="compile_engine_const_2", func_name="main")
b8 = sch.get_block(name="T_less_1", func_name="main")
b9 = sch.get_block(name="compile_engine_const_3", func_name="main")
b10 = sch.get_block(name="T_add_2", func_name="main")
b11 = sch.get_block(name="T_where_1", func_name="main")
b12 = sch.get_block(name="T_take_1", func_name="main")
b13 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b10)
sch.compute_inline(block=b9)
sch.compute_inline(block=b8)
sch.compute_inline(block=b7)
sch.compute_inline(block=b6)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
sch.annotate(block_or_loop=b13, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b13, ann_key="meta_schedule.vectorize", ann_val=64)
v14 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b13, ann_key="meta_schedule.unroll_explicit", ann_val=v14)
l15 = sch.sample_compute_location(block=b12, decision=2)
sch.compute_at(block=b12, loop=l15, preserve_unit_loops=True)
l16 = sch.sample_compute_location(block=b11, decision=1)
sch.compute_at(block=b11, loop=l16, preserve_unit_loops=True)
l17 = sch.sample_compute_location(block=b5, decision=2)
sch.compute_at(block=b5, loop=l17, preserve_unit_loops=True)
l18 = sch.sample_compute_location(block=b4, decision=2)
sch.compute_at(block=b4, loop=l18, preserve_unit_loops=True)
sch.enter_postproc()
b19 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b19, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b19, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b19, ann_key="meta_schedule.unroll_explicit")
b20, b21, b22, b23, b24 = sch.get_child_blocks(b19)
l25, l26, l27, l28 = sch.get_loops(block=b20)
l29 = sch.fuse(l25, l26)
sch.parallel(loop=l29)
l30, l31, l32, l33, l34 = sch.get_loops(block=b21)
l35 = sch.fuse(l30)
sch.parallel(loop=l35)
l36, l37, l38, l39 = sch.get_loops(block=b22)
l40 = sch.fuse(l36)
sch.parallel(loop=l40)
l41, l42, l43, l44, l45 = sch.get_loops(block=b23)
l46 = sch.fuse(l41)
sch.parallel(loop=l46)
l47, l48 = sch.get_loops(block=b24)
l49 = sch.fuse(l47)
sch.parallel(loop=l49)
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #19: GFLOPs: 4.0067. Time: 0.1965 ms. Best GFLOPs: 19.3910
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #20: GFLOPs: 3.9549. Time: 0.1990 ms. Best GFLOPs: 19.3910
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #21: GFLOPs: 7.7309. Time: 0.1018 ms. Best GFLOPs: 19.3910
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #22: GFLOPs: 4.8922. Time: 0.1609 ms. Best GFLOPs: 19.3910
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #23: Error in building: LocalBuilder: An exception occurred
Subprocess terminated
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384), "int64"], placeholder_1: T.Buffer[(30522, 1024), "float32"], placeholder_2: T.Buffer[(1, 384, 1024), "float32"], placeholder_3: T.Buffer[(1, 384), "int64"], placeholder_4: T.Buffer[(2, 1024), "float32"], T_add: T.Buffer[(1, 384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        T_where = T.alloc_buffer([1, 384], dtype="int64")
        T_take = T.alloc_buffer([1, 384, 1024], dtype="float32")
        T_where_1 = T.alloc_buffer([1, 384], dtype="int64")
        T_take_1 = T.alloc_buffer([1, 384, 1024], dtype="float32")
        for i0_i1_fused in T.parallel(384, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for ax0, ax1, ax2 in T.grid(1, 1, 1024):
                for ax0_1, ax1_1 in T.grid(1, 1):
                    with T.block("T_where_1"):
                        ax0_2 = T.axis.spatial(1, 0)
                        ax1_2 = T.axis.spatial(384, i0_i1_fused)
                        T.reads(placeholder_3[ax0_2, ax1_2])
                        T.writes(T_where_1[ax0_2, ax1_2])
                        T_where_1[ax0_2, ax1_2] = T.Select(T.cast(placeholder_3[ax0_2, ax1_2] < T.int64(0), "int32") != 0, placeholder_3[ax0_2, ax1_2] + T.int64(2), placeholder_3[ax0_2, ax1_2])
                with T.block("T_take_1"):
                    ax0_3 = T.axis.spatial(1, 0)
                    ax1_3, ax2_1 = T.axis.remap("SS", [i0_i1_fused, ax2])
                    T.reads(placeholder_4[T.min(T.max(T.int64(0), T_where_1[ax0_3, ax1_3]), T.int64(1)), ax2_1], T_where_1[ax0_3, ax1_3])
                    T.writes(T_take_1[ax0_3, ax1_3, ax2_1])
                    T_take_1[ax0_3, ax1_3, ax2_1] = placeholder_4[T.min(T.max(T.int64(0), T_where_1[ax0_3, ax1_3]), T.int64(1)), ax2_1]
            for ax0_4, ax1_4 in T.grid(1, 1):
                with T.block("T_where"):
                    ax0_5 = T.axis.spatial(1, 0)
                    ax1_5 = T.axis.spatial(384, i0_i1_fused)
                    T.reads(placeholder[ax0_5, ax1_5])
                    T.writes(T_where[ax0_5, ax1_5])
                    T_where[ax0_5, ax1_5] = T.Select(T.cast(placeholder[ax0_5, ax1_5] < T.int64(0), "int32") != 0, placeholder[ax0_5, ax1_5] + T.int64(30522), placeholder[ax0_5, ax1_5])
            for i2 in T.serial(1024):
                for ax0_6, ax1_6, ax2 in T.grid(1, 1, 1):
                    with T.block("T_take"):
                        ax0_7 = T.axis.spatial(1, 0)
                        ax1_7, ax2_2 = T.axis.remap("SS", [i0_i1_fused, i2])
                        T.reads(placeholder_1[T.min(T.max(T.int64(0), T_where[ax0_7, ax1_7]), T.int64(30521)), ax2_2], T_where[ax0_7, ax1_7])
                        T.writes(T_take[ax0_7, ax1_7, ax2_2])
                        T_take[ax0_7, ax1_7, ax2_2] = placeholder_1[T.min(T.max(T.int64(0), T_where[ax0_7, ax1_7]), T.int64(30521)), ax2_2]
                with T.block("T_add_3"):
                    ax0_8 = T.axis.spatial(1, 0)
                    ax1_8, ax2_3 = T.axis.remap("SS", [i0_i1_fused, i2])
                    T.reads(T_take[ax0_8, ax1_8, ax2_3], placeholder_2[ax0_8, ax1_8, ax2_3], T_take_1[ax0_8, ax1_8, ax2_3])
                    T.writes(T_add[ax0_8, ax1_8, ax2_3])
                    T_add[ax0_8, ax1_8, ax2_3] = T_take[ax0_8, ax1_8, ax2_3] + placeholder_2[ax0_8, ax1_8, ax2_3] + T_take_1[ax0_8, ax1_8, ax2_3]
    

b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_less", func_name="main")
b2 = sch.get_block(name="compile_engine_const_1", func_name="main")
b3 = sch.get_block(name="T_add", func_name="main")
b4 = sch.get_block(name="T_where", func_name="main")
b5 = sch.get_block(name="T_take", func_name="main")
b6 = sch.get_block(name="T_add_1", func_name="main")
b7 = sch.get_block(name="compile_engine_const_2", func_name="main")
b8 = sch.get_block(name="T_less_1", func_name="main")
b9 = sch.get_block(name="compile_engine_const_3", func_name="main")
b10 = sch.get_block(name="T_add_2", func_name="main")
b11 = sch.get_block(name="T_where_1", func_name="main")
b12 = sch.get_block(name="T_take_1", func_name="main")
b13 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b10)
sch.compute_inline(block=b9)
sch.compute_inline(block=b8)
sch.compute_inline(block=b7)
sch.compute_inline(block=b6)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
sch.annotate(block_or_loop=b13, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b13, ann_key="meta_schedule.vectorize", ann_val=64)
v14 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b13, ann_key="meta_schedule.unroll_explicit", ann_val=v14)
l15 = sch.sample_compute_location(block=b12, decision=1)
sch.compute_at(block=b12, loop=l15, preserve_unit_loops=True)
l16 = sch.sample_compute_location(block=b11, decision=4)
sch.compute_at(block=b11, loop=l16, preserve_unit_loops=True)
l17 = sch.sample_compute_location(block=b5, decision=2)
sch.compute_at(block=b5, loop=l17, preserve_unit_loops=True)
l18 = sch.sample_compute_location(block=b4, decision=1)
sch.compute_at(block=b4, loop=l18, preserve_unit_loops=True)
sch.enter_postproc()
b19 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b19, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b19, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b19, ann_key="meta_schedule.unroll_explicit")
b20, b21, b22, b23, b24 = sch.get_child_blocks(b19)
l25, l26, l27, l28, l29, l30, l31 = sch.get_loops(block=b20)
l32 = sch.fuse(l25, l26)
sch.parallel(loop=l32)
sch.annotate(block_or_loop=l32, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l32, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35, l36 = sch.get_loops(block=b21)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l37, l38, l39 = sch.get_loops(block=b22)
sch.annotate(block_or_loop=l37, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l37, ann_key="pragma_unroll_explicit", ann_val=1)
l40, l41, l42, l43, l44 = sch.get_loops(block=b23)
sch.annotate(block_or_loop=l40, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l40, ann_key="pragma_unroll_explicit", ann_val=1)
l45, l46 = sch.get_loops(block=b24)
sch.annotate(block_or_loop=l45, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l45, ann_key="pragma_unroll_explicit", ann_val=1)
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #24: GFLOPs: 7.4454. Time: 0.1057 ms. Best GFLOPs: 19.3910
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #25: GFLOPs: 4.7767. Time: 0.1648 ms. Best GFLOPs: 19.3910
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #26: Error in building: LocalBuilder: An exception occurred
Subprocess terminated
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384), "int64"], placeholder_1: T.Buffer[(30522, 1024), "float32"], placeholder_2: T.Buffer[(1, 384, 1024), "float32"], placeholder_3: T.Buffer[(1, 384), "int64"], placeholder_4: T.Buffer[(2, 1024), "float32"], T_add: T.Buffer[(1, 384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        T_where = T.alloc_buffer([1, 384], dtype="int64")
        T_take = T.alloc_buffer([1, 384, 1024], dtype="float32")
        T_where_1 = T.alloc_buffer([1, 384], dtype="int64")
        for i0_i1_fused_fused_fused_fused in T.parallel(384):
            for ax0, ax1, ax2 in T.grid(1, 1, 1024):
                for ax0_1, ax1_1 in T.grid(1, 1):
                    with T.block("T_where"):
                        ax0_2 = T.axis.spatial(1, 0)
                        ax1_2 = T.axis.spatial(384, i0_i1_fused_fused_fused_fused)
                        T.reads(placeholder[ax0_2, ax1_2])
                        T.writes(T_where[ax0_2, ax1_2])
                        T_where[ax0_2, ax1_2] = T.Select(T.cast(placeholder[ax0_2, ax1_2] < T.int64(0), "int32") != 0, placeholder[ax0_2, ax1_2] + T.int64(30522), placeholder[ax0_2, ax1_2])
                with T.block("T_take"):
                    ax0_3 = T.axis.spatial(1, 0)
                    ax1_3, ax2_1 = T.axis.remap("SS", [i0_i1_fused_fused_fused_fused, ax2])
                    T.reads(placeholder_1[T.min(T.max(T.int64(0), T_where[ax0_3, ax1_3]), T.int64(30521)), ax2_1], T_where[ax0_3, ax1_3])
                    T.writes(T_take[ax0_3, ax1_3, ax2_1])
                    T_take[ax0_3, ax1_3, ax2_1] = placeholder_1[T.min(T.max(T.int64(0), T_where[ax0_3, ax1_3]), T.int64(30521)), ax2_1]
            for i2 in T.serial(1024):
                for ax0_4, ax1_4 in T.grid(1, 1):
                    with T.block("T_where_1"):
                        ax0_5 = T.axis.spatial(1, 0)
                        ax1_5 = T.axis.spatial(384, i0_i1_fused_fused_fused_fused)
                        T.reads(placeholder_3[ax0_5, ax1_5])
                        T.writes(T_where_1[ax0_5, ax1_5])
                        T_where_1[ax0_5, ax1_5] = T.Select(T.cast(placeholder_3[ax0_5, ax1_5] < T.int64(0), "int32") != 0, placeholder_3[ax0_5, ax1_5] + T.int64(2), placeholder_3[ax0_5, ax1_5])
                with T.block("T_add_3"):
                    ax0_6 = T.axis.spatial(1, 0)
                    ax1_6, ax2 = T.axis.remap("SS", [i0_i1_fused_fused_fused_fused, i2])
                    T.reads(T_take[ax0_6, ax1_6, ax2], placeholder_2[ax0_6, ax1_6, ax2], placeholder_4[T.min(T.max(T.int64(0), T_where_1[ax0_6, ax1_6]), T.int64(1)), ax2], T_where_1[ax0_6, ax1_6])
                    T.writes(T_add[ax0_6, ax1_6, ax2])
                    T_add[ax0_6, ax1_6, ax2] = T_take[ax0_6, ax1_6, ax2] + placeholder_2[ax0_6, ax1_6, ax2] + placeholder_4[T.min(T.max(T.int64(0), T_where_1[ax0_6, ax1_6]), T.int64(1)), ax2]
    

b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_less", func_name="main")
b2 = sch.get_block(name="compile_engine_const_1", func_name="main")
b3 = sch.get_block(name="T_add", func_name="main")
b4 = sch.get_block(name="T_where", func_name="main")
b5 = sch.get_block(name="T_take", func_name="main")
b6 = sch.get_block(name="T_add_1", func_name="main")
b7 = sch.get_block(name="compile_engine_const_2", func_name="main")
b8 = sch.get_block(name="T_less_1", func_name="main")
b9 = sch.get_block(name="compile_engine_const_3", func_name="main")
b10 = sch.get_block(name="T_add_2", func_name="main")
b11 = sch.get_block(name="T_where_1", func_name="main")
b12 = sch.get_block(name="T_take_1", func_name="main")
b13 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b10)
sch.compute_inline(block=b9)
sch.compute_inline(block=b8)
sch.compute_inline(block=b7)
sch.compute_inline(block=b6)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
sch.annotate(block_or_loop=b13, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b13, ann_key="meta_schedule.vectorize", ann_val=64)
v14 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b13, ann_key="meta_schedule.unroll_explicit", ann_val=v14)
l15 = sch.sample_compute_location(block=b12, decision=-2)
sch.compute_at(block=b12, loop=l15, preserve_unit_loops=True)
l16 = sch.sample_compute_location(block=b11, decision=2)
sch.compute_at(block=b11, loop=l16, preserve_unit_loops=True)
l17 = sch.sample_compute_location(block=b5, decision=1)
sch.compute_at(block=b5, loop=l17, preserve_unit_loops=True)
l18 = sch.sample_compute_location(block=b4, decision=4)
sch.compute_at(block=b4, loop=l18, preserve_unit_loops=True)
sch.enter_postproc()
b19 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b19, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b19, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b19, ann_key="meta_schedule.unroll_explicit")
b20, b21, b22, b23 = sch.get_child_blocks(b19)
l24, l25, l26, l27, l28, l29, l30 = sch.get_loops(block=b20)
l31 = sch.fuse(l24, l25)
sch.parallel(loop=l31)
l32, l33, l34, l35 = sch.get_loops(block=b21)
l36 = sch.fuse(l32)
sch.parallel(loop=l36)
l37, l38, l39, l40 = sch.get_loops(block=b22)
l41 = sch.fuse(l37)
sch.parallel(loop=l41)
l42, l43 = sch.get_loops(block=b23)
l44 = sch.fuse(l42)
sch.parallel(loop=l44)
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #27: GFLOPs: 11.2940. Time: 0.0697 ms. Best GFLOPs: 19.3910
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #28: GFLOPs: 9.3619. Time: 0.0841 ms. Best GFLOPs: 19.3910
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #29: Error in building: LocalBuilder: An exception occurred
Subprocess terminated
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384), "int64"], placeholder_1: T.Buffer[(30522, 1024), "float32"], placeholder_2: T.Buffer[(1, 384, 1024), "float32"], placeholder_3: T.Buffer[(1, 384), "int64"], placeholder_4: T.Buffer[(2, 1024), "float32"], T_add: T.Buffer[(1, 384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        T_where = T.alloc_buffer([1, 384], dtype="int64")
        T_where_1 = T.alloc_buffer([1, 384], dtype="int64")
        T_take = T.alloc_buffer([1, 384, 1024], dtype="float32")
        for i0_i1_fused in T.parallel(384, annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for ax0, ax1 in T.grid(1, 1):
                with T.block("T_where"):
                    ax0_1 = T.axis.spatial(1, 0)
                    ax1_1 = T.axis.spatial(384, i0_i1_fused)
                    T.reads(placeholder[ax0_1, ax1_1])
                    T.writes(T_where[ax0_1, ax1_1])
                    T_where[ax0_1, ax1_1] = T.Select(T.cast(placeholder[ax0_1, ax1_1] < T.int64(0), "int32") != 0, placeholder[ax0_1, ax1_1] + T.int64(30522), placeholder[ax0_1, ax1_1])
            for i2 in T.serial(1024):
                for ax0, ax1 in T.grid(1, 1):
                    with T.block("T_where_1"):
                        ax0_2 = T.axis.spatial(1, 0)
                        ax1_2 = T.axis.spatial(384, i0_i1_fused)
                        T.reads(placeholder_3[ax0_2, ax1_2])
                        T.writes(T_where_1[ax0_2, ax1_2])
                        T_where_1[ax0_2, ax1_2] = T.Select(T.cast(placeholder_3[ax0_2, ax1_2] < T.int64(0), "int32") != 0, placeholder_3[ax0_2, ax1_2] + T.int64(2), placeholder_3[ax0_2, ax1_2])
                for ax0_3, ax1_3, ax2 in T.grid(1, 1, 1):
                    with T.block("T_take_1"):
                        ax0_4 = T.axis.spatial(1, 0)
                        ax1_4, ax2_1 = T.axis.remap("SS", [i0_i1_fused, i2])
                        T.reads(placeholder_4[T.min(T.max(T.int64(0), T_where_1[ax0_4, ax1_4]), T.int64(1)), ax2_1], T_where_1[ax0_4, ax1_4])
                        T.writes(T_take[ax0_4, ax1_4, ax2_1])
                        T_take[ax0_4, ax1_4, ax2_1] = placeholder_4[T.min(T.max(T.int64(0), T_where_1[ax0_4, ax1_4]), T.int64(1)), ax2_1]
                with T.block("T_add_3"):
                    ax0_5 = T.axis.spatial(1, 0)
                    ax1_5, ax2 = T.axis.remap("SS", [i0_i1_fused, i2])
                    T.reads(placeholder_1[T.min(T.max(T.int64(0), T_where[ax0_5, ax1_5]), T.int64(30521)), ax2], T_where[ax0_5, ax1_5], placeholder_2[ax0_5, ax1_5, ax2], T_take[ax0_5, ax1_5, ax2])
                    T.writes(T_add[ax0_5, ax1_5, ax2])
                    T_add[ax0_5, ax1_5, ax2] = placeholder_1[T.min(T.max(T.int64(0), T_where[ax0_5, ax1_5]), T.int64(30521)), ax2] + placeholder_2[ax0_5, ax1_5, ax2] + T_take[ax0_5, ax1_5, ax2]
    

b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_less", func_name="main")
b2 = sch.get_block(name="compile_engine_const_1", func_name="main")
b3 = sch.get_block(name="T_add", func_name="main")
b4 = sch.get_block(name="T_where", func_name="main")
b5 = sch.get_block(name="T_take", func_name="main")
b6 = sch.get_block(name="T_add_1", func_name="main")
b7 = sch.get_block(name="compile_engine_const_2", func_name="main")
b8 = sch.get_block(name="T_less_1", func_name="main")
b9 = sch.get_block(name="compile_engine_const_3", func_name="main")
b10 = sch.get_block(name="T_add_2", func_name="main")
b11 = sch.get_block(name="T_where_1", func_name="main")
b12 = sch.get_block(name="T_take_1", func_name="main")
b13 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b10)
sch.compute_inline(block=b9)
sch.compute_inline(block=b8)
sch.compute_inline(block=b7)
sch.compute_inline(block=b6)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
sch.annotate(block_or_loop=b13, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b13, ann_key="meta_schedule.vectorize", ann_val=64)
v14 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b13, ann_key="meta_schedule.unroll_explicit", ann_val=v14)
l15 = sch.sample_compute_location(block=b12, decision=2)
sch.compute_at(block=b12, loop=l15, preserve_unit_loops=True)
l16 = sch.sample_compute_location(block=b11, decision=2)
sch.compute_at(block=b11, loop=l16, preserve_unit_loops=True)
l17 = sch.sample_compute_location(block=b5, decision=-2)
sch.compute_at(block=b5, loop=l17, preserve_unit_loops=True)
l18 = sch.sample_compute_location(block=b4, decision=1)
sch.compute_at(block=b4, loop=l18, preserve_unit_loops=True)
sch.enter_postproc()
b19 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b19, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b19, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b19, ann_key="meta_schedule.unroll_explicit")
b20, b21, b22, b23 = sch.get_child_blocks(b19)
l24, l25, l26, l27 = sch.get_loops(block=b20)
l28 = sch.fuse(l24, l25)
sch.parallel(loop=l28)
sch.annotate(block_or_loop=l28, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l28, ann_key="pragma_unroll_explicit", ann_val=1)
l29, l30, l31, l32 = sch.get_loops(block=b21)
sch.annotate(block_or_loop=l29, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l29, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35, l36, l37 = sch.get_loops(block=b22)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l38, l39 = sch.get_loops(block=b23)
sch.annotate(block_or_loop=l38, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l38, ann_key="pragma_unroll_explicit", ann_val=1)
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #30: Error in building: LocalBuilder: An exception occurred
Subprocess terminated
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384), "int64"], placeholder_1: T.Buffer[(30522, 1024), "float32"], placeholder_2: T.Buffer[(1, 384, 1024), "float32"], placeholder_3: T.Buffer[(1, 384), "int64"], placeholder_4: T.Buffer[(2, 1024), "float32"], T_add: T.Buffer[(1, 384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        T_where = T.alloc_buffer([1, 384], dtype="int64")
        T_take = T.alloc_buffer([1, 384, 1024], dtype="float32")
        T_take_1 = T.alloc_buffer([1, 384, 1024], dtype="float32")
        for i0_i1_fused in T.parallel(384):
            for i2 in T.serial(1024):
                with T.block("T_take_1"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1, ax2 = T.axis.remap("SS", [i0_i1_fused, i2])
                    T.reads(placeholder_3[ax0, ax1], placeholder_4[T.min(T.max(T.int64(0), placeholder_3[ax0, ax1]), T.int64(1)) : T.min(T.max(T.int64(0), placeholder_3[ax0, ax1] + T.int64(2)), T.int64(1)) + T.int64(1), ax2])
                    T.writes(T_take_1[ax0, ax1, ax2])
                    T_take_1[ax0, ax1, ax2] = placeholder_4[T.min(T.max(T.int64(0), T.Select(T.cast(placeholder_3[ax0, ax1] < T.int64(0), "int32") != 0, placeholder_3[ax0, ax1] + T.int64(2), placeholder_3[ax0, ax1])), T.int64(1)), ax2]
        for i0_i1_fused_fused_fused in T.parallel(384):
            for ax0, ax1, ax2 in T.grid(1, 1, 1024):
                for ax0_1, ax1_1 in T.grid(1, 1):
                    with T.block("T_where"):
                        ax0_2 = T.axis.spatial(1, 0)
                        ax1_2 = T.axis.spatial(384, i0_i1_fused_fused_fused)
                        T.reads(placeholder[ax0_2, ax1_2])
                        T.writes(T_where[ax0_2, ax1_2])
                        T_where[ax0_2, ax1_2] = T.Select(T.cast(placeholder[ax0_2, ax1_2] < T.int64(0), "int32") != 0, placeholder[ax0_2, ax1_2] + T.int64(30522), placeholder[ax0_2, ax1_2])
                with T.block("T_take"):
                    ax0_3 = T.axis.spatial(1, 0)
                    ax1_3, ax2_1 = T.axis.remap("SS", [i0_i1_fused_fused_fused, ax2])
                    T.reads(placeholder_1[T.min(T.max(T.int64(0), T_where[ax0_3, ax1_3]), T.int64(30521)), ax2_1], T_where[ax0_3, ax1_3])
                    T.writes(T_take[ax0_3, ax1_3, ax2_1])
                    T_take[ax0_3, ax1_3, ax2_1] = placeholder_1[T.min(T.max(T.int64(0), T_where[ax0_3, ax1_3]), T.int64(30521)), ax2_1]
            for i2 in T.serial(1024):
                with T.block("T_add_3"):
                    ax0_4 = T.axis.spatial(1, 0)
                    ax1_4, ax2 = T.axis.remap("SS", [i0_i1_fused_fused_fused, i2])
                    T.reads(T_take[ax0_4, ax1_4, ax2], placeholder_2[ax0_4, ax1_4, ax2], T_take_1[ax0_4, ax1_4, ax2])
                    T.writes(T_add[ax0_4, ax1_4, ax2])
                    T_add[ax0_4, ax1_4, ax2] = T_take[ax0_4, ax1_4, ax2] + placeholder_2[ax0_4, ax1_4, ax2] + T_take_1[ax0_4, ax1_4, ax2]
    

b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_less", func_name="main")
b2 = sch.get_block(name="compile_engine_const_1", func_name="main")
b3 = sch.get_block(name="T_add", func_name="main")
b4 = sch.get_block(name="T_where", func_name="main")
b5 = sch.get_block(name="T_take", func_name="main")
b6 = sch.get_block(name="T_add_1", func_name="main")
b7 = sch.get_block(name="compile_engine_const_2", func_name="main")
b8 = sch.get_block(name="T_less_1", func_name="main")
b9 = sch.get_block(name="compile_engine_const_3", func_name="main")
b10 = sch.get_block(name="T_add_2", func_name="main")
b11 = sch.get_block(name="T_where_1", func_name="main")
b12 = sch.get_block(name="T_take_1", func_name="main")
b13 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b10)
sch.compute_inline(block=b9)
sch.compute_inline(block=b8)
sch.compute_inline(block=b7)
sch.compute_inline(block=b6)
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
sch.compute_inline(block=b0)
sch.annotate(block_or_loop=b13, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b13, ann_key="meta_schedule.vectorize", ann_val=64)
v14 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b13, ann_key="meta_schedule.unroll_explicit", ann_val=v14)
l15 = sch.sample_compute_location(block=b12, decision=-1)
sch.compute_at(block=b12, loop=l15, preserve_unit_loops=True)
l16 = sch.sample_compute_location(block=b11, decision=-2)
sch.compute_at(block=b11, loop=l16, preserve_unit_loops=True)
l17 = sch.sample_compute_location(block=b5, decision=1)
sch.compute_at(block=b5, loop=l17, preserve_unit_loops=True)
l18 = sch.sample_compute_location(block=b4, decision=4)
sch.compute_at(block=b4, loop=l18, preserve_unit_loops=True)
sch.enter_postproc()
b19 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b19, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b19, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b19, ann_key="meta_schedule.unroll_explicit")
b20, b21, b22, b23 = sch.get_child_blocks(b19)
l24, l25, l26 = sch.get_loops(block=b20)
l27 = sch.fuse(l24, l25)
sch.parallel(loop=l27)
l28, l29, l30, l31, l32, l33, l34 = sch.get_loops(block=b21)
l35 = sch.fuse(l28, l29)
sch.parallel(loop=l35)
l36, l37, l38, l39 = sch.get_loops(block=b22)
l40 = sch.fuse(l36)
sch.parallel(loop=l40)
l41, l42 = sch.get_loops(block=b23)
l43 = sch.fuse(l41)
sch.parallel(loop=l43)
[19:19:08] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #5: "fused_less_add_where_take_add_less_add_where_take_add"] Trial #31: GFLOPs: 11.3299. Time: 0.0695 ms. Best GFLOPs: 19.3910
[19:19:09] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #5: "fused_less_add_where_take_add_less_add_where_take_add"
 ID |                                                       Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                              fused_squeeze |          1 |      1 |         0.0001 |      12.6516 |               12.6516 |     32 |            
  1 |      fused_reshape_add_reshape_transpose_reshape_transpose |     393216 |     24 |         2.4269 |     162.0252 |             3888.6041 |     32 |            
  2 |       fused_expand_dims_expand_dims_cast_subtract_multiply |        768 |      1 |         0.0512 |      15.0019 |               15.0019 |     32 |            
  3 |    fused_reshape_add_reshape_transpose_reshape_transpose_1 |     393216 |     24 |         0.8998 |     437.0154 |            10488.3689 |     32 |            
  4 |                                                 fused_mean |     393600 |     49 |        10.0733 |      39.0736 |             1914.6079 |     32 |            
  5 |      fused_less_add_where_take_add_less_add_where_take_add |     787200 |      1 |        19.3910 |      40.5961 |               40.5961 |     32 |            
  6 |                fused_reshape_add_reshape_transpose_reshape |     393216 |     24 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                      fused_nn_batch_matmul |  301989888 |     24 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                   fused_reshape_divide_add |    4718592 |     24 |            N/A |          N/A |                   N/A |      0 |            
  9 |                                           fused_nn_softmax |    9437184 |     24 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                              fused_reshape |          1 |     24 |            N/A |          N/A |                   N/A |      0 |            
 11 |                                    fused_nn_batch_matmul_1 |  301989888 |     24 |            N/A |          N/A |                   N/A |      0 |            
 12 |                            fused_reshape_transpose_reshape |          1 |     24 |            N/A |          N/A |                   N/A |      0 |            
 13 |                                             fused_nn_dense |  805306368 |     96 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_add_sqrt_divide_multiply_add |    1180032 |     48 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                            fused_reshape_1 |          1 |     48 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_dense_1 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_reshape_add_multiply_divide_erf_add_multiply_reshape |    7864320 |     24 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_dense_2 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 19 |                                      fused_reshape_add_add |     786432 |     48 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                             fused_subtract |     393216 |     49 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                           fused_power_mean |     393600 |     49 |            N/A |          N/A |                   N/A |      0 |            
 22 |                 fused_add_sqrt_divide_multiply_add_reshape |    1180032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                           fused_nn_dense_3 |    1572864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                    fused_reshape_add_split |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                            fused_squeeze_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 192
Total latency (us): 16359.8

[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #0: GFLOPs: 1.3444. Time: 0.2925 ms. Best GFLOPs: 1.3444
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #1: GFLOPs: 3.2927. Time: 0.1194 ms. Best GFLOPs: 3.2927
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #2: GFLOPs: 5.4010. Time: 0.0728 ms. Best GFLOPs: 5.4010
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #3: GFLOPs: 1.5613. Time: 0.2519 ms. Best GFLOPs: 5.4010
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #4: GFLOPs: 0.0480. Time: 8.1995 ms. Best GFLOPs: 5.4010
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #5: GFLOPs: 0.0285. Time: 13.7767 ms. Best GFLOPs: 5.4010
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #6: GFLOPs: 0.3290. Time: 1.1952 ms. Best GFLOPs: 5.4010
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #7: GFLOPs: 0.4764. Time: 0.8254 ms. Best GFLOPs: 5.4010
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #8: GFLOPs: 2.9940. Time: 0.1313 ms. Best GFLOPs: 5.4010
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #9: GFLOPs: 5.0866. Time: 0.0773 ms. Best GFLOPs: 5.4010
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #10: GFLOPs: 3.5805. Time: 0.1098 ms. Best GFLOPs: 5.4010
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #11: GFLOPs: 0.9038. Time: 0.4351 ms. Best GFLOPs: 5.4010
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #12: GFLOPs: 0.9315. Time: 0.4221 ms. Best GFLOPs: 5.4010
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #13: GFLOPs: 3.9740. Time: 0.0989 ms. Best GFLOPs: 5.4010
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #14: GFLOPs: 7.9656. Time: 0.0494 ms. Best GFLOPs: 7.9656
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #15: GFLOPs: 3.6022. Time: 0.1092 ms. Best GFLOPs: 7.9656
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #16: GFLOPs: 4.1146. Time: 0.0956 ms. Best GFLOPs: 7.9656
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #17: GFLOPs: 7.2451. Time: 0.0543 ms. Best GFLOPs: 7.9656
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #18: GFLOPs: 0.7667. Time: 0.5129 ms. Best GFLOPs: 7.9656
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #19: GFLOPs: 0.8313. Time: 0.4730 ms. Best GFLOPs: 7.9656
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #20: GFLOPs: 6.3013. Time: 0.0624 ms. Best GFLOPs: 7.9656
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #21: GFLOPs: 0.9771. Time: 0.4025 ms. Best GFLOPs: 7.9656
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #22: GFLOPs: 2.4142. Time: 0.1629 ms. Best GFLOPs: 7.9656
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #23: GFLOPs: 0.6436. Time: 0.6109 ms. Best GFLOPs: 7.9656
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #24: GFLOPs: 1.4159. Time: 0.2777 ms. Best GFLOPs: 7.9656
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #25: GFLOPs: 1.7379. Time: 0.2263 ms. Best GFLOPs: 7.9656
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #26: GFLOPs: 1.1659. Time: 0.3373 ms. Best GFLOPs: 7.9656
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #27: GFLOPs: 1.3701. Time: 0.2870 ms. Best GFLOPs: 7.9656
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #28: GFLOPs: 2.9377. Time: 0.1338 ms. Best GFLOPs: 7.9656
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #29: GFLOPs: 9.5277. Time: 0.0413 ms. Best GFLOPs: 9.5277
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #30: GFLOPs: 1.4616. Time: 0.2690 ms. Best GFLOPs: 9.5277
[19:19:09] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #6: "fused_reshape_add_reshape_transpose_reshape"] Trial #31: GFLOPs: 1.4829. Time: 0.2652 ms. Best GFLOPs: 9.5277
[19:19:11] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #6: "fused_reshape_add_reshape_transpose_reshape"
 ID |                                                       Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                              fused_squeeze |          1 |      1 |         0.0001 |      12.6516 |               12.6516 |     32 |            
  1 |      fused_reshape_add_reshape_transpose_reshape_transpose |     393216 |     24 |         2.4269 |     162.0252 |             3888.6041 |     32 |            
  2 |       fused_expand_dims_expand_dims_cast_subtract_multiply |        768 |      1 |         0.0512 |      15.0019 |               15.0019 |     32 |            
  3 |    fused_reshape_add_reshape_transpose_reshape_transpose_1 |     393216 |     24 |         0.8998 |     437.0154 |            10488.3689 |     32 |            
  4 |                                                 fused_mean |     393600 |     49 |        10.0733 |      39.0736 |             1914.6079 |     32 |            
  5 |      fused_less_add_where_take_add_less_add_where_take_add |     787200 |      1 |        19.3910 |      40.5961 |               40.5961 |     32 |            
  6 |                fused_reshape_add_reshape_transpose_reshape |     393216 |     24 |         9.5277 |      41.2707 |              990.4966 |     32 |            
  7 |                                      fused_nn_batch_matmul |  301989888 |     24 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                   fused_reshape_divide_add |    4718592 |     24 |            N/A |          N/A |                   N/A |      0 |            
  9 |                                           fused_nn_softmax |    9437184 |     24 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                              fused_reshape |          1 |     24 |            N/A |          N/A |                   N/A |      0 |            
 11 |                                    fused_nn_batch_matmul_1 |  301989888 |     24 |            N/A |          N/A |                   N/A |      0 |            
 12 |                            fused_reshape_transpose_reshape |          1 |     24 |            N/A |          N/A |                   N/A |      0 |            
 13 |                                             fused_nn_dense |  805306368 |     96 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_add_sqrt_divide_multiply_add |    1180032 |     48 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                            fused_reshape_1 |          1 |     48 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_dense_1 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_reshape_add_multiply_divide_erf_add_multiply_reshape |    7864320 |     24 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_dense_2 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 19 |                                      fused_reshape_add_add |     786432 |     48 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                             fused_subtract |     393216 |     49 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                           fused_power_mean |     393600 |     49 |            N/A |          N/A |                   N/A |      0 |            
 22 |                 fused_add_sqrt_divide_multiply_add_reshape |    1180032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                           fused_nn_dense_3 |    1572864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                    fused_reshape_add_split |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                            fused_squeeze_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 224
Total latency (us): 17350.3

[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #0: GFLOPs: 37.9979. Time: 7.9475 ms. Best GFLOPs: 37.9979
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #1: GFLOPs: 46.6175. Time: 6.4780 ms. Best GFLOPs: 46.6175
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #2: GFLOPs: 39.1373. Time: 7.7162 ms. Best GFLOPs: 46.6175
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #3: GFLOPs: 18.6073. Time: 16.2297 ms. Best GFLOPs: 46.6175
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #4: GFLOPs: 25.7371. Time: 11.7336 ms. Best GFLOPs: 46.6175
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #5: GFLOPs: 29.3328. Time: 10.2953 ms. Best GFLOPs: 46.6175
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #6: GFLOPs: 40.1888. Time: 7.5143 ms. Best GFLOPs: 46.6175
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #7: GFLOPs: 18.6350. Time: 16.2056 ms. Best GFLOPs: 46.6175
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #8: GFLOPs: 31.8326. Time: 9.4868 ms. Best GFLOPs: 46.6175
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #9: GFLOPs: 68.2907. Time: 4.4221 ms. Best GFLOPs: 68.2907
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #10: GFLOPs: 23.7464. Time: 12.7173 ms. Best GFLOPs: 68.2907
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #11: GFLOPs: 39.9624. Time: 7.5569 ms. Best GFLOPs: 68.2907
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #12: GFLOPs: 33.4638. Time: 9.0244 ms. Best GFLOPs: 68.2907
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #13: GFLOPs: 11.1923. Time: 26.9820 ms. Best GFLOPs: 68.2907
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #14: GFLOPs: 26.5376. Time: 11.3797 ms. Best GFLOPs: 68.2907
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #15: GFLOPs: 51.7428. Time: 5.8364 ms. Best GFLOPs: 68.2907
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #16: GFLOPs: 25.6307. Time: 11.7823 ms. Best GFLOPs: 68.2907
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #17: GFLOPs: 40.0146. Time: 7.5470 ms. Best GFLOPs: 68.2907
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #18: GFLOPs: 43.0426. Time: 7.0161 ms. Best GFLOPs: 68.2907
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #19: GFLOPs: 18.7779. Time: 16.0822 ms. Best GFLOPs: 68.2907
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #20: GFLOPs: 26.3304. Time: 11.4692 ms. Best GFLOPs: 68.2907
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #21: GFLOPs: 27.8396. Time: 10.8475 ms. Best GFLOPs: 68.2907
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #22: GFLOPs: 42.0184. Time: 7.1871 ms. Best GFLOPs: 68.2907
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #23: GFLOPs: 15.5373. Time: 19.4364 ms. Best GFLOPs: 68.2907
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #24: GFLOPs: 17.2607. Time: 17.4958 ms. Best GFLOPs: 68.2907
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #25: GFLOPs: 40.2421. Time: 7.5043 ms. Best GFLOPs: 68.2907
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #26: GFLOPs: 77.6256. Time: 3.8903 ms. Best GFLOPs: 77.6256
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #27: GFLOPs: 55.1817. Time: 5.4726 ms. Best GFLOPs: 77.6256
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #28: GFLOPs: 22.8355. Time: 13.2246 ms. Best GFLOPs: 77.6256
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #29: GFLOPs: 25.9054. Time: 11.6574 ms. Best GFLOPs: 77.6256
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #30: GFLOPs: 86.3671. Time: 3.4966 ms. Best GFLOPs: 86.3671
[19:19:11] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #7: "fused_nn_batch_matmul"] Trial #31: GFLOPs: 36.6832. Time: 8.2324 ms. Best GFLOPs: 86.3671
[19:19:13] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #7: "fused_nn_batch_matmul"
 ID |                                                       Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                              fused_squeeze |          1 |      1 |         0.0001 |      12.6516 |               12.6516 |     32 |            
  1 |      fused_reshape_add_reshape_transpose_reshape_transpose |     393216 |     24 |         2.4269 |     162.0252 |             3888.6041 |     32 |            
  2 |       fused_expand_dims_expand_dims_cast_subtract_multiply |        768 |      1 |         0.0512 |      15.0019 |               15.0019 |     32 |            
  3 |    fused_reshape_add_reshape_transpose_reshape_transpose_1 |     393216 |     24 |         0.8998 |     437.0154 |            10488.3689 |     32 |            
  4 |                                                 fused_mean |     393600 |     49 |        10.0733 |      39.0736 |             1914.6079 |     32 |            
  5 |      fused_less_add_where_take_add_less_add_where_take_add |     787200 |      1 |        19.3910 |      40.5961 |               40.5961 |     32 |            
  6 |                fused_reshape_add_reshape_transpose_reshape |     393216 |     24 |         9.5277 |      41.2707 |              990.4966 |     32 |            
  7 |                                      fused_nn_batch_matmul |  301989888 |     24 |        86.3671 |    3496.5859 |            83918.0613 |     32 |            
  8 |                                   fused_reshape_divide_add |    4718592 |     24 |            N/A |          N/A |                   N/A |      0 |            
  9 |                                           fused_nn_softmax |    9437184 |     24 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                              fused_reshape |          1 |     24 |            N/A |          N/A |                   N/A |      0 |            
 11 |                                    fused_nn_batch_matmul_1 |  301989888 |     24 |            N/A |          N/A |                   N/A |      0 |            
 12 |                            fused_reshape_transpose_reshape |          1 |     24 |            N/A |          N/A |                   N/A |      0 |            
 13 |                                             fused_nn_dense |  805306368 |     96 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_add_sqrt_divide_multiply_add |    1180032 |     48 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                            fused_reshape_1 |          1 |     48 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_dense_1 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_reshape_add_multiply_divide_erf_add_multiply_reshape |    7864320 |     24 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_dense_2 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 19 |                                      fused_reshape_add_add |     786432 |     48 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                             fused_subtract |     393216 |     49 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                           fused_power_mean |     393600 |     49 |            N/A |          N/A |                   N/A |      0 |            
 22 |                 fused_add_sqrt_divide_multiply_add_reshape |    1180032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                           fused_nn_dense_3 |    1572864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                    fused_reshape_add_split |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                            fused_squeeze_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 256
Total latency (us): 101268

[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #0: GFLOPs: 1.0490. Time: 4.4983 ms. Best GFLOPs: 1.0490
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #1: GFLOPs: 0.9941. Time: 4.7466 ms. Best GFLOPs: 1.0490
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #2: GFLOPs: 1.8616. Time: 2.5347 ms. Best GFLOPs: 1.8616
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #3: GFLOPs: 1.7448. Time: 2.7044 ms. Best GFLOPs: 1.8616
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #4: GFLOPs: 2.1031. Time: 2.2437 ms. Best GFLOPs: 2.1031
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #5: GFLOPs: 4.5422. Time: 1.0388 ms. Best GFLOPs: 4.5422
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #8: "fused_reshape_divide_add"] Trial #6: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(16, 384, 384), "float32"], placeholder_1: T.Buffer[(1, 1, 1, 384), "float32"], T_add: T.Buffer[(1, 16, 384, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        T_reshape = T.alloc_buffer([1, 16, 384, 384], dtype="float32")
        for i0_i1_i2_fused in T.parallel(6144, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3 in T.serial(384):
                with T.block("T_reshape"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(16, i0_i1_i2_fused // 384)
                    ax2 = T.axis.spatial(384, i0_i1_i2_fused % 384)
                    ax3 = T.axis.spatial(384, i3)
                    T.reads(placeholder[((ax3 // 384 + ax2) // 384 + ax1) % 16, (ax3 // 384 + ax2) % 384, ax3 % 384])
                    T.writes(T_reshape[ax0, ax1, ax2, ax3])
                    T_reshape[ax0, ax1, ax2, ax3] = placeholder[((ax3 // 384 + ax2) // 384 + ax1) % 16, (ax3 // 384 + ax2) % 384, ax3 % 384]
        for i0_i1_i2_fused in T.parallel(6144, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3 in T.serial(384):
                with T.block("T_add"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(16, i0_i1_i2_fused // 384)
                    ax2 = T.axis.spatial(384, i0_i1_i2_fused % 384)
                    ax3 = T.axis.spatial(384, i3)
                    T.reads(T_reshape[ax0, ax1, ax2, ax3], placeholder_1[ax0, 0, 0, ax3])
                    T.writes(T_add[ax0, ax1, ax2, ax3])
                    T_add[ax0, ax1, ax2, ax3] = T_reshape[ax0, ax1, ax2, ax3] / T.float32(8) + placeholder_1[ax0, 0, 0, ax3]
    

b0 = sch.get_block(name="T_reshape", func_name="main")
b1 = sch.get_block(name="compile_engine_const", func_name="main")
b2 = sch.get_block(name="T_divide", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v4 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v4)
l5 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l5, preserve_unit_loops=True)
sch.enter_postproc()
b6 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b6, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b6, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit")
b7, b8 = sch.get_child_blocks(b6)
l9, l10, l11, l12 = sch.get_loops(block=b7)
l13 = sch.fuse(l9, l10, l11)
sch.parallel(loop=l13)
sch.annotate(block_or_loop=l13, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l13, ann_key="pragma_unroll_explicit", ann_val=1)
l14, l15, l16, l17 = sch.get_loops(block=b8)
l18 = sch.fuse(l14, l15, l16)
sch.parallel(loop=l18)
sch.annotate(block_or_loop=l18, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l18, ann_key="pragma_unroll_explicit", ann_val=1)
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #7: GFLOPs: 8.2015. Time: 0.5753 ms. Best GFLOPs: 8.2015
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #8: GFLOPs: 2.1506. Time: 2.1941 ms. Best GFLOPs: 8.2015
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #9: GFLOPs: 7.1721. Time: 0.6579 ms. Best GFLOPs: 8.2015
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #10: GFLOPs: 4.5024. Time: 1.0480 ms. Best GFLOPs: 8.2015
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #11: GFLOPs: 7.4739. Time: 0.6313 ms. Best GFLOPs: 8.2015
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #12: GFLOPs: 10.0329. Time: 0.4703 ms. Best GFLOPs: 10.0329
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #13: GFLOPs: 16.7627. Time: 0.2815 ms. Best GFLOPs: 16.7627
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #14: GFLOPs: 6.2306. Time: 0.7573 ms. Best GFLOPs: 16.7627
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #15: GFLOPs: 18.6130. Time: 0.2535 ms. Best GFLOPs: 18.6130
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #16: GFLOPs: 11.9577. Time: 0.3946 ms. Best GFLOPs: 18.6130
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #17: GFLOPs: 3.0486. Time: 1.5478 ms. Best GFLOPs: 18.6130
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #18: GFLOPs: 15.2885. Time: 0.3086 ms. Best GFLOPs: 18.6130
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #8: "fused_reshape_divide_add"] Trial #19: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(16, 384, 384), "float32"], placeholder_1: T.Buffer[(1, 1, 1, 384), "float32"], T_add: T.Buffer[(1, 16, 384, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        T_reshape = T.alloc_buffer([1, 16, 384, 384], dtype="float32")
        for i0_i1_i2_fused in T.parallel(6144, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3 in T.serial(384):
                with T.block("T_reshape"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(16, i0_i1_i2_fused // 384)
                    ax2 = T.axis.spatial(384, i0_i1_i2_fused % 384)
                    ax3 = T.axis.spatial(384, i3)
                    T.reads(placeholder[((ax3 // 384 + ax2) // 384 + ax1) % 16, (ax3 // 384 + ax2) % 384, ax3 % 384])
                    T.writes(T_reshape[ax0, ax1, ax2, ax3])
                    T_reshape[ax0, ax1, ax2, ax3] = placeholder[((ax3 // 384 + ax2) // 384 + ax1) % 16, (ax3 // 384 + ax2) % 384, ax3 % 384]
        for i0_i1_i2_fused in T.parallel(6144, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3 in T.serial(384):
                with T.block("T_add"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(16, i0_i1_i2_fused // 384)
                    ax2 = T.axis.spatial(384, i0_i1_i2_fused % 384)
                    ax3 = T.axis.spatial(384, i3)
                    T.reads(T_reshape[ax0, ax1, ax2, ax3], placeholder_1[ax0, 0, 0, ax3])
                    T.writes(T_add[ax0, ax1, ax2, ax3])
                    T_add[ax0, ax1, ax2, ax3] = T_reshape[ax0, ax1, ax2, ax3] / T.float32(8) + placeholder_1[ax0, 0, 0, ax3]
    

b0 = sch.get_block(name="T_reshape", func_name="main")
b1 = sch.get_block(name="compile_engine_const", func_name="main")
b2 = sch.get_block(name="T_divide", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v4 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v4)
l5 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l5, preserve_unit_loops=True)
sch.enter_postproc()
b6 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b6, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b6, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit")
b7, b8 = sch.get_child_blocks(b6)
l9, l10, l11, l12 = sch.get_loops(block=b7)
l13 = sch.fuse(l9, l10, l11)
sch.parallel(loop=l13)
sch.annotate(block_or_loop=l13, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l13, ann_key="pragma_unroll_explicit", ann_val=1)
l14, l15, l16, l17 = sch.get_loops(block=b8)
l18 = sch.fuse(l14, l15, l16)
sch.parallel(loop=l18)
sch.annotate(block_or_loop=l18, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l18, ann_key="pragma_unroll_explicit", ann_val=1)
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #20: GFLOPs: 37.6756. Time: 0.1252 ms. Best GFLOPs: 37.6756
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #21: GFLOPs: 47.1537. Time: 0.1001 ms. Best GFLOPs: 47.1537
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #22: GFLOPs: 11.5938. Time: 0.4070 ms. Best GFLOPs: 47.1537
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #23: GFLOPs: 17.7489. Time: 0.2659 ms. Best GFLOPs: 47.1537
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #24: GFLOPs: 7.1580. Time: 0.6592 ms. Best GFLOPs: 47.1537
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #25: GFLOPs: 4.9039. Time: 0.9622 ms. Best GFLOPs: 47.1537
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #26: GFLOPs: 28.0373. Time: 0.1683 ms. Best GFLOPs: 47.1537
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #27: GFLOPs: 8.0174. Time: 0.5885 ms. Best GFLOPs: 47.1537
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #28: GFLOPs: 15.3142. Time: 0.3081 ms. Best GFLOPs: 47.1537
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #29: GFLOPs: 30.6237. Time: 0.1541 ms. Best GFLOPs: 47.1537
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #30: GFLOPs: 26.8029. Time: 0.1760 ms. Best GFLOPs: 47.1537
[19:19:13] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #8: "fused_reshape_divide_add"] Trial #31: GFLOPs: 25.8417. Time: 0.1826 ms. Best GFLOPs: 47.1537
[19:19:14] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #8: "fused_reshape_divide_add"
 ID |                                                       Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                              fused_squeeze |          1 |      1 |         0.0001 |      12.6516 |               12.6516 |     32 |            
  1 |      fused_reshape_add_reshape_transpose_reshape_transpose |     393216 |     24 |         2.4269 |     162.0252 |             3888.6041 |     32 |            
  2 |       fused_expand_dims_expand_dims_cast_subtract_multiply |        768 |      1 |         0.0512 |      15.0019 |               15.0019 |     32 |            
  3 |    fused_reshape_add_reshape_transpose_reshape_transpose_1 |     393216 |     24 |         0.8998 |     437.0154 |            10488.3689 |     32 |            
  4 |                                                 fused_mean |     393600 |     49 |        10.0733 |      39.0736 |             1914.6079 |     32 |            
  5 |      fused_less_add_where_take_add_less_add_where_take_add |     787200 |      1 |        19.3910 |      40.5961 |               40.5961 |     32 |            
  6 |                fused_reshape_add_reshape_transpose_reshape |     393216 |     24 |         9.5277 |      41.2707 |              990.4966 |     32 |            
  7 |                                      fused_nn_batch_matmul |  301989888 |     24 |        86.3671 |    3496.5859 |            83918.0613 |     32 |            
  8 |                                   fused_reshape_divide_add |    4718592 |     24 |        47.1537 |     100.0683 |             2401.6391 |     32 |            
  9 |                                           fused_nn_softmax |    9437184 |     24 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                              fused_reshape |          1 |     24 |            N/A |          N/A |                   N/A |      0 |            
 11 |                                    fused_nn_batch_matmul_1 |  301989888 |     24 |            N/A |          N/A |                   N/A |      0 |            
 12 |                            fused_reshape_transpose_reshape |          1 |     24 |            N/A |          N/A |                   N/A |      0 |            
 13 |                                             fused_nn_dense |  805306368 |     96 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_add_sqrt_divide_multiply_add |    1180032 |     48 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                            fused_reshape_1 |          1 |     48 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_dense_1 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_reshape_add_multiply_divide_erf_add_multiply_reshape |    7864320 |     24 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_dense_2 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 19 |                                      fused_reshape_add_add |     786432 |     48 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                             fused_subtract |     393216 |     49 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                           fused_power_mean |     393600 |     49 |            N/A |          N/A |                   N/A |      0 |            
 22 |                 fused_add_sqrt_divide_multiply_add_reshape |    1180032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                           fused_nn_dense_3 |    1572864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                    fused_reshape_add_split |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                            fused_squeeze_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 288
Total latency (us): 103670

[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #0: GFLOPs: 3.3742. Time: 2.7968 ms. Best GFLOPs: 3.3742
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #1: GFLOPs: 0.6510. Time: 14.4958 ms. Best GFLOPs: 3.3742
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #2: GFLOPs: 0.3826. Time: 24.6641 ms. Best GFLOPs: 3.3742
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #3: GFLOPs: 0.4353. Time: 21.6782 ms. Best GFLOPs: 3.3742
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #4: GFLOPs: 0.8408. Time: 11.2247 ms. Best GFLOPs: 3.3742
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #5: GFLOPs: 0.9375. Time: 10.0665 ms. Best GFLOPs: 3.3742
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #6: GFLOPs: 1.2573. Time: 7.5057 ms. Best GFLOPs: 3.3742
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #7: GFLOPs: 0.8816. Time: 10.7048 ms. Best GFLOPs: 3.3742
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #8: GFLOPs: 0.0967. Time: 97.5508 ms. Best GFLOPs: 3.3742
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #9: GFLOPs: 2.8706. Time: 3.2876 ms. Best GFLOPs: 3.3742
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #10: GFLOPs: 0.1070. Time: 88.2153 ms. Best GFLOPs: 3.3742
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #11: GFLOPs: 1.9797. Time: 4.7671 ms. Best GFLOPs: 3.3742
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #12: GFLOPs: 0.1134. Time: 83.1938 ms. Best GFLOPs: 3.3742
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #13: GFLOPs: 3.9534. Time: 2.3871 ms. Best GFLOPs: 3.9534
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #14: GFLOPs: 0.4353. Time: 21.6790 ms. Best GFLOPs: 3.9534
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #15: GFLOPs: 4.7145. Time: 2.0018 ms. Best GFLOPs: 4.7145
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #16: GFLOPs: 4.0192. Time: 2.3480 ms. Best GFLOPs: 4.7145
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #17: GFLOPs: 2.3803. Time: 3.9646 ms. Best GFLOPs: 4.7145
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #18: GFLOPs: 0.0503. Time: 187.6274 ms. Best GFLOPs: 4.7145
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #19: GFLOPs: 1.9682. Time: 4.7949 ms. Best GFLOPs: 4.7145
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #20: GFLOPs: 2.6018. Time: 3.6272 ms. Best GFLOPs: 4.7145
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #9: "fused_nn_softmax"] Trial #21: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 384, 384), "float32"], T_softmax_norm: T.Buffer[(1, 16, 384, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        T_softmax_maxelem = T.alloc_buffer([1, 16, 384], dtype="float32")
        T_softmax_exp = T.alloc_buffer([1, 16, 384, 384], dtype="float32")
        T_softmax_expsum = T.alloc_buffer([1, 16, 384], dtype="float32")
        T_softmax_expsum_rf = T.alloc_buffer([1, 16, 384, 64], dtype="float32")
        T_softmax_maxelem_rf = T.alloc_buffer([1, 16, 384, 8], dtype="float32")
        for i0_i1_fused in T.parallel(16, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for ax0, ax1, ax2, ax3 in T.grid(8, 1, 1, 384):
                with T.block("T_softmax_maxelem_rf_init"):
                    vi3_1 = T.axis.spatial(8, ax0)
                    i0 = T.axis.spatial(1, 0)
                    i1, i2 = T.axis.remap("SS", [i0_i1_fused, ax3])
                    T.reads()
                    T.writes(T_softmax_maxelem_rf[i0, i1, i2, vi3_1])
                    T_softmax_maxelem_rf[i0, i1, i2, vi3_1] = T.float32(-3.4028234663852886e+38)
                for ax4 in T.serial(48):
                    with T.block("T_softmax_maxelem_rf_update"):
                        vi3_1 = T.axis.spatial(8, ax0)
                        i0 = T.axis.spatial(1, 0)
                        i1, i2, vi3_0 = T.axis.remap("SSR", [i0_i1_fused, ax3, ax4])
                        T.reads(T_softmax_maxelem_rf[i0, i1, i2, vi3_1], placeholder[i0, i1, i2, vi3_0 * 8 + vi3_1])
                        T.writes(T_softmax_maxelem_rf[i0, i1, i2, vi3_1])
                        T_softmax_maxelem_rf[i0, i1, i2, vi3_1] = T.max(T_softmax_maxelem_rf[i0, i1, i2, vi3_1], placeholder[i0, i1, i2, vi3_0 * 8 + vi3_1])
            for i2 in T.serial(384):
                with T.block("T_softmax_maxelem_init"):
                    i0 = T.axis.spatial(1, 0)
                    i1, i2_1 = T.axis.remap("SS", [i0_i1_fused, i2])
                    T.reads()
                    T.writes(T_softmax_maxelem[i0, i1, i2_1])
                    T_softmax_maxelem[i0, i1, i2_1] = T.float32(-3.4028234663852886e+38)
                for ax0, ax1, ax2, ax3 in T.grid(8, 1, 1, 1):
                    with T.block("T_softmax_maxelem_update"):
                        vi3_1 = T.axis.reduce(8, ax0)
                        i0 = T.axis.spatial(1, 0)
                        i1, i2_2 = T.axis.remap("SS", [i0_i1_fused, i2])
                        T.reads(T_softmax_maxelem[i0, i1, i2_2], T_softmax_maxelem_rf[i0, i1, i2_2, vi3_1])
                        T.writes(T_softmax_maxelem[i0, i1, i2_2])
                        T_softmax_maxelem[i0, i1, i2_2] = T.max(T_softmax_maxelem[i0, i1, i2_2], T_softmax_maxelem_rf[i0, i1, i2_2, vi3_1])
                for i3 in T.serial(384):
                    with T.block("T_softmax_exp"):
                        i0 = T.axis.spatial(1, 0)
                        i1, i2_3, i3_1 = T.axis.remap("SSS", [i0_i1_fused, i2, i3])
                        T.reads(placeholder[i0, i1, i2_3, i3_1], T_softmax_maxelem[i0, i1, i2_3])
                        T.writes(T_softmax_exp[i0, i1, i2_3, i3_1])
                        T_softmax_exp[i0, i1, i2_3, i3_1] = T.exp(placeholder[i0, i1, i2_3, i3_1] - T_softmax_maxelem[i0, i1, i2_3], dtype="float32")
        for i0_i1_i2_fused in T.parallel(6144, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3_1_fused_init in T.vectorized(64):
                with T.block("T_softmax_expsum_rf_init"):
                    vi3_1 = T.axis.spatial(64, i3_1_fused_init)
                    i0 = T.axis.spatial(1, 0)
                    i1 = T.axis.spatial(16, i0_i1_i2_fused // 384)
                    i2_4 = T.axis.spatial(384, i0_i1_i2_fused % 384)
                    T.reads()
                    T.writes(T_softmax_expsum_rf[i0, i1, i2_4, vi3_1])
                    T_softmax_expsum_rf[i0, i1, i2_4, vi3_1] = T.float32(0)
            for i3_0 in T.serial(6):
                for i3_1_fused in T.vectorized(64):
                    with T.block("T_softmax_expsum_rf_update"):
                        vi3_1 = T.axis.spatial(64, i3_1_fused)
                        i0 = T.axis.spatial(1, 0)
                        i1 = T.axis.spatial(16, i0_i1_i2_fused // 384)
                        i2_5 = T.axis.spatial(384, i0_i1_i2_fused % 384)
                        vi3_0 = T.axis.reduce(6, i3_0)
                        T.reads(T_softmax_expsum_rf[i0, i1, i2_5, vi3_1], T_softmax_exp[i0, i1, i2_5, vi3_0 * 64 + vi3_1])
                        T.writes(T_softmax_expsum_rf[i0, i1, i2_5, vi3_1])
                        T_softmax_expsum_rf[i0, i1, i2_5, vi3_1] = T_softmax_expsum_rf[i0, i1, i2_5, vi3_1] + T_softmax_exp[i0, i1, i2_5, vi3_0 * 64 + vi3_1]
        for i0_i1_i2_fused in T.parallel(6144, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            with T.block("T_softmax_expsum_init"):
                i0 = T.axis.spatial(1, 0)
                i1 = T.axis.spatial(16, i0_i1_i2_fused // 384)
                i2_6 = T.axis.spatial(384, i0_i1_i2_fused % 384)
                T.reads()
                T.writes(T_softmax_expsum[i0, i1, i2_6])
                T_softmax_expsum[i0, i1, i2_6] = T.float32(0)
            for ax0, ax1, ax2, ax3 in T.grid(64, 1, 1, 1):
                with T.block("T_softmax_expsum_update"):
                    vi3_1 = T.axis.reduce(64, ax0)
                    i0 = T.axis.spatial(1, 0)
                    i1 = T.axis.spatial(16, i0_i1_i2_fused // 384)
                    i2_7 = T.axis.spatial(384, i0_i1_i2_fused % 384)
                    T.reads(T_softmax_expsum[i0, i1, i2_7], T_softmax_expsum_rf[i0, i1, i2_7, vi3_1])
                    T.writes(T_softmax_expsum[i0, i1, i2_7])
                    T_softmax_expsum[i0, i1, i2_7] = T_softmax_expsum[i0, i1, i2_7] + T_softmax_expsum_rf[i0, i1, i2_7, vi3_1]
            for i3 in T.serial(384):
                with T.block("T_softmax_norm"):
                    i0 = T.axis.spatial(1, 0)
                    i1 = T.axis.spatial(16, i0_i1_i2_fused // 384)
                    i2_8 = T.axis.spatial(384, i0_i1_i2_fused % 384)
                    i3_2 = T.axis.spatial(384, i3)
                    T.reads(T_softmax_exp[i0, i1, i2_8, i3_2], T_softmax_expsum[i0, i1, i2_8])
                    T.writes(T_softmax_norm[i0, i1, i2_8, i3_2])
                    T.block_attr({"axis":3})
                    T_softmax_norm[i0, i1, i2_8, i3_2] = T_softmax_exp[i0, i1, i2_8, i3_2] / T_softmax_expsum[i0, i1, i2_8]
    

b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
l4, l5, l6, l7 = sch.get_loops(block=b2)
v8, v9 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[6, 64])
l10, l11 = sch.split(loop=l7, factors=[v8, v9])
b12 = sch.rfactor(loop=l11, factor_axis=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.random_compute_producer", ann_val=1)
l13, l14, l15, l16 = sch.get_loops(block=b0)
v17, v18 = sch.sample_perfect_tile(loop=l16, n=2, max_innermost_factor=64, decision=[48, 8])
l19, l20 = sch.split(loop=l16, factors=[v17, v18])
b21 = sch.rfactor(loop=l20, factor_axis=3)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.random_compute_producer", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v22 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v22)
b23, = sch.get_producers(block=b2)
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.random_compute_producer")
l24 = sch.sample_compute_location(block=b2, decision=2)
sch.compute_at(block=b2, loop=l24, preserve_unit_loops=True)
l25 = sch.sample_compute_location(block=b23, decision=-1)
sch.compute_at(block=b23, loop=l25, preserve_unit_loops=True)
l26 = sch.sample_compute_location(block=b1, decision=-1)
sch.compute_at(block=b1, loop=l26, preserve_unit_loops=True)
b27, = sch.get_producers(block=b0)
sch.unannotate(block_or_loop=b0, ann_key="meta_schedule.random_compute_producer")
l28 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l28, preserve_unit_loops=True)
l29 = sch.sample_compute_location(block=b27, decision=1)
sch.compute_at(block=b27, loop=l29, preserve_unit_loops=True)
sch.enter_postproc()
b30 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b30, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b30, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b30, ann_key="meta_schedule.unroll_explicit")
b31, b32, b33, b34, b35, b36 = sch.get_child_blocks(b30)
l37, l38, l39, l40, l41, l42, l43 = sch.get_loops(block=b31)
l44 = sch.fuse(l37, l38)
sch.parallel(loop=l44)
sch.annotate(block_or_loop=l44, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l44, ann_key="pragma_unroll_explicit", ann_val=1)
l45, l46, l47, l48, l49, l50 = sch.get_loops(block=b32)
sch.annotate(block_or_loop=l45, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l45, ann_key="pragma_unroll_explicit", ann_val=1)
l51, l52, l53 = sch.get_loops(block=b33)
sch.annotate(block_or_loop=l51, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l51, ann_key="pragma_unroll_explicit", ann_val=1)
l54, l55, l56, l57, l58 = sch.get_loops(block=b34)
l59 = sch.fuse(l54, l55, l56)
sch.parallel(loop=l59)
l60 = sch.fuse(l58)
sch.vectorize(loop=l60)
sch.annotate(block_or_loop=l59, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l59, ann_key="pragma_unroll_explicit", ann_val=1)
l61, l62, l63, l64, l65, l66, l67 = sch.get_loops(block=b35)
l68 = sch.fuse(l61, l62, l63)
sch.parallel(loop=l68)
sch.annotate(block_or_loop=l68, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l68, ann_key="pragma_unroll_explicit", ann_val=1)
l69, l70 = sch.get_loops(block=b36)
sch.annotate(block_or_loop=l69, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l69, ann_key="pragma_unroll_explicit", ann_val=1)
b71 = sch.get_block(name="T_softmax_maxelem_rf", func_name="main")
l72, l73, l74, l75, l76, l77 = sch.get_loops(block=b71)
b78 = sch.decompose_reduction(block=b71, loop=l77)
b79 = sch.get_block(name="T_softmax_maxelem", func_name="main")
l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b79)
b86 = sch.decompose_reduction(block=b79, loop=l82)
b87 = sch.get_block(name="T_softmax_expsum_rf", func_name="main")
l88, l89, l90 = sch.get_loops(block=b87)
b91 = sch.decompose_reduction(block=b87, loop=l89)
b92 = sch.get_block(name="T_softmax_expsum", func_name="main")
l93, l94, l95, l96, l97 = sch.get_loops(block=b92)
b98 = sch.decompose_reduction(block=b92, loop=l94)
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #22: GFLOPs: 1.9710. Time: 4.7880 ms. Best GFLOPs: 4.7145
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #23: GFLOPs: 0.1967. Time: 47.9752 ms. Best GFLOPs: 4.7145
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #9: "fused_nn_softmax"] Trial #24: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 384, 384), "float32"], T_softmax_norm: T.Buffer[(1, 16, 384, 384), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        T_softmax_maxelem = T.alloc_buffer([1, 16, 384], dtype="float32")
        T_softmax_exp = T.alloc_buffer([1, 16, 384, 384], dtype="float32")
        T_softmax_expsum = T.alloc_buffer([1, 16, 384], dtype="float32")
        T_softmax_expsum_rf = T.alloc_buffer([1, 16, 384, 3], dtype="float32")
        T_softmax_maxelem_rf = T.alloc_buffer([1, 16, 384, 96], dtype="float32")
        for i0_i1_fused in T.parallel(16, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for ax0, ax1, ax2 in T.grid(1, 1, 384):
                for ax0_init in T.serial(96):
                    with T.block("T_softmax_maxelem_rf_init"):
                        vi3_0 = T.axis.spatial(96, ax0_init)
                        i0 = T.axis.spatial(1, 0)
                        i1, i2 = T.axis.remap("SS", [i0_i1_fused, ax2])
                        T.reads()
                        T.writes(T_softmax_maxelem_rf[i0, i1, i2, vi3_0])
                        T_softmax_maxelem_rf[i0, i1, i2, vi3_0] = T.float32(-3.4028234663852886e+38)
                with T.block("T_softmax_maxelem_init"):
                    i0 = T.axis.spatial(1, 0)
                    i1, i2 = T.axis.remap("SS", [i0_i1_fused, ax2])
                    T.reads()
                    T.writes(T_softmax_maxelem[i0, i1, i2])
                    T_softmax_maxelem[i0, i1, i2] = T.float32(-3.4028234663852886e+38)
                for ax0_1 in T.serial(96):
                    for ax0_2, ax1_1, ax2_1, ax3, ax4 in T.grid(1, 1, 1, 1, 4):
                        with T.block("T_softmax_maxelem_rf_update"):
                            vi3_0 = T.axis.spatial(96, ax0_1)
                            i0 = T.axis.spatial(1, 0)
                            i1, i2, vi3_1 = T.axis.remap("SSR", [i0_i1_fused, ax2, ax4])
                            T.reads(T_softmax_maxelem_rf[i0, i1, i2, vi3_0], placeholder[i0, i1, i2, vi3_0 * 4 + vi3_1])
                            T.writes(T_softmax_maxelem_rf[i0, i1, i2, vi3_0])
                            T_softmax_maxelem_rf[i0, i1, i2, vi3_0] = T.max(T_softmax_maxelem_rf[i0, i1, i2, vi3_0], placeholder[i0, i1, i2, vi3_0 * 4 + vi3_1])
                    for ax1_2, ax2_2, ax3 in T.grid(1, 1, 1):
                        with T.block("T_softmax_maxelem_update"):
                            vi3_0 = T.axis.reduce(96, ax0_1)
                            i0 = T.axis.spatial(1, 0)
                            i1, i2 = T.axis.remap("SS", [i0_i1_fused, ax2])
                            T.reads(T_softmax_maxelem[i0, i1, i2], T_softmax_maxelem_rf[i0, i1, i2, vi3_0])
                            T.writes(T_softmax_maxelem[i0, i1, i2])
                            T_softmax_maxelem[i0, i1, i2] = T.max(T_softmax_maxelem[i0, i1, i2], T_softmax_maxelem_rf[i0, i1, i2, vi3_0])
                for ax3 in T.serial(384):
                    with T.block("T_softmax_exp"):
                        i0 = T.axis.spatial(1, 0)
                        i1, i2, i3 = T.axis.remap("SSS", [i0_i1_fused, ax2, ax3])
                        T.reads(placeholder[i0, i1, i2, i3], T_softmax_maxelem[i0, i1, i2])
                        T.writes(T_softmax_exp[i0, i1, i2, i3])
                        T_softmax_exp[i0, i1, i2, i3] = T.exp(placeholder[i0, i1, i2, i3] - T_softmax_maxelem[i0, i1, i2], dtype="float32")
            for i2 in T.serial(384):
                for ax0_init in T.serial(3):
                    with T.block("T_softmax_expsum_rf_init"):
                        vi3_1 = T.axis.spatial(3, ax0_init)
                        i0 = T.axis.spatial(1, 0)
                        i1, i2_1 = T.axis.remap("SS", [i0_i1_fused, i2])
                        T.reads()
                        T.writes(T_softmax_expsum_rf[i0, i1, i2_1, vi3_1])
                        T_softmax_expsum_rf[i0, i1, i2_1, vi3_1] = T.float32(0)
                with T.block("T_softmax_expsum_init"):
                    i0 = T.axis.spatial(1, 0)
                    i1, i2_2 = T.axis.remap("SS", [i0_i1_fused, i2])
                    T.reads()
                    T.writes(T_softmax_expsum[i0, i1, i2_2])
                    T_softmax_expsum[i0, i1, i2_2] = T.float32(0)
                for ax0 in T.serial(3):
                    for ax0_3, ax1_3, ax2_3, ax3, ax4 in T.grid(1, 1, 1, 1, 128):
                        with T.block("T_softmax_expsum_rf_update"):
                            vi3_1 = T.axis.spatial(3, ax0)
                            i0 = T.axis.spatial(1, 0)
                            i1, i2_3, vi3_0 = T.axis.remap("SSR", [i0_i1_fused, i2, ax4])
                            T.reads(T_softmax_expsum_rf[i0, i1, i2_3, vi3_1], T_softmax_exp[i0, i1, i2_3, vi3_0 * 3 + vi3_1])
                            T.writes(T_softmax_expsum_rf[i0, i1, i2_3, vi3_1])
                            T_softmax_expsum_rf[i0, i1, i2_3, vi3_1] = T_softmax_expsum_rf[i0, i1, i2_3, vi3_1] + T_softmax_exp[i0, i1, i2_3, vi3_0 * 3 + vi3_1]
                    for ax1_4, ax2_4, ax3 in T.grid(1, 1, 1):
                        with T.block("T_softmax_expsum_update"):
                            vi3_1 = T.axis.reduce(3, ax0)
                            i0 = T.axis.spatial(1, 0)
                            i1, i2_4 = T.axis.remap("SS", [i0_i1_fused, i2])
                            T.reads(T_softmax_expsum[i0, i1, i2_4], T_softmax_expsum_rf[i0, i1, i2_4, vi3_1])
                            T.writes(T_softmax_expsum[i0, i1, i2_4])
                            T_softmax_expsum[i0, i1, i2_4] = T_softmax_expsum[i0, i1, i2_4] + T_softmax_expsum_rf[i0, i1, i2_4, vi3_1]
                for i3 in T.serial(384):
                    with T.block("T_softmax_norm"):
                        i0 = T.axis.spatial(1, 0)
                        i1, i2_5, i3_1 = T.axis.remap("SSS", [i0_i1_fused, i2, i3])
                        T.reads(T_softmax_exp[i0, i1, i2_5, i3_1], T_softmax_expsum[i0, i1, i2_5])
                        T.writes(T_softmax_norm[i0, i1, i2_5, i3_1])
                        T.block_attr({"axis":3})
                        T_softmax_norm[i0, i1, i2_5, i3_1] = T_softmax_exp[i0, i1, i2_5, i3_1] / T_softmax_expsum[i0, i1, i2_5]
    

b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
l4, l5, l6, l7 = sch.get_loops(block=b2)
v8, v9 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[128, 3])
l10, l11 = sch.split(loop=l7, factors=[v8, v9])
b12 = sch.rfactor(loop=l11, factor_axis=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.random_compute_producer", ann_val=1)
l13, l14, l15, l16 = sch.get_loops(block=b0)
v17, v18 = sch.sample_perfect_tile(loop=l16, n=2, max_innermost_factor=64, decision=[96, 4])
l19, l20 = sch.split(loop=l16, factors=[v17, v18])
b21 = sch.rfactor(loop=l19, factor_axis=3)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.random_compute_producer", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v22 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v22)
b23, = sch.get_producers(block=b2)
sch.unannotate(block_or_loop=b2, ann_key="meta_schedule.random_compute_producer")
l24 = sch.sample_compute_location(block=b2, decision=2)
sch.compute_at(block=b2, loop=l24, preserve_unit_loops=True)
l25 = sch.sample_compute_location(block=b23, decision=3)
sch.compute_at(block=b23, loop=l25, preserve_unit_loops=True)
l26 = sch.sample_compute_location(block=b1, decision=1)
sch.compute_at(block=b1, loop=l26, preserve_unit_loops=True)
b27, = sch.get_producers(block=b0)
sch.unannotate(block_or_loop=b0, ann_key="meta_schedule.random_compute_producer")
l28 = sch.sample_compute_location(block=b0, decision=4)
sch.compute_at(block=b0, loop=l28, preserve_unit_loops=True)
l29 = sch.sample_compute_location(block=b27, decision=5)
sch.compute_at(block=b27, loop=l29, preserve_unit_loops=True)
sch.enter_postproc()
b30 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b30, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b30, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b30, ann_key="meta_schedule.unroll_explicit")
b31, b32, b33, b34, b35, b36 = sch.get_child_blocks(b30)
l37, l38, l39, l40, l41, l42, l43, l44, l45, l46, l47 = sch.get_loops(block=b31)
l48 = sch.fuse(l37, l38)
sch.parallel(loop=l48)
sch.annotate(block_or_loop=l48, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l48, ann_key="pragma_unroll_explicit", ann_val=1)
l49, l50, l51, l52, l53, l54, l55, l56 = sch.get_loops(block=b32)
sch.annotate(block_or_loop=l49, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l49, ann_key="pragma_unroll_explicit", ann_val=1)
l57, l58, l59, l60, l61 = sch.get_loops(block=b33)
sch.annotate(block_or_loop=l57, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l57, ann_key="pragma_unroll_explicit", ann_val=1)
l62, l63, l64, l65, l66, l67, l68, l69 = sch.get_loops(block=b34)
sch.annotate(block_or_loop=l62, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l62, ann_key="pragma_unroll_explicit", ann_val=1)
l70, l71, l72, l73, l74, l75 = sch.get_loops(block=b35)
sch.annotate(block_or_loop=l70, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l70, ann_key="pragma_unroll_explicit", ann_val=1)
l76, l77, l78 = sch.get_loops(block=b36)
sch.annotate(block_or_loop=l76, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l76, ann_key="pragma_unroll_explicit", ann_val=1)
b79 = sch.get_block(name="T_softmax_maxelem_rf", func_name="main")
l80, l81, l82, l83, l84, l85, l86, l87, l88, l89 = sch.get_loops(block=b79)
b90 = sch.decompose_reduction(block=b79, loop=l84)
b91 = sch.get_block(name="T_softmax_maxelem", func_name="main")
l92, l93, l94, l95, l96, l97, l98, l99 = sch.get_loops(block=b91)
b100 = sch.decompose_reduction(block=b91, loop=l96)
b101 = sch.get_block(name="T_softmax_expsum_rf", func_name="main")
l102, l103, l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b101)
b110 = sch.decompose_reduction(block=b101, loop=l104)
b111 = sch.get_block(name="T_softmax_expsum", func_name="main")
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b111)
b118 = sch.decompose_reduction(block=b111, loop=l114)
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #25: GFLOPs: 1.9045. Time: 4.9552 ms. Best GFLOPs: 4.7145
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #26: GFLOPs: 2.0663. Time: 4.5672 ms. Best GFLOPs: 4.7145
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #27: GFLOPs: 3.0840. Time: 3.0601 ms. Best GFLOPs: 4.7145
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #28: GFLOPs: 1.4252. Time: 6.6215 ms. Best GFLOPs: 4.7145
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #29: GFLOPs: 0.0174. Time: 542.8622 ms. Best GFLOPs: 4.7145
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #30: GFLOPs: 0.3146. Time: 29.9934 ms. Best GFLOPs: 4.7145
[19:19:14] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #9: "fused_nn_softmax"] Trial #31: GFLOPs: 0.7821. Time: 12.0660 ms. Best GFLOPs: 4.7145
[19:19:15] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #9: "fused_nn_softmax"
 ID |                                                       Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                              fused_squeeze |          1 |      1 |         0.0001 |      12.6516 |               12.6516 |     32 |            
  1 |      fused_reshape_add_reshape_transpose_reshape_transpose |     393216 |     24 |         2.4269 |     162.0252 |             3888.6041 |     32 |            
  2 |       fused_expand_dims_expand_dims_cast_subtract_multiply |        768 |      1 |         0.0512 |      15.0019 |               15.0019 |     32 |            
  3 |    fused_reshape_add_reshape_transpose_reshape_transpose_1 |     393216 |     24 |         0.8998 |     437.0154 |            10488.3689 |     32 |            
  4 |                                                 fused_mean |     393600 |     49 |        10.0733 |      39.0736 |             1914.6079 |     32 |            
  5 |      fused_less_add_where_take_add_less_add_where_take_add |     787200 |      1 |        19.3910 |      40.5961 |               40.5961 |     32 |            
  6 |                fused_reshape_add_reshape_transpose_reshape |     393216 |     24 |         9.5277 |      41.2707 |              990.4966 |     32 |            
  7 |                                      fused_nn_batch_matmul |  301989888 |     24 |        86.3671 |    3496.5859 |            83918.0613 |     32 |            
  8 |                                   fused_reshape_divide_add |    4718592 |     24 |        47.1537 |     100.0683 |             2401.6391 |     32 |            
  9 |                                           fused_nn_softmax |    9437184 |     24 |         4.7145 |    2001.7558 |            48042.1395 |     32 |            
 10 |                                              fused_reshape |          1 |     24 |            N/A |          N/A |                   N/A |      0 |            
 11 |                                    fused_nn_batch_matmul_1 |  301989888 |     24 |            N/A |          N/A |                   N/A |      0 |            
 12 |                            fused_reshape_transpose_reshape |          1 |     24 |            N/A |          N/A |                   N/A |      0 |            
 13 |                                             fused_nn_dense |  805306368 |     96 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_add_sqrt_divide_multiply_add |    1180032 |     48 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                            fused_reshape_1 |          1 |     48 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_dense_1 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_reshape_add_multiply_divide_erf_add_multiply_reshape |    7864320 |     24 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_dense_2 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 19 |                                      fused_reshape_add_add |     786432 |     48 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                             fused_subtract |     393216 |     49 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                           fused_power_mean |     393600 |     49 |            N/A |          N/A |                   N/A |      0 |            
 22 |                 fused_add_sqrt_divide_multiply_add_reshape |    1180032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                           fused_nn_dense_3 |    1572864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                    fused_reshape_add_split |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                            fused_squeeze_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 320
Total latency (us): 151712

[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #0: GFLOPs: 0.0000. Time: 0.1661 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #1: GFLOPs: 0.0000. Time: 0.1983 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #2: GFLOPs: 0.0000. Time: 0.1184 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #3: GFLOPs: 0.0000. Time: 0.1112 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #4: GFLOPs: 0.0000. Time: 0.1147 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #5: GFLOPs: 0.0000. Time: 0.1155 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #6: GFLOPs: 0.0000. Time: 0.0737 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #7: GFLOPs: 0.0000. Time: 0.2172 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #8: GFLOPs: 0.0000. Time: 0.1947 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #9: GFLOPs: 0.0000. Time: 0.1126 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #10: GFLOPs: 0.0000. Time: 0.1440 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #11: GFLOPs: 0.0000. Time: 0.1054 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #12: GFLOPs: 0.0000. Time: 0.2853 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #13: GFLOPs: 0.0000. Time: 0.0948 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #14: GFLOPs: 0.0000. Time: 0.2187 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #15: GFLOPs: 0.0000. Time: 4.8274 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #16: GFLOPs: 0.0000. Time: 6.3632 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #17: GFLOPs: 0.0000. Time: 6.4511 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #18: GFLOPs: 0.0000. Time: 3.0700 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #19: GFLOPs: 0.0000. Time: 1.0094 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #20: GFLOPs: 0.0000. Time: 0.4396 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #21: GFLOPs: 0.0000. Time: 0.2106 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #22: GFLOPs: 0.0000. Time: 0.1856 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #23: GFLOPs: 0.0000. Time: 0.2771 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #24: GFLOPs: 0.0000. Time: 0.2571 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #25: GFLOPs: 0.0000. Time: 0.1703 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #26: GFLOPs: 0.0000. Time: 0.1996 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #27: GFLOPs: 0.0000. Time: 0.2956 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #28: GFLOPs: 0.0000. Time: 0.1092 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #29: GFLOPs: 0.0000. Time: 0.1103 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #30: GFLOPs: 0.0000. Time: 0.0957 ms. Best GFLOPs: 0.0000
[19:19:15] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #10: "fused_reshape"] Trial #31: GFLOPs: 0.0000. Time: 5.5436 ms. Best GFLOPs: 0.0000
[19:19:16] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #10: "fused_reshape"
 ID |                                                       Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                              fused_squeeze |          1 |      1 |         0.0001 |      12.6516 |               12.6516 |     32 |            
  1 |      fused_reshape_add_reshape_transpose_reshape_transpose |     393216 |     24 |         2.4269 |     162.0252 |             3888.6041 |     32 |            
  2 |       fused_expand_dims_expand_dims_cast_subtract_multiply |        768 |      1 |         0.0512 |      15.0019 |               15.0019 |     32 |            
  3 |    fused_reshape_add_reshape_transpose_reshape_transpose_1 |     393216 |     24 |         0.8998 |     437.0154 |            10488.3689 |     32 |            
  4 |                                                 fused_mean |     393600 |     49 |        10.0733 |      39.0736 |             1914.6079 |     32 |            
  5 |      fused_less_add_where_take_add_less_add_where_take_add |     787200 |      1 |        19.3910 |      40.5961 |               40.5961 |     32 |            
  6 |                fused_reshape_add_reshape_transpose_reshape |     393216 |     24 |         9.5277 |      41.2707 |              990.4966 |     32 |            
  7 |                                      fused_nn_batch_matmul |  301989888 |     24 |        86.3671 |    3496.5859 |            83918.0613 |     32 |            
  8 |                                   fused_reshape_divide_add |    4718592 |     24 |        47.1537 |     100.0683 |             2401.6391 |     32 |            
  9 |                                           fused_nn_softmax |    9437184 |     24 |         4.7145 |    2001.7558 |            48042.1395 |     32 |            
 10 |                                              fused_reshape |          1 |     24 |         0.0000 |      73.6705 |             1768.0929 |     32 |            
 11 |                                    fused_nn_batch_matmul_1 |  301989888 |     24 |            N/A |          N/A |                   N/A |      0 |            
 12 |                            fused_reshape_transpose_reshape |          1 |     24 |            N/A |          N/A |                   N/A |      0 |            
 13 |                                             fused_nn_dense |  805306368 |     96 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_add_sqrt_divide_multiply_add |    1180032 |     48 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                            fused_reshape_1 |          1 |     48 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_dense_1 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_reshape_add_multiply_divide_erf_add_multiply_reshape |    7864320 |     24 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_dense_2 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 19 |                                      fused_reshape_add_add |     786432 |     48 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                             fused_subtract |     393216 |     49 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                           fused_power_mean |     393600 |     49 |            N/A |          N/A |                   N/A |      0 |            
 22 |                 fused_add_sqrt_divide_multiply_add_reshape |    1180032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                           fused_nn_dense_3 |    1572864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                    fused_reshape_add_split |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                            fused_squeeze_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 352
Total latency (us): 153480

[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #0: GFLOPs: 12.9438. Time: 23.3308 ms. Best GFLOPs: 12.9438
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #1: GFLOPs: 11.3494. Time: 26.6085 ms. Best GFLOPs: 12.9438
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #2: GFLOPs: 13.5992. Time: 22.2064 ms. Best GFLOPs: 13.5992
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #3: GFLOPs: 16.9437. Time: 17.8231 ms. Best GFLOPs: 16.9437
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #4: GFLOPs: 16.3886. Time: 18.4268 ms. Best GFLOPs: 16.9437
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #5: GFLOPs: 13.2657. Time: 22.7647 ms. Best GFLOPs: 16.9437
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #6: GFLOPs: 17.2052. Time: 17.5523 ms. Best GFLOPs: 17.2052
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #7: GFLOPs: 19.5463. Time: 15.4499 ms. Best GFLOPs: 19.5463
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #8: GFLOPs: 28.6654. Time: 10.5350 ms. Best GFLOPs: 28.6654
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #9: GFLOPs: 6.4465. Time: 46.8459 ms. Best GFLOPs: 28.6654
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #10: GFLOPs: 15.9915. Time: 18.8844 ms. Best GFLOPs: 28.6654
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #11: GFLOPs: 15.7955. Time: 19.1187 ms. Best GFLOPs: 28.6654
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #12: GFLOPs: 23.9115. Time: 12.6295 ms. Best GFLOPs: 28.6654
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #13: GFLOPs: 8.1273. Time: 37.1576 ms. Best GFLOPs: 28.6654
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #14: GFLOPs: 19.3180. Time: 15.6325 ms. Best GFLOPs: 28.6654
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #15: GFLOPs: 10.2907. Time: 29.3458 ms. Best GFLOPs: 28.6654
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #16: GFLOPs: 23.0216. Time: 13.1177 ms. Best GFLOPs: 28.6654
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #17: GFLOPs: 20.8258. Time: 14.5007 ms. Best GFLOPs: 28.6654
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #18: GFLOPs: 27.8468. Time: 10.8447 ms. Best GFLOPs: 28.6654
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #19: GFLOPs: 35.9377. Time: 8.4031 ms. Best GFLOPs: 35.9377
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #20: GFLOPs: 11.8057. Time: 25.5800 ms. Best GFLOPs: 35.9377
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #21: GFLOPs: 13.1470. Time: 22.9703 ms. Best GFLOPs: 35.9377
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #22: GFLOPs: 46.6469. Time: 6.4740 ms. Best GFLOPs: 46.6469
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #23: GFLOPs: 37.7208. Time: 8.0059 ms. Best GFLOPs: 46.6469
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #24: GFLOPs: 26.8236. Time: 11.2584 ms. Best GFLOPs: 46.6469
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #25: GFLOPs: 14.0327. Time: 21.5204 ms. Best GFLOPs: 46.6469
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #26: GFLOPs: 59.6188. Time: 5.0653 ms. Best GFLOPs: 59.6188
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #27: GFLOPs: 6.7479. Time: 44.7530 ms. Best GFLOPs: 59.6188
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #28: GFLOPs: 11.0499. Time: 27.3297 ms. Best GFLOPs: 59.6188
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #29: GFLOPs: 17.9361. Time: 16.8370 ms. Best GFLOPs: 59.6188
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #30: GFLOPs: 15.2148. Time: 19.8485 ms. Best GFLOPs: 59.6188
[19:19:16] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #11: "fused_nn_batch_matmul_1"] Trial #31: GFLOPs: 21.4278. Time: 14.0934 ms. Best GFLOPs: 59.6188
[19:19:17] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #11: "fused_nn_batch_matmul_1"
 ID |                                                       Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                              fused_squeeze |          1 |      1 |         0.0001 |      12.6516 |               12.6516 |     32 |            
  1 |      fused_reshape_add_reshape_transpose_reshape_transpose |     393216 |     24 |         2.4269 |     162.0252 |             3888.6041 |     32 |            
  2 |       fused_expand_dims_expand_dims_cast_subtract_multiply |        768 |      1 |         0.0512 |      15.0019 |               15.0019 |     32 |            
  3 |    fused_reshape_add_reshape_transpose_reshape_transpose_1 |     393216 |     24 |         0.8998 |     437.0154 |            10488.3689 |     32 |            
  4 |                                                 fused_mean |     393600 |     49 |        10.0733 |      39.0736 |             1914.6079 |     32 |            
  5 |      fused_less_add_where_take_add_less_add_where_take_add |     787200 |      1 |        19.3910 |      40.5961 |               40.5961 |     32 |            
  6 |                fused_reshape_add_reshape_transpose_reshape |     393216 |     24 |         9.5277 |      41.2707 |              990.4966 |     32 |            
  7 |                                      fused_nn_batch_matmul |  301989888 |     24 |        86.3671 |    3496.5859 |            83918.0613 |     32 |            
  8 |                                   fused_reshape_divide_add |    4718592 |     24 |        47.1537 |     100.0683 |             2401.6391 |     32 |            
  9 |                                           fused_nn_softmax |    9437184 |     24 |         4.7145 |    2001.7558 |            48042.1395 |     32 |            
 10 |                                              fused_reshape |          1 |     24 |         0.0000 |      73.6705 |             1768.0929 |     32 |            
 11 |                                    fused_nn_batch_matmul_1 |  301989888 |     24 |        59.6188 |    5065.3446 |           121568.2700 |     32 |            
 12 |                            fused_reshape_transpose_reshape |          1 |     24 |            N/A |          N/A |                   N/A |      0 |            
 13 |                                             fused_nn_dense |  805306368 |     96 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_add_sqrt_divide_multiply_add |    1180032 |     48 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                            fused_reshape_1 |          1 |     48 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_dense_1 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_reshape_add_multiply_divide_erf_add_multiply_reshape |    7864320 |     24 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_dense_2 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 19 |                                      fused_reshape_add_add |     786432 |     48 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                             fused_subtract |     393216 |     49 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                           fused_power_mean |     393600 |     49 |            N/A |          N/A |                   N/A |      0 |            
 22 |                 fused_add_sqrt_divide_multiply_add_reshape |    1180032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                           fused_nn_dense_3 |    1572864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                    fused_reshape_add_split |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                            fused_squeeze_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 384
Total latency (us): 275049

[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #0: GFLOPs: 0.0000. Time: 0.2647 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #1: GFLOPs: 0.0000. Time: 0.1266 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #2: GFLOPs: 0.0000. Time: 0.1635 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #3: GFLOPs: 0.0000. Time: 0.1009 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #4: GFLOPs: 0.0000. Time: 0.0807 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #5: GFLOPs: 0.0000. Time: 0.2404 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #6: GFLOPs: 0.0000. Time: 0.2349 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #7: GFLOPs: 0.0000. Time: 0.1174 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #8: GFLOPs: 0.0000. Time: 0.3467 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #9: GFLOPs: 0.0000. Time: 0.4816 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #10: GFLOPs: 0.0000. Time: 0.2335 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #11: GFLOPs: 0.0000. Time: 0.0674 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #12: GFLOPs: 0.0000. Time: 0.1059 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #13: GFLOPs: 0.0000. Time: 0.1003 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #14: GFLOPs: 0.0000. Time: 0.1618 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #15: GFLOPs: 0.0000. Time: 0.1001 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #16: GFLOPs: 0.0000. Time: 0.1906 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #17: GFLOPs: 0.0000. Time: 0.0825 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #18: GFLOPs: 0.0000. Time: 0.0633 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #19: GFLOPs: 0.0000. Time: 1.6072 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #20: GFLOPs: 0.0000. Time: 2.3725 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #21: GFLOPs: 0.0000. Time: 1.6075 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #22: GFLOPs: 0.0000. Time: 1.3699 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #23: GFLOPs: 0.0000. Time: 1.9079 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #24: GFLOPs: 0.0000. Time: 20.0797 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #25: GFLOPs: 0.0000. Time: 1.7267 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #26: GFLOPs: 0.0000. Time: 0.7642 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #27: GFLOPs: 0.0000. Time: 1.9592 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #28: GFLOPs: 0.0000. Time: 0.3736 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #29: GFLOPs: 0.0000. Time: 2.2623 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #30: GFLOPs: 0.0000. Time: 0.3674 ms. Best GFLOPs: 0.0000
[19:19:17] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #12: "fused_reshape_transpose_reshape"] Trial #31: GFLOPs: 0.0000. Time: 0.2510 ms. Best GFLOPs: 0.0000
[19:19:18] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #12: "fused_reshape_transpose_reshape"
 ID |                                                       Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                              fused_squeeze |          1 |      1 |         0.0001 |      12.6516 |               12.6516 |     32 |            
  1 |      fused_reshape_add_reshape_transpose_reshape_transpose |     393216 |     24 |         2.4269 |     162.0252 |             3888.6041 |     32 |            
  2 |       fused_expand_dims_expand_dims_cast_subtract_multiply |        768 |      1 |         0.0512 |      15.0019 |               15.0019 |     32 |            
  3 |    fused_reshape_add_reshape_transpose_reshape_transpose_1 |     393216 |     24 |         0.8998 |     437.0154 |            10488.3689 |     32 |            
  4 |                                                 fused_mean |     393600 |     49 |        10.0733 |      39.0736 |             1914.6079 |     32 |            
  5 |      fused_less_add_where_take_add_less_add_where_take_add |     787200 |      1 |        19.3910 |      40.5961 |               40.5961 |     32 |            
  6 |                fused_reshape_add_reshape_transpose_reshape |     393216 |     24 |         9.5277 |      41.2707 |              990.4966 |     32 |            
  7 |                                      fused_nn_batch_matmul |  301989888 |     24 |        86.3671 |    3496.5859 |            83918.0613 |     32 |            
  8 |                                   fused_reshape_divide_add |    4718592 |     24 |        47.1537 |     100.0683 |             2401.6391 |     32 |            
  9 |                                           fused_nn_softmax |    9437184 |     24 |         4.7145 |    2001.7558 |            48042.1395 |     32 |            
 10 |                                              fused_reshape |          1 |     24 |         0.0000 |      73.6705 |             1768.0929 |     32 |            
 11 |                                    fused_nn_batch_matmul_1 |  301989888 |     24 |        59.6188 |    5065.3446 |           121568.2700 |     32 |            
 12 |                            fused_reshape_transpose_reshape |          1 |     24 |         0.0000 |      63.3190 |             1519.6562 |     32 |            
 13 |                                             fused_nn_dense |  805306368 |     96 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_add_sqrt_divide_multiply_add |    1180032 |     48 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                            fused_reshape_1 |          1 |     48 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_dense_1 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_reshape_add_multiply_divide_erf_add_multiply_reshape |    7864320 |     24 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_dense_2 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 19 |                                      fused_reshape_add_add |     786432 |     48 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                             fused_subtract |     393216 |     49 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                           fused_power_mean |     393600 |     49 |            N/A |          N/A |                   N/A |      0 |            
 22 |                 fused_add_sqrt_divide_multiply_add_reshape |    1180032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                           fused_nn_dense_3 |    1572864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                    fused_reshape_add_split |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                            fused_squeeze_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 416
Total latency (us): 276568

[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #0: GFLOPs: 47.9994. Time: 16.7774 ms. Best GFLOPs: 47.9994
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #1: GFLOPs: 35.5229. Time: 22.6701 ms. Best GFLOPs: 47.9994
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #2: GFLOPs: 5.5893. Time: 144.0804 ms. Best GFLOPs: 47.9994
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #3: GFLOPs: 52.9462. Time: 15.2099 ms. Best GFLOPs: 52.9462
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #4: GFLOPs: 26.3164. Time: 30.6009 ms. Best GFLOPs: 52.9462
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #5: GFLOPs: 21.7801. Time: 36.9743 ms. Best GFLOPs: 52.9462
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #6: GFLOPs: 15.8972. Time: 50.6570 ms. Best GFLOPs: 52.9462
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #7: GFLOPs: 21.5039. Time: 37.4493 ms. Best GFLOPs: 52.9462
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #8: GFLOPs: 32.7546. Time: 24.5861 ms. Best GFLOPs: 52.9462
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #9: GFLOPs: 3.4742. Time: 231.7930 ms. Best GFLOPs: 52.9462
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #10: GFLOPs: 44.3163. Time: 18.1718 ms. Best GFLOPs: 52.9462
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #11: GFLOPs: 35.5323. Time: 22.6641 ms. Best GFLOPs: 52.9462
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:65: [Task #13: "fused_nn_dense"] Trial #12: Error in building: LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(384, 1024), "float32"], placeholder_1: T.Buffer[(1024, 1024), "float32"], T_matmul_NT: T.Buffer[(384, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"tir.noalias": True, "global_symbol": "main"})
        # body
        # with T.block("root")
        T_matmul_NT_global = T.alloc_buffer([384, 1024], dtype="float32")
        for i0_0_i1_0_fused in T.parallel(48, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1, i1_1 in T.grid(2, 2):
                for i0_2_init, i1_2_init, i0_3_init, i1_3_init in T.grid(4, 32, 2, 8):
                    with T.block("T_matmul_NT_init"):
                        i = T.axis.spatial(384, i0_0_i1_0_fused // 2 * 16 + i0_1 * 8 + i0_2_init * 2 + i0_3_init)
                        j = T.axis.spatial(1024, i0_0_i1_0_fused % 2 * 512 + i1_1 * 256 + i1_2_init * 8 + i1_3_init)
                        T.reads()
                        T.writes(T_matmul_NT_global[i, j])
                        T.block_attr({"layout_free_placeholders":[placeholder_1], "meta_schedule.tiling_structure":"SSRSRS"})
                        T_matmul_NT_global[i, j] = T.float32(0)
                for i2_0, i0_2, i1_2, i2_1, i0_3, i1_3 in T.grid(1024, 4, 32, 1, 2, 8):
                    with T.block("T_matmul_NT_update"):
                        i = T.axis.spatial(384, i0_0_i1_0_fused // 2 * 16 + i0_1 * 8 + i0_2 * 2 + i0_3)
                        j = T.axis.spatial(1024, i0_0_i1_0_fused % 2 * 512 + i1_1 * 256 + i1_2 * 8 + i1_3)
                        k = T.axis.reduce(1024, i2_0)
                        T.reads(T_matmul_NT_global[i, j], placeholder[i, k], placeholder_1[j, k])
                        T.writes(T_matmul_NT_global[i, j])
                        T.block_attr({"layout_free_placeholders":[placeholder_1], "meta_schedule.tiling_structure":"SSRSRS"})
                        T_matmul_NT_global[i, j] = T_matmul_NT_global[i, j] + placeholder[i, k] * placeholder_1[j, k]
            for ax0, ax1 in T.grid(16, 512):
                with T.block("T_matmul_NT_global"):
                    v0 = T.axis.spatial(384, i0_0_i1_0_fused // 2 * 16 + ax0)
                    v1 = T.axis.spatial(1024, i0_0_i1_0_fused % 2 * 512 + ax1)
                    T.reads(T_matmul_NT_global[v0, v1])
                    T.writes(T_matmul_NT[v0, v1])
                    T_matmul_NT[v0, v1] = T_matmul_NT_global[v0, v1]
    

b0 = sch.get_block(name="T_matmul_NT", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4 = sch.get_loops(block=b0)
v5, v6, v7, v8 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[24, 2, 4, 2])
l9, l10, l11, l12 = sch.split(loop=l2, factors=[v5, v6, v7, v8])
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[2, 2, 32, 8])
l17, l18, l19, l20 = sch.split(loop=l3, factors=[v13, v14, v15, v16])
v21, v22 = sch.sample_perfect_tile(loop=l4, n=2, max_innermost_factor=64, decision=[1024, 1])
l23, l24 = sch.split(loop=l4, factors=[v21, v22])
sch.reorder(l9, l17, l10, l18, l23, l11, l19, l24, l12, l20)
b25 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="global")
sch.reverse_compute_at(block=b25, loop=l17, preserve_unit_loops=True)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=128)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v26 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v26)
sch.enter_postproc()
b27 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b27, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b27, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b27, ann_key="meta_schedule.unroll_explicit")
b28, b29 = sch.get_child_blocks(b27)
l30, l31, l32, l33, l34, l35, l36, l37, l38, l39 = sch.get_loops(block=b28)
l40 = sch.fuse(l30, l31)
sch.parallel(loop=l40)
sch.annotate(block_or_loop=l40, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l40, ann_key="pragma_unroll_explicit", ann_val=1)
l41, l42, l43 = sch.get_loops(block=b29)
sch.annotate(block_or_loop=l41, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l41, ann_key="pragma_unroll_explicit", ann_val=1)
b44 = sch.get_block(name="T_matmul_NT", func_name="main")
l45, l46, l47, l48, l49, l50, l51, l52, l53 = sch.get_loops(block=b44)
b54 = sch.decompose_reduction(block=b44, loop=l48)
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #13: GFLOPs: 6.9741. Time: 115.4707 ms. Best GFLOPs: 52.9462
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #14: GFLOPs: 9.8127. Time: 82.0674 ms. Best GFLOPs: 52.9462
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #15: GFLOPs: 37.7250. Time: 21.3467 ms. Best GFLOPs: 52.9462
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #16: GFLOPs: 35.5320. Time: 22.6643 ms. Best GFLOPs: 52.9462
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #17: GFLOPs: 39.8348. Time: 20.2161 ms. Best GFLOPs: 52.9462
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #18: GFLOPs: 25.1739. Time: 31.9898 ms. Best GFLOPs: 52.9462
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #19: GFLOPs: 43.2848. Time: 18.6048 ms. Best GFLOPs: 52.9462
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #20: GFLOPs: 45.5973. Time: 17.6613 ms. Best GFLOPs: 52.9462
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #21: GFLOPs: 15.0249. Time: 53.5982 ms. Best GFLOPs: 52.9462
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #22: GFLOPs: 16.1279. Time: 49.9326 ms. Best GFLOPs: 52.9462
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #23: GFLOPs: 38.0418. Time: 21.1690 ms. Best GFLOPs: 52.9462
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #24: GFLOPs: 4.0251. Time: 200.0717 ms. Best GFLOPs: 52.9462
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #25: GFLOPs: 5.5140. Time: 146.0470 ms. Best GFLOPs: 52.9462
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #26: GFLOPs: 4.0620. Time: 198.2514 ms. Best GFLOPs: 52.9462
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #27: GFLOPs: 23.8249. Time: 33.8010 ms. Best GFLOPs: 52.9462
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #28: GFLOPs: 9.2901. Time: 86.6842 ms. Best GFLOPs: 52.9462
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #29: GFLOPs: 11.1880. Time: 71.9796 ms. Best GFLOPs: 52.9462
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #30: GFLOPs: 6.8787. Time: 117.0721 ms. Best GFLOPs: 52.9462
[19:19:18] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #13: "fused_nn_dense"] Trial #31: GFLOPs: 60.6909. Time: 13.2690 ms. Best GFLOPs: 60.6909
[19:19:19] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #13: "fused_nn_dense"
 ID |                                                       Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                              fused_squeeze |          1 |      1 |         0.0001 |      12.6516 |               12.6516 |     32 |            
  1 |      fused_reshape_add_reshape_transpose_reshape_transpose |     393216 |     24 |         2.4269 |     162.0252 |             3888.6041 |     32 |            
  2 |       fused_expand_dims_expand_dims_cast_subtract_multiply |        768 |      1 |         0.0512 |      15.0019 |               15.0019 |     32 |            
  3 |    fused_reshape_add_reshape_transpose_reshape_transpose_1 |     393216 |     24 |         0.8998 |     437.0154 |            10488.3689 |     32 |            
  4 |                                                 fused_mean |     393600 |     49 |        10.0733 |      39.0736 |             1914.6079 |     32 |            
  5 |      fused_less_add_where_take_add_less_add_where_take_add |     787200 |      1 |        19.3910 |      40.5961 |               40.5961 |     32 |            
  6 |                fused_reshape_add_reshape_transpose_reshape |     393216 |     24 |         9.5277 |      41.2707 |              990.4966 |     32 |            
  7 |                                      fused_nn_batch_matmul |  301989888 |     24 |        86.3671 |    3496.5859 |            83918.0613 |     32 |            
  8 |                                   fused_reshape_divide_add |    4718592 |     24 |        47.1537 |     100.0683 |             2401.6391 |     32 |            
  9 |                                           fused_nn_softmax |    9437184 |     24 |         4.7145 |    2001.7558 |            48042.1395 |     32 |            
 10 |                                              fused_reshape |          1 |     24 |         0.0000 |      73.6705 |             1768.0929 |     32 |            
 11 |                                    fused_nn_batch_matmul_1 |  301989888 |     24 |        59.6188 |    5065.3446 |           121568.2700 |     32 |            
 12 |                            fused_reshape_transpose_reshape |          1 |     24 |         0.0000 |      63.3190 |             1519.6562 |     32 |            
 13 |                                             fused_nn_dense |  805306368 |     96 |        60.6909 |   13268.9729 |          1273821.3993 |     32 |            
 14 |                         fused_add_sqrt_divide_multiply_add |    1180032 |     48 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                            fused_reshape_1 |          1 |     48 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_dense_1 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_reshape_add_multiply_divide_erf_add_multiply_reshape |    7864320 |     24 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_dense_2 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 19 |                                      fused_reshape_add_add |     786432 |     48 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                             fused_subtract |     393216 |     49 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                           fused_power_mean |     393600 |     49 |            N/A |          N/A |                   N/A |      0 |            
 22 |                 fused_add_sqrt_divide_multiply_add_reshape |    1180032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                           fused_nn_dense_3 |    1572864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                    fused_reshape_add_split |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                            fused_squeeze_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 448
Total latency (us): 1.55039e+06

[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #0: GFLOPs: 30.8618. Time: 0.0382 ms. Best GFLOPs: 30.8618
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #1: GFLOPs: 30.0879. Time: 0.0392 ms. Best GFLOPs: 30.8618
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #2: GFLOPs: 31.9648. Time: 0.0369 ms. Best GFLOPs: 31.9648
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #3: GFLOPs: 30.6713. Time: 0.0385 ms. Best GFLOPs: 31.9648
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #4: GFLOPs: 33.0425. Time: 0.0357 ms. Best GFLOPs: 33.0425
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #5: GFLOPs: 34.5268. Time: 0.0342 ms. Best GFLOPs: 34.5268
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #6: GFLOPs: 27.5477. Time: 0.0428 ms. Best GFLOPs: 34.5268
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #7: GFLOPs: 31.7911. Time: 0.0371 ms. Best GFLOPs: 34.5268
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #8: GFLOPs: 32.3616. Time: 0.0365 ms. Best GFLOPs: 34.5268
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #9: GFLOPs: 29.4607. Time: 0.0401 ms. Best GFLOPs: 34.5268
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #10: GFLOPs: 30.2646. Time: 0.0390 ms. Best GFLOPs: 34.5268
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #11: GFLOPs: 34.0316. Time: 0.0347 ms. Best GFLOPs: 34.5268
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #12: GFLOPs: 28.4956. Time: 0.0414 ms. Best GFLOPs: 34.5268
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #13: GFLOPs: 30.7952. Time: 0.0383 ms. Best GFLOPs: 34.5268
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #14: GFLOPs: 31.9738. Time: 0.0369 ms. Best GFLOPs: 34.5268
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #15: GFLOPs: 31.1913. Time: 0.0378 ms. Best GFLOPs: 34.5268
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #16: GFLOPs: 31.4111. Time: 0.0376 ms. Best GFLOPs: 34.5268
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #17: GFLOPs: 31.6120. Time: 0.0373 ms. Best GFLOPs: 34.5268
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #18: GFLOPs: 31.7295. Time: 0.0372 ms. Best GFLOPs: 34.5268
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #19: GFLOPs: 29.4693. Time: 0.0400 ms. Best GFLOPs: 34.5268
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #20: GFLOPs: 33.2066. Time: 0.0355 ms. Best GFLOPs: 34.5268
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #21: GFLOPs: 32.4559. Time: 0.0364 ms. Best GFLOPs: 34.5268
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #22: GFLOPs: 32.7008. Time: 0.0361 ms. Best GFLOPs: 34.5268
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #23: GFLOPs: 32.6258. Time: 0.0362 ms. Best GFLOPs: 34.5268
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #24: GFLOPs: 32.2294. Time: 0.0366 ms. Best GFLOPs: 34.5268
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #25: GFLOPs: 32.0447. Time: 0.0368 ms. Best GFLOPs: 34.5268
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #26: GFLOPs: 30.4603. Time: 0.0387 ms. Best GFLOPs: 34.5268
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #27: GFLOPs: 31.8196. Time: 0.0371 ms. Best GFLOPs: 34.5268
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #28: GFLOPs: 30.8253. Time: 0.0383 ms. Best GFLOPs: 34.5268
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #29: GFLOPs: 31.8655. Time: 0.0370 ms. Best GFLOPs: 34.5268
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #30: GFLOPs: 31.2520. Time: 0.0378 ms. Best GFLOPs: 34.5268
[19:19:19] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #14: "fused_add_sqrt_divide_multiply_add"] Trial #31: GFLOPs: 33.3886. Time: 0.0353 ms. Best GFLOPs: 34.5268
[19:19:20] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #14: "fused_add_sqrt_divide_multiply_add"
 ID |                                                       Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                              fused_squeeze |          1 |      1 |         0.0001 |      12.6516 |               12.6516 |     32 |            
  1 |      fused_reshape_add_reshape_transpose_reshape_transpose |     393216 |     24 |         2.4269 |     162.0252 |             3888.6041 |     32 |            
  2 |       fused_expand_dims_expand_dims_cast_subtract_multiply |        768 |      1 |         0.0512 |      15.0019 |               15.0019 |     32 |            
  3 |    fused_reshape_add_reshape_transpose_reshape_transpose_1 |     393216 |     24 |         0.8998 |     437.0154 |            10488.3689 |     32 |            
  4 |                                                 fused_mean |     393600 |     49 |        10.0733 |      39.0736 |             1914.6079 |     32 |            
  5 |      fused_less_add_where_take_add_less_add_where_take_add |     787200 |      1 |        19.3910 |      40.5961 |               40.5961 |     32 |            
  6 |                fused_reshape_add_reshape_transpose_reshape |     393216 |     24 |         9.5277 |      41.2707 |              990.4966 |     32 |            
  7 |                                      fused_nn_batch_matmul |  301989888 |     24 |        86.3671 |    3496.5859 |            83918.0613 |     32 |            
  8 |                                   fused_reshape_divide_add |    4718592 |     24 |        47.1537 |     100.0683 |             2401.6391 |     32 |            
  9 |                                           fused_nn_softmax |    9437184 |     24 |         4.7145 |    2001.7558 |            48042.1395 |     32 |            
 10 |                                              fused_reshape |          1 |     24 |         0.0000 |      73.6705 |             1768.0929 |     32 |            
 11 |                                    fused_nn_batch_matmul_1 |  301989888 |     24 |        59.6188 |    5065.3446 |           121568.2700 |     32 |            
 12 |                            fused_reshape_transpose_reshape |          1 |     24 |         0.0000 |      63.3190 |             1519.6562 |     32 |            
 13 |                                             fused_nn_dense |  805306368 |     96 |        60.6909 |   13268.9729 |          1273821.3993 |     32 |            
 14 |                         fused_add_sqrt_divide_multiply_add |    1180032 |     48 |        34.5268 |      34.1772 |             1640.5078 |     32 |            
 15 |                                            fused_reshape_1 |          1 |     48 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_dense_1 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_reshape_add_multiply_divide_erf_add_multiply_reshape |    7864320 |     24 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_dense_2 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 19 |                                      fused_reshape_add_add |     786432 |     48 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                             fused_subtract |     393216 |     49 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                           fused_power_mean |     393600 |     49 |            N/A |          N/A |                   N/A |      0 |            
 22 |                 fused_add_sqrt_divide_multiply_add_reshape |    1180032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                           fused_nn_dense_3 |    1572864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                    fused_reshape_add_split |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                            fused_squeeze_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 480
Total latency (us): 1.55203e+06

[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #0: GFLOPs: 0.0000. Time: 0.0119 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #1: GFLOPs: 0.0000. Time: 0.0121 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #2: GFLOPs: 0.0000. Time: 0.0122 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #3: GFLOPs: 0.0000. Time: 0.0123 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #4: GFLOPs: 0.0000. Time: 0.0128 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #5: GFLOPs: 0.0000. Time: 0.0121 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #6: GFLOPs: 0.0000. Time: 0.0122 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #7: GFLOPs: 0.0000. Time: 0.0179 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #8: GFLOPs: 0.0000. Time: 0.0406 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #9: GFLOPs: 0.0000. Time: 0.1087 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #10: GFLOPs: 0.0000. Time: 0.0227 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #11: GFLOPs: 0.0000. Time: 0.0267 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #12: GFLOPs: 0.0000. Time: 0.0372 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #13: GFLOPs: 0.0000. Time: 0.0126 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #14: GFLOPs: 0.0000. Time: 0.0328 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #15: GFLOPs: 0.0000. Time: 0.0111 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #16: GFLOPs: 0.0000. Time: 0.0322 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #17: GFLOPs: 0.0000. Time: 0.0427 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #18: GFLOPs: 0.0000. Time: 0.0570 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #19: GFLOPs: 0.0000. Time: 0.0278 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #20: GFLOPs: 0.0000. Time: 0.0115 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #21: GFLOPs: 0.0000. Time: 0.0167 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #22: GFLOPs: 0.0000. Time: 0.0115 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #23: GFLOPs: 0.0000. Time: 0.0123 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #24: GFLOPs: 0.0000. Time: 0.0299 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #25: GFLOPs: 0.0000. Time: 0.0236 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #26: GFLOPs: 0.0000. Time: 0.0140 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #27: GFLOPs: 0.0000. Time: 0.0196 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #28: GFLOPs: 0.0000. Time: 0.0248 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #29: GFLOPs: 0.0000. Time: 0.0210 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #30: GFLOPs: 0.0000. Time: 0.0537 ms. Best GFLOPs: 0.0000
[19:19:20] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #15: "fused_reshape_1"] Trial #31: GFLOPs: 0.0000. Time: 0.0193 ms. Best GFLOPs: 0.0000
[19:19:21] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #15: "fused_reshape_1"
 ID |                                                       Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                              fused_squeeze |          1 |      1 |         0.0001 |      12.6516 |               12.6516 |     32 |            
  1 |      fused_reshape_add_reshape_transpose_reshape_transpose |     393216 |     24 |         2.4269 |     162.0252 |             3888.6041 |     32 |            
  2 |       fused_expand_dims_expand_dims_cast_subtract_multiply |        768 |      1 |         0.0512 |      15.0019 |               15.0019 |     32 |            
  3 |    fused_reshape_add_reshape_transpose_reshape_transpose_1 |     393216 |     24 |         0.8998 |     437.0154 |            10488.3689 |     32 |            
  4 |                                                 fused_mean |     393600 |     49 |        10.0733 |      39.0736 |             1914.6079 |     32 |            
  5 |      fused_less_add_where_take_add_less_add_where_take_add |     787200 |      1 |        19.3910 |      40.5961 |               40.5961 |     32 |            
  6 |                fused_reshape_add_reshape_transpose_reshape |     393216 |     24 |         9.5277 |      41.2707 |              990.4966 |     32 |            
  7 |                                      fused_nn_batch_matmul |  301989888 |     24 |        86.3671 |    3496.5859 |            83918.0613 |     32 |            
  8 |                                   fused_reshape_divide_add |    4718592 |     24 |        47.1537 |     100.0683 |             2401.6391 |     32 |            
  9 |                                           fused_nn_softmax |    9437184 |     24 |         4.7145 |    2001.7558 |            48042.1395 |     32 |            
 10 |                                              fused_reshape |          1 |     24 |         0.0000 |      73.6705 |             1768.0929 |     32 |            
 11 |                                    fused_nn_batch_matmul_1 |  301989888 |     24 |        59.6188 |    5065.3446 |           121568.2700 |     32 |            
 12 |                            fused_reshape_transpose_reshape |          1 |     24 |         0.0000 |      63.3190 |             1519.6562 |     32 |            
 13 |                                             fused_nn_dense |  805306368 |     96 |        60.6909 |   13268.9729 |          1273821.3993 |     32 |            
 14 |                         fused_add_sqrt_divide_multiply_add |    1180032 |     48 |        34.5268 |      34.1772 |             1640.5078 |     32 |            
 15 |                                            fused_reshape_1 |          1 |     48 |         0.0001 |      11.1313 |              534.3017 |     32 |            
 16 |                                           fused_nn_dense_1 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_reshape_add_multiply_divide_erf_add_multiply_reshape |    7864320 |     24 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_dense_2 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 19 |                                      fused_reshape_add_add |     786432 |     48 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                             fused_subtract |     393216 |     49 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                           fused_power_mean |     393600 |     49 |            N/A |          N/A |                   N/A |      0 |            
 22 |                 fused_add_sqrt_divide_multiply_add_reshape |    1180032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                           fused_nn_dense_3 |    1572864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                    fused_reshape_add_split |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                            fused_squeeze_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 512
Total latency (us): 1.55256e+06

[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #0: GFLOPs: 69.2701. Time: 46.5024 ms. Best GFLOPs: 69.2701
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #1: GFLOPs: 27.2659. Time: 118.1414 ms. Best GFLOPs: 69.2701
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #2: GFLOPs: 3.9897. Time: 807.3786 ms. Best GFLOPs: 69.2701
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #3: GFLOPs: 7.0806. Time: 454.9390 ms. Best GFLOPs: 69.2701
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #4: GFLOPs: 25.9862. Time: 123.9592 ms. Best GFLOPs: 69.2701
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #5: GFLOPs: 11.5848. Time: 278.0567 ms. Best GFLOPs: 69.2701
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #6: GFLOPs: 7.9170. Time: 406.8749 ms. Best GFLOPs: 69.2701
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #7: GFLOPs: 6.8791. Time: 468.2616 ms. Best GFLOPs: 69.2701
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #8: GFLOPs: 10.0560. Time: 320.3288 ms. Best GFLOPs: 69.2701
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #9: GFLOPs: 22.9291. Time: 140.4865 ms. Best GFLOPs: 69.2701
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #10: GFLOPs: 27.6873. Time: 116.3429 ms. Best GFLOPs: 69.2701
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #11: GFLOPs: 5.8649. Time: 549.2385 ms. Best GFLOPs: 69.2701
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #12: GFLOPs: 35.6006. Time: 90.4823 ms. Best GFLOPs: 69.2701
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #13: GFLOPs: 8.8438. Time: 364.2338 ms. Best GFLOPs: 69.2701
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #14: GFLOPs: 5.9085. Time: 545.1816 ms. Best GFLOPs: 69.2701
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #15: GFLOPs: 46.4908. Time: 69.2873 ms. Best GFLOPs: 69.2701
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #16: GFLOPs: 35.2908. Time: 91.2767 ms. Best GFLOPs: 69.2701
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #17: GFLOPs: 6.1300. Time: 525.4863 ms. Best GFLOPs: 69.2701
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #18: GFLOPs: 20.6275. Time: 156.1619 ms. Best GFLOPs: 69.2701
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #19: GFLOPs: 41.4985. Time: 77.6228 ms. Best GFLOPs: 69.2701
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #20: GFLOPs: 20.3749. Time: 158.0979 ms. Best GFLOPs: 69.2701
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #21: GFLOPs: 74.8792. Time: 43.0189 ms. Best GFLOPs: 74.8792
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #22: GFLOPs: 17.5160. Time: 183.9015 ms. Best GFLOPs: 74.8792
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #23: GFLOPs: 36.9834. Time: 87.0992 ms. Best GFLOPs: 74.8792
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #24: GFLOPs: 37.4642. Time: 85.9815 ms. Best GFLOPs: 74.8792
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #25: GFLOPs: 38.7608. Time: 83.1053 ms. Best GFLOPs: 74.8792
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #26: GFLOPs: 79.3862. Time: 40.5766 ms. Best GFLOPs: 79.3862
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #27: GFLOPs: 26.3402. Time: 122.2933 ms. Best GFLOPs: 79.3862
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #28: GFLOPs: 7.1960. Time: 447.6386 ms. Best GFLOPs: 79.3862
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #29: GFLOPs: 71.4919. Time: 45.0572 ms. Best GFLOPs: 79.3862
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #30: GFLOPs: 57.0894. Time: 56.4242 ms. Best GFLOPs: 79.3862
[19:19:21] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #16: "fused_nn_dense_1"] Trial #31: GFLOPs: 26.5561. Time: 121.2988 ms. Best GFLOPs: 79.3862
[19:19:22] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #16: "fused_nn_dense_1"
 ID |                                                       Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                              fused_squeeze |          1 |      1 |         0.0001 |      12.6516 |               12.6516 |     32 |            
  1 |      fused_reshape_add_reshape_transpose_reshape_transpose |     393216 |     24 |         2.4269 |     162.0252 |             3888.6041 |     32 |            
  2 |       fused_expand_dims_expand_dims_cast_subtract_multiply |        768 |      1 |         0.0512 |      15.0019 |               15.0019 |     32 |            
  3 |    fused_reshape_add_reshape_transpose_reshape_transpose_1 |     393216 |     24 |         0.8998 |     437.0154 |            10488.3689 |     32 |            
  4 |                                                 fused_mean |     393600 |     49 |        10.0733 |      39.0736 |             1914.6079 |     32 |            
  5 |      fused_less_add_where_take_add_less_add_where_take_add |     787200 |      1 |        19.3910 |      40.5961 |               40.5961 |     32 |            
  6 |                fused_reshape_add_reshape_transpose_reshape |     393216 |     24 |         9.5277 |      41.2707 |              990.4966 |     32 |            
  7 |                                      fused_nn_batch_matmul |  301989888 |     24 |        86.3671 |    3496.5859 |            83918.0613 |     32 |            
  8 |                                   fused_reshape_divide_add |    4718592 |     24 |        47.1537 |     100.0683 |             2401.6391 |     32 |            
  9 |                                           fused_nn_softmax |    9437184 |     24 |         4.7145 |    2001.7558 |            48042.1395 |     32 |            
 10 |                                              fused_reshape |          1 |     24 |         0.0000 |      73.6705 |             1768.0929 |     32 |            
 11 |                                    fused_nn_batch_matmul_1 |  301989888 |     24 |        59.6188 |    5065.3446 |           121568.2700 |     32 |            
 12 |                            fused_reshape_transpose_reshape |          1 |     24 |         0.0000 |      63.3190 |             1519.6562 |     32 |            
 13 |                                             fused_nn_dense |  805306368 |     96 |        60.6909 |   13268.9729 |          1273821.3993 |     32 |            
 14 |                         fused_add_sqrt_divide_multiply_add |    1180032 |     48 |        34.5268 |      34.1772 |             1640.5078 |     32 |            
 15 |                                            fused_reshape_1 |          1 |     48 |         0.0001 |      11.1313 |              534.3017 |     32 |            
 16 |                                           fused_nn_dense_1 | 3221225472 |     24 |        79.3862 |   40576.6247 |           973838.9920 |     32 |            
 17 | fused_reshape_add_multiply_divide_erf_add_multiply_reshape |    7864320 |     24 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_dense_2 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 19 |                                      fused_reshape_add_add |     786432 |     48 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                             fused_subtract |     393216 |     49 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                           fused_power_mean |     393600 |     49 |            N/A |          N/A |                   N/A |      0 |            
 22 |                 fused_add_sqrt_divide_multiply_add_reshape |    1180032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                           fused_nn_dense_3 |    1572864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                    fused_reshape_add_split |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                            fused_squeeze_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 544
Total latency (us): 2.5264e+06

[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #0: GFLOPs: 1.6213. Time: 4.8507 ms. Best GFLOPs: 1.6213
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #1: GFLOPs: 1.6188. Time: 4.8580 ms. Best GFLOPs: 1.6213
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #2: GFLOPs: 1.6388. Time: 4.7988 ms. Best GFLOPs: 1.6388
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #3: GFLOPs: 1.9932. Time: 3.9455 ms. Best GFLOPs: 1.9932
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #4: GFLOPs: 2.0551. Time: 3.8268 ms. Best GFLOPs: 2.0551
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #5: GFLOPs: 1.3907. Time: 5.6548 ms. Best GFLOPs: 2.0551
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #6: GFLOPs: 1.8040. Time: 4.3594 ms. Best GFLOPs: 2.0551
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #7: GFLOPs: 2.0650. Time: 3.8083 ms. Best GFLOPs: 2.0650
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #8: GFLOPs: 1.4989. Time: 5.2469 ms. Best GFLOPs: 2.0650
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #9: GFLOPs: 4.0371. Time: 1.9480 ms. Best GFLOPs: 4.0371
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #10: GFLOPs: 3.5541. Time: 2.2127 ms. Best GFLOPs: 4.0371
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #11: GFLOPs: 4.0001. Time: 1.9661 ms. Best GFLOPs: 4.0371
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #12: GFLOPs: 4.0892. Time: 1.9232 ms. Best GFLOPs: 4.0892
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #13: GFLOPs: 3.7672. Time: 2.0876 ms. Best GFLOPs: 4.0892
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #14: GFLOPs: 4.0321. Time: 1.9504 ms. Best GFLOPs: 4.0892
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #15: GFLOPs: 4.0963. Time: 1.9199 ms. Best GFLOPs: 4.0963
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #16: GFLOPs: 2.5936. Time: 3.0322 ms. Best GFLOPs: 4.0963
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #17: GFLOPs: 1.9161. Time: 4.1043 ms. Best GFLOPs: 4.0963
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #18: GFLOPs: 2.1612. Time: 3.6389 ms. Best GFLOPs: 4.0963
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #19: GFLOPs: 2.6332. Time: 2.9866 ms. Best GFLOPs: 4.0963
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #20: GFLOPs: 2.9758. Time: 2.6428 ms. Best GFLOPs: 4.0963
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #21: GFLOPs: 2.5961. Time: 3.0293 ms. Best GFLOPs: 4.0963
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #22: GFLOPs: 1.7596. Time: 4.4695 ms. Best GFLOPs: 4.0963
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #23: GFLOPs: 2.5320. Time: 3.1060 ms. Best GFLOPs: 4.0963
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #24: GFLOPs: 2.6955. Time: 2.9176 ms. Best GFLOPs: 4.0963
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #25: GFLOPs: 2.7615. Time: 2.8478 ms. Best GFLOPs: 4.0963
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #26: GFLOPs: 3.6948. Time: 2.1285 ms. Best GFLOPs: 4.0963
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #27: GFLOPs: 2.3712. Time: 3.3167 ms. Best GFLOPs: 4.0963
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #28: GFLOPs: 2.6731. Time: 2.9420 ms. Best GFLOPs: 4.0963
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #29: GFLOPs: 2.4048. Time: 3.2703 ms. Best GFLOPs: 4.0963
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #30: GFLOPs: 1.7865. Time: 4.4020 ms. Best GFLOPs: 4.0963
[19:19:22] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"] Trial #31: GFLOPs: 2.3612. Time: 3.3306 ms. Best GFLOPs: 4.0963
[19:19:23] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"
 ID |                                                       Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                              fused_squeeze |          1 |      1 |         0.0001 |      12.6516 |               12.6516 |     32 |            
  1 |      fused_reshape_add_reshape_transpose_reshape_transpose |     393216 |     24 |         2.4269 |     162.0252 |             3888.6041 |     32 |            
  2 |       fused_expand_dims_expand_dims_cast_subtract_multiply |        768 |      1 |         0.0512 |      15.0019 |               15.0019 |     32 |            
  3 |    fused_reshape_add_reshape_transpose_reshape_transpose_1 |     393216 |     24 |         0.8998 |     437.0154 |            10488.3689 |     32 |            
  4 |                                                 fused_mean |     393600 |     49 |        10.0733 |      39.0736 |             1914.6079 |     32 |            
  5 |      fused_less_add_where_take_add_less_add_where_take_add |     787200 |      1 |        19.3910 |      40.5961 |               40.5961 |     32 |            
  6 |                fused_reshape_add_reshape_transpose_reshape |     393216 |     24 |         9.5277 |      41.2707 |              990.4966 |     32 |            
  7 |                                      fused_nn_batch_matmul |  301989888 |     24 |        86.3671 |    3496.5859 |            83918.0613 |     32 |            
  8 |                                   fused_reshape_divide_add |    4718592 |     24 |        47.1537 |     100.0683 |             2401.6391 |     32 |            
  9 |                                           fused_nn_softmax |    9437184 |     24 |         4.7145 |    2001.7558 |            48042.1395 |     32 |            
 10 |                                              fused_reshape |          1 |     24 |         0.0000 |      73.6705 |             1768.0929 |     32 |            
 11 |                                    fused_nn_batch_matmul_1 |  301989888 |     24 |        59.6188 |    5065.3446 |           121568.2700 |     32 |            
 12 |                            fused_reshape_transpose_reshape |          1 |     24 |         0.0000 |      63.3190 |             1519.6562 |     32 |            
 13 |                                             fused_nn_dense |  805306368 |     96 |        60.6909 |   13268.9729 |          1273821.3993 |     32 |            
 14 |                         fused_add_sqrt_divide_multiply_add |    1180032 |     48 |        34.5268 |      34.1772 |             1640.5078 |     32 |            
 15 |                                            fused_reshape_1 |          1 |     48 |         0.0001 |      11.1313 |              534.3017 |     32 |            
 16 |                                           fused_nn_dense_1 | 3221225472 |     24 |        79.3862 |   40576.6247 |           973838.9920 |     32 |            
 17 | fused_reshape_add_multiply_divide_erf_add_multiply_reshape |    7864320 |     24 |         4.0963 |    1919.8607 |            46076.6573 |     32 |            
 18 |                                           fused_nn_dense_2 | 3221225472 |     24 |            N/A |          N/A |                   N/A |      0 |            
 19 |                                      fused_reshape_add_add |     786432 |     48 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                             fused_subtract |     393216 |     49 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                           fused_power_mean |     393600 |     49 |            N/A |          N/A |                   N/A |      0 |            
 22 |                 fused_add_sqrt_divide_multiply_add_reshape |    1180032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                           fused_nn_dense_3 |    1572864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                    fused_reshape_add_split |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                            fused_squeeze_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 576
Total latency (us): 2.57248e+06

[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #0: GFLOPs: 59.0883. Time: 54.5154 ms. Best GFLOPs: 59.0883
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #1: GFLOPs: 3.2682. Time: 985.6321 ms. Best GFLOPs: 59.0883
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #2: GFLOPs: 32.7258. Time: 98.4309 ms. Best GFLOPs: 59.0883
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #3: GFLOPs: 32.7462. Time: 98.3696 ms. Best GFLOPs: 59.0883
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #4: GFLOPs: 5.4452. Time: 591.5663 ms. Best GFLOPs: 59.0883
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #5: GFLOPs: 76.6918. Time: 42.0022 ms. Best GFLOPs: 76.6918
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #6: GFLOPs: 69.5884. Time: 46.2897 ms. Best GFLOPs: 76.6918
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #7: GFLOPs: 54.6177. Time: 58.9777 ms. Best GFLOPs: 76.6918
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #8: GFLOPs: 48.9704. Time: 65.7790 ms. Best GFLOPs: 76.6918
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #9: GFLOPs: 18.5035. Time: 174.0875 ms. Best GFLOPs: 76.6918
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #10: GFLOPs: 3.3998. Time: 947.4629 ms. Best GFLOPs: 76.6918
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #11: GFLOPs: 37.3154. Time: 86.3243 ms. Best GFLOPs: 76.6918
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #12: GFLOPs: 107.5352. Time: 29.9551 ms. Best GFLOPs: 107.5352
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #13: GFLOPs: 34.7623. Time: 92.6643 ms. Best GFLOPs: 107.5352
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #14: GFLOPs: 30.2650. Time: 106.4341 ms. Best GFLOPs: 107.5352
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #15: GFLOPs: 114.9441. Time: 28.0243 ms. Best GFLOPs: 114.9441
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #16: GFLOPs: 20.0937. Time: 160.3102 ms. Best GFLOPs: 114.9441
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #17: GFLOPs: 12.0707. Time: 266.8629 ms. Best GFLOPs: 114.9441
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #18: GFLOPs: 97.9625. Time: 32.8822 ms. Best GFLOPs: 114.9441
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #19: GFLOPs: 44.3795. Time: 72.5836 ms. Best GFLOPs: 114.9441
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #20: GFLOPs: 12.3214. Time: 261.4341 ms. Best GFLOPs: 114.9441
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #21: GFLOPs: 35.1939. Time: 91.5280 ms. Best GFLOPs: 114.9441
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #22: GFLOPs: 9.4396. Time: 341.2453 ms. Best GFLOPs: 114.9441
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #23: GFLOPs: 4.0318. Time: 798.9592 ms. Best GFLOPs: 114.9441
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #24: GFLOPs: 76.5878. Time: 42.0593 ms. Best GFLOPs: 114.9441
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #25: GFLOPs: 27.7700. Time: 115.9966 ms. Best GFLOPs: 114.9441
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #26: GFLOPs: 75.2384. Time: 42.8136 ms. Best GFLOPs: 114.9441
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #27: GFLOPs: 44.0581. Time: 73.1131 ms. Best GFLOPs: 114.9441
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #28: GFLOPs: 19.5214. Time: 165.0100 ms. Best GFLOPs: 114.9441
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #29: GFLOPs: 1.1638. Time: 2767.9306 ms. Best GFLOPs: 114.9441
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #30: GFLOPs: 6.7164. Time: 479.6089 ms. Best GFLOPs: 114.9441
[19:19:23] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #18: "fused_nn_dense_2"] Trial #31: GFLOPs: 18.9648. Time: 169.8531 ms. Best GFLOPs: 114.9441
[19:19:24] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #18: "fused_nn_dense_2"
 ID |                                                       Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                              fused_squeeze |          1 |      1 |         0.0001 |      12.6516 |               12.6516 |     32 |            
  1 |      fused_reshape_add_reshape_transpose_reshape_transpose |     393216 |     24 |         2.4269 |     162.0252 |             3888.6041 |     32 |            
  2 |       fused_expand_dims_expand_dims_cast_subtract_multiply |        768 |      1 |         0.0512 |      15.0019 |               15.0019 |     32 |            
  3 |    fused_reshape_add_reshape_transpose_reshape_transpose_1 |     393216 |     24 |         0.8998 |     437.0154 |            10488.3689 |     32 |            
  4 |                                                 fused_mean |     393600 |     49 |        10.0733 |      39.0736 |             1914.6079 |     32 |            
  5 |      fused_less_add_where_take_add_less_add_where_take_add |     787200 |      1 |        19.3910 |      40.5961 |               40.5961 |     32 |            
  6 |                fused_reshape_add_reshape_transpose_reshape |     393216 |     24 |         9.5277 |      41.2707 |              990.4966 |     32 |            
  7 |                                      fused_nn_batch_matmul |  301989888 |     24 |        86.3671 |    3496.5859 |            83918.0613 |     32 |            
  8 |                                   fused_reshape_divide_add |    4718592 |     24 |        47.1537 |     100.0683 |             2401.6391 |     32 |            
  9 |                                           fused_nn_softmax |    9437184 |     24 |         4.7145 |    2001.7558 |            48042.1395 |     32 |            
 10 |                                              fused_reshape |          1 |     24 |         0.0000 |      73.6705 |             1768.0929 |     32 |            
 11 |                                    fused_nn_batch_matmul_1 |  301989888 |     24 |        59.6188 |    5065.3446 |           121568.2700 |     32 |            
 12 |                            fused_reshape_transpose_reshape |          1 |     24 |         0.0000 |      63.3190 |             1519.6562 |     32 |            
 13 |                                             fused_nn_dense |  805306368 |     96 |        60.6909 |   13268.9729 |          1273821.3993 |     32 |            
 14 |                         fused_add_sqrt_divide_multiply_add |    1180032 |     48 |        34.5268 |      34.1772 |             1640.5078 |     32 |            
 15 |                                            fused_reshape_1 |          1 |     48 |         0.0001 |      11.1313 |              534.3017 |     32 |            
 16 |                                           fused_nn_dense_1 | 3221225472 |     24 |        79.3862 |   40576.6247 |           973838.9920 |     32 |            
 17 | fused_reshape_add_multiply_divide_erf_add_multiply_reshape |    7864320 |     24 |         4.0963 |    1919.8607 |            46076.6573 |     32 |            
 18 |                                           fused_nn_dense_2 | 3221225472 |     24 |       114.9441 |   28024.2894 |           672582.9456 |     32 |            
 19 |                                      fused_reshape_add_add |     786432 |     48 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                             fused_subtract |     393216 |     49 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                           fused_power_mean |     393600 |     49 |            N/A |          N/A |                   N/A |      0 |            
 22 |                 fused_add_sqrt_divide_multiply_add_reshape |    1180032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                           fused_nn_dense_3 |    1572864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                    fused_reshape_add_split |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                            fused_squeeze_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 608
Total latency (us): 3.24506e+06

[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #0: GFLOPs: 26.6625. Time: 0.0295 ms. Best GFLOPs: 26.6625
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #1: GFLOPs: 25.0421. Time: 0.0314 ms. Best GFLOPs: 26.6625
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #2: GFLOPs: 13.1878. Time: 0.0596 ms. Best GFLOPs: 26.6625
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #3: GFLOPs: 13.5720. Time: 0.0579 ms. Best GFLOPs: 26.6625
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #4: GFLOPs: 26.1784. Time: 0.0300 ms. Best GFLOPs: 26.6625
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #5: GFLOPs: 24.2378. Time: 0.0324 ms. Best GFLOPs: 26.6625
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #6: GFLOPs: 22.4811. Time: 0.0350 ms. Best GFLOPs: 26.6625
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #7: GFLOPs: 23.8329. Time: 0.0330 ms. Best GFLOPs: 26.6625
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #8: GFLOPs: 24.4951. Time: 0.0321 ms. Best GFLOPs: 26.6625
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #9: GFLOPs: 24.7422. Time: 0.0318 ms. Best GFLOPs: 26.6625
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #10: GFLOPs: 9.2367. Time: 0.0851 ms. Best GFLOPs: 26.6625
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #11: GFLOPs: 25.1044. Time: 0.0313 ms. Best GFLOPs: 26.6625
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #12: GFLOPs: 13.3861. Time: 0.0587 ms. Best GFLOPs: 26.6625
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #13: GFLOPs: 24.7745. Time: 0.0317 ms. Best GFLOPs: 26.6625
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #14: GFLOPs: 14.9989. Time: 0.0524 ms. Best GFLOPs: 26.6625
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #15: GFLOPs: 23.4359. Time: 0.0336 ms. Best GFLOPs: 26.6625
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #16: GFLOPs: 10.4562. Time: 0.0752 ms. Best GFLOPs: 26.6625
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #17: GFLOPs: 48.4813. Time: 0.0162 ms. Best GFLOPs: 48.4813
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #18: GFLOPs: 18.1160. Time: 0.0434 ms. Best GFLOPs: 48.4813
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #19: GFLOPs: 48.8159. Time: 0.0161 ms. Best GFLOPs: 48.8159
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #20: GFLOPs: 48.3190. Time: 0.0163 ms. Best GFLOPs: 48.8159
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #21: GFLOPs: 49.3365. Time: 0.0159 ms. Best GFLOPs: 49.3365
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #22: GFLOPs: 48.1883. Time: 0.0163 ms. Best GFLOPs: 49.3365
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #23: GFLOPs: 26.0746. Time: 0.0302 ms. Best GFLOPs: 49.3365
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #24: GFLOPs: 26.5358. Time: 0.0296 ms. Best GFLOPs: 49.3365
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #25: GFLOPs: 49.4058. Time: 0.0159 ms. Best GFLOPs: 49.4058
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #26: GFLOPs: 26.7814. Time: 0.0294 ms. Best GFLOPs: 49.4058
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #27: GFLOPs: 26.5235. Time: 0.0297 ms. Best GFLOPs: 49.4058
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #28: GFLOPs: 26.7219. Time: 0.0294 ms. Best GFLOPs: 49.4058
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #29: GFLOPs: 18.0570. Time: 0.0436 ms. Best GFLOPs: 49.4058
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #30: GFLOPs: 48.0804. Time: 0.0164 ms. Best GFLOPs: 49.4058
[19:19:24] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #19: "fused_reshape_add_add"] Trial #31: GFLOPs: 18.4540. Time: 0.0426 ms. Best GFLOPs: 49.4058
[19:19:25] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #19: "fused_reshape_add_add"
 ID |                                                       Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                              fused_squeeze |          1 |      1 |         0.0001 |      12.6516 |               12.6516 |     32 |            
  1 |      fused_reshape_add_reshape_transpose_reshape_transpose |     393216 |     24 |         2.4269 |     162.0252 |             3888.6041 |     32 |            
  2 |       fused_expand_dims_expand_dims_cast_subtract_multiply |        768 |      1 |         0.0512 |      15.0019 |               15.0019 |     32 |            
  3 |    fused_reshape_add_reshape_transpose_reshape_transpose_1 |     393216 |     24 |         0.8998 |     437.0154 |            10488.3689 |     32 |            
  4 |                                                 fused_mean |     393600 |     49 |        10.0733 |      39.0736 |             1914.6079 |     32 |            
  5 |      fused_less_add_where_take_add_less_add_where_take_add |     787200 |      1 |        19.3910 |      40.5961 |               40.5961 |     32 |            
  6 |                fused_reshape_add_reshape_transpose_reshape |     393216 |     24 |         9.5277 |      41.2707 |              990.4966 |     32 |            
  7 |                                      fused_nn_batch_matmul |  301989888 |     24 |        86.3671 |    3496.5859 |            83918.0613 |     32 |            
  8 |                                   fused_reshape_divide_add |    4718592 |     24 |        47.1537 |     100.0683 |             2401.6391 |     32 |            
  9 |                                           fused_nn_softmax |    9437184 |     24 |         4.7145 |    2001.7558 |            48042.1395 |     32 |            
 10 |                                              fused_reshape |          1 |     24 |         0.0000 |      73.6705 |             1768.0929 |     32 |            
 11 |                                    fused_nn_batch_matmul_1 |  301989888 |     24 |        59.6188 |    5065.3446 |           121568.2700 |     32 |            
 12 |                            fused_reshape_transpose_reshape |          1 |     24 |         0.0000 |      63.3190 |             1519.6562 |     32 |            
 13 |                                             fused_nn_dense |  805306368 |     96 |        60.6909 |   13268.9729 |          1273821.3993 |     32 |            
 14 |                         fused_add_sqrt_divide_multiply_add |    1180032 |     48 |        34.5268 |      34.1772 |             1640.5078 |     32 |            
 15 |                                            fused_reshape_1 |          1 |     48 |         0.0001 |      11.1313 |              534.3017 |     32 |            
 16 |                                           fused_nn_dense_1 | 3221225472 |     24 |        79.3862 |   40576.6247 |           973838.9920 |     32 |            
 17 | fused_reshape_add_multiply_divide_erf_add_multiply_reshape |    7864320 |     24 |         4.0963 |    1919.8607 |            46076.6573 |     32 |            
 18 |                                           fused_nn_dense_2 | 3221225472 |     24 |       114.9441 |   28024.2894 |           672582.9456 |     32 |            
 19 |                                      fused_reshape_add_add |     786432 |     48 |        49.4058 |      15.9178 |              764.0545 |     32 |            
 20 |                                             fused_subtract |     393216 |     49 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                           fused_power_mean |     393600 |     49 |            N/A |          N/A |                   N/A |      0 |            
 22 |                 fused_add_sqrt_divide_multiply_add_reshape |    1180032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                           fused_nn_dense_3 |    1572864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                    fused_reshape_add_split |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                            fused_squeeze_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 640
Total latency (us): 3.24583e+06

[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #0: GFLOPs: 15.7549. Time: 0.0250 ms. Best GFLOPs: 15.7549
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #1: GFLOPs: 32.5056. Time: 0.0121 ms. Best GFLOPs: 32.5056
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #2: GFLOPs: 36.4266. Time: 0.0108 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #3: GFLOPs: 26.0581. Time: 0.0151 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #4: GFLOPs: 18.1969. Time: 0.0216 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #5: GFLOPs: 13.4758. Time: 0.0292 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #6: GFLOPs: 19.7245. Time: 0.0199 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #7: GFLOPs: 23.7669. Time: 0.0165 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #8: GFLOPs: 18.8159. Time: 0.0209 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #9: GFLOPs: 9.5865. Time: 0.0410 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #10: GFLOPs: 7.8425. Time: 0.0501 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #11: GFLOPs: 23.3004. Time: 0.0169 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #12: GFLOPs: 12.3216. Time: 0.0319 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #13: GFLOPs: 15.5046. Time: 0.0254 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #14: GFLOPs: 22.6747. Time: 0.0173 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #15: GFLOPs: 32.7527. Time: 0.0120 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #16: GFLOPs: 26.3154. Time: 0.0149 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #17: GFLOPs: 9.5990. Time: 0.0410 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #18: GFLOPs: 15.3327. Time: 0.0256 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #19: GFLOPs: 22.1790. Time: 0.0177 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #20: GFLOPs: 12.0958. Time: 0.0325 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #21: GFLOPs: 9.2176. Time: 0.0427 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #22: GFLOPs: 18.6574. Time: 0.0211 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #23: GFLOPs: 8.7385. Time: 0.0450 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #24: GFLOPs: 6.3048. Time: 0.0624 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #25: GFLOPs: 13.7058. Time: 0.0287 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #26: GFLOPs: 7.5826. Time: 0.0519 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #27: GFLOPs: 10.5828. Time: 0.0372 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #28: GFLOPs: 14.0260. Time: 0.0280 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #29: GFLOPs: 8.9095. Time: 0.0441 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #30: GFLOPs: 8.1558. Time: 0.0482 ms. Best GFLOPs: 36.4266
[19:19:25] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #20: "fused_subtract"] Trial #31: GFLOPs: 0.8090. Time: 0.4860 ms. Best GFLOPs: 36.4266
[19:19:26] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #20: "fused_subtract"
 ID |                                                       Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                              fused_squeeze |          1 |      1 |         0.0001 |      12.6516 |               12.6516 |     32 |            
  1 |      fused_reshape_add_reshape_transpose_reshape_transpose |     393216 |     24 |         2.4269 |     162.0252 |             3888.6041 |     32 |            
  2 |       fused_expand_dims_expand_dims_cast_subtract_multiply |        768 |      1 |         0.0512 |      15.0019 |               15.0019 |     32 |            
  3 |    fused_reshape_add_reshape_transpose_reshape_transpose_1 |     393216 |     24 |         0.8998 |     437.0154 |            10488.3689 |     32 |            
  4 |                                                 fused_mean |     393600 |     49 |        10.0733 |      39.0736 |             1914.6079 |     32 |            
  5 |      fused_less_add_where_take_add_less_add_where_take_add |     787200 |      1 |        19.3910 |      40.5961 |               40.5961 |     32 |            
  6 |                fused_reshape_add_reshape_transpose_reshape |     393216 |     24 |         9.5277 |      41.2707 |              990.4966 |     32 |            
  7 |                                      fused_nn_batch_matmul |  301989888 |     24 |        86.3671 |    3496.5859 |            83918.0613 |     32 |            
  8 |                                   fused_reshape_divide_add |    4718592 |     24 |        47.1537 |     100.0683 |             2401.6391 |     32 |            
  9 |                                           fused_nn_softmax |    9437184 |     24 |         4.7145 |    2001.7558 |            48042.1395 |     32 |            
 10 |                                              fused_reshape |          1 |     24 |         0.0000 |      73.6705 |             1768.0929 |     32 |            
 11 |                                    fused_nn_batch_matmul_1 |  301989888 |     24 |        59.6188 |    5065.3446 |           121568.2700 |     32 |            
 12 |                            fused_reshape_transpose_reshape |          1 |     24 |         0.0000 |      63.3190 |             1519.6562 |     32 |            
 13 |                                             fused_nn_dense |  805306368 |     96 |        60.6909 |   13268.9729 |          1273821.3993 |     32 |            
 14 |                         fused_add_sqrt_divide_multiply_add |    1180032 |     48 |        34.5268 |      34.1772 |             1640.5078 |     32 |            
 15 |                                            fused_reshape_1 |          1 |     48 |         0.0001 |      11.1313 |              534.3017 |     32 |            
 16 |                                           fused_nn_dense_1 | 3221225472 |     24 |        79.3862 |   40576.6247 |           973838.9920 |     32 |            
 17 | fused_reshape_add_multiply_divide_erf_add_multiply_reshape |    7864320 |     24 |         4.0963 |    1919.8607 |            46076.6573 |     32 |            
 18 |                                           fused_nn_dense_2 | 3221225472 |     24 |       114.9441 |   28024.2894 |           672582.9456 |     32 |            
 19 |                                      fused_reshape_add_add |     786432 |     48 |        49.4058 |      15.9178 |              764.0545 |     32 |            
 20 |                                             fused_subtract |     393216 |     49 |        36.4266 |      10.7947 |              528.9426 |     32 |            
 21 |                                           fused_power_mean |     393600 |     49 |            N/A |          N/A |                   N/A |      0 |            
 22 |                 fused_add_sqrt_divide_multiply_add_reshape |    1180032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                           fused_nn_dense_3 |    1572864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                    fused_reshape_add_split |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                            fused_squeeze_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 672
Total latency (us): 3.24636e+06

[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #0: GFLOPs: 0.0590. Time: 6.6666 ms. Best GFLOPs: 0.0590
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #1: GFLOPs: 0.2652. Time: 1.4842 ms. Best GFLOPs: 0.2652
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #2: GFLOPs: 0.1886. Time: 2.0866 ms. Best GFLOPs: 0.2652
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #3: GFLOPs: 0.2220. Time: 1.7733 ms. Best GFLOPs: 0.2652
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #4: GFLOPs: 0.8305. Time: 0.4739 ms. Best GFLOPs: 0.8305
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #5: GFLOPs: 1.7085. Time: 0.2304 ms. Best GFLOPs: 1.7085
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #6: GFLOPs: 1.8286. Time: 0.2152 ms. Best GFLOPs: 1.8286
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #7: GFLOPs: 2.1484. Time: 0.1832 ms. Best GFLOPs: 2.1484
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #8: GFLOPs: 3.9388. Time: 0.0999 ms. Best GFLOPs: 3.9388
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #9: GFLOPs: 9.0959. Time: 0.0433 ms. Best GFLOPs: 9.0959
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #10: GFLOPs: 1.2801. Time: 0.3075 ms. Best GFLOPs: 9.0959
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #11: GFLOPs: 2.8059. Time: 0.1403 ms. Best GFLOPs: 9.0959
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #12: GFLOPs: 1.7808. Time: 0.2210 ms. Best GFLOPs: 9.0959
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #13: GFLOPs: 2.9783. Time: 0.1322 ms. Best GFLOPs: 9.0959
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #14: GFLOPs: 1.9471. Time: 0.2021 ms. Best GFLOPs: 9.0959
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #15: GFLOPs: 2.7042. Time: 0.1456 ms. Best GFLOPs: 9.0959
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #16: GFLOPs: 3.8651. Time: 0.1018 ms. Best GFLOPs: 9.0959
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #17: GFLOPs: 3.7357. Time: 0.1054 ms. Best GFLOPs: 9.0959
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #18: GFLOPs: 1.9320. Time: 0.2037 ms. Best GFLOPs: 9.0959
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #19: GFLOPs: 6.8154. Time: 0.0578 ms. Best GFLOPs: 9.0959
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #20: GFLOPs: 1.9092. Time: 0.2062 ms. Best GFLOPs: 9.0959
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #21: GFLOPs: 9.1047. Time: 0.0432 ms. Best GFLOPs: 9.1047
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #22: GFLOPs: 2.0262. Time: 0.1943 ms. Best GFLOPs: 9.1047
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #23: GFLOPs: 2.4411. Time: 0.1612 ms. Best GFLOPs: 9.1047
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #24: GFLOPs: 2.2086. Time: 0.1782 ms. Best GFLOPs: 9.1047
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #25: GFLOPs: 3.6824. Time: 0.1069 ms. Best GFLOPs: 9.1047
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #26: GFLOPs: 2.4871. Time: 0.1583 ms. Best GFLOPs: 9.1047
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #27: GFLOPs: 1.7056. Time: 0.2308 ms. Best GFLOPs: 9.1047
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #28: GFLOPs: 2.4288. Time: 0.1621 ms. Best GFLOPs: 9.1047
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #29: GFLOPs: 2.6215. Time: 0.1501 ms. Best GFLOPs: 9.1047
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #30: GFLOPs: 4.0606. Time: 0.0969 ms. Best GFLOPs: 9.1047
[19:19:26] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #21: "fused_power_mean"] Trial #31: GFLOPs: 4.4246. Time: 0.0890 ms. Best GFLOPs: 9.1047
[19:19:26] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #21: "fused_power_mean"
 ID |                                                       Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                              fused_squeeze |          1 |      1 |         0.0001 |      12.6516 |               12.6516 |     32 |            
  1 |      fused_reshape_add_reshape_transpose_reshape_transpose |     393216 |     24 |         2.4269 |     162.0252 |             3888.6041 |     32 |            
  2 |       fused_expand_dims_expand_dims_cast_subtract_multiply |        768 |      1 |         0.0512 |      15.0019 |               15.0019 |     32 |            
  3 |    fused_reshape_add_reshape_transpose_reshape_transpose_1 |     393216 |     24 |         0.8998 |     437.0154 |            10488.3689 |     32 |            
  4 |                                                 fused_mean |     393600 |     49 |        10.0733 |      39.0736 |             1914.6079 |     32 |            
  5 |      fused_less_add_where_take_add_less_add_where_take_add |     787200 |      1 |        19.3910 |      40.5961 |               40.5961 |     32 |            
  6 |                fused_reshape_add_reshape_transpose_reshape |     393216 |     24 |         9.5277 |      41.2707 |              990.4966 |     32 |            
  7 |                                      fused_nn_batch_matmul |  301989888 |     24 |        86.3671 |    3496.5859 |            83918.0613 |     32 |            
  8 |                                   fused_reshape_divide_add |    4718592 |     24 |        47.1537 |     100.0683 |             2401.6391 |     32 |            
  9 |                                           fused_nn_softmax |    9437184 |     24 |         4.7145 |    2001.7558 |            48042.1395 |     32 |            
 10 |                                              fused_reshape |          1 |     24 |         0.0000 |      73.6705 |             1768.0929 |     32 |            
 11 |                                    fused_nn_batch_matmul_1 |  301989888 |     24 |        59.6188 |    5065.3446 |           121568.2700 |     32 |            
 12 |                            fused_reshape_transpose_reshape |          1 |     24 |         0.0000 |      63.3190 |             1519.6562 |     32 |            
 13 |                                             fused_nn_dense |  805306368 |     96 |        60.6909 |   13268.9729 |          1273821.3993 |     32 |            
 14 |                         fused_add_sqrt_divide_multiply_add |    1180032 |     48 |        34.5268 |      34.1772 |             1640.5078 |     32 |            
 15 |                                            fused_reshape_1 |          1 |     48 |         0.0001 |      11.1313 |              534.3017 |     32 |            
 16 |                                           fused_nn_dense_1 | 3221225472 |     24 |        79.3862 |   40576.6247 |           973838.9920 |     32 |            
 17 | fused_reshape_add_multiply_divide_erf_add_multiply_reshape |    7864320 |     24 |         4.0963 |    1919.8607 |            46076.6573 |     32 |            
 18 |                                           fused_nn_dense_2 | 3221225472 |     24 |       114.9441 |   28024.2894 |           672582.9456 |     32 |            
 19 |                                      fused_reshape_add_add |     786432 |     48 |        49.4058 |      15.9178 |              764.0545 |     32 |            
 20 |                                             fused_subtract |     393216 |     49 |        36.4266 |      10.7947 |              528.9426 |     32 |            
 21 |                                           fused_power_mean |     393600 |     49 |         9.1047 |      43.2305 |             2118.2969 |     32 |            
 22 |                 fused_add_sqrt_divide_multiply_add_reshape |    1180032 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                           fused_nn_dense_3 |    1572864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                    fused_reshape_add_split |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                            fused_squeeze_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 704
Total latency (us): 3.24847e+06

[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #0: GFLOPs: 30.1117. Time: 0.0392 ms. Best GFLOPs: 30.1117
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #1: GFLOPs: 28.0101. Time: 0.0421 ms. Best GFLOPs: 30.1117
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #2: GFLOPs: 30.4291. Time: 0.0388 ms. Best GFLOPs: 30.4291
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #3: GFLOPs: 31.3288. Time: 0.0377 ms. Best GFLOPs: 31.3288
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #4: GFLOPs: 31.1484. Time: 0.0379 ms. Best GFLOPs: 31.3288
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #5: GFLOPs: 32.6638. Time: 0.0361 ms. Best GFLOPs: 32.6638
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #6: GFLOPs: 31.3905. Time: 0.0376 ms. Best GFLOPs: 32.6638
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #7: GFLOPs: 30.1367. Time: 0.0392 ms. Best GFLOPs: 32.6638
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #8: GFLOPs: 29.7521. Time: 0.0397 ms. Best GFLOPs: 32.6638
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #9: GFLOPs: 30.4016. Time: 0.0388 ms. Best GFLOPs: 32.6638
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #10: GFLOPs: 29.4369. Time: 0.0401 ms. Best GFLOPs: 32.6638
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #11: GFLOPs: 30.6352. Time: 0.0385 ms. Best GFLOPs: 32.6638
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #12: GFLOPs: 30.3022. Time: 0.0389 ms. Best GFLOPs: 32.6638
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #13: GFLOPs: 33.9318. Time: 0.0348 ms. Best GFLOPs: 33.9318
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #14: GFLOPs: 32.3546. Time: 0.0365 ms. Best GFLOPs: 33.9318
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #15: GFLOPs: 28.1601. Time: 0.0419 ms. Best GFLOPs: 33.9318
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #16: GFLOPs: 31.0351. Time: 0.0380 ms. Best GFLOPs: 33.9318
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #17: GFLOPs: 29.6888. Time: 0.0397 ms. Best GFLOPs: 33.9318
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #18: GFLOPs: 31.7946. Time: 0.0371 ms. Best GFLOPs: 33.9318
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #19: GFLOPs: 30.6728. Time: 0.0385 ms. Best GFLOPs: 33.9318
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #20: GFLOPs: 58.1517. Time: 0.0203 ms. Best GFLOPs: 58.1517
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #21: GFLOPs: 58.2745. Time: 0.0202 ms. Best GFLOPs: 58.2745
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #22: GFLOPs: 36.4042. Time: 0.0324 ms. Best GFLOPs: 58.2745
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #23: GFLOPs: 26.2339. Time: 0.0450 ms. Best GFLOPs: 58.2745
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #24: GFLOPs: 44.2424. Time: 0.0267 ms. Best GFLOPs: 58.2745
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #25: GFLOPs: 38.9798. Time: 0.0303 ms. Best GFLOPs: 58.2745
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #26: GFLOPs: 26.4897. Time: 0.0445 ms. Best GFLOPs: 58.2745
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #27: GFLOPs: 34.0937. Time: 0.0346 ms. Best GFLOPs: 58.2745
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #28: GFLOPs: 22.5663. Time: 0.0523 ms. Best GFLOPs: 58.2745
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #29: GFLOPs: 35.6303. Time: 0.0331 ms. Best GFLOPs: 58.2745
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #30: GFLOPs: 32.2796. Time: 0.0366 ms. Best GFLOPs: 58.2745
[19:19:27] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #22: "fused_add_sqrt_divide_multiply_add_reshape"] Trial #31: GFLOPs: 25.8995. Time: 0.0456 ms. Best GFLOPs: 58.2745
[19:19:29] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #22: "fused_add_sqrt_divide_multiply_add_reshape"
 ID |                                                       Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                              fused_squeeze |          1 |      1 |         0.0001 |      12.6516 |               12.6516 |     32 |            
  1 |      fused_reshape_add_reshape_transpose_reshape_transpose |     393216 |     24 |         2.4269 |     162.0252 |             3888.6041 |     32 |            
  2 |       fused_expand_dims_expand_dims_cast_subtract_multiply |        768 |      1 |         0.0512 |      15.0019 |               15.0019 |     32 |            
  3 |    fused_reshape_add_reshape_transpose_reshape_transpose_1 |     393216 |     24 |         0.8998 |     437.0154 |            10488.3689 |     32 |            
  4 |                                                 fused_mean |     393600 |     49 |        10.0733 |      39.0736 |             1914.6079 |     32 |            
  5 |      fused_less_add_where_take_add_less_add_where_take_add |     787200 |      1 |        19.3910 |      40.5961 |               40.5961 |     32 |            
  6 |                fused_reshape_add_reshape_transpose_reshape |     393216 |     24 |         9.5277 |      41.2707 |              990.4966 |     32 |            
  7 |                                      fused_nn_batch_matmul |  301989888 |     24 |        86.3671 |    3496.5859 |            83918.0613 |     32 |            
  8 |                                   fused_reshape_divide_add |    4718592 |     24 |        47.1537 |     100.0683 |             2401.6391 |     32 |            
  9 |                                           fused_nn_softmax |    9437184 |     24 |         4.7145 |    2001.7558 |            48042.1395 |     32 |            
 10 |                                              fused_reshape |          1 |     24 |         0.0000 |      73.6705 |             1768.0929 |     32 |            
 11 |                                    fused_nn_batch_matmul_1 |  301989888 |     24 |        59.6188 |    5065.3446 |           121568.2700 |     32 |            
 12 |                            fused_reshape_transpose_reshape |          1 |     24 |         0.0000 |      63.3190 |             1519.6562 |     32 |            
 13 |                                             fused_nn_dense |  805306368 |     96 |        60.6909 |   13268.9729 |          1273821.3993 |     32 |            
 14 |                         fused_add_sqrt_divide_multiply_add |    1180032 |     48 |        34.5268 |      34.1772 |             1640.5078 |     32 |            
 15 |                                            fused_reshape_1 |          1 |     48 |         0.0001 |      11.1313 |              534.3017 |     32 |            
 16 |                                           fused_nn_dense_1 | 3221225472 |     24 |        79.3862 |   40576.6247 |           973838.9920 |     32 |            
 17 | fused_reshape_add_multiply_divide_erf_add_multiply_reshape |    7864320 |     24 |         4.0963 |    1919.8607 |            46076.6573 |     32 |            
 18 |                                           fused_nn_dense_2 | 3221225472 |     24 |       114.9441 |   28024.2894 |           672582.9456 |     32 |            
 19 |                                      fused_reshape_add_add |     786432 |     48 |        49.4058 |      15.9178 |              764.0545 |     32 |            
 20 |                                             fused_subtract |     393216 |     49 |        36.4266 |      10.7947 |              528.9426 |     32 |            
 21 |                                           fused_power_mean |     393600 |     49 |         9.1047 |      43.2305 |             2118.2969 |     32 |            
 22 |                 fused_add_sqrt_divide_multiply_add_reshape |    1180032 |      1 |        58.2745 |      20.2495 |               20.2495 |     32 |            
 23 |                                           fused_nn_dense_3 |    1572864 |      1 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                    fused_reshape_add_split |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                            fused_squeeze_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 736
Total latency (us): 3.24849e+06

[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #0: GFLOPs: 1.8396. Time: 0.8550 ms. Best GFLOPs: 1.8396
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #1: GFLOPs: 32.6491. Time: 0.0482 ms. Best GFLOPs: 32.6491
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #2: GFLOPs: 17.0778. Time: 0.0921 ms. Best GFLOPs: 32.6491
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #3: GFLOPs: 29.2552. Time: 0.0538 ms. Best GFLOPs: 32.6491
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #4: GFLOPs: 33.3660. Time: 0.0471 ms. Best GFLOPs: 33.3660
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #5: GFLOPs: 4.1763. Time: 0.3766 ms. Best GFLOPs: 33.3660
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #6: GFLOPs: 6.0318. Time: 0.2608 ms. Best GFLOPs: 33.3660
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #7: GFLOPs: 2.7570. Time: 0.5705 ms. Best GFLOPs: 33.3660
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #8: GFLOPs: 11.0087. Time: 0.1429 ms. Best GFLOPs: 33.3660
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #9: GFLOPs: 14.4898. Time: 0.1085 ms. Best GFLOPs: 33.3660
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #10: GFLOPs: 13.1715. Time: 0.1194 ms. Best GFLOPs: 33.3660
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #11: GFLOPs: 2.6899. Time: 0.5847 ms. Best GFLOPs: 33.3660
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #12: GFLOPs: 3.8926. Time: 0.4041 ms. Best GFLOPs: 33.3660
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #13: GFLOPs: 15.5417. Time: 0.1012 ms. Best GFLOPs: 33.3660
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #14: GFLOPs: 13.2448. Time: 0.1188 ms. Best GFLOPs: 33.3660
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #15: GFLOPs: 0.3306. Time: 4.7573 ms. Best GFLOPs: 33.3660
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #16: GFLOPs: 12.6137. Time: 0.1247 ms. Best GFLOPs: 33.3660
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #17: GFLOPs: 5.6748. Time: 0.2772 ms. Best GFLOPs: 33.3660
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #18: GFLOPs: 11.8711. Time: 0.1325 ms. Best GFLOPs: 33.3660
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #19: GFLOPs: 2.1813. Time: 0.7211 ms. Best GFLOPs: 33.3660
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #20: GFLOPs: 1.2091. Time: 1.3008 ms. Best GFLOPs: 33.3660
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #21: GFLOPs: 3.3008. Time: 0.4765 ms. Best GFLOPs: 33.3660
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #22: GFLOPs: 3.8657. Time: 0.4069 ms. Best GFLOPs: 33.3660
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #23: GFLOPs: 5.4470. Time: 0.2888 ms. Best GFLOPs: 33.3660
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #24: GFLOPs: 3.2651. Time: 0.4817 ms. Best GFLOPs: 33.3660
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #25: GFLOPs: 3.8867. Time: 0.4047 ms. Best GFLOPs: 33.3660
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #26: GFLOPs: 1.0628. Time: 1.4799 ms. Best GFLOPs: 33.3660
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #27: GFLOPs: 0.2678. Time: 5.8742 ms. Best GFLOPs: 33.3660
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #28: GFLOPs: 0.2577. Time: 6.1039 ms. Best GFLOPs: 33.3660
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #29: GFLOPs: 0.9117. Time: 1.7253 ms. Best GFLOPs: 33.3660
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #30: GFLOPs: 11.6688. Time: 0.1348 ms. Best GFLOPs: 33.3660
[19:19:29] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #23: "fused_nn_dense_3"] Trial #31: GFLOPs: 11.5986. Time: 0.1356 ms. Best GFLOPs: 33.3660
[19:19:31] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #23: "fused_nn_dense_3"
 ID |                                                       Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                              fused_squeeze |          1 |      1 |         0.0001 |      12.6516 |               12.6516 |     32 |            
  1 |      fused_reshape_add_reshape_transpose_reshape_transpose |     393216 |     24 |         2.4269 |     162.0252 |             3888.6041 |     32 |            
  2 |       fused_expand_dims_expand_dims_cast_subtract_multiply |        768 |      1 |         0.0512 |      15.0019 |               15.0019 |     32 |            
  3 |    fused_reshape_add_reshape_transpose_reshape_transpose_1 |     393216 |     24 |         0.8998 |     437.0154 |            10488.3689 |     32 |            
  4 |                                                 fused_mean |     393600 |     49 |        10.0733 |      39.0736 |             1914.6079 |     32 |            
  5 |      fused_less_add_where_take_add_less_add_where_take_add |     787200 |      1 |        19.3910 |      40.5961 |               40.5961 |     32 |            
  6 |                fused_reshape_add_reshape_transpose_reshape |     393216 |     24 |         9.5277 |      41.2707 |              990.4966 |     32 |            
  7 |                                      fused_nn_batch_matmul |  301989888 |     24 |        86.3671 |    3496.5859 |            83918.0613 |     32 |            
  8 |                                   fused_reshape_divide_add |    4718592 |     24 |        47.1537 |     100.0683 |             2401.6391 |     32 |            
  9 |                                           fused_nn_softmax |    9437184 |     24 |         4.7145 |    2001.7558 |            48042.1395 |     32 |            
 10 |                                              fused_reshape |          1 |     24 |         0.0000 |      73.6705 |             1768.0929 |     32 |            
 11 |                                    fused_nn_batch_matmul_1 |  301989888 |     24 |        59.6188 |    5065.3446 |           121568.2700 |     32 |            
 12 |                            fused_reshape_transpose_reshape |          1 |     24 |         0.0000 |      63.3190 |             1519.6562 |     32 |            
 13 |                                             fused_nn_dense |  805306368 |     96 |        60.6909 |   13268.9729 |          1273821.3993 |     32 |            
 14 |                         fused_add_sqrt_divide_multiply_add |    1180032 |     48 |        34.5268 |      34.1772 |             1640.5078 |     32 |            
 15 |                                            fused_reshape_1 |          1 |     48 |         0.0001 |      11.1313 |              534.3017 |     32 |            
 16 |                                           fused_nn_dense_1 | 3221225472 |     24 |        79.3862 |   40576.6247 |           973838.9920 |     32 |            
 17 | fused_reshape_add_multiply_divide_erf_add_multiply_reshape |    7864320 |     24 |         4.0963 |    1919.8607 |            46076.6573 |     32 |            
 18 |                                           fused_nn_dense_2 | 3221225472 |     24 |       114.9441 |   28024.2894 |           672582.9456 |     32 |            
 19 |                                      fused_reshape_add_add |     786432 |     48 |        49.4058 |      15.9178 |              764.0545 |     32 |            
 20 |                                             fused_subtract |     393216 |     49 |        36.4266 |      10.7947 |              528.9426 |     32 |            
 21 |                                           fused_power_mean |     393600 |     49 |         9.1047 |      43.2305 |             2118.2969 |     32 |            
 22 |                 fused_add_sqrt_divide_multiply_add_reshape |    1180032 |      1 |        58.2745 |      20.2495 |               20.2495 |     32 |            
 23 |                                           fused_nn_dense_3 |    1572864 |      1 |        33.3660 |      47.1397 |               47.1397 |     32 |            
 24 |                                    fused_reshape_add_split |        768 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                            fused_squeeze_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 768
Total latency (us): 3.24854e+06

[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #0: GFLOPs: 0.0126. Time: 0.0608 ms. Best GFLOPs: 0.0126
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #1: GFLOPs: 0.0317. Time: 0.0243 ms. Best GFLOPs: 0.0317
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #2: GFLOPs: 0.0167. Time: 0.0460 ms. Best GFLOPs: 0.0317
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #3: GFLOPs: 0.0241. Time: 0.0319 ms. Best GFLOPs: 0.0317
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #4: GFLOPs: 0.0168. Time: 0.0458 ms. Best GFLOPs: 0.0317
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #5: GFLOPs: 0.0411. Time: 0.0187 ms. Best GFLOPs: 0.0411
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #6: GFLOPs: 0.0269. Time: 0.0286 ms. Best GFLOPs: 0.0411
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #7: GFLOPs: 0.0159. Time: 0.0483 ms. Best GFLOPs: 0.0411
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #8: GFLOPs: 0.0207. Time: 0.0370 ms. Best GFLOPs: 0.0411
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #9: GFLOPs: 0.0315. Time: 0.0244 ms. Best GFLOPs: 0.0411
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #10: GFLOPs: 0.0128. Time: 0.0599 ms. Best GFLOPs: 0.0411
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #11: GFLOPs: 0.0295. Time: 0.0261 ms. Best GFLOPs: 0.0411
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #12: GFLOPs: 0.0384. Time: 0.0200 ms. Best GFLOPs: 0.0411
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #13: GFLOPs: 0.0292. Time: 0.0263 ms. Best GFLOPs: 0.0411
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #14: GFLOPs: 0.0385. Time: 0.0199 ms. Best GFLOPs: 0.0411
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #15: GFLOPs: 0.0161. Time: 0.0476 ms. Best GFLOPs: 0.0411
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #16: GFLOPs: 0.0252. Time: 0.0304 ms. Best GFLOPs: 0.0411
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #17: GFLOPs: 0.0128. Time: 0.0601 ms. Best GFLOPs: 0.0411
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #18: GFLOPs: 0.0008. Time: 1.0201 ms. Best GFLOPs: 0.0411
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #19: GFLOPs: 0.0018. Time: 0.4194 ms. Best GFLOPs: 0.0411
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #20: GFLOPs: 0.0052. Time: 0.1483 ms. Best GFLOPs: 0.0411
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #21: GFLOPs: 0.0054. Time: 0.1415 ms. Best GFLOPs: 0.0411
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #22: GFLOPs: 0.0127. Time: 0.0604 ms. Best GFLOPs: 0.0411
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #23: GFLOPs: 0.0171. Time: 0.0450 ms. Best GFLOPs: 0.0411
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #24: GFLOPs: 0.0160. Time: 0.0480 ms. Best GFLOPs: 0.0411
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #25: GFLOPs: 0.0181. Time: 0.0425 ms. Best GFLOPs: 0.0411
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #26: GFLOPs: 0.0218. Time: 0.0352 ms. Best GFLOPs: 0.0411
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #27: GFLOPs: 0.0604. Time: 0.0127 ms. Best GFLOPs: 0.0604
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #28: GFLOPs: 0.0378. Time: 0.0203 ms. Best GFLOPs: 0.0604
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #29: GFLOPs: 0.0382. Time: 0.0201 ms. Best GFLOPs: 0.0604
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #30: GFLOPs: 0.0355. Time: 0.0216 ms. Best GFLOPs: 0.0604
[19:19:31] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #24: "fused_reshape_add_split"] Trial #31: GFLOPs: 0.0602. Time: 0.0128 ms. Best GFLOPs: 0.0604
[19:19:33] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #24: "fused_reshape_add_split"
 ID |                                                       Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                              fused_squeeze |          1 |      1 |         0.0001 |      12.6516 |               12.6516 |     32 |            
  1 |      fused_reshape_add_reshape_transpose_reshape_transpose |     393216 |     24 |         2.4269 |     162.0252 |             3888.6041 |     32 |            
  2 |       fused_expand_dims_expand_dims_cast_subtract_multiply |        768 |      1 |         0.0512 |      15.0019 |               15.0019 |     32 |            
  3 |    fused_reshape_add_reshape_transpose_reshape_transpose_1 |     393216 |     24 |         0.8998 |     437.0154 |            10488.3689 |     32 |            
  4 |                                                 fused_mean |     393600 |     49 |        10.0733 |      39.0736 |             1914.6079 |     32 |            
  5 |      fused_less_add_where_take_add_less_add_where_take_add |     787200 |      1 |        19.3910 |      40.5961 |               40.5961 |     32 |            
  6 |                fused_reshape_add_reshape_transpose_reshape |     393216 |     24 |         9.5277 |      41.2707 |              990.4966 |     32 |            
  7 |                                      fused_nn_batch_matmul |  301989888 |     24 |        86.3671 |    3496.5859 |            83918.0613 |     32 |            
  8 |                                   fused_reshape_divide_add |    4718592 |     24 |        47.1537 |     100.0683 |             2401.6391 |     32 |            
  9 |                                           fused_nn_softmax |    9437184 |     24 |         4.7145 |    2001.7558 |            48042.1395 |     32 |            
 10 |                                              fused_reshape |          1 |     24 |         0.0000 |      73.6705 |             1768.0929 |     32 |            
 11 |                                    fused_nn_batch_matmul_1 |  301989888 |     24 |        59.6188 |    5065.3446 |           121568.2700 |     32 |            
 12 |                            fused_reshape_transpose_reshape |          1 |     24 |         0.0000 |      63.3190 |             1519.6562 |     32 |            
 13 |                                             fused_nn_dense |  805306368 |     96 |        60.6909 |   13268.9729 |          1273821.3993 |     32 |            
 14 |                         fused_add_sqrt_divide_multiply_add |    1180032 |     48 |        34.5268 |      34.1772 |             1640.5078 |     32 |            
 15 |                                            fused_reshape_1 |          1 |     48 |         0.0001 |      11.1313 |              534.3017 |     32 |            
 16 |                                           fused_nn_dense_1 | 3221225472 |     24 |        79.3862 |   40576.6247 |           973838.9920 |     32 |            
 17 | fused_reshape_add_multiply_divide_erf_add_multiply_reshape |    7864320 |     24 |         4.0963 |    1919.8607 |            46076.6573 |     32 |            
 18 |                                           fused_nn_dense_2 | 3221225472 |     24 |       114.9441 |   28024.2894 |           672582.9456 |     32 |            
 19 |                                      fused_reshape_add_add |     786432 |     48 |        49.4058 |      15.9178 |              764.0545 |     32 |            
 20 |                                             fused_subtract |     393216 |     49 |        36.4266 |      10.7947 |              528.9426 |     32 |            
 21 |                                           fused_power_mean |     393600 |     49 |         9.1047 |      43.2305 |             2118.2969 |     32 |            
 22 |                 fused_add_sqrt_divide_multiply_add_reshape |    1180032 |      1 |        58.2745 |      20.2495 |               20.2495 |     32 |            
 23 |                                           fused_nn_dense_3 |    1572864 |      1 |        33.3660 |      47.1397 |               47.1397 |     32 |            
 24 |                                    fused_reshape_add_split |        768 |      1 |         0.0604 |      12.7131 |               12.7131 |     32 |            
 25 |                                            fused_squeeze_1 |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 800
Total latency (us): 3.24855e+06

[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #0: GFLOPs: 0.0000. Time: 0.0069 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #1: GFLOPs: 0.0000. Time: 0.0065 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #2: GFLOPs: 0.0000. Time: 0.0065 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #3: GFLOPs: 0.0000. Time: 0.0074 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #4: GFLOPs: 0.0000. Time: 0.0096 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #5: GFLOPs: 0.0000. Time: 0.0064 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #6: GFLOPs: 0.0000. Time: 0.0064 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #7: GFLOPs: 0.0000. Time: 0.0067 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #8: GFLOPs: 0.0000. Time: 0.0064 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #9: GFLOPs: 0.0000. Time: 0.0064 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #10: GFLOPs: 0.0000. Time: 0.0066 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #11: GFLOPs: 0.0000. Time: 0.0067 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #12: GFLOPs: 0.0000. Time: 0.0118 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #13: GFLOPs: 0.0000. Time: 0.0110 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #14: GFLOPs: 0.0000. Time: 0.0120 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #15: GFLOPs: 0.0000. Time: 0.0235 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #16: GFLOPs: 0.0000. Time: 0.0128 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #17: GFLOPs: 0.0000. Time: 0.0123 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #18: GFLOPs: 0.0000. Time: 0.0102 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #19: GFLOPs: 0.0000. Time: 0.0163 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #20: GFLOPs: 0.0000. Time: 0.0125 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #21: GFLOPs: 0.0000. Time: 0.0146 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #22: GFLOPs: 0.0000. Time: 0.0095 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #23: GFLOPs: 0.0000. Time: 0.0090 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #24: GFLOPs: 0.0000. Time: 0.0090 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #25: GFLOPs: 0.0000. Time: 0.0074 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #26: GFLOPs: 0.0000. Time: 0.0084 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #27: GFLOPs: 0.0000. Time: 0.0098 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #28: GFLOPs: 0.0000. Time: 0.0090 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #29: GFLOPs: 0.0000. Time: 0.0096 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #30: GFLOPs: 0.0000. Time: 0.0106 ms. Best GFLOPs: 0.0000
[19:19:33] /home/yj/tvm/src/meta_schedule/measure_callback/echo_statistics.cc:52: [Task #25: "fused_squeeze_1"] Trial #31: GFLOPs: 0.0000. Time: 0.0069 ms. Best GFLOPs: 0.0000
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/gradient_based.cc:172: [Updated] Task #25: "fused_squeeze_1"
 ID |                                                       Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                              fused_squeeze |          1 |      1 |         0.0001 |      12.6516 |               12.6516 |     32 |            
  1 |      fused_reshape_add_reshape_transpose_reshape_transpose |     393216 |     24 |         2.4269 |     162.0252 |             3888.6041 |     32 |            
  2 |       fused_expand_dims_expand_dims_cast_subtract_multiply |        768 |      1 |         0.0512 |      15.0019 |               15.0019 |     32 |            
  3 |    fused_reshape_add_reshape_transpose_reshape_transpose_1 |     393216 |     24 |         0.8998 |     437.0154 |            10488.3689 |     32 |            
  4 |                                                 fused_mean |     393600 |     49 |        10.0733 |      39.0736 |             1914.6079 |     32 |            
  5 |      fused_less_add_where_take_add_less_add_where_take_add |     787200 |      1 |        19.3910 |      40.5961 |               40.5961 |     32 |            
  6 |                fused_reshape_add_reshape_transpose_reshape |     393216 |     24 |         9.5277 |      41.2707 |              990.4966 |     32 |            
  7 |                                      fused_nn_batch_matmul |  301989888 |     24 |        86.3671 |    3496.5859 |            83918.0613 |     32 |            
  8 |                                   fused_reshape_divide_add |    4718592 |     24 |        47.1537 |     100.0683 |             2401.6391 |     32 |            
  9 |                                           fused_nn_softmax |    9437184 |     24 |         4.7145 |    2001.7558 |            48042.1395 |     32 |            
 10 |                                              fused_reshape |          1 |     24 |         0.0000 |      73.6705 |             1768.0929 |     32 |            
 11 |                                    fused_nn_batch_matmul_1 |  301989888 |     24 |        59.6188 |    5065.3446 |           121568.2700 |     32 |            
 12 |                            fused_reshape_transpose_reshape |          1 |     24 |         0.0000 |      63.3190 |             1519.6562 |     32 |            
 13 |                                             fused_nn_dense |  805306368 |     96 |        60.6909 |   13268.9729 |          1273821.3993 |     32 |            
 14 |                         fused_add_sqrt_divide_multiply_add |    1180032 |     48 |        34.5268 |      34.1772 |             1640.5078 |     32 |            
 15 |                                            fused_reshape_1 |          1 |     48 |         0.0001 |      11.1313 |              534.3017 |     32 |            
 16 |                                           fused_nn_dense_1 | 3221225472 |     24 |        79.3862 |   40576.6247 |           973838.9920 |     32 |            
 17 | fused_reshape_add_multiply_divide_erf_add_multiply_reshape |    7864320 |     24 |         4.0963 |    1919.8607 |            46076.6573 |     32 |            
 18 |                                           fused_nn_dense_2 | 3221225472 |     24 |       114.9441 |   28024.2894 |           672582.9456 |     32 |            
 19 |                                      fused_reshape_add_add |     786432 |     48 |        49.4058 |      15.9178 |              764.0545 |     32 |            
 20 |                                             fused_subtract |     393216 |     49 |        36.4266 |      10.7947 |              528.9426 |     32 |            
 21 |                                           fused_power_mean |     393600 |     49 |         9.1047 |      43.2305 |             2118.2969 |     32 |            
 22 |                 fused_add_sqrt_divide_multiply_add_reshape |    1180032 |      1 |        58.2745 |      20.2495 |               20.2495 |     32 |            
 23 |                                           fused_nn_dense_3 |    1572864 |      1 |        33.3660 |      47.1397 |               47.1397 |     32 |            
 24 |                                    fused_reshape_add_split |        768 |      1 |         0.0604 |      12.7131 |               12.7131 |     32 |            
 25 |                                            fused_squeeze_1 |          1 |      1 |         0.0002 |       6.3752 |                6.3752 |     32 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 832
Total latency (us): 3.24856e+06

[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #13: "fused_nn_dense"
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #13 has finished. Remaining task(s): 25
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #16: "fused_nn_dense_1"
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #16 has finished. Remaining task(s): 24
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #18: "fused_nn_dense_2"
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #18 has finished. Remaining task(s): 23
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #11: "fused_nn_batch_matmul_1"
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #11 has finished. Remaining task(s): 22
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #7: "fused_nn_batch_matmul"
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #7 has finished. Remaining task(s): 21
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #9: "fused_nn_softmax"
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #9 has finished. Remaining task(s): 20
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #17: "fused_reshape_add_multiply_divide_erf_add_multiply_reshape"
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #17 has finished. Remaining task(s): 19
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #3: "fused_reshape_add_reshape_transpose_reshape_transpose_1"
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #3 has finished. Remaining task(s): 18
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #1: "fused_reshape_add_reshape_transpose_reshape_transpose"
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #1 has finished. Remaining task(s): 17
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #8: "fused_reshape_divide_add"
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #8 has finished. Remaining task(s): 16
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #21: "fused_power_mean"
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #21 has finished. Remaining task(s): 15
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #4: "fused_mean"
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #4 has finished. Remaining task(s): 14
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #10: "fused_reshape"
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #10 has finished. Remaining task(s): 13
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #14: "fused_add_sqrt_divide_multiply_add"
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #14 has finished. Remaining task(s): 12
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #12: "fused_reshape_transpose_reshape"
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #12 has finished. Remaining task(s): 11
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #6: "fused_reshape_add_reshape_transpose_reshape"
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #6 has finished. Remaining task(s): 10
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #19: "fused_reshape_add_add"
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #19 has finished. Remaining task(s): 9
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #15: "fused_reshape_1"
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #15 has finished. Remaining task(s): 8
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #20: "fused_subtract"
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #20 has finished. Remaining task(s): 7
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #23: "fused_nn_dense_3"
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #23 has finished. Remaining task(s): 6
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #5: "fused_less_add_where_take_add_less_add_where_take_add"
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #5 has finished. Remaining task(s): 5
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #22: "fused_add_sqrt_divide_multiply_add_reshape"
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #22 has finished. Remaining task(s): 4
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #2: "fused_expand_dims_expand_dims_cast_subtract_multiply"
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #2 has finished. Remaining task(s): 3
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #24: "fused_reshape_add_split"
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #24 has finished. Remaining task(s): 2
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #0: "fused_squeeze"
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #0 has finished. Remaining task(s): 1
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:125: Scheduler picks Task #25: "fused_squeeze_1"
[19:19:35] /home/yj/tvm/src/meta_schedule/task_scheduler/task_scheduler.cc:138: Task #25 has finished. Remaining task(s): 0
[[-5.3374934 -5.3062587 -5.542543  -5.3425026 -5.5216813 -5.4375243
  -5.3884144 -5.249525  -5.482299  -5.311686  -5.3168125 -5.275595
  -5.300343  -5.2909136 -5.39059   -5.377473  -5.385159  -5.392664
  -5.663179  -5.4149594 -5.2512975 -5.253053  -5.29611   -5.4016438
  -5.344783  -5.3327913 -5.355472  -5.394808  -5.411599  -5.331217
  -5.311767  -5.3580694 -5.370785  -5.447153  -5.369843  -5.423852
  -5.561553  -5.2726927 -5.3410487 -5.429331  -5.542346  -5.5172353
  -5.497843  -5.5658655 -5.3694024 -5.3568954 -5.529141  -5.5087304
  -5.4780474 -5.336035  -5.288697  -5.264308  -5.387511  -5.355639
  -5.440107  -5.31545   -5.3132167 -5.323966  -5.2983837 -5.4980326
  -5.3009005 -5.4705157 -5.3116765 -5.3689566 -5.342016  -5.4349294
  -5.327086  -5.4159274 -5.5334654 -5.6010833 -5.4065    -5.356364
  -5.3501625 -5.364629  -5.3562264 -5.4778967 -5.3134584 -5.511961
  -5.2947826 -5.303432  -5.283123  -5.2846103 -5.4922566 -5.3759623
  -5.448497  -5.3183126 -5.522096  -5.28238   -5.435272  -5.4819303
  -5.224978  -5.5076776 -5.35782   -5.294352  -5.2147985 -5.4074554
  -5.291318  -5.4873714 -5.2662835 -5.393016  -5.3955154 -5.352267
  -5.41742   -5.396737  -5.5537553 -5.5909247 -5.5298433 -5.22267
  -5.3978343 -5.311088  -5.3261566 -5.3745065 -5.4324217 -5.5437264
  -5.4801435 -5.310415  -5.587302  -5.448223  -5.4465694 -5.353013
  -5.423995  -5.449813  -5.367423  -5.2488236 -5.2420893 -5.419729
  -5.4267945 -5.228934  -5.517907  -5.3803096 -5.254394  -5.4588723
  -5.218843  -5.4401917 -5.4886174 -5.444278  -5.4645133 -5.4576197
  -5.446351  -5.3730693 -5.423932  -5.4922767 -5.4193935 -5.586153
  -5.463524  -5.4548197 -5.600159  -5.331121  -5.498156  -5.642288
  -5.38171   -5.3296056 -5.2677417 -5.4316335 -5.401846  -5.376312
  -5.5291295 -5.5009274 -5.364055  -5.4586797 -5.336721  -5.311494
  -5.5037284 -5.223845  -5.453903  -5.561545  -5.544466  -5.5983586
  -5.5313416 -5.597674  -5.466911  -5.4289155 -5.4400835 -5.576435
  -5.533783  -5.4547005 -5.57288   -5.300165  -5.2247014 -5.236561
  -5.358453  -5.485647  -5.4860396 -5.4579625 -5.2796664 -5.3143644
  -5.454609  -5.399378  -5.4939685 -5.6023593 -5.4663296 -5.2889113
  -5.3970323 -5.476372  -5.3738713 -5.5946565 -5.4289646 -5.481261
  -5.5929394 -5.380168  -5.53211   -5.3433113 -5.534989  -5.5176673
  -5.509201  -5.5207834 -5.4189715 -5.378732  -5.3854923 -5.321623
  -5.3712864 -5.3720837 -5.3306255 -5.479058  -5.461394  -5.4889765
  -5.48448   -5.2971263 -5.5518146 -5.293907  -5.54596   -5.471456
  -5.2544236 -5.2907023 -5.4368443 -5.420519  -5.28847   -5.2226253
  -5.3427954 -5.5753937 -5.430247  -5.527039  -5.4167676 -5.3990855
  -5.395391  -5.3487096 -5.478272  -5.5040994 -5.575501  -5.455312
  -5.4761305 -5.4851556 -5.5295677 -5.5247846 -5.4334536 -5.347627
  -5.448765  -5.3714404 -5.412809  -5.593757  -5.385537  -5.5569468
  -5.4472246 -5.42472   -5.220853  -5.3021703 -5.4883547 -5.3501825
  -5.450708  -5.4509907 -5.5237875 -5.5460863 -5.4014    -5.4066353
  -5.4275827 -5.3516965 -5.4717216 -5.3712416 -5.2922077 -5.4586415
  -5.498128  -5.406146  -5.517645  -5.4562488 -5.562099  -5.3749657
  -5.4346147 -5.426841  -5.398097  -5.4575877 -5.409794  -5.4947634
  -5.354482  -5.355924  -5.5106683 -5.4298525 -5.553645  -5.3673
  -5.4067698 -5.518837  -5.265368  -5.419531  -5.3520103 -5.39588
  -5.4362116 -5.339549  -5.404366  -5.31494   -5.291896  -5.371961
  -5.2854743 -5.3962984 -5.328738  -5.4661946 -5.440236  -5.4656773
  -5.4757276 -5.5247626 -5.3890443 -5.4741454 -5.56081   -5.4690156
  -5.4942374 -5.4060607 -5.384311  -5.4313273 -5.434626  -5.306547
  -5.3997784 -5.5174026 -5.3335896 -5.5213833 -5.422998  -5.404004
  -5.4195533 -5.4528666 -5.4458995 -5.42134   -5.4263783 -5.4448214
  -5.448509  -5.422926  -5.3640914 -5.414785  -5.367221  -5.618182
  -5.576814  -5.333482  -5.322497  -5.4684725 -5.42011   -5.3097153
  -5.3244815 -5.432     -5.3689666 -5.4630437 -5.3848643 -5.5581393
  -5.488342  -5.479661  -5.353382  -5.431443  -5.542115  -5.4076476
  -5.4261923 -5.414963  -5.3802843 -5.4251266 -5.562077  -5.4290166
  -5.3562117 -5.523834  -5.3767548 -5.400564  -5.472121  -5.4833393
  -5.3992095 -5.2938657 -5.2507763 -5.2873793 -5.323932  -5.411513
  -5.5093665 -5.4228997 -5.3202147 -5.3502355 -5.3493567 -5.4426403
  -5.4629807 -5.494591  -5.496244  -5.3447304 -5.4287844 -5.3811398]]
[[-5.3375015 -5.30627   -5.5425572 -5.3425035 -5.521692  -5.437533
  -5.388424  -5.249528  -5.482311  -5.3116884 -5.316823  -5.275598
  -5.300346  -5.290918  -5.3905954 -5.3774815 -5.3851643 -5.392674
  -5.6631913 -5.414975  -5.251299  -5.253059  -5.2961154 -5.4016547
  -5.34479   -5.332796  -5.3554807 -5.3948135 -5.411608  -5.331224
  -5.3117805 -5.358084  -5.370787  -5.447167  -5.3698535 -5.4238653
  -5.561563  -5.272694  -5.341056  -5.4293394 -5.5423603 -5.51725
  -5.49785   -5.565867  -5.3694158 -5.356908  -5.529152  -5.5087423
  -5.4780545 -5.3360434 -5.288699  -5.2643137 -5.387525  -5.3556457
  -5.4401116 -5.3154526 -5.313227  -5.3239746 -5.2983804 -5.4980445
  -5.300905  -5.4705234 -5.311681  -5.368969  -5.3420186 -5.4349437
  -5.3270917 -5.4159374 -5.5334816 -5.601095  -5.4065175 -5.3563714
  -5.350168  -5.3646407 -5.356231  -5.4779086 -5.313466  -5.5119696
  -5.2947927 -5.3034444 -5.283127  -5.2846127 -5.4922667 -5.375971
  -5.448501  -5.3183312 -5.5220976 -5.2823844 -5.4352846 -5.481935
  -5.22498   -5.50769   -5.3578296 -5.294355  -5.214805  -5.407464
  -5.2913227 -5.487384  -5.2662926 -5.393022  -5.3955235 -5.3522763
  -5.417431  -5.3967466 -5.5537653 -5.5909357 -5.5298524 -5.222672
  -5.3978395 -5.311098  -5.3261595 -5.3745093 -5.4324346 -5.5437417
  -5.480155  -5.310418  -5.5873175 -5.448236  -5.446575  -5.35302
  -5.4240093 -5.4498286 -5.367429  -5.248829  -5.242093  -5.4197373
  -5.426807  -5.2289324 -5.5179195 -5.3803124 -5.254404  -5.4588814
  -5.218842  -5.440207  -5.4886193 -5.4442954 -5.464528  -5.4576287
  -5.446358  -5.3730755 -5.4239464 -5.4922843 -5.4194036 -5.58617
  -5.4635277 -5.454822  -5.600165  -5.331129  -5.4981704 -5.6423016
  -5.3817205 -5.32961   -5.267745  -5.4316435 -5.4018545 -5.3763237
  -5.529135  -5.5009437 -5.3640666 -5.458687  -5.336732  -5.3114996
  -5.50374   -5.2238536 -5.453911  -5.5615597 -5.5444765 -5.5983677
  -5.5313525 -5.5976815 -5.466926  -5.4289184 -5.4400997 -5.5764456
  -5.533792  -5.4547124 -5.5728917 -5.300171  -5.224699  -5.2365594
  -5.358457  -5.4856553 -5.4860454 -5.457975  -5.2796745 -5.3143687
  -5.454617  -5.3993855 -5.4939766 -5.6023746 -5.4663405 -5.2889147
  -5.3970437 -5.4763803 -5.3738804 -5.5946655 -5.428984  -5.4812775
  -5.592942  -5.3801723 -5.532119  -5.3433194 -5.5350094 -5.51768
  -5.5092144 -5.5207915 -5.418976  -5.378747  -5.385507  -5.3216224
  -5.371295  -5.37209   -5.330633  -5.4790664 -5.461402  -5.48899
  -5.4844947 -5.2971315 -5.5518284 -5.293921  -5.5459723 -5.4714627
  -5.2544217 -5.2907033 -5.436853  -5.420527  -5.2884755 -5.222628
  -5.342799  -5.5754046 -5.430263  -5.5270524 -5.416773  -5.399095
  -5.3953943 -5.348713  -5.4782834 -5.504108  -5.575518  -5.4553204
  -5.476141  -5.4851685 -5.5295706 -5.524796  -5.433467  -5.347631
  -5.4487734 -5.3714423 -5.412817  -5.593774  -5.3855352 -5.5569553
  -5.44724   -5.42473   -5.2208548 -5.3021784 -5.488364  -5.350189
  -5.4507184 -5.4510016 -5.523797  -5.5461006 -5.4014096 -5.406642
  -5.4275875 -5.351704  -5.47173   -5.3712482 -5.2922096 -5.4586515
  -5.49814   -5.4061594 -5.517655  -5.4562607 -5.562109  -5.374971
  -5.434624  -5.426844  -5.398108  -5.457598  -5.4097967 -5.494771
  -5.3544927 -5.3559256 -5.510683  -5.429863  -5.553666  -5.367305
  -5.4067817 -5.518851  -5.2653723 -5.4195333 -5.352011  -5.395887
  -5.43622   -5.3395624 -5.4043736 -5.3149376 -5.2919016 -5.3719687
  -5.2854743 -5.396308  -5.3287425 -5.4661994 -5.440248  -5.4656925
  -5.4757433 -5.5247746 -5.389054  -5.474158  -5.560827  -5.4690275
  -5.494248  -5.4060726 -5.384323  -5.431335  -5.434632  -5.3065567
  -5.3997927 -5.5174055 -5.333597  -5.5213947 -5.4230056 -5.404015
  -5.419563  -5.452878  -5.445913  -5.421347  -5.42639   -5.444827
  -5.448522  -5.422933  -5.364097  -5.414789  -5.3672304 -5.6181955
  -5.576827  -5.3334856 -5.3225055 -5.4684772 -5.4201126 -5.3097258
  -5.3244834 -5.4320045 -5.368976  -5.4630475 -5.3848696 -5.5581455
  -5.488355  -5.4796677 -5.353392  -5.431457  -5.542125  -5.4076552
  -5.4262013 -5.414974  -5.380285  -5.425134  -5.562093  -5.4290233
  -5.3562202 -5.523848  -5.3767605 -5.400573  -5.4721274 -5.4833465
  -5.399216  -5.293869  -5.2507777 -5.2873774 -5.323941  -5.4115195
  -5.509378  -5.4229026 -5.320222  -5.350242  -5.349366  -5.442651
  -5.4629827 -5.4946055 -5.496253  -5.344737  -5.428791  -5.381144 ]]
