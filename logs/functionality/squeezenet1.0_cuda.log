https://storage.cloud.google.com/octoml-aquarium-models/onnx_model_zoo/vision_classification_squeezenet1.0.onnx
file existed. Skipping downloading.
/home/yj/models/squeezenet1.0.onnx
Starting to build with relay.
2022-05-13 01:20:50.371 INFO Logging directory: /tmp/tmpr0c2dcs7/logs
2022-05-13 01:20:50.371 INFO Working directory: /tmp/tmpr0c2dcs7
2022-05-13 01:20:50.371 INFO LocalBuilder: max_workers = 24
2022-05-13 01:20:50.682 INFO LocalRunner: max_workers = 1
2022-05-13 01:20:57.585 INFO 
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |            N/A |          N/A |                   N/A |      0 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |            N/A |          N/A |                   N/A |      0 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |            N/A |          N/A |                   N/A |      0 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |            N/A |          N/A |                   N/A |      0 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |            N/A |          N/A |                   N/A |      0 |            
  9 |              fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |            fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |            fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                  fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 0
Total latency (us): 0

2022-05-13 01:20:57.585 INFO Scheduler picks Task #0: "fused_nn_conv2d_add_nn_relu"
2022-05-13 01:22:41.506 INFO Sending 32 sample(s) to builder
2022-05-13 01:23:13.642 INFO Sending 32 sample(s) to runner
2022-05-13 01:23:22.163 INFO Scheduler picks Task #1: "fused_nn_conv2d_add_nn_relu_1"
2022-05-13 01:25:05.138 INFO Sending 32 sample(s) to builder
2022-05-13 01:25:15.576 INFO Sending 32 sample(s) to runner
2022-05-13 01:25:24.429 INFO Scheduler picks Task #2: "fused_nn_conv2d_add_nn_relu_2"
2022-05-13 01:27:14.852 INFO Sending 32 sample(s) to builder
2022-05-13 01:27:41.867 INFO Sending 32 sample(s) to runner
2022-05-13 01:27:50.759 INFO Scheduler picks Task #3: "fused_nn_conv2d_add_nn_relu_3"
2022-05-13 01:29:40.638 INFO Sending 32 sample(s) to builder
2022-05-13 01:30:12.416 INFO Sending 32 sample(s) to runner
2022-05-13 01:30:21.473 INFO Scheduler picks Task #4: "fused_nn_conv2d_add_nn_relu_4"
2022-05-13 01:31:24.726 INFO Sending 32 sample(s) to builder
2022-05-13 01:31:33.855 INFO Sending 32 sample(s) to runner
2022-05-13 01:31:46.416 INFO Scheduler picks Task #5: "fused_nn_max_pool2d"
2022-05-13 01:31:56.898 INFO Sending 5 sample(s) to builder
2022-05-13 01:31:57.678 INFO Sending 5 sample(s) to runner
2022-05-13 01:31:58.991 INFO Scheduler picks Task #6: "fused_nn_conv2d_add_nn_relu_5"
2022-05-13 01:32:58.318 INFO Sending 32 sample(s) to builder
2022-05-13 01:33:29.838 INFO Sending 32 sample(s) to runner
2022-05-13 01:33:38.946 INFO Scheduler picks Task #7: "fused_nn_conv2d_add_nn_relu_6"
2022-05-13 01:34:39.811 INFO Sending 32 sample(s) to builder
2022-05-13 01:34:49.557 INFO Sending 32 sample(s) to runner
2022-05-13 01:34:58.710 INFO Scheduler picks Task #8: "fused_nn_conv2d_add_nn_relu_7"
2022-05-13 01:35:58.601 INFO Sending 32 sample(s) to builder
2022-05-13 01:36:21.081 INFO Sending 32 sample(s) to runner
2022-05-13 01:36:29.681 INFO Scheduler picks Task #9: "fused_concatenate"
2022-05-13 01:36:45.525 INFO Sending 5 sample(s) to builder
2022-05-13 01:36:46.275 INFO Sending 5 sample(s) to runner
2022-05-13 01:36:47.472 INFO Scheduler picks Task #10: "fused_nn_max_pool2d_1"
2022-05-13 01:36:58.131 INFO Sending 5 sample(s) to builder
2022-05-13 01:36:58.911 INFO Sending 5 sample(s) to runner
2022-05-13 01:37:00.305 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_8"
2022-05-13 01:38:01.535 INFO Sending 32 sample(s) to builder
2022-05-13 01:38:16.971 INFO Sending 32 sample(s) to runner
2022-05-13 01:38:26.066 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_9"
2022-05-13 01:39:27.132 INFO Sending 32 sample(s) to builder
2022-05-13 01:39:35.210 INFO Sending 32 sample(s) to runner
2022-05-13 01:39:44.524 INFO Scheduler picks Task #13: "fused_nn_conv2d_add_nn_relu_10"
2022-05-13 01:40:44.782 INFO Sending 32 sample(s) to builder
2022-05-13 01:41:16.803 INFO Sending 32 sample(s) to runner
2022-05-13 01:41:25.647 INFO Scheduler picks Task #14: "fused_concatenate_1"
2022-05-13 01:41:38.009 INFO Sending 5 sample(s) to builder
2022-05-13 01:41:38.763 INFO Sending 5 sample(s) to runner
2022-05-13 01:41:40.462 INFO Scheduler picks Task #15: "fused_nn_max_pool2d_2"
2022-05-13 01:41:51.113 INFO Sending 5 sample(s) to builder
2022-05-13 01:41:51.884 INFO Sending 5 sample(s) to runner
2022-05-13 01:41:53.524 INFO Scheduler picks Task #16: "fused_nn_conv2d_add_nn_relu_11"
2022-05-13 01:42:50.946 INFO Sending 32 sample(s) to builder
2022-05-13 01:42:59.950 INFO Sending 32 sample(s) to runner
2022-05-13 01:43:08.649 INFO Scheduler picks Task #17: "fused_nn_conv2d_add_nn_relu_12"
2022-05-13 01:44:05.715 INFO Sending 32 sample(s) to builder
2022-05-13 01:44:10.156 INFO Sending 32 sample(s) to runner
2022-05-13 01:44:19.303 INFO Scheduler picks Task #18: "fused_nn_conv2d_add_nn_relu_13"
2022-05-13 01:45:15.082 INFO Sending 32 sample(s) to builder
2022-05-13 01:45:29.022 INFO Sending 32 sample(s) to runner
2022-05-13 01:45:37.051 INFO Scheduler picks Task #19: "fused_concatenate_2"
2022-05-13 01:45:49.230 INFO Sending 5 sample(s) to builder
2022-05-13 01:45:49.966 INFO Sending 5 sample(s) to runner
2022-05-13 01:45:51.663 INFO Scheduler picks Task #20: "fused_nn_conv2d_add_nn_relu_14"
2022-05-13 01:46:47.500 INFO Sending 32 sample(s) to builder
2022-05-13 01:46:51.448 INFO Sending 32 sample(s) to runner
2022-05-13 01:47:00.488 INFO Scheduler picks Task #21: "fused_nn_conv2d_add_nn_relu_15"
2022-05-13 01:47:56.753 INFO Sending 32 sample(s) to builder
2022-05-13 01:48:12.278 INFO Sending 32 sample(s) to runner
2022-05-13 01:48:21.457 INFO Scheduler picks Task #22: "fused_nn_conv2d_add_nn_relu_16"
2022-05-13 01:49:17.230 INFO Sending 32 sample(s) to builder
2022-05-13 01:49:24.889 INFO Sending 32 sample(s) to runner
2022-05-13 01:49:33.383 INFO Scheduler picks Task #23: "fused_concatenate_3"
2022-05-13 01:49:45.619 INFO Sending 5 sample(s) to builder
2022-05-13 01:49:46.352 INFO Sending 5 sample(s) to runner
2022-05-13 01:49:48.140 INFO Scheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_17"
2022-05-13 01:50:47.185 INFO Sending 32 sample(s) to builder
2022-05-13 01:50:58.473 INFO Sending 32 sample(s) to runner
2022-05-13 01:51:08.231 INFO Scheduler picks Task #25: "fused_nn_global_avg_pool2d"
2022-05-13 01:51:20.455 INFO Sending 31 sample(s) to builder
2022-05-13 01:51:22.552 INFO Sending 31 sample(s) to runner
2022-05-13 01:51:30.667 INFO Scheduler picks Task #26: "fused_reshape"
2022-05-13 01:51:35.196 INFO Sending 5 sample(s) to builder
2022-05-13 01:51:35.912 INFO Sending 5 sample(s) to runner
2022-05-13 01:51:37.509 INFO Scheduler picks Task #27: "fused_nn_softmax"
2022-05-13 01:51:52.137 INFO Sending 32 sample(s) to builder
2022-05-13 01:51:55.582 INFO Sending 32 sample(s) to runner
2022-05-13 01:52:04.121 INFO Scheduler picks Task #28: "fused_reshape_1"
2022-05-13 01:52:08.904 INFO Sending 5 sample(s) to builder
2022-05-13 01:52:09.620 INFO Sending 5 sample(s) to runner
2022-05-13 01:52:12.003 INFO [Updated] Task #0: "fused_nn_conv2d_add_nn_relu"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |            N/A |          N/A |                   N/A |      0 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |            N/A |          N/A |                   N/A |      0 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |            N/A |          N/A |                   N/A |      0 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |            N/A |          N/A |                   N/A |      0 |            
  9 |              fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |            fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |            fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                  fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 32
Total latency (us): 49.3523

2022-05-13 01:52:12.935 INFO [Updated] Task #1: "fused_nn_conv2d_add_nn_relu_1"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |            N/A |          N/A |                   N/A |      0 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |            N/A |          N/A |                   N/A |      0 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |            N/A |          N/A |                   N/A |      0 |            
  9 |              fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |            fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |            fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                  fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 64
Total latency (us): 101.117

2022-05-13 01:52:13.969 INFO [Updated] Task #2: "fused_nn_conv2d_add_nn_relu_2"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |            N/A |          N/A |                   N/A |      0 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |            N/A |          N/A |                   N/A |      0 |            
  9 |              fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |            fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |            fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                  fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 96
Total latency (us): 133.933

2022-05-13 01:52:15.082 INFO [Updated] Task #3: "fused_nn_conv2d_add_nn_relu_3"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |            N/A |          N/A |                   N/A |      0 |            
  9 |              fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |            fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |            fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                  fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 128
Total latency (us): 175.492

2022-05-13 01:52:16.060 INFO [Updated] Task #4: "fused_nn_conv2d_add_nn_relu_4"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |            N/A |          N/A |                   N/A |      0 |            
  9 |              fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |            fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |            fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                  fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 160
Total latency (us): 201.565

2022-05-13 01:52:16.547 INFO [Updated] Task #5: "fused_nn_max_pool2d"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |            N/A |          N/A |                   N/A |      0 |            
  9 |              fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |            fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |            fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                  fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 165
Total latency (us): 207.131

2022-05-13 01:52:17.541 INFO [Updated] Task #6: "fused_nn_conv2d_add_nn_relu_5"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |            N/A |          N/A |                   N/A |      0 |            
  9 |              fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |            fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |            fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                  fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 197
Total latency (us): 214.381

2022-05-13 01:52:18.553 INFO [Updated] Task #7: "fused_nn_conv2d_add_nn_relu_6"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |            N/A |          N/A |                   N/A |      0 |            
  9 |              fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |            fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |            fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                  fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 229
Total latency (us): 225.558

2022-05-13 01:52:19.571 INFO [Updated] Task #8: "fused_nn_conv2d_add_nn_relu_7"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |            
  9 |              fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |            fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |            fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                  fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 261
Total latency (us): 239.961

2022-05-13 01:52:20.267 INFO [Updated] Task #9: "fused_concatenate"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |            
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |            fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |            fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                  fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 266
Total latency (us): 248.134

2022-05-13 01:52:20.798 INFO [Updated] Task #10: "fused_nn_max_pool2d_1"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |            
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |            fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |            fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                  fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 271
Total latency (us): 251.396

2022-05-13 01:52:21.934 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_8"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |            
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |            fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |            fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                  fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 303
Total latency (us): 259.665

2022-05-13 01:52:23.080 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_9"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |            
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |            fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |            fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                  fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 335
Total latency (us): 270.441

2022-05-13 01:52:24.228 INFO [Updated] Task #13: "fused_nn_conv2d_add_nn_relu_10"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |            
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |            
 14 |            fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |            fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                  fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 367
Total latency (us): 283.053

2022-05-13 01:52:25.008 INFO [Updated] Task #14: "fused_concatenate_1"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |            
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |            
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |            fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                  fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 372
Total latency (us): 288.928

2022-05-13 01:52:25.625 INFO [Updated] Task #15: "fused_nn_max_pool2d_2"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |            
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |            
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |            fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                  fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 377
Total latency (us): 291.153

2022-05-13 01:52:26.952 INFO [Updated] Task #16: "fused_nn_conv2d_add_nn_relu_11"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |            
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |            
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |            fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                  fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 409
Total latency (us): 298.883

2022-05-13 01:52:28.247 INFO [Updated] Task #17: "fused_nn_conv2d_add_nn_relu_12"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |            
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |            
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |            fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                  fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 441
Total latency (us): 313.108

2022-05-13 01:52:29.510 INFO [Updated] Task #18: "fused_nn_conv2d_add_nn_relu_13"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |            
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |            
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |            
 19 |            fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                  fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 473
Total latency (us): 325.403

2022-05-13 01:52:30.251 INFO [Updated] Task #19: "fused_concatenate_2"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |            
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |            
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |            
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                  fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 478
Total latency (us): 329.836

2022-05-13 01:52:31.523 INFO [Updated] Task #20: "fused_nn_conv2d_add_nn_relu_14"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |            
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |            
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |            
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                  fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 510
Total latency (us): 340.598

2022-05-13 01:52:32.976 INFO [Updated] Task #21: "fused_nn_conv2d_add_nn_relu_15"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |            
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |            
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |            
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |            
 23 |            fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                  fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 542
Total latency (us): 353.859

2022-05-13 01:52:34.372 INFO [Updated] Task #22: "fused_nn_conv2d_add_nn_relu_16"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |            
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |            
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |            
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |            
 23 |            fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                  fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 574
Total latency (us): 368.746

2022-05-13 01:52:35.257 INFO [Updated] Task #23: "fused_concatenate_3"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |            
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |            
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |            
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |            
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                  fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 579
Total latency (us): 373.185

2022-05-13 01:52:36.784 INFO [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_17"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |            
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |            
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |            
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |            
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 26 |                  fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 611
Total latency (us): 447.848

2022-05-13 01:52:37.986 INFO [Updated] Task #25: "fused_nn_global_avg_pool2d"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |            
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |            
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |            
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |            
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     31 |            
 26 |                  fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 642
Total latency (us): 450.385

2022-05-13 01:52:39.136 INFO [Updated] Task #26: "fused_reshape"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |            
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |            
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |            
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |            
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     31 |            
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 647
Total latency (us): 452.559

2022-05-13 01:52:40.449 INFO [Updated] Task #27: "fused_nn_softmax"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |            
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |            
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |            
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |            
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     31 |            
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |            
 28 |                fused_reshape_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 679
Total latency (us): 454.953

2022-05-13 01:52:41.428 INFO [Updated] Task #28: "fused_reshape_1"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |            
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |            
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |            
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |            
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |            
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |            
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |            
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |            
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |            
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |            
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |            
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |            
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |            
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |            
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |            
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |            
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     31 |            
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |            
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 684
Total latency (us): 457.121

2022-05-13 01:52:41.429 INFO Scheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_17"
2022-05-13 01:52:41.429 INFO Task #24 has finished. Remaining task(s): 28
2022-05-13 01:52:41.429 INFO Scheduler picks Task #1: "fused_nn_conv2d_add_nn_relu_1"
2022-05-13 01:52:41.429 INFO Task #1 has finished. Remaining task(s): 27
2022-05-13 01:52:41.429 INFO Scheduler picks Task #0: "fused_nn_conv2d_add_nn_relu"
2022-05-13 01:52:41.429 INFO Task #0 has finished. Remaining task(s): 26
2022-05-13 01:52:41.429 INFO Scheduler picks Task #3: "fused_nn_conv2d_add_nn_relu_3"
2022-05-13 01:52:41.429 INFO Task #3 has finished. Remaining task(s): 25
2022-05-13 01:52:41.429 INFO Scheduler picks Task #2: "fused_nn_conv2d_add_nn_relu_2"
2022-05-13 01:52:41.429 INFO Task #2 has finished. Remaining task(s): 24
2022-05-13 01:52:41.429 INFO Scheduler picks Task #4: "fused_nn_conv2d_add_nn_relu_4"
2022-05-13 01:52:41.429 INFO Task #4 has finished. Remaining task(s): 23
2022-05-13 01:52:41.429 INFO Scheduler picks Task #22: "fused_nn_conv2d_add_nn_relu_16"
2022-05-13 01:52:41.429 INFO Task #22 has finished. Remaining task(s): 22
2022-05-13 01:52:41.429 INFO Scheduler picks Task #8: "fused_nn_conv2d_add_nn_relu_7"
2022-05-13 01:52:41.430 INFO Task #8 has finished. Remaining task(s): 21
2022-05-13 01:52:41.430 INFO Scheduler picks Task #17: "fused_nn_conv2d_add_nn_relu_12"
2022-05-13 01:52:41.430 INFO Task #17 has finished. Remaining task(s): 20
2022-05-13 01:52:41.430 INFO Scheduler picks Task #21: "fused_nn_conv2d_add_nn_relu_15"
2022-05-13 01:52:41.430 INFO Task #21 has finished. Remaining task(s): 19
2022-05-13 01:52:41.430 INFO Scheduler picks Task #13: "fused_nn_conv2d_add_nn_relu_10"
2022-05-13 01:52:41.430 INFO Task #13 has finished. Remaining task(s): 18
2022-05-13 01:52:41.430 INFO Scheduler picks Task #18: "fused_nn_conv2d_add_nn_relu_13"
2022-05-13 01:52:41.430 INFO Task #18 has finished. Remaining task(s): 17
2022-05-13 01:52:41.430 INFO Scheduler picks Task #7: "fused_nn_conv2d_add_nn_relu_6"
2022-05-13 01:52:41.430 INFO Task #7 has finished. Remaining task(s): 16
2022-05-13 01:52:41.430 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_9"
2022-05-13 01:52:41.430 INFO Task #12 has finished. Remaining task(s): 15
2022-05-13 01:52:41.430 INFO Scheduler picks Task #20: "fused_nn_conv2d_add_nn_relu_14"
2022-05-13 01:52:41.430 INFO Task #20 has finished. Remaining task(s): 14
2022-05-13 01:52:41.430 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_8"
2022-05-13 01:52:41.430 INFO Task #11 has finished. Remaining task(s): 13
2022-05-13 01:52:41.430 INFO Scheduler picks Task #9: "fused_concatenate"
2022-05-13 01:53:19.612 INFO Sending 0 sample(s) to builder
2022-05-13 01:53:19.613 INFO Sending 0 sample(s) to runner
2022-05-13 01:53:19.614 INFO [Updated] Task #9: "fused_concatenate"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |            
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |            
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     31 |            
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |            
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 684
Total latency (us): 457.121

2022-05-13 01:53:19.614 INFO Scheduler picks Task #16: "fused_nn_conv2d_add_nn_relu_11"
2022-05-13 01:53:19.614 INFO Task #16 has finished. Remaining task(s): 12
2022-05-13 01:53:19.614 INFO Scheduler picks Task #6: "fused_nn_conv2d_add_nn_relu_5"
2022-05-13 01:53:19.614 INFO Task #6 has finished. Remaining task(s): 11
2022-05-13 01:53:19.614 INFO Scheduler picks Task #14: "fused_concatenate_1"
2022-05-13 01:53:47.826 INFO Sending 0 sample(s) to builder
2022-05-13 01:53:47.827 INFO Sending 0 sample(s) to runner
2022-05-13 01:53:47.828 INFO [Updated] Task #14: "fused_concatenate_1"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     31 |            
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |            
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 684
Total latency (us): 457.121

2022-05-13 01:53:47.828 INFO Scheduler picks Task #5: "fused_nn_max_pool2d"
2022-05-13 01:54:07.390 INFO Sending 0 sample(s) to builder
2022-05-13 01:54:07.392 INFO Sending 0 sample(s) to runner
2022-05-13 01:54:07.393 INFO [Updated] Task #5: "fused_nn_max_pool2d"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     31 |            
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |            
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 684
Total latency (us): 457.121

2022-05-13 01:54:07.393 INFO Scheduler picks Task #23: "fused_concatenate_3"
2022-05-13 01:54:35.644 INFO Sending 0 sample(s) to builder
2022-05-13 01:54:35.645 INFO Sending 0 sample(s) to runner
2022-05-13 01:54:35.646 INFO [Updated] Task #23: "fused_concatenate_3"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     31 |            
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |            
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 684
Total latency (us): 457.121

2022-05-13 01:54:35.646 INFO Scheduler picks Task #19: "fused_concatenate_2"
2022-05-13 01:55:04.097 INFO Sending 0 sample(s) to builder
2022-05-13 01:55:04.098 INFO Sending 0 sample(s) to runner
2022-05-13 01:55:04.099 INFO [Updated] Task #19: "fused_concatenate_2"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     31 |            
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |            
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 684
Total latency (us): 457.121

2022-05-13 01:55:04.099 INFO Scheduler picks Task #9: "fused_concatenate"
2022-05-13 01:55:42.133 INFO Sending 0 sample(s) to builder
2022-05-13 01:55:42.134 INFO Sending 0 sample(s) to runner
2022-05-13 01:55:42.135 INFO [Updated] Task #9: "fused_concatenate"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     31 |            
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |            
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 684
Total latency (us): 457.121

2022-05-13 01:55:42.135 INFO Scheduler picks Task #10: "fused_nn_max_pool2d_1"
2022-05-13 01:56:01.482 INFO Sending 0 sample(s) to builder
2022-05-13 01:56:01.483 INFO Sending 0 sample(s) to runner
2022-05-13 01:56:01.484 INFO [Updated] Task #10: "fused_nn_max_pool2d_1"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     31 |            
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |            
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 684
Total latency (us): 457.121

2022-05-13 01:56:01.484 INFO Scheduler picks Task #14: "fused_concatenate_1"
2022-05-13 01:56:29.766 INFO Sending 0 sample(s) to builder
2022-05-13 01:56:29.767 INFO Sending 0 sample(s) to runner
2022-05-13 01:56:29.768 INFO [Updated] Task #14: "fused_concatenate_1"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     31 |            
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |            
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 684
Total latency (us): 457.121

2022-05-13 01:56:29.768 INFO Scheduler picks Task #5: "fused_nn_max_pool2d"
2022-05-13 01:56:49.187 INFO Sending 0 sample(s) to builder
2022-05-13 01:56:49.188 INFO Sending 0 sample(s) to runner
2022-05-13 01:56:49.189 INFO [Updated] Task #5: "fused_nn_max_pool2d"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     31 |            
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |            
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 684
Total latency (us): 457.121

2022-05-13 01:56:49.189 INFO Scheduler picks Task #9: "fused_concatenate"
2022-05-13 01:57:27.348 INFO Sending 0 sample(s) to builder
2022-05-13 01:57:27.349 INFO Sending 0 sample(s) to runner
2022-05-13 01:57:27.350 INFO [Updated] Task #9: "fused_concatenate"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     31 |            
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |            
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 684
Total latency (us): 457.121

2022-05-13 01:57:27.350 INFO Scheduler picks Task #25: "fused_nn_global_avg_pool2d"
2022-05-13 01:57:51.060 INFO Sending 1 sample(s) to builder
2022-05-13 01:57:51.614 INFO Sending 1 sample(s) to runner
2022-05-13 01:57:52.967 INFO [Updated] Task #25: "fused_nn_global_avg_pool2d"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     32 |            
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |            
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 685
Total latency (us): 457.121

2022-05-13 01:57:52.968 INFO Scheduler picks Task #27: "fused_nn_softmax"
2022-05-13 01:57:52.968 INFO Task #27 has finished. Remaining task(s): 10
2022-05-13 01:57:52.968 INFO Scheduler picks Task #15: "fused_nn_max_pool2d_2"
2022-05-13 01:58:12.578 INFO Sending 0 sample(s) to builder
2022-05-13 01:58:12.580 INFO Sending 0 sample(s) to runner
2022-05-13 01:58:12.581 INFO [Updated] Task #15: "fused_nn_max_pool2d_2"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     32 |            
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |          Y 
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 685
Total latency (us): 457.121

2022-05-13 01:58:12.581 INFO Scheduler picks Task #23: "fused_concatenate_3"
2022-05-13 01:58:41.052 INFO Sending 0 sample(s) to builder
2022-05-13 01:58:41.053 INFO Sending 0 sample(s) to runner
2022-05-13 01:58:41.054 INFO [Updated] Task #23: "fused_concatenate_3"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     32 |            
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |          Y 
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 685
Total latency (us): 457.121

2022-05-13 01:58:41.054 INFO Scheduler picks Task #19: "fused_concatenate_2"
2022-05-13 01:59:09.328 INFO Sending 0 sample(s) to builder
2022-05-13 01:59:09.329 INFO Sending 0 sample(s) to runner
2022-05-13 01:59:09.330 INFO [Updated] Task #19: "fused_concatenate_2"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     32 |            
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |          Y 
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 685
Total latency (us): 457.121

2022-05-13 01:59:09.330 INFO Scheduler picks Task #26: "fused_reshape"
2022-05-13 01:59:17.678 INFO Sending 0 sample(s) to builder
2022-05-13 01:59:17.679 INFO Sending 0 sample(s) to runner
2022-05-13 01:59:17.679 INFO [Updated] Task #26: "fused_reshape"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     32 |            
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |          Y 
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 685
Total latency (us): 457.121

2022-05-13 01:59:17.680 INFO Scheduler picks Task #28: "fused_reshape_1"
2022-05-13 01:59:26.677 INFO Sending 0 sample(s) to builder
2022-05-13 01:59:26.677 INFO Sending 0 sample(s) to runner
2022-05-13 01:59:26.678 INFO [Updated] Task #28: "fused_reshape_1"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     32 |            
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |          Y 
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 685
Total latency (us): 457.121

2022-05-13 01:59:26.678 INFO Scheduler picks Task #9: "fused_concatenate"
2022-05-13 02:00:04.791 INFO Sending 0 sample(s) to builder
2022-05-13 02:00:04.792 INFO Sending 0 sample(s) to runner
2022-05-13 02:00:04.793 INFO [Updated] Task #9: "fused_concatenate"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     32 |            
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |          Y 
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 685
Total latency (us): 457.121

2022-05-13 02:00:04.793 INFO Scheduler picks Task #14: "fused_concatenate_1"
2022-05-13 02:00:32.947 INFO Sending 0 sample(s) to builder
2022-05-13 02:00:32.948 INFO Sending 0 sample(s) to runner
2022-05-13 02:00:32.949 INFO [Updated] Task #14: "fused_concatenate_1"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     32 |            
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |          Y 
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 685
Total latency (us): 457.121

2022-05-13 02:00:32.949 INFO Scheduler picks Task #5: "fused_nn_max_pool2d"
2022-05-13 02:00:52.497 INFO Sending 0 sample(s) to builder
2022-05-13 02:00:52.498 INFO Sending 0 sample(s) to runner
2022-05-13 02:00:52.499 INFO [Updated] Task #5: "fused_nn_max_pool2d"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |            
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     32 |            
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |          Y 
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 685
Total latency (us): 457.121

2022-05-13 02:00:52.499 INFO Scheduler picks Task #9: "fused_concatenate"
2022-05-13 02:01:30.863 INFO Task #9 has finished. Remaining task(s): 9
2022-05-13 02:01:30.864 INFO Scheduler picks Task #10: "fused_nn_max_pool2d_1"
2022-05-13 02:01:50.200 INFO Sending 0 sample(s) to builder
2022-05-13 02:01:50.201 INFO Sending 0 sample(s) to runner
2022-05-13 02:01:50.202 INFO [Updated] Task #10: "fused_nn_max_pool2d_1"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |          Y 
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     32 |            
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |          Y 
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 685
Total latency (us): 457.121

2022-05-13 02:01:50.202 INFO Scheduler picks Task #23: "fused_concatenate_3"
2022-05-13 02:02:18.465 INFO Sending 0 sample(s) to builder
2022-05-13 02:02:18.466 INFO Sending 0 sample(s) to runner
2022-05-13 02:02:18.467 INFO [Updated] Task #23: "fused_concatenate_3"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |          Y 
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     32 |            
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |          Y 
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 685
Total latency (us): 457.121

2022-05-13 02:02:18.467 INFO Scheduler picks Task #19: "fused_concatenate_2"
2022-05-13 02:02:46.735 INFO Sending 0 sample(s) to builder
2022-05-13 02:02:46.736 INFO Sending 0 sample(s) to runner
2022-05-13 02:02:46.737 INFO [Updated] Task #19: "fused_concatenate_2"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |          Y 
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     32 |            
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |          Y 
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 685
Total latency (us): 457.121

2022-05-13 02:02:46.737 INFO Scheduler picks Task #14: "fused_concatenate_1"
2022-05-13 02:03:14.965 INFO Sending 0 sample(s) to builder
2022-05-13 02:03:14.966 INFO Sending 0 sample(s) to runner
2022-05-13 02:03:14.966 INFO [Updated] Task #14: "fused_concatenate_1"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |          Y 
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     32 |            
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |          Y 
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 685
Total latency (us): 457.121

2022-05-13 02:03:14.967 INFO Scheduler picks Task #5: "fused_nn_max_pool2d"
2022-05-13 02:03:34.656 INFO Sending 0 sample(s) to builder
2022-05-13 02:03:34.657 INFO Sending 0 sample(s) to runner
2022-05-13 02:03:34.658 INFO [Updated] Task #5: "fused_nn_max_pool2d"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |            
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |          Y 
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |            
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     32 |            
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |          Y 
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 685
Total latency (us): 457.121

2022-05-13 02:03:34.658 INFO Scheduler picks Task #25: "fused_nn_global_avg_pool2d"
2022-05-13 02:03:34.658 INFO Task #25 has finished. Remaining task(s): 8
2022-05-13 02:03:34.658 INFO Scheduler picks Task #14: "fused_concatenate_1"
2022-05-13 02:04:02.971 INFO Task #14 has finished. Remaining task(s): 7
2022-05-13 02:04:02.972 INFO Scheduler picks Task #5: "fused_nn_max_pool2d"
2022-05-13 02:04:22.588 INFO Task #5 has finished. Remaining task(s): 6
2022-05-13 02:04:22.589 INFO Scheduler picks Task #15: "fused_nn_max_pool2d_2"
2022-05-13 02:04:42.208 INFO Sending 0 sample(s) to builder
2022-05-13 02:04:42.210 INFO Sending 0 sample(s) to runner
2022-05-13 02:04:42.211 INFO [Updated] Task #15: "fused_nn_max_pool2d_2"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |          Y 
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |          Y 
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |          Y 
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     32 |          Y 
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |          Y 
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 685
Total latency (us): 457.121

2022-05-13 02:04:42.211 INFO Scheduler picks Task #23: "fused_concatenate_3"
2022-05-13 02:05:10.376 INFO Sending 0 sample(s) to builder
2022-05-13 02:05:10.377 INFO Sending 0 sample(s) to runner
2022-05-13 02:05:10.378 INFO [Updated] Task #23: "fused_concatenate_3"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |          Y 
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |          Y 
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |          Y 
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     32 |          Y 
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |          Y 
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 685
Total latency (us): 457.121

2022-05-13 02:05:10.378 INFO Scheduler picks Task #19: "fused_concatenate_2"
2022-05-13 02:05:38.427 INFO Sending 0 sample(s) to builder
2022-05-13 02:05:38.428 INFO Sending 0 sample(s) to runner
2022-05-13 02:05:38.429 INFO [Updated] Task #19: "fused_concatenate_2"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |          Y 
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |          Y 
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |          Y 
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     32 |          Y 
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |          Y 
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 685
Total latency (us): 457.121

2022-05-13 02:05:38.429 INFO Scheduler picks Task #10: "fused_nn_max_pool2d_1"
2022-05-13 02:05:57.749 INFO Sending 0 sample(s) to builder
2022-05-13 02:05:57.750 INFO Sending 0 sample(s) to runner
2022-05-13 02:05:57.751 INFO [Updated] Task #10: "fused_nn_max_pool2d_1"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |          Y 
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |          Y 
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |          Y 
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     32 |          Y 
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |          Y 
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 685
Total latency (us): 457.121

2022-05-13 02:05:57.751 INFO Scheduler picks Task #26: "fused_reshape"
2022-05-13 02:06:06.051 INFO Sending 0 sample(s) to builder
2022-05-13 02:06:06.052 INFO Sending 0 sample(s) to runner
2022-05-13 02:06:06.052 INFO [Updated] Task #26: "fused_reshape"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |          Y 
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |          Y 
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |          Y 
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     32 |          Y 
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |          Y 
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 685
Total latency (us): 457.121

2022-05-13 02:06:06.053 INFO Scheduler picks Task #28: "fused_reshape_1"
2022-05-13 02:06:14.883 INFO Sending 0 sample(s) to builder
2022-05-13 02:06:14.883 INFO Sending 0 sample(s) to runner
2022-05-13 02:06:14.884 INFO [Updated] Task #28: "fused_reshape_1"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |          Y 
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |          Y 
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |          Y 
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |            
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |            
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     32 |          Y 
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |          Y 
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 685
Total latency (us): 457.121

2022-05-13 02:06:14.884 INFO Scheduler picks Task #23: "fused_concatenate_3"
2022-05-13 02:06:43.224 INFO Task #23 has finished. Remaining task(s): 5
2022-05-13 02:06:43.225 INFO Scheduler picks Task #19: "fused_concatenate_2"
2022-05-13 02:07:11.486 INFO Task #19 has finished. Remaining task(s): 4
2022-05-13 02:07:11.486 INFO Scheduler picks Task #10: "fused_nn_max_pool2d_1"
2022-05-13 02:07:30.597 INFO Sending 0 sample(s) to builder
2022-05-13 02:07:30.598 INFO Sending 0 sample(s) to runner
2022-05-13 02:07:30.599 INFO [Updated] Task #10: "fused_nn_max_pool2d_1"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |          Y 
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |          Y 
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |          Y 
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |          Y 
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |          Y 
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     32 |          Y 
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |          Y 
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 685
Total latency (us): 457.121

2022-05-13 02:07:30.599 INFO Scheduler picks Task #15: "fused_nn_max_pool2d_2"
2022-05-13 02:07:50.014 INFO Sending 0 sample(s) to builder
2022-05-13 02:07:50.015 INFO Sending 0 sample(s) to runner
2022-05-13 02:07:50.016 INFO [Updated] Task #15: "fused_nn_max_pool2d_2"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |          Y 
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |          Y 
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |          Y 
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |          Y 
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |          Y 
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     32 |          Y 
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |          Y 
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 685
Total latency (us): 457.121

2022-05-13 02:07:50.016 INFO Scheduler picks Task #26: "fused_reshape"
2022-05-13 02:07:58.475 INFO Sending 0 sample(s) to builder
2022-05-13 02:07:58.476 INFO Sending 0 sample(s) to runner
2022-05-13 02:07:58.477 INFO [Updated] Task #26: "fused_reshape"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |          Y 
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |          Y 
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |          Y 
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |          Y 
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |          Y 
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     32 |          Y 
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |          Y 
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 685
Total latency (us): 457.121

2022-05-13 02:07:58.477 INFO Scheduler picks Task #28: "fused_reshape_1"
2022-05-13 02:08:07.467 INFO Sending 0 sample(s) to builder
2022-05-13 02:08:07.468 INFO Sending 0 sample(s) to runner
2022-05-13 02:08:07.469 INFO [Updated] Task #28: "fused_reshape_1"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |          Y 
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |          Y 
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |            
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |          Y 
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |          Y 
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |          Y 
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     32 |          Y 
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |          Y 
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 685
Total latency (us): 457.121

2022-05-13 02:08:07.469 INFO Scheduler picks Task #10: "fused_nn_max_pool2d_1"
2022-05-13 02:08:26.952 INFO Task #10 has finished. Remaining task(s): 3
2022-05-13 02:08:26.953 INFO Scheduler picks Task #15: "fused_nn_max_pool2d_2"
2022-05-13 02:08:46.442 INFO Sending 0 sample(s) to builder
2022-05-13 02:08:46.444 INFO Sending 0 sample(s) to runner
2022-05-13 02:08:46.445 INFO [Updated] Task #15: "fused_nn_max_pool2d_2"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |          Y 
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |          Y 
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |          Y 
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |          Y 
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |          Y 
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |          Y 
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     32 |          Y 
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |          Y 
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 685
Total latency (us): 457.121

2022-05-13 02:08:46.445 INFO Scheduler picks Task #26: "fused_reshape"
2022-05-13 02:08:54.797 INFO Sending 0 sample(s) to builder
2022-05-13 02:08:54.798 INFO Sending 0 sample(s) to runner
2022-05-13 02:08:54.798 INFO [Updated] Task #26: "fused_reshape"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |          Y 
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |          Y 
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |          Y 
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |          Y 
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |          Y 
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |          Y 
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     32 |          Y 
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |          Y 
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 685
Total latency (us): 457.121

2022-05-13 02:08:54.799 INFO Scheduler picks Task #28: "fused_reshape_1"
2022-05-13 02:09:03.646 INFO Sending 0 sample(s) to builder
2022-05-13 02:09:03.647 INFO Sending 0 sample(s) to runner
2022-05-13 02:09:03.648 INFO [Updated] Task #28: "fused_reshape_1"
 ID |                           Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
----------------------------------------------------------------------------------------------------------------------------------------
  0 |    fused_nn_conv2d_add_nn_relu |  49926656 |      2 |      2023.2775 |      24.6761 |               49.3523 |     32 |          Y 
  1 |  fused_nn_conv2d_add_nn_relu_1 |  28099968 |      2 |      1085.6820 |      25.8823 |               51.7646 |     32 |          Y 
  2 |  fused_nn_conv2d_add_nn_relu_2 |  53934336 |      2 |      3287.0364 |      16.4082 |               32.8164 |     32 |          Y 
  3 |  fused_nn_conv2d_add_nn_relu_3 |  56144000 |      2 |      2701.9332 |      20.7792 |               41.5584 |     32 |          Y 
  4 |  fused_nn_conv2d_add_nn_relu_4 |  44158464 |      1 |      1693.5979 |      26.0738 |               26.0738 |     32 |          Y 
  5 |            fused_nn_max_pool2d |   1742400 |      1 |       313.0403 |       5.5661 |                5.5661 |      5 |          Y 
  6 |  fused_nn_conv2d_add_nn_relu_5 |   6292000 |      1 |       867.9417 |       7.2493 |                7.2493 |     32 |          Y 
  7 |  fused_nn_conv2d_add_nn_relu_6 |  12487200 |      1 |      1117.2251 |      11.1770 |               11.1770 |     32 |          Y 
  8 |  fused_nn_conv2d_add_nn_relu_7 |   6582400 |      2 |       914.0231 |       7.2016 |               14.4031 |     32 |          Y 
  9 |              fused_concatenate |         1 |      2 |         0.0002 |       4.0866 |                8.1733 |      5 |          Y 
 10 |          fused_nn_max_pool2d_1 |    839808 |      1 |       257.4343 |       3.2622 |                3.2622 |      5 |          Y 
 11 |  fused_nn_conv2d_add_nn_relu_8 |   6018624 |      1 |       727.9110 |       8.2684 |                8.2684 |     32 |          Y 
 12 |  fused_nn_conv2d_add_nn_relu_9 |  11990592 |      1 |      1112.7081 |      10.7760 |               10.7760 |     32 |          Y 
 13 | fused_nn_conv2d_add_nn_relu_10 |   6158592 |      2 |       976.6041 |       6.3061 |               12.6123 |     32 |          Y 
 14 |            fused_concatenate_1 |         1 |      2 |         0.0003 |       2.9372 |                5.8744 |      5 |          Y 
 15 |          fused_nn_max_pool2d_2 |    389376 |      1 |       174.9771 |       2.2253 |                2.2253 |      5 |            
 16 | fused_nn_conv2d_add_nn_relu_11 |   4169568 |      1 |       539.3874 |       7.7302 |                7.7302 |     32 |          Y 
 17 | fused_nn_conv2d_add_nn_relu_12 |   6246240 |      1 |       439.1109 |      14.2247 |               14.2247 |     32 |          Y 
 18 | fused_nn_conv2d_add_nn_relu_13 |   3179904 |      2 |       517.2439 |       6.1478 |               12.2956 |     32 |          Y 
 19 |            fused_concatenate_2 |         1 |      2 |         0.0005 |       2.2164 |                4.4329 |      5 |          Y 
 20 | fused_nn_conv2d_add_nn_relu_14 |   8328320 |      1 |       773.8824 |      10.7617 |               10.7617 |     32 |          Y 
 21 | fused_nn_conv2d_add_nn_relu_15 |  11097216 |      1 |       836.8568 |      13.2606 |               13.2606 |     32 |          Y 
 22 | fused_nn_conv2d_add_nn_relu_16 |   5624320 |      2 |       755.5675 |       7.4438 |               14.8877 |     32 |          Y 
 23 |            fused_concatenate_3 |         1 |      2 |         0.0005 |       2.2192 |                4.4383 |      5 |          Y 
 24 | fused_nn_conv2d_add_nn_relu_17 | 173394000 |      1 |      2322.3499 |      74.6632 |               74.6632 |     32 |          Y 
 25 |     fused_nn_global_avg_pool2d |    170000 |      1 |        66.9886 |       2.5377 |                2.5377 |     32 |          Y 
 26 |                  fused_reshape |         1 |      1 |         0.0005 |       2.1739 |                2.1739 |      5 |            
 27 |               fused_nn_softmax |      4000 |      1 |         1.6712 |       2.3934 |                2.3934 |     32 |          Y 
 28 |                fused_reshape_1 |         1 |      1 |         0.0005 |       2.1684 |                2.1684 |      5 |            
----------------------------------------------------------------------------------------------------------------------------------------
Total trials: 685
Total latency (us): 457.121

2022-05-13 02:09:03.648 INFO Scheduler picks Task #15: "fused_nn_max_pool2d_2"
2022-05-13 02:09:23.153 INFO Task #15 has finished. Remaining task(s): 2
2022-05-13 02:09:23.154 INFO Scheduler picks Task #26: "fused_reshape"
2022-05-13 02:09:31.671 INFO Task #26 has finished. Remaining task(s): 1
2022-05-13 02:09:31.672 INFO Scheduler picks Task #28: "fused_reshape_1"
2022-05-13 02:09:40.724 INFO Task #28 has finished. Remaining task(s): 0
2022-05-13 02:09:40.822 INFO Saved XGBModel to /tmp/tmpr0c2dcs7/cost_model.xgb
The result is correct!
